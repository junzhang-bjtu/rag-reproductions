# Quantum Theory for Mathematicians

**Author(s):** Brian C. Hall

# Context

Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5© Springer Science+Business Media New York 2013

Volume 267

Graduate Texts in Mathematics

Series EditorsSheldon Axler and Kenneth Ribet

Advisory EditorsColin Adams, Alejandro Adem, Ruth Charney, Irene M. Gamba, Roger E. Howe, David Jerison, Jeffrey C. Lagarias, Jill Pipher, Fadil Santosa and Amie Wilkinson

For further volumes: http://​www.​springer.​com/​series/​136

Graduate Texts in Mathematics bridge the gap between passive study and creative understanding, offering graduate-level introductions to advanced topics in mathematics. The volumes are carefully written as teaching aids and highlight characteristic features of the theory. Although these books are frequently used as textbooks in graduate courses, they are also suitable for individual study.

Brian C. Hall

Quantum Theory for Mathematicians

Brian C. Hall

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

ISSN 0072-5285e-ISSN 2197-5612

ISBN 978-1-4614-7115-8e-ISBN 978-1-4614-7116-5

Springer New York Heidelberg Dordrecht London

Library of Congress Control Number: 2013937175

© Springer Science+Business Media New York 2013

This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part of the material is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microfilms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. Exempted from this legal reservation are brief excerpts in connection with reviews or scholarly analysis or material supplied specifically for the purpose of being entered and executed on a computer system, for exclusive use by the purchaser of the work. Duplication of this publication or parts thereof is permitted only under the provisions of the Copyright Law of the Publisher's location, in its current version, and permission for use must always be obtained from Springer. Permissions for use may be obtained through RightsLink at the Copyright Clearance Center. Violations are liable to prosecution under the respective Copyright Law.

The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a specific statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use.

While the advice and information in this book are believed to be true and accurate at the date of publication, neither the authors nor the editors nor the publisher can accept any legal responsibility for any errors or omissions that may be made. The publisher makes no warranty, express or implied, with respect to the material contained herein.

Printed on acid-free paper

Springer is part of Springer Science+Business Media (www.springer.com)

For as the heavens are higher than the earth, so are my ways higher than your ways, and my thoughts than your thoughts, says the Lord.

Isaiah 55:9

Preface

Ideas from quantum physics play important roles in many parts of modern mathematics. Many parts of representation theory, for example, are motivated by quantum mechanics, including the Wigner–Mackey theory of induced representations, the Kirillov–Kostant orbit method, and, of course, quantum groups. The Jones polynomial in knot theory, the Gromov–Witten invariants in topology, and mirror symmetry in algebraic topology are other notable examples. The awarding of the 1990 Fields Medal to Ed Witten, a physicist, gives an idea of the scope of the influence of quantum theory in mathematics.

Despite the importance of quantum mechanics to mathematics, there is no easy way for mathematicians to learn the subject. Quantum mechanics books in the physics literature are generally not easily understood by most mathematicians. There is, of course, a lower level of mathematical precision in such books than mathematicians are accustomed to. In addition, physics books on quantum mechanics assume knowledge of classical mechanics that mathematicians often do not have. And, finally, there is a subtle difference in "culture"—differences in terminology and notation—that can make reading the physics literature like reading a foreign language for the mathematician. There are few books that attempt to translate quantum theory into terms that mathematicians can understand.

This book is intended as an introduction to quantum mechanics for mathematicians with little prior exposure to physics. The twin goals of the book are (1) to explain the physical ideas of quantum mechanics in language mathematicians will be comfortable with, and (2) to develop the necessary mathematical tools to treat those ideas in a rigorous fashion. I have attempted to give a reasonably comprehensive treatment of nonrelativistic quantum mechanics, including topics found in typical physics texts (e.g., the harmonic oscillator, the hydrogen atom, and the WKB approximation) as well as more mathematical topics (e.g., quantization schemes, the Stone–von Neumann theorem, and geometric quantization). I have also attempted to minimize the mathematical prerequisites. I do not assume, for example, any prior knowledge of spectral theory or unbounded operators, but provide a full treatment of those topics in Chaps. 6 through 10 of the text. Similarly, I do not assume familiarity with the theory of Lie groups and Lie algebras, but provide a detailed account of those topics in Chap.​ 16 . Whenever possible, I provide full proofs of the stated results.

Most of the text will be accessible to graduate students in mathematics who have had a first course in real analysis, covering the basics of L 2 spaces and Hilbert spaces. Appendix A reviews some of the results that are used in the main body of the text. In Chaps.​ 21 and  , however, I assume knowledge of the theory of manifolds. I have attempted to provide motivation for many of the definitions and proofs in the text, with the result that there is a fair amount of discussion interspersed with the standard definition-theorem-proof style of mathematical exposition. There are exercises at the end of each chapter, making the book suitable for graduate courses as well as for independent study.

In comparison to the present work, classics such as Reed and Simon 34] and Glimm and Jaffe [14], along with the recent book of Schmüdgen [35], are more focused on the mathematical underpinnings of the theory than on the physical ideas. Hannabuss's text [22] is fairly accessible to mathematicians, but—despite the word "graduate" in the title of the series—uses an undergraduate level of mathematics. The recent book of Takhtajan [39], meanwhile, has an expository bent to it, but provides less physical motivation and is less self-contained than the present book. Whereas, for example, Takhtajan begins with Lagrangian and Hamiltonian mechanics on manifolds, I begin with "low-tech" classical mechanics on the real line. Similarly, Takhtajan assumes knowledge of unbounded operators and Lie groups, while I provide substantial expositions of both of those subjects. Finally, there is the work of Folland [13], which I highly recommend, but which deals with quantum field theory, whereas the present book treats only nonrelativistic quantum mechanics, except for a very brief discussion of quantum field theory in [Sect.​ 20.​6

The book begins with a quick introduction to the main ideas of classical and quantum mechanics. After a brief account in Chap.​ 1 of the historical origins of quantum theory, I turn in Chap.​ 2 to a discussion of the necessary background from classical mechanics. This includes Newton's equation in varying degrees of generality, along with a discussion of important physical quantities such as energy, momentum, and angular momentum, and conditions under which these quantities are "conserved" (i.e., constant along each solution of Newton's equation). I give a short treatment here of Poisson brackets and Hamilton's form of Newton's equation, deferring a full discussion of "fancy" classical mechanics to Chap.​ 21 .

In Chap.​ 3 , I attempt to motivate the structures of quantum mechanics in the simplest setting. Although I discuss the "axioms" (in standard physics terminology) of quantum mechanics, I resolutely avoid a strictly axiomatic approach to the subject (using, say, C ∗ -algebras). Rather, I try to provide some motivation for the position and momentum operators and the Hilbert space approach to quantum theory, as they connect to the probabilistic aspect of the theory. I do not attempt to explain the strange probabilistic nature of quantum theory, if, indeed, there is any explanation of it. Rather, I try to elucidate how the wave function, along with the position and momentum operators, encodes the relevant probabilities.

In Chaps.​ 4 and  , we look into two illustrative cases of the Schrödinger equation in one space dimension: a free particle and a particle in a square well. In these chapters, we encounter such important concepts as the distinction between phase velocity and group velocity and the distinction between a discrete and a continuous spectrum.

In Chaps.​ 6 through  , we look into some of the technical mathematical issues that are swept under the carpet in earlier chapters. I have tried to design this section of the book in such a way that a reader can take in as much or as little of the mathematical details as desired. For a reader who simply wants the big picture, I outline the main ideas and results of spectral theory in Chap.​ 6 , including a discussion of the prototypical example of an operator with a continuous spectrum: the momentum operator. For a reader who wants more information, I provide statements of the spectral theorem (in two different forms) for bounded self-adjoint operators in Chap.​ 7 , and an introduction to the notion of unbounded self-adjoint operators in Chap.​ 9 . Finally, for the reader who wants all the details, I give proofs of the spectral theorem for bounded and unbounded self-adjoint operators, in Chaps.​ 8 and  , respectively.

In Chaps.​ 11 through  , we turn to the vitally important canonical commutation relations. These are used in Chap.​ 11 to derive algebraically the spectrum of the quantum harmonic oscillator. In Chap.​ 12 , we discuss the uncertainty principle, both in its general form (for arbitrary pairs of noncommuting operators) and in its specific form (for the position and momentum operators). We pay careful attention to subtle domain issues that are usually glossed over in the physics literature. In Chap.​ 13 , we look at different "quantization schemes" (i.e., different ways of ordering products of the noncommuting position and momentum operators). In Chap.​ 14 , we turn to the celebrated Stone–von Neumann theorem, which provides a uniqueness result for representations of the canonical commutation relations. As in the case of the uncertainty principle, there are some subtle domain issues here that require attention.

In Chaps.​ 15 through  , we examine some less elementary issues in quantum theory. Chapter 15 addresses the WKB (Wentzel–Kramers–Brillouin) approximation, which gives simple but approximate formulas for the eigenvectors and eigenvalues for the Hamiltonian operator in one dimension. After this, we introduce ( Chap.​ 16 ) the notion of Lie groups, Lie algebras, and their representations, all of which play an important role in many parts of quantum mechanics. In Chap.​ 17 , we consider the example of angular momentum and spin, which can be understood in terms of the representations of the rotation group SO (3). Here a more mathematical approach—especially the relationship between Lie group representations and Lie algebra representations—can substantially clarify a topic that is rather mysterious in the physics literature. In particular, the concept of "fractional spin" can be understood as describing a representation of the Lie algebra of the rotation group for which there is no associated representation of the rotation group itself. In Chap.​ 18 , we illustrate these ideas by describing the energy levels of the hydrogen atom, including a discussion of the hidden symmetries of hydrogen, which account for the "accidental degeneracy" in the levels. In Chap.​ 19 , we look more closely at the concept of the "state" of a system in quantum mechanics. We look at the notion of subsystems of a quantum system in terms of tensor products of Hilbert spaces, and we see in this setting that the notion of "pure state" (a unit vector in the relevant Hilbert space) is not adequate. We are led, then, to the notion of a mixed state (or density matrix). We also examine the idea that, in quantum mechanics, "identical particles are indistinguishable."

Finally, in Chaps.​ 21 through  , we examine some advanced topics in classical and quantum mechanics. We begin, in Chap.​ 20 , by considering the path integral formulation of quantum mechanics, both from the heuristic perspective of the Feynman path integral, and from the rigorous perspective of the Feynman–Kac formula. Then, in Chap.​ 21 , we give a brief treatment of Hamiltonian mechanics on manifolds. Finally, we consider the machinery of geometric quantization, beginning with the Euclidean case in Chap.​ 22 and continuing with the general case in Chap.​ 23 .

I am grateful to all who have offered suggestions or made corrections to the manuscript, including Renato Bettiol, Edward Burkard, Matt Cecil, Tiancong Chen, Bo Jacoby, Will Kirwin, Nicole Kroeger, Wicharn Lewkeeratiyutkul, Jeff Mitchell, Eleanor Pettus, Ambar Sengupta, and Augusto Stoffel. I am particularly grateful to Michel Talagrand who read almost the entire manuscript and made numerous corrections and suggestions. Finally, I offer a special word of thanks to my advisor and friend, Leonard Gross, who started me on the path toward understanding the mathematical foundations of quantum mechanics. Readers are encouraged to send me comments or corrections at bhall@nd.edu.

Brian C. Hall

Notre Dame, IN, USA

Contents

1 The Experimental Origins of Quantum Mechanics 1

1.​1 Is Light a Wave or a Particle?​ 1

1.​2 Is an Electron a Wave or a Particle?​ 7

1.​3 Schrödinger and Heisenberg 13

1.​4 A Matter of Interpretation 14

1.​5 Exercises 16

2 A First Approach to Classical Mechanics 19

 2.1 Motion in    19

 2.2 Motion in    23

2.​3 Systems of Particles 26

2.​4 Angular Momentum 31

2.​5 Poisson Brackets and Hamiltonian Mechanics 33

2.​6 The Kepler Problem and the Runge–Lenz Vector 41

2.​7 Exercises 46

3 A First Approach to Quantum Mechanics 53

3.​1 Waves, Particles, and Probabilities 53

3.​2 A Few Words About Operators and Their Adjoints 55

3.​3 Position and the Position Operator 58

3.​4 Momentum and the Momentum Operator 59

3.​5 The Position and Momentum Operators 62

3.​6 Axioms of Quantum Mechanics:​ Operators and Measurements 64

3.​7 Time-Evolution in Quantum Theory 70

3.​8 The Heisenberg Picture 78

3.​9 Example:​ A Particle in a Box 80

 3.10 Quantum Mechanics for a Particle in    82

3.​11 Systems of Multiple Particles 84

3.​12 Physics Notation 85

3.​13 Exercises 88

4 The Free Schrödinger Equation 91

4.​1 Solution by Means of the Fourier Transform 92

4.​2 Solution as a Convolution 94

4.​3 Propagation of the Wave Packet:​ First Approach 97

4.​4 Propagation of the Wave Packet:​ Second Approach 100

4.​5 Spread of the Wave Packet 104

4.​6 Exercises 106

5 A Particle in a Square Well 109

5.​1 The Time-Independent Schrödinger Equation 109

5.​2 Domain Questions and the Matching Conditions 111

5.​3 Finding Square-Integrable Solutions 112

5.​4 Tunneling and the Classically Forbidden Region 118

5.​5 Discrete and Continuous Spectrum 119

5.​6 Exercises 120

6 Perspectives on the Spectral Theorem 123

6.​1 The Difficulties with the Infinite-Dimensional Case 123

6.​2 The Goals of Spectral Theory 125

6.​3 A Guide to Reading 126

6.​4 The Position Operator 126

6.​5 Multiplication Operators 127

6.​6 The Momentum Operator 127

7 The Spectral Theorem for Bounded Self-Adjoint Operators:​ Statements 131

7.​1 Elementary Properties of Bounded Operators 131

7.​2 Spectral Theorem for Bounded Self-Adjoint Operators, I 137

7.​3 Spectral Theorem for Bounded Self-Adjoint Operators, II 144

7.​4 Exercises 150

8 The Spectral Theorem for Bounded Self-Adjoint Operators:​ Proofs 153

8.​1 Proof of the Spectral Theorem, First Version 153

8.​2 Proof of the Spectral Theorem, Second Version 162

8.​3 Exercises 166

9 Unbounded Self-Adjoint Operators 169

9.​1 Introduction 169

9.​2 Adjoint and Closure of an Unbounded Operator 170

9.​3 Elementary Properties of Adjoints and Closed Operators 173

9.​4 The Spectrum of an Unbounded Operator 177

9.​5 Conditions for Self-Adjointness and Essential Self-Adjointness 179

9.​6 A Counterexample 182

9.​7 An Example 184

9.​8 The Basic Operators of Quantum Mechanics 185

9.​9 Sums of Self-Adjoint Operators 190

9.​10 Another Counterexample 193

9.​11 Exercises 196

10 The Spectral Theorem for Unbounded Self-Adjoint Operators 201

10.​1 Statements of the Spectral Theorem 202

10.​2 Stone's Theorem and One-Parameter Unitary Groups 207

10.​3 The Spectral Theorem for Bounded Normal Operators 213

10.​4 Proof of the Spectral Theorem for Unbounded Self-Adjoint Operators 220

10.​5 Exercises 224

11 The Harmonic Oscillator 227

11.​1 The Role of the Harmonic Oscillator 227

11.​2 The Algebraic Approach 228

11.​3 The Analytic Approach 232

11.​4 Domain Conditions and Completeness 233

11.​5 Exercises 236

12 The Uncertainty Principle 239

12.​1 Uncertainty Principle, First Version 241

12.​2 A Counterexample 245

12.​3 Uncertainty Principle, Second Version 246

12.​4 Minimum Uncertainty States 249

12.​5 Exercises 251

13 Quantization Schemes for Euclidean Space 255

13.​1 Ordering Ambiguities 255

13.​2 Some Common Quantization Schemes 256

 13.3 The Weyl Quantization for    261

13.​4 The "No Go" Theorem of Groenewold 271

13.​5 Exercises 275

14 The Stone–von Neumann Theorem 279

14.​1 A Heuristic Argument 279

14.​2 The Exponentiated Commutation Relations 281

14.​3 The Theorem 286

14.​4 The Segal–Bargmann Space 292

14.​5 Exercises 301

15 The WKB Approximation 305

15.​1 Introduction 305

15.​2 The Old Quantum Theory and the Bohr–Sommerfeld Condition 306

15.​3 Classical and Semiclassical Approximations 308

15.​4 The WKB Approximation Away from the Turning Points 311

15.​5 The Airy Function and the Connection Formulas 315

15.​6 A Rigorous Error Estimate 320

15.​7 Other Approaches 328

15.​8 Exercises 329

16 Lie Groups, Lie Algebras, and Representations 333

16.​1 Summary 334

16.​2 Matrix Lie Groups 335

16.​3 Lie Algebras 338

16.​4 The Matrix Exponential 339

16.​5 The Lie Algebra of a Matrix Lie Group 342

16.​6 Relationships Between Lie Groups and Lie Algebras 344

16.​7 Finite-Dimensional Representations of Lie Groups and Lie Algebras 350

16.​8 New Representations from Old 358

16.​9 Infinite-Dimensional Unitary Representations 360

16.​10 Exercises 363

17 Angular Momentum and Spin 367

17.​1 The Role of Angular Momentum in Quantum Mechanics 367

 17.2 The Angular Momentum Operators in    368

17.​3 Angular Momentum from the Lie Algebra Point of View 369

17.​4 The Irreducible Representations of so (3) 370

17.​5 The Irreducible Representations of SO (3) 375

 17.6 Realizing the Representations Inside L 2 ( S 2 )  376

 17.7 Realizing the Representations Inside    380

17.​8 Spin 383

17.​9 Tensor Products of Representations:​ "Addition of Angular Momentum" 384

17.​10 Vectors and Vector Operators 387

17.​11 Exercises 390

18 Radial Potentials and the Hydrogen Atom 393

18.​1 Radial Potentials 393

18.​2 The Hydrogen Atom:​ Preliminaries 396

18.​3 The Bound States of the Hydrogen Atom 397

18.​4 The Runge–Lenz Vector in the Quantum Kepler Problem 401

18.​5 The Role of Spin 409

18.​6 Runge–Lenz Calculations 410

18.​7 Exercises 416

19 Systems and Subsystems, Multiple Particles 419

19.​1 Introduction 419

19.​2 Trace-Class and Hilbert–Schmidt Operators 421

19.​3 Density Matrices:​ The General Notion of the State of a Quantum System 422

19.​4 Modified Axioms for Quantum Mechanics 427

19.​5 Composite Systems and the Tensor Product 429

19.​6 Multiple Particles:​ Bosons and Fermions 433

19.​7 "Statistics" and the Pauli Exclusion Principle 435

19.​8 Exercises 438

20 The Path Integral Formulation of Quantum Mechanics 441

20.​1 Trotter Product Formula 442

20.​2 Formal Derivation of the Feynman Path Integral 444

20.​3 The Imaginary-Time Calculation 447

20.​4 The Wiener Measure 448

20.​5 The Feynman–Kac Formula 449

20.​6 Path Integrals in Quantum Field Theory 451

20.​7 Exercises 453

21 Hamiltonian Mechanics on Manifolds 455

21.​1 Calculus on Manifolds 455

21.​2 Mechanics on Symplectic Manifolds 459

21.​3 Exercises 465

22 Geometric Quantization on Euclidean Space 467

22.​1 Introduction 467

22.​2 Prequantization 468

22.​3 Problems with Prequantization 472

22.​4 Quantization 474

22.​5 Quantization of Observables 478

22.​6 Exercises 482

23 Geometric Quantization on Manifolds 483

23.​1 Introduction 483

23.​2 Line Bundles and Connections 485

23.​3 Prequantization 490

23.​4 Polarizations 492

23.​5 Quantization Without Half-Forms 495

23.​6 Quantization with Half-Forms:​ The Real Case 505

23.​7 Quantization with Half-Forms:​ The Complex Case 518

23.​8 Pairing Maps 521

23.​9 Exercises 523

A Review of Basic Material527

A.1 Tensor Products of Vector Spaces527

A.2 Measure Theory529

A.3 Elementary Functional Analysis530

A.4 Hilbert Spaces and Operators on Them537

References545

Index549
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_1

© Springer Science+Business Media New York 2013

# 1. The Experimental Origins of Quantum Mechanics

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

Quantum mechanics, with its controversial probabilistic nature and curious blending of waves and particles, is a very strange theory. It was not invented because anyone thought this is the way the world should behave, but because various experiments showed that this is the way the world does behave, like it or not. Craig Hogan, director of the Fermilab Particle Astrophysics Center, put it this way:

Quantum mechanics, with its controversial probabilistic nature and curious blending of waves and particles, is a very strange theory. It was not invented because anyone thought this is the way the world should behave, but because various experiments showed that this is the way the world does behave, like it or not. Craig Hogan, director of the Fermilab Particle Astrophysics Center, put it this way:

> No theorist in his right mind would have invented quantum mechanics unless forced to by data.1

Although the first hint of quantum mechanics came in 1900 with Planck's solution to the problem of blackbody radiation, the full theory did not emerge until 1925–1926, with Heisenberg's matrix model, Schrödinger's wave model, and Born's statistical interpretation of the wave model.

## 1.1 Is Light a Wave or a Particle?

### 1.1.1 Newton Versus Huygens

Beginning in the late seventeenth century and continuing into the early eighteenth century, there was a vigorous debate in the scientific community over the nature of light. One camp, following the views of Isaac Newton, claimed that light consisted of a group of particles or "corpuscles." The other camp, led by the Dutch physicist Christiaan Huygens, claimed that light was a wave. Newton argued that only a corpuscular theory could account for the observed tendency of light to travel in straight lines. Huygens and others, on the other hand, argued that a wave theory could explain numerous observed aspects of light, including the bending or "refraction" of light as it passes from one medium to another, as from air into water. Newton's reputation was such that his "corpuscular" theory remained the dominant one until the early nineteenth century.

### 1.1.2 The Ascendance of the Wave Theory of Light

In 1804, Thomas Young published two papers describing and explaining his double-slit experiment. In this experiment, sunlight passes through a small hole in a piece of cardboard and strikes another piece of cardboard containing two small holes. The light then strikes a third piece of cardboard, where the pattern of light may be observed. Young observed "fringes" or alternating regions of high and low intensity for the light. Young believed that light was a wave and he postulated that these fringes were the result of interference between the waves emanating from the two holes. Young drew an analogy between light and water, where in the case of water, interference is readily observed. If two circular waves of water cross each other, there will be some points where a peak of one wave matches up with a trough of another wave, resulting in destructive interference, that is, a partial cancellation between the two waves, resulting in a small amplitude of the combined wave at that point. At other points, on the other hand, a peak in one wave will line up with a peak in the other, or a trough with a trough. At such points, there is constructive interference, with the result that the amplitude of the combined wave is large at that point. The pattern of constructive and destructive interference will produce something like a checkerboard pattern of alternating regions of large and small amplitudes in the combined wave. The dimensions of each region will be roughly on the order of the wavelength of the individual waves.

Based on this analogy with water waves, Young was able to explain the interference fringes that he observed and to predict the wavelength that light must have in order for the specific patterns he observed to occur. Based on his observations, Young claimed that the wavelength of visible light ranged from about 1/36,000 in. (about 700 nm) at the red end of the spectrum to about 1/60,000 in. (about 425 nm) at the violet end of the spectrum, results that agree with modern measurements.

Figure 1.1 shows how circular waves emitted from two different points form an interference pattern. One should think of Young's second piece of cardboard as being at the top of the figure, with holes near the top left and top right of the figure. Figure 1.2 then plots the intensity (i.e., the square of the displacement) as a function of x, with y having the value corresponding to the bottom of Fig. 1.1.

Figure 1.1

Interference of waves emitted from two slits.

Figure 1.2

Intensity plot for a horizontal line across the bottom of Fig. 1.1.

Despite the convincing nature of Young's experiment, many proponents of the corpuscular theory of light remained unconvinced. In 1818, the French Academy of Sciences set up a competition for papers explaining the observed properties of light. One of the submissions was a paper by Augustin-Jean Fresnel in which he elaborated on Huygens's wave model of refraction. A supporter of the corpuscular theory of light, Siméon-Denis Poisson read Fresnel's submission and ridiculed it by pointing out that if that theory were true, light passing by an opaque disk would diffract around the edges of the disk to produce a bright spot in the center of the shadow of the disk, a prediction that Poisson considered absurd. Nevertheless, the head of the judging committee for the competition, François Arago, decided to put the issue to an experimental test and found that such a spot does in fact occur. Although this spot is often called "Arago's spot," or even, ironically, "Poisson's spot," Arago eventually realized that the spot had been observed 100 years earlier in separate experiments by Delisle and Maraldi.

Arago's observation of Poisson's spot led to widespread acceptance of the wave theory of light. This theory gained even greater acceptance in 1865, when James Clerk Maxwell put together what are today known as Maxwell's equations. Maxwell showed that his equations predicted that electromagnetic waves would propagate at a certain speed, which agreed with the observed speed of light. Maxwell thus concluded that light is simply an electromagnetic wave. From 1865 until the end of the nineteenth century, the debate over the wave-versus-particle nature of light was considered to have been conclusively settled in favor of the wave theory.

### 1.1.3 Blackbody Radiation

In the early twentieth century, the wave theory of light began to experience new challenges. The first challenge came from the theory of blackbody radiation. In physics, a blackbody is an idealized object that perfectly absorbs all electromagnetic radiation that hits it. A blackbody can be approximated in the real world by an object with a highly absorbent surface such as "lamp black." The problem of blackbody radiation concerns the distribution of electromagnetic radiation in a cavity within a blackbody. Although the walls of the blackbody absorb the radiation that hits it, thermal vibrations of the atoms making up the walls cause the blackbody to emit electromagnetic radiation. (At normal temperatures, most of the radiation emitted would be in the infrared range.)

In the cavity, then, electromagnetic radiation is constantly absorbed and re-emitted until thermal equilibrium is reached, at which point the absorption and emission of radiation are perfectly balanced at each frequency. According to the "equipartition theorem" of (classical) statistical mechanics, the energy in any given mode of electromagnetic radiation should be exponentially distributed, with an average value equal to k B T, where T is the temperature and k B is Boltzmann's constant. (The temperature should be measured on a scale where absolute zero corresponds to T = 0. ) The difficulty with this prediction is that the average amount of energy is the same for every mode (hence the term "equipartition"). Thus, once one adds up over all modes—of which there are infinitely many—the predicted amount of energy in the cavity is infinite. This strange prediction is referred to as the ultraviolet catastrophe, since the infinitude of the energy comes from the ultraviolet (high-frequency) end of the spectrum. This ultraviolet catastrophe does not seem to make physical sense and certainly does not match up with the observed energy spectrum within real-world blackbodies.

An alternative prediction of the blackbody energy spectrum was offered by Max Planck in a paper published in 1900. Planck postulated that the energy in the electromagnetic field at a given frequency ω should be "quantized," meaning that this energy should come only in integer multiples of a certain basic unit equal to ![
$$\\hslash \\omega,$$
](A272900_1_En_1_Chapter_IEq1.gif) where ![
$$\\hslash $$
](A272900_1_En_1_Chapter_IEq2.gif) is a constant, which we now call Planck's constant. Planck postulated that the energy would again be exponentially distributed, but only over integer multiples of ![
$$\\hslash \\omega.$$
](A272900_1_En_1_Chapter_IEq3.gif) At low frequencies, Planck's theory predicts essentially the same energy as in classical statistical mechanics. At high frequencies, namely at frequencies where ![
$$\\hslash \\omega$$
](A272900_1_En_1_Chapter_IEq4.gif) is large compared to k B T, Planck's theory predicts a rapid fall-off of the average energy (see Exercise 2 for details). Indeed, if we measure mass, distance, and time in units of grams, centimeters, and seconds, respectively, and we assign ![
$$\\hslash $$
](A272900_1_En_1_Chapter_IEq5.gif) the numerical value

![
$$\\displaystyle{\\hslash = 1.054 \\times 1{0}^{-27},}$$
](A272900_1_En_1_Chapter_Equa.gif)

then Planck's predictions match the experimentally observed blackbody spectrum.

Planck pictured the walls of the blackbody as being made up of independent oscillators of different frequencies, each of which is restricted to have energies of ![
$$\\hslash \\omega.$$
](A272900_1_En_1_Chapter_IEq6.gif) Although this picture was clearly not intended as a realistic physical explanation of the quantization of electromagnetic energy in blackbodies, it does suggest that Planck thought that energy quantization arose from properties of the walls of the cavity, rather than in intrinsic properties of the electromagnetic radiation. Einstein, on the other hand, in assessing Planck's model, argued that energy quantization was inherent in the radiation itself. In Einstein's picture, then, electromagnetic energy at a given frequency—whether in a blackbody cavity or not—comes in packets or quanta having energy proportional to the frequency. Each quantum of electromagnetic energy constitutes what we now call a photon, which we may think of as a particle of light. Thus, Planck's model of blackbody radiation began a rebirth of the particle theory of light.

It is worth mentioning, in passing, that in 1900, the same year in which Planck's paper on blackbody radiation appeared, Lord Kelvin gave a lecture that drew attention to another difficulty with the classical theory of statistical mechanics. Kelvin described two "clouds" over nineteenth-century physics at the dawn of the twentieth century. The first of these clouds concerned aether—a hypothetical medium through which electromagnetic radiation propagates—and the failure of Michelson and Morley to observe the motion of earth relative to the aether. Under this cloud lurked the theory of special relativity. The second of Kelvin's clouds concerned heat capacities in gases. The equipartition theorem of classical statistical mechanics made predictions for the ratio of heat capacity at constant pressure (c p ) and the heat capacity at constant volume (c v ). These predictions deviated substantially from the experimentally measured ratios. Under the second cloud lurked the theory of quantum mechanics, because the resolution of this discrepancy is similar to Planck's resolution of the blackbody problem. As in the case of blackbody radiation, quantum mechanics gives rise to a correction to the equipartition theorem, thus resulting in different predictions for the ratio of c p to c v , predictions that can be reconciled with the observed ratios.

### 1.1.4 The Photoelectric Effect

The year 1905 was Einstein's annus mirabilis (miraculous year), in which Einstein published four ground-breaking papers, two on the special theory of relativity and one each on Brownian motion and the photoelectric effect. It was for the photoelectric effect that Einstein won the Nobel Prize in physics in 1921. In the photoelectric effect, electromagnetic radiation striking a metal causes electrons to be emitted from the metal. Einstein found that as one increases the intensity of the incident light, the number of emitted electrons increases, but the energy of each electron does not change. This result is difficult to explain from the perspective of the wave theory of light. After all, if light is simply an electromagnetic wave, then increasing the intensity of the light amounts to increasing the strength of the electric and magnetic fields involved. Increasing the strength of the fields, in turn, ought to increase the amount of energy transferred to the electrons.

Einstein's results, on the other hand, are readily explained from a particle theory of light. Suppose light is actually a stream of particles (photons) with the energy of each particle determined by its frequency. Then increasing the intensity of light at a given frequency simply increases the number of photons and does not affect the energy of each photon. If each photon has a certain likelihood of hitting an electron and causing it to escape from the metal, then the energy of the escaping electron will be determined by the frequency of the incident light and not by the intensity of that light. The photoelectric effect, then, provided another compelling reason for believing that light can behave in a particlelike manner.

### 1.1.5 The Double-Slit Experiment, Revisited

Although the work of Planck and Einstein suggests that there is a particlelike aspect to light, there is certainly also a wavelike aspect to light, as shown by Young, Arago, and Maxwell, among others. Thus, somehow, light must in some situations behave like a wave and in some situations like a particle, a phenomenon known as "wave–particle duality." William Lawrence Bragg described the situation thus:

> God runs electromagnetics on Monday, Wednesday, and Friday by the wave theory, and the devil runs them by quantum theory on Tuesday, Thursday, and Saturday.

(Apparently Sunday, being a day of rest, did not need to be accounted for.)

In particular, we have already seen that Young's double-slit experiment in the early nineteenth century was one important piece of evidence in favor of the wave theory of light. If light is really made up of particles, as blackbody radiation and the photoelectric effect suggest, one must give a particle-based explanation of the double-slit experiment. J.J. Thomson suggested in 1907 that the patterns of light seen in the double-slit experiment could be the result of different photons somehow interfering with one another. Thomson thus suggested that if the intensity of light were sufficiently reduced, the photons in the light would become widely separated and the interference pattern might disappear. In 1909, Geoffrey Ingram Taylor set out to test this suggestion and found that even when the intensity of light was drastically reduced (to the point that it took three months for one of the images to form), the interference pattern remained the same.

Since Taylor's results suggest that interference remains even when the photons are widely separated, the photons are not interfering with one another. Rather, as Paul Dirac put it in Chap.​ 1 of [6], "Each photon then interferes only with itself." To state this in a different way, since there is no interference when there is only one slit, Taylor's results suggest that each individual photon passes through both slits. By the early 1960s, it became possible to perform double-slit experiments with electrons instead of photons, yielding even more dramatic confirmations of the strange behavior of matter in the quantum realm. (See Sect. 1.2.4.)

## 1.2 Is an Electron a Wave or a Particle?

In the early part of the twentieth century, the atomic theory of matter became firmly established. (Einstein's 1905 paper on Brownian motion was an important confirmation of the theory and provided the first calculation of atomic masses in everyday units.) Experiments performed in 1909 by Hans Geiger and Ernest Marsden, under the direction of Ernest Rutherford, led Rutherford to put forward in 1911 a picture of atoms in which a small nucleus contains most of the mass of the atom. In Rutherford's model, each atom has a positively charged nucleus with charge nq, where n is a positive integer (the atomic number) and q is the basic unit of charge first observed in Millikan's famous oil-drop experiment. Surrounding the nucleus is a cloud of n electrons, each having negative charge − q. When atoms bind into molecules, some of the electrons of one atom may be shared with another atom to form a bond between the atoms. This picture of atoms and their binding led to the modern theory of chemistry.

Basic to the atomic theory is that electrons are particles; indeed, the number of electrons per atom is supposed to be the atomic number. Nevertheless, it did not take long after the atomic theory of matter was confirmed before wavelike properties of electrons began to be observed. The situation, then, is the reverse of that with light. While light was long thought to be a wave (at least from the publication of Maxwell's equations in 1865 until Planck's work in 1900) and was only later seen to have particlelike behavior, electrons were initially thought to be particles and were only later seen to have wavelike properties. In the end, however, both light and electrons have both wavelike and particlelike properties.

### 1.2.1 The Spectrum of Hydrogen

If electricity is passed through a tube containing hydrogen gas, the gas will emit light. If that light is separated into different frequencies by means of a prism, bands will become apparent, indicating that the light is not a continuous mix of many different frequencies, but rather consists only of a discrete family of frequencies. In view of the photonic theory of light, the energy in each photon is proportional to its frequency. Thus, each observed frequency corresponds to a certain amount of energy being transferred from a hydrogen atom to the electromagnetic field.

Now, a hydrogen atom consists of a single proton surrounded by a single electron. Since the proton is much more massive than the electron, one can picture the proton as being stationary, with the electron orbiting it. The idea, then, is that the current being passed through the gas causes some of the electrons to move to a higher-energy state. Eventually, that electron will return to a lower-energy state, emitting a photon in the process. In this way, by observing the energies (or, equivalently, the frequencies) of the emitted photons, one can work backwards to the change in energy of the electron.

The curious thing about the state of affairs in the preceding paragraph is that the energies of the emitted photons—and hence, also, the energies of the electron—come only in a discrete family of possible values. Based on the observed frequencies, Johannes Rydberg concluded in 1888 that the possible energies of the electron were of the form

![
$$\\displaystyle{ E_{n} = -\\frac{R} {{n}^{2}}. }$$
](A272900_1_En_1_Chapter_Equ1.gif)

(1.1)

Here, R is the "Rydberg constant," given (in "Gaussian units") by

![
$$\\displaystyle{R = \\frac{m_{e}{Q}^{4}} {2{\\hslash }^{2}},}$$
](A272900_1_En_1_Chapter_Equb.gif)

where Q is the charge of the electron and m e is the mass of the electron. (Technically, m e should be replaced by the reduced mass μ of the proton–electron system; that is, ![
$$\\mu = m_{e}m_{p}/\(m_{e} + m_{p}\),$$
](A272900_1_En_1_Chapter_IEq7.gif) where m p is the mass of the proton. However, since the proton mass is much greater than the electron mass, μ is almost the same as m e and we will neglect the difference between the two.) The energies in (1.1) agree with experiment, in that all the observed frequencies in hydrogen are (at least to the precision available at the time of Rydberg) of the form

![
$$\\displaystyle{ \\omega = \\frac{1} {\\hslash }\\left \(E_{n} - E_{m}\\right \), }$$
](A272900_1_En_1_Chapter_Equ2.gif)

(1.2)

for some n > m. It should be noted that Johann Balmer had already observed in 1885 frequencies of the same form, but only in the case m = 2, and that Balmer's work influenced Rydberg.

The frequencies in (1.2) are known as the spectrum of hydrogen. Balmer and Rydberg were merely attempting to find a simple formula that would match the observed frequencies in hydrogen. Neither of them had a theoretical explanation for why only these particular frequencies occur. Such an explanation would have to wait until the beginnings of quantum theory in the twentieth century.

### 1.2.2 The Bohr–de Broglie Model of the Hydrogen Atom

In 1913, Niels Bohr introduced a model of the hydrogen atom that attempted to explain the observed spectrum of hydrogen. Bohr pictured the hydrogen atom as consisting of an electron orbiting a positively charged nucleus, in much the same way that a planet orbits the sun. Classically, the force exerted on the electron by the proton follows the inverse square law of the form

![
$$\\displaystyle{ F = \\frac{{Q}^{2}} {{r}^{2}}, }$$
](A272900_1_En_1_Chapter_Equ3.gif)

(1.3)

where Q is the charge of the electron, in appropriate units.

If the electron is in a circular orbit, its trajectory in the plane of the orbit will take the form

![
$$\\displaystyle{\(x\(t\),y\(t\)\) = \(r\\cos \(\\omega t\),r\\sin \(\\omega t\)\).}$$
](A272900_1_En_1_Chapter_Equc.gif)

If we take the second derivative with respect to time to obtain the acceleration vector a, we obtain

![
$$\\displaystyle{\\mathbf{a}\(t\) = \({-\\omega }^{2}r\\cos \(\\omega t\),{-\\omega }^{2}r\\sin \(\\omega t\)\),}$$
](A272900_1_En_1_Chapter_Equd.gif)

so that the magnitude of the acceleration vector is ω 2 r. Newton's second law, F = ma, then requires that

![
$$\\displaystyle{m{_{e}\\omega }^{2}r = \\frac{{e}^{2}} {{r}^{2}},}$$
](A272900_1_En_1_Chapter_Eque.gif)

so that

![
$$\\displaystyle{\\omega = \\sqrt{ \\frac{{Q}^{2 } } {m_{e}{r}^{3}}}.}$$
](A272900_1_En_1_Chapter_Equf.gif)

From the formula for the frequency, we can calculate that the momentum (mass times velocity) has magnitude

![
$$\\displaystyle{ p = \\sqrt{\\frac{m_{e } {Q}^{2 } } {r}}. }$$
](A272900_1_En_1_Chapter_Equ4.gif)

(1.4)

We can also calculate the angular momentum J, which for a circular orbit is just the momentum times the distance from the nucleus, as

![
$$\\displaystyle{J = \\sqrt{m_{e } {Q}^{2 } r}.}$$
](A272900_1_En_1_Chapter_Equg.gif)

Bohr postulated that the electron obeys classical mechanics, except that its angular momentum is "quantized." Specifically, in Bohr's model, the angular momentum is required to be an integer multiple of ℏ (Planck's constant). Setting J equal to nℏ yields

![
$$\\displaystyle{ r_{n} = \\frac{{n}^{2}{\\hslash }^{2}} {m_{e}{Q}^{2}}. }$$
](A272900_1_En_1_Chapter_Equ5.gif)

(1.5)

If one calculates the energy of an orbit with radius r n , one finds (Exercise 3) that it agrees precisely with the Rydberg energies in (1.1). Bohr further postulated that an electron could move from one allowed state to another, emitting a packet of light in the process with frequency given by (1.2).

Bohr did not explain why the angular momentum of an electron is quantized, nor how it moved from one allowed orbit to another. As such, his theory of atomic behavior was clearly not complete; it belongs to the "old quantum mechanics" that was superseded by the matrix model of Heisenberg and the wave model of Schrödinger. Nevertheless, Bohr's model was an important step in the process of understanding the behavior of atoms, and Bohr was awarded the 1922 Nobel Prize in physics for his work. Some remnant of Bohr's approach survives in modern quantum theory, in the WKB approximation (Chap.​ 15), where the Bohr–Sommerfeld condition gives an approximation to the energy levels of a one-dimensional quantum system.

In 1924, Louis de Broglie reinterpreted Bohr's condition on the angular momentum as a wave condition. The de Broglie hypothesis is that an electron can be described by a wave, where the spatial frequency k of the wave is related to the momentum of the electron by the relation

![
$$\\displaystyle{ p = \\hslash k. }$$
](A272900_1_En_1_Chapter_Equ6.gif)

(1.6)

Here, "frequency" is defined so that the frequency of the function cos(kx) is k. This is "angular" frequency, which differs by a factor of 2π from the cycles-per-unit-distance frequency. Thus, the period associated with a given frequency k is 2π ∕ k.

In de Broglie's approach, we are supposed to imagine a wave superimposed on the classical trajectory of the electron, with the quantization condition now being that the wave should match up with itself when going all the way around the orbit. This condition means that the orbit should consist of an integer number of periods of the wave:

![
$$\\displaystyle{2\\pi r = n\\frac{2\\pi } {k}.}$$
](A272900_1_En_1_Chapter_Equh.gif)

Using (1.6) along with the expression (1.4) for p, we obtain

![
$$\\displaystyle{2\\pi r = n2\\pi \\frac{\\hslash } {p} = 2\\pi n\\hslash \\sqrt{ \\frac{r} {m_{e}{Q}^{2}}}.}$$
](A272900_1_En_1_Chapter_Equi.gif)

Solving this equation for r gives precisely the Bohr radii in (1.5).

Thus, de Broglie's wave hypothesis gives an alternative to Bohr's quantization of angular momentum as an explanation of the allowed energies of hydrogen. Of course, if one accepts de Broglie's wave hypothesis for electrons, one would expect to see wavelike behavior of electrons not just in the hydrogen atom, but in other situations as well, an expectation that would soon be fulfilled. Figure 1.3 shows the first 10 Bohr radii. For the 8th and 10th radii, the Bohr wave is shown superimposed onto the orbit.

Figure 1.3

The Bohr radii for n = 1 to n = 10, with de Broglie waves superimposed for n = 8 and n = 10.

### 1.2.3 Electron Diffraction

In 1925, Clinton Davisson and Lester Germer were studying properties of nickel by bombarding a thin film of nickel with low-energy electrons. As a result of a problem with their equipment, the nickel was accidentally heated to a very high temperature. When the nickel cooled, it formed into large crystalline pieces, rather than the small crystals in the original sample. After this recrystallization, Davisson and Germer observed peaks in the pattern of electrons reflecting off of the nickel sample that had not been present when using the original sample. They were at a loss to explain this pattern until, in 1926, Davisson learned of the de Broglie hypothesis and suspected that they were observing the wavelike behavior of electrons that de Broglie had predicted.

After this realization, Davisson and Germer began to look systematically for wavelike peaks in their experiments. Specifically, they attempted to show that the pattern of angles at which the electrons reflected matched the patterns one sees in x-ray diffraction. After numerous additional measurements, they were able to show a very close correspondence between the pattern of electrons and the patterns seen in x-ray diffraction. Since x-rays were by this time known to be waves of electromagnetic radiation, the Davisson–Germer experiment was a strong confirmation of de Broglie's wave picture of electrons. Davisson and Germer published their results in two papers in 1927, and Davisson shared the 1937 Nobel Prize in physics with George Paget, who had observed electron diffraction shortly after Davisson and Germer.

### 1.2.4 The Double-Slit Experiment with Electrons

Although quantum theory clearly predicts that electrons passing through a double slit will experience interference similar to that observed in light, it was not until Clauss Jönsson's work in 1961 that this prediction was confirmed experimentally. The main difficulty is the much smaller wavelength for electrons of reasonable energy than for visible light. Jönsson's electrons, for example, had a de Broglie wavelength of 5 nm, as compared to a wavelength of roughly 500 nm for visible light (depending on the color).

In results published in 1989, a team led by Akira Tonomura at Hitachi performed a double-slit experiment in which they were able to record the results one electron at a time. (Similar but less definitive experiments were carried out by Pier Giorgio Merli, GianFranco Missiroli and Giulio Pozzi in Bologna in 1974 and published in the American Journal of Physics in 1976.) In the Hitachi experiment, each electron passes through the slits and then strikes a screen, causing a small spot of light to appear. The location of this spot is then recorded for each electron, one at a time. The key point is that each individual electron strikes the screen at a single point. That is to say, individual electrons are not smeared out across the screen in a wavelike pattern, but rather behave like point particles, in that the observed location of the electron is indeed a point. Each electron, however, strikes the screen at a different point, and once a large number of the electrons have struck and their locations have been recorded, an interference pattern emerges.

It is not the variability of the locations of the electrons that is surprising, since this could be accounted for by small variations in the way the electrons are shot toward the slits. Rather, it is the distinctive interference pattern that is surprising, with rapid variations in the pattern of electron strikes over short distances, including regions where almost no electron strikes occur. (Compare Fig. 1.4 to Fig. 1.2.) Note also that in the experiment, the electrons are widely separated, so that there is never more than one electron in the apparatus at any one time. Thus, the electrons cannot interfere with one another; rather, each electron interferes with itself. Figure 1.4 shows results from the Hitachi experiment, with the number of observed electrons increasing from about 150 in the first image to 160,000 in the last image.

Figure 1.4

Four images from the 1989 experiment at Hitachi showing the impact of individual electrons gradually building up to form an interference pattern. Image by Akira Tonomura and Wikimedia Commons user Belsazar. File is licensed under the Creative Commons Attribution-Share Alike 3.0 Unported license.

## 1.3 Schrödinger and Heisenberg

In 1925, Werner Heisenberg proposed a model of quantum mechanics based on treating the position and momentum of the particle as, essentially, matrices of size ∞ × ∞. Actually, Heisenberg himself was not familiar with the theory of matrices, which was not a standard part of the mathematical education of physicists at the time. Nevertheless, he had quantities of the form x jk and p jk (where j and k each vary over all integers), which we can recognize as matrices, as well as expressions such as ![
$$\\sum _{l}x_{jl}p_{lk}$$
](A272900_1_En_1_Chapter_IEq8.gif), which we can recognize as a matrix product. After Heisenberg explained his theory to Max Born, Born recognized the connection of Heisenberg's formulas to matrix theory and made the matrix point of view explicit, in a paper coauthored by Born and his assistant, Pascual Jordan. Born, Heisenberg, and Jordan then all published a paper together elaborating upon their theory. The papers of Heisenberg, of Born and Jordan, and of Born, Heisenberg, and Jordan all appeared in 1925. Heisenberg received the 1932 Nobel Prize in physics (actually awarded in 1933) for his work. Born's exclusion from this prize was controversial, and may have been influenced by Jordan's connections with the Nazi party in Germany. (Heisenberg's own work for the Nazis during World War II was also a source of much controversy after the war.) In any case, Born was awarded the Nobel Prize in physics in 1954 for his work on the statistical interpretation of quantum mechanics (Sect. 1.4).

Meanwhile, in 1926, Erwin Schrödinger published four remarkable papers in which he proposed a wave theory of quantum mechanics, along the lines of the de Broglie hypothesis. In these papers, Schrödinger described how the waves evolve over time and showed that the energy levels of, for example, the hydrogen atom could be understood as eigenvalues of a certain operator. (See Chap.​ 18 for the computation for hydrogen.) Schrödinger also showed that the Heisenberg–Born–Jordan matrix model could be incorporated into the wave theory, thus showing that the matrix theory and the wave theory were equivalent (see Sect.​ 3.​8). This book describes the mathematical structure of quantum mechanics in essentially the form proposed by Schrödinger in 1926. Schrödinger shared the 1933 Nobel Prize in physics with Paul Dirac.

## 1.4 A Matter of Interpretation

Although Schrödinger's 1926 papers gave the correct mathematical description of quantum mechanics (as it is generally accepted today), he did not provide a widely accepted interpretation of the theory. That task fell to Born, who in a 1926 paper proposed that the "wave function" (as the wave appearing in the Schrödinger equation is generally called) should be interpreted statistically, that is, as determining the probabilities for observations of the system. Over time, Born's statistical approach developed into the Copenhagen interpretation of quantum mechanics. Under this interpretation, the wave function ψ of the system is not directly observable. Rather, ψ merely determines the probability of observing a particular result.

In particular, if ψ is properly normalized, then the quantity ![
$${\\left \\vert \\psi \(x\)\\right \\vert }^{2}$$
](A272900_1_En_1_Chapter_IEq9.gif) is the probability distribution for the position of the particle. Even if ψ itself is spread out over a large region in space, any measurement of the position of the particle will show that the particle is located at a single point, just as we see for the electrons in the two-slit experiment in Fig. 1.4. Thus, a measurement of a particle's position does not show the particle "smeared out" over a large region of space, even if the wave function ψ is smeared out over a large region.

Consider, for example, how Born's interpretation of the Schrödinger equation would play out in the context of the Hitachi double-slit experiment depicted in Fig. 1.4. Born would say that each electron has a wave function that evolves in time according to the Schrödinger equation (an equation of wave type). Each particle's wave function, then, will propagate through the slits in a manner similar to that pictured in Fig. 1.1. If there is a screen at the bottom of Fig. 1.1, then the electron will hit the screen at a single point, even though the wave function is very spread out. The wave function does not determine where the particle hits the screen; it merely determines the probabilities for where the particle hits the screen. If a whole sequence of electrons passes through the slits, one after the other, over time a probability distribution will emerge, determined by the square of the magnitude of the wave function, which is shown in Fig. 1.2. Thus, the probability distribution of electrons, as seen from a large number of electrons as in Fig. 1.4, shows wavelike interference patterns, even though each individual electron strikes the screen at a single point.

It is essential to the theory that the wave function ψ(x) itself is not the probability density for the location of the particle. Rather, the probability density is ![
$${\\left \\vert \\psi \(x\)\\right \\vert }^{2}$$
](A272900_1_En_1_Chapter_IEq10.gif). The difference is crucial, because probability densities are intrinsically positive and thus do not exhibit destructive interference. The wave function itself, however, is complex-valued, and the real and imaginary parts of the wave function take on both positive and negative values, which can interfere constructively or destructively. The part of the wave function passing through the first slit, for example, can interfere with the part of the wave function passing through the second slit. Only after this interference has taken place do we take the magnitude squared of the wave function to obtain the probability distribution, which will, therefore, show the sorts of peaks and valleys we see in Fig. 1.2.

Born's introduction of a probabilistic element into the interpretation of quantum mechanics was—and to some extent still is—controversial. Einstein, for example, is often quoted as saying something along the lines of, "God does not play at dice with the universe." Einstein expressed the same sentiment in various ways over the years. His earliest known statement to this effect was in a letter to Born in December 1926, in which he said,

> Quantum mechanics is certainly imposing. But an inner voice tells me that it is not yet the real thing. The theory says a lot, but does not really bring us any closer to the secret of the "old one." I, at any rate, am convinced that He does not throw dice.

Many other physicists and philosophers have questioned the probabilistic interpretation of quantum mechanics, and have sought alternatives, such as "hidden variable" theories. Nevertheless, the Copenhagen interpretation of quantum mechanics, essentially as proposed by Born in 1926, remains the standard one. This book resolutely avoids all controversies surrounding the interpretation of quantum mechanics. Chapter 3, for example, presents the standard statistical interpretation of the theory without question. The book may nevertheless be of use to the more philosophically minded reader, in that one must learn something of quantum mechanics before delving into the (often highly technical) discussions about its interpretation.

## 1.5 Exercises

1.

Beginning with the formula for the sum of a geometric series, use differentiation to obtain the identity

![
$$\\displaystyle{\\sum _{n=0}^{\\infty }n{e}^{-An} = \\frac{{e}^{-A}} {{\(1 - {e}^{-A}\)}^{2}}.}$$
](A272900_1_En_1_Chapter_Equj.gif)

2.

In Planck's model of blackbody radiation, the energy in a given frequency ω of electromagnetic radiation is distributed randomly over all numbers of the form nℏω, where n = 0, 1, 2,.... Specifically, the likelihood of finding energy nℏω is postulated to be

![
$$\\displaystyle\\begin{array}{rcl} p\(E& =& n\\hslash \\omega \) = \\frac{1} {Z}{e}^{-\\beta n\\hslash \\omega }, {}\\\\ Z& =& \\frac{1} {1 - {e}^{-\\beta \\hslash \\omega }} {}\\\\ \\end{array}$$
](A272900_1_En_1_Chapter_Equ7.gif)

where Z is a normalization constant, which is chosen so that the sum over n of the probabilities is 1. Here ![
$$\\beta = 1/\(k_{B}T\),$$
](A272900_1_En_1_Chapter_IEq11.gif) where T is the temperature and k B is Boltzmann's constant. The expected value of the energy, denoted ![
$$\\left \\langle E\\right \\rangle \\!\\!,$$
](A272900_1_En_1_Chapter_IEq12.gif) is defined to be

![
$$\\displaystyle{\\left \\langle E\\right \\rangle = \\frac{1} {Z}\\sum _{n=0}^{\\infty }\(n\\hslash \\omega \){e}^{-\\beta n\\hslash \\omega }.}$$
](A272900_1_En_1_Chapter_Equk.gif)

(a)

Using Exercise 1, show that

![
$$\\displaystyle{\\left \\langle E\\right \\rangle = \\frac{\\hslash \\omega } {{e}^{\\beta \\hslash \\omega } - 1}.}$$
](A272900_1_En_1_Chapter_Equl.gif)

(b)

Show that ![
$$\\left \\langle E\\right \\rangle$$
](A272900_1_En_1_Chapter_IEq13.gif) behaves like ![
$$1/\\beta = k_{B}T$$
](A272900_1_En_1_Chapter_IEq14.gif) for small ω, but that ![
$$\\left \\langle E\\right \\rangle$$
](A272900_1_En_1_Chapter_IEq15.gif) decays exponentially as ω tends to infinity.

Note: In applying the above calculation to blackbody radiation, one must also take into account the number of modes having frequency in a given range, say between ω 0 and ![
$$\\omega _{0} +\\varepsilon.$$
](A272900_1_En_1_Chapter_IEq16.gif) The exact number of such frequencies depends on the shape of the cavity, but according to Weyl's law, this number will be approximately proportional to ![
$$\\varepsilon \\omega _{0}^{2}$$
](A272900_1_En_1_Chapter_IEq17.gif) for large values of ω 0. Thus, the amount of energy per unit of frequency is

![
$$\\displaystyle{ C \\frac{{\\hslash \\omega }^{3}} {{e}^{\\beta \\hslash \\omega } - 1}, }$$
](A272900_1_En_1_Chapter_Equ8.gif)

(1.7)

where C is a constant involving the volume of the cavity and the speed of light. The relation (1.7) is known as Planck's law.

3.

In classical mechanics, the kinetic energy of an electron is m e v 2 ∕ 2, where v is the magnitude of the velocity. Meanwhile, the potential energy associated with the force law (1.3) is ![
$$V \(r\) = -{Q}^{2}/r,$$
](A272900_1_En_1_Chapter_IEq18.gif) since ![
$$dV/dr = F.$$
](A272900_1_En_1_Chapter_IEq19.gif) Show that if the particle is moving in a circular orbit with radius r n given by (1.5), then the total energy (kinetic plus potential) of the particle is E n , as given in (1.1).

References

[6].

P.A.M. Dirac, The Principles of Quantum Mechanics, 4th edn. (Oxford University Press, Oxford, 1982)

Footnotes

1

Quoted in "Is Space Digital?" by Michael Moyer, Scientific American, February 2012, pp. 30–36.
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_2

© Springer Science+Business Media New York 2013

# 2. A First Approach to Classical Mechanics

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

We begin by considering the motion of a single particle in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_2_Chapter_IEq0.gif) which may be thought of as a particle sliding along a wire, or a particle with motion that just happens to lie in a line. We let x(t) denote the particle's position as a function of time. The particle's velocity is then

![
$$\\displaystyle{v\(t\) :=\\dot{ x}\(t\),}$$
](A272900_1_En_2_Chapter_Equ01.gif)

where we use a dot over a symbol to denote the derivative of that quantity with respect to the time t.

## 2.1 Motion in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_2_Chapter_IEq1.gif)

### 2.1.1 Newton's law

We begin by considering the motion of a single particle in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_2_Chapter_IEq2.gif) which may be thought of as a particle sliding along a wire, or a particle with motion that just happens to lie in a line. We let x(t) denote the particle's position as a function of time. The particle's velocity is then

![
$$\\displaystyle{v\(t\) :=\\dot{ x}\(t\),}$$
](A272900_1_En_2_Chapter_Equa.gif)

where we use a dot over a symbol to denote the derivative of that quantity with respect to the time t.

The particle's acceleration is then

![
$$\\displaystyle{a\(t\) =\\dot{ v}\(t\) =\\ddot{ x}\(t\),}$$
](A272900_1_En_2_Chapter_Equb.gif)

where ![
$$\\ddot{x}$$
](A272900_1_En_2_Chapter_IEq3.gif) denotes the second derivative of x with respect to t. We assume that there is a force acting on the particle and we assume at first that the force F is a function of the particle's position only. (Later, we will look at the case of forces that depend also on velocity.)

Under these assumptions, Newton's second law (F = ma) takes the form

![
$$\\displaystyle{ F\(x\(t\)\) = ma = m\\ddot{x}\(t\), }$$
](A272900_1_En_2_Chapter_Equ1.gif)

(2.1)

where m is the mass of the particle, which is assumed to be positive. We will henceforth abbreviate Newton's second law as simply "Newton's law," since we will use the second law much more frequently than the others. Since (2.1) is of second order, the appropriate initial conditions (needed to get a unique solution) are the position and velocity at some initial time t 0. So we look for solutions of (2.1) subject to

![
$$\\displaystyle\\begin{array}{rcl} x\(t_{0}\)& =& x_{0} {}\\\\ \\dot{x}\(t_{0}\)& =& v_{0}. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ2.gif)

Assuming that F is a smooth function, standard results from the elementary theory of differential equations tell us that there exists a unique local solution to (2.1) for each pair of initial conditions. (A local solution is one defined for t in a neighborhood of the initial time t 0.) Since (2.1) is in general a nonlinear equation, one cannot expect that, for a general force function F, the solutions will exist for all t. If, for example, F(x) = x 2, then any solution with positive initial position and positive initial velocity will escape to infinity in finite time. (Apply Exercise 4 with ![
$$V \(x\) = -{x}^{3}/3.$$
](A272900_1_En_2_Chapter_IEq4.gif)) For a proof existence and uniqueness, see Example 8.2 and Theorem 8.13 in [28].

Definition 2.1

A solution x(t) to Newton's law is called a trajectory.

Example 2.2 (Harmonic Oscillator)

If the force is given by Hooke's law, ![
$$F\(x\) = -kx,$$
](A272900_1_En_2_Chapter_IEq5.gif) where k is a positive constant, then Newton's law can be written as ![
$$m\\ddot{x} + kx = 0.$$
](A272900_1_En_2_Chapter_IEq6.gif) The general solution of this equation is

![
$$\\displaystyle{x\(t\) = a\\cos \(\\omega t\) + b\\sin \(\\omega t\),}$$
](A272900_1_En_2_Chapter_Equc.gif)

where ![
$$\\omega := \\sqrt{k/m}$$
](A272900_1_En_2_Chapter_IEq7.gif) is the frequency of oscillation.

The system in Example 2.2 is referred to as a (classical) harmonic oscillator. This system can describe a mass on a spring, where the force is proportional to the distance x that the spring is stretched from its equilibrium position. The minus sign in − kx indicates that the force pulls the oscillator back toward equilibrium. Here and elsewhere in the book, we use the "angular" notion of frequency, which is the rate of change of the argument of a sine or cosine function. If ω is the angular frequency, then the "ordinary" frequency—i.e., the number of cycles per unit of time—is ω ∕ 2π. Saying that x has (angular) frequency ω means that x is periodic with period 2π ∕ ω.

### 2.1.2 Conservation of Energy

We return now to the case of a general force function F(x). We define the kinetic energy of the system to be ![
$$\\frac{1} {2}m{v}^{2}.$$
](A272900_1_En_2_Chapter_IEq8.gif) We also define the potential energy of the system as the function

![
$$\\displaystyle{ V \(x\) = -\\int F\(x\)\\ dx, }$$
](A272900_1_En_2_Chapter_Equ3.gif)

(2.2)

so that ![
$$F\(x\) = -dV/dx.$$
](A272900_1_En_2_Chapter_IEq9.gif) (The potential energy is defined only up to adding a constant.) The total energy E of the system is then

![
$$\\displaystyle{ E\(x,v\) = \\frac{1} {2}m{v}^{2} + V \(x\). }$$
](A272900_1_En_2_Chapter_Equ4.gif)

(2.3)

The chief significance of the energy function is that it is conserved, meaning that its value along any trajectory is constant.

Theorem 2.3

Suppose a particle satisfies Newton's law in the form ![
$$m\\ddot{x} = F\(x\).$$
](A272900_1_En_2_Chapter_IEq10.gif) Let V and E be as in (2.2) and (2.3). Then the energy E is conserved, meaning that for each solution x(t) of Newton's law, ![
$$E\(x\(t\),\\dot{x}\(t\)\)$$
](A272900_1_En_2_Chapter_IEq11.gif) is independent of t.

Proof.

We verify this by differentiation, using the chain rule:

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}E\(x\(t\),\\dot{x}\(t\)\)& =& \\frac{d} {dt}\\left \(\\frac{1} {2}m{\(\\dot{x}\(t\)\)}^{2} + V \(x\(t\)\)\\right\) {}\\\\ & =& m\\dot{x}\(t\)\\ddot{x}\(t\) + \\frac{dV } {dx} \\dot{x}\(t\) {}\\\\ & =& \\dot{x}\(t\)\[m\\ddot{x}\(t\) - F\(x\(t\)\)\]. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ5.gif)

This last expression is zero by Newton's law. Thus, the time-derivative of the energy along any trajectory is zero, so ![
$$E\(x\(t\),\\dot{x}\(t\)\)$$
](A272900_1_En_2_Chapter_IEq12.gif) is independent of t, as claimed.

We may call the energy a conserved quantity (or constant of motion), since the particle neither gains nor loses energy as the particle moves according to Newton's law.

Let us see how conservation of energy helps us understand the solution to Newton's law. We may reduce the second-order equation ![
$$m\\ddot{x} = F\(x\)$$
](A272900_1_En_2_Chapter_IEq13.gif) to a pair of first-order equations, simply by introducing the velocity v as a new variable. That is, we look for pairs of functions (x(t), v(t)) that satisfy the following system of equations

![
$$\\displaystyle\\begin{array}{rcl} \\frac{dx} {dt} & =& v\(t\) \\\\ \\frac{dv} {dt} & =& \\frac{1} {m}F\(x\(t\)\).{}\\end{array}$$
](A272900_1_En_2_Chapter_Equ6.gif)

(2.4)

If (x(t), v(t)) is a solution to this system, then we can immediately see that x(t) satisfies Newton's law, just by substituting dx ∕ dt for v in the second equation. We refer to the set of possible pairs of the form (x, v) (i.e., ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq14.gif)) as the phase space of the particle in ![
$${\\mathbb{R}}^{1}.$$
](A272900_1_En_2_Chapter_IEq15.gif) The appropriate initial conditions for this first-order system are x(0) = x 0 and v(0) = v 0.

Once we are working in phase space, we can use the conservation of energy to help us. Conservation of energy means that each solution to the system (2.4) must lie entirely on a single "level curve" of the energy function, that is, the set

![
$$\\displaystyle{ \\left \\{\\left.\(x,v\) \\in {\\mathbb{R}}^{2}\\right\\vert E\(x,v\) = E\(x_{ 0},v_{0}\)\\right\\}. }$$
](A272900_1_En_2_Chapter_Equ7.gif)

(2.5)

If F—and therefore also V —is smooth, then E is a smooth function of x and v. Then as long as (2.5) contains no critical points of E, this set will be a smooth curve in ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq16.gif) by the implicit function theorem. If the level set (2.5) is also a simple closed curve, then the solutions of (2.5) will simply wind around and around this curve. Thus, the set that the solutions to (2.5) trace out in phase space can be determined simply from the conservation of energy. The only thing not apparent at the moment is how this curve is parameterized as a function of time.

In mechanics, a conserved quantity—such as the energy in the one-dimensional version of Newton's law—is often referred to as an "integral of motion." The reason for this is that although Newton's second law is a second-order equation in x, the energy depends only on x and ![
$$\\dot{x}$$
](A272900_1_En_2_Chapter_IEq17.gif) and not on ![
$$\\ddot{x}.$$
](A272900_1_En_2_Chapter_IEq18.gif) Thus, the equation

![
$$\\displaystyle{\\frac{m} {2} {\(\\dot{x}\(t\)\)}^{2} + V \(x\(t\)\) = E_{ 0},}$$
](A272900_1_En_2_Chapter_Equd.gif)

where E 0 is the value of the energy at time t 0, is actually a first-order differential equation. We can solve for ![
$$\\dot{x}$$
](A272900_1_En_2_Chapter_IEq19.gif) to put this equation into a more standard form:

![
$$\\displaystyle{ \\dot{x}\(t\) = \\pm \\sqrt{\\frac{2\(E_{0 } - V \(x\(t\)\)\)} {m}}. }$$
](A272900_1_En_2_Chapter_Equ8.gif)

(2.6)

What this means is that by using conservation of energy we have turned the original second-order equation into a first-order equation. We have therefore "integrated" the original equation once, that is, changed an equation of the form ![
$$\\ddot{x}\(t\) = \\cdots $$
](A272900_1_En_2_Chapter_IEq20.gif) into an equation of the form ![
$$\\dot{x}\(t\) = \\cdots \\,.$$
](A272900_1_En_2_Chapter_IEq21.gif) The first-order equation (2.6) is separable and can be solved more-or-less explicitly (Exercise 1).

### 2.1.3 Systems with Damping

Up to now, we have considered forces that depend only on position. It is common, however, to consider forces that depend on the velocity as well as the position. In the case of a damped harmonic oscillator, for example, one typically assumes that there is, in addition to the force of the spring, a damping force (friction, say) that is proportional to the velocity. Thus, ![
$$F = -kx -\\gamma \\dot{ x},$$
](A272900_1_En_2_Chapter_IEq22.gif) where k is, as before, the spring constant and where γ > 0 is the damping constant. The minus sign in front of ![
$$\\gamma \\dot{x}$$
](A272900_1_En_2_Chapter_IEq23.gif) reflects that the damping force operates in the opposite direction to the velocity, causing the particle to slow down. The equation of motion for such a system is then

![
$$\\displaystyle{m\\ddot{x} +\\gamma \\dot{ x} + kx = 0.}$$
](A272900_1_En_2_Chapter_Eque.gif)

If γ is small, the solutions to this equation display decaying oscillation, meaning sines and cosines multiplied by a decaying exponential; if γ is large, the solutions are pure decaying exponentials (Exercise 5).

In the case of the damped harmonic oscillator, there is no longer a conserved energy. Specifically, there is no nonconstant continuous function E on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq24.gif) such that ![
$$E\(x\(t\),\\dot{x}\(t\)\)$$
](A272900_1_En_2_Chapter_IEq25.gif) is independent of t for all solutions of Newton's law. To see this, we simply observe that for γ > 0, all solutions x(t) have the property that ![
$$\(x\(t\),\\dot{x}\(t\)\)$$
](A272900_1_En_2_Chapter_IEq26.gif) tends to the origin in the plane as t tends to infinity. Thus, if E is continuous and constant along each trajectory, the value of E at the starting point has to be the same as the value at the origin.

We now consider a general system with damping.

Proposition 2.4

Suppose a particle moves in the presence of a force law given by ![
$$F\(x,\\dot{x}\) = F_{1}\(x\) -\\gamma \\dot{ x},$$
](A272900_1_En_2_Chapter_IEq27.gif) with γ > 0. Define the energy E of the system by

![
$$\\displaystyle{E\(x,\\dot{x}\) = \\frac{1} {2}m\\dot{{x}}^{2} + V \(x\),}$$
](A272900_1_En_2_Chapter_Equf.gif)

where ![
$$dV/dx = -F_{1}\(x\).$$
](A272900_1_En_2_Chapter_IEq28.gif) Then along any trajectory x(t), we have

![
$$\\displaystyle{ \\frac{d} {dt}E\(x\(t\),\\dot{x}\(t\)\) = -\\gamma \\dot{x}{\(t\)}^{2} \\leq 0.}$$
](A272900_1_En_2_Chapter_Equg.gif)

Thus, although the energy is not conserved, it is decreasing with time, which gives us some information about the behavior of the system.

Proof.

We differentiate as in the proof of Theorem 2.3, except that now ![
$$dV/dx = -F_{1}\(x\)$$
](A272900_1_En_2_Chapter_IEq29.gif):

![
$$\\displaystyle{ \\frac{d} {dt}E\(x\(t\),\\dot{x}\(t\)\) =\\dot{ x}\(t\)\[m\\ddot{x}\(t\) - F_{1}\(x\(t\)\)\].}$$
](A272900_1_En_2_Chapter_Equh.gif)

Since F 1 is not the full force function, the quantity in square brackets equals not zero but ![
$$-\\gamma \\dot{x}.$$
](A272900_1_En_2_Chapter_IEq30.gif) Thus, ![
$$dE/dt = -\\gamma \\dot{{x}}^{2}.$$
](A272900_1_En_2_Chapter_IEq31.gif)

We can interpret Proposition 2.4 as saying that in the presence of friction, the system we are studying gives up some of its energy to heat energy in the environment, so that the energy of our system decreases with time. We will see that in higher dimensions, it is possible to have conservation of energy in the presence of velocity-dependent forces, provided that these forces act perpendicularly to the velocity.

## 2.2 Motion in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq3012.gif)

We now consider a particle moving in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_2_Chapter_IEq33.gif) The position x = (x 1,..., x n ) of a particle is now a vector in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq34.gif) as is the velocity v and acceleration a. We let

![
$$\\displaystyle{\\mathbf{\\dot{x}} = \(\\dot{x}_{1},\\ldots,\\dot{x}_{n}\)}$$
](A272900_1_En_2_Chapter_Equi.gif)

denote the derivative of x with respect to t and we let ![
$$\\mathbf{\\ddot{x}}$$
](A272900_1_En_2_Chapter_IEq35.gif) denote the second derivative of x with respect to t. Newton's law now takes the form

![
$$\\displaystyle{ m\\mathbf{\\ddot{x}}\(t\) = \\mathbf{F\(x}\(t\),\\mathbf{\\dot{x}}\(t\)\), }$$
](A272900_1_En_2_Chapter_Equ9.gif)

(2.7)

where ![
$$\\mathbf{F} : {\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n} \\rightarrow {\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq36.gif) is some force law, which in general may depend on both the position and velocity of the particle.

We begin by considering forces that are independent of velocity, and we look for a conserved energy function in this setting.

Proposition 2.5

Consider Newton's law ( 2.7 ) in the case of a velocity-independent force: ![
$$m\\mathbf{\\ddot{x}}\(t\) = \\mathbf{F}\(\\mathbf{x}\(t\)\).$$
](A272900_1_En_2_Chapter_IEq37.gif) Then an energy function of the form

![
$$\\displaystyle{E\(\\mathbf{x},\\mathbf{\\dot{x}}\) = \\frac{1} {2}m{\\left \\vert \\mathbf{\\dot{x}}\\right\\vert }^{2} + V \(\\mathbf{x}\)}$$
](A272900_1_En_2_Chapter_Equj.gif)

is conserved if and only if V satisfies

![
$$\\displaystyle{-\\nabla V = \\mathbf{F},}$$
](A272900_1_En_2_Chapter_Equk.gif)

where ∇V is the gradient of V.

Saying that E is "conserved" means that ![
$$E\(\\mathbf{x}\(t\),\\mathbf{\\dot{x}}\(t\)\)$$
](A272900_1_En_2_Chapter_IEq38.gif) is independent of t for each solution x(t) of Newton's law. The function V is the potential energy of the system.

Proof.

Differentiating gives

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \(\\frac{1} {2}m{\\left \\vert \\mathbf{\\dot{x}}\(t\)\\right\\vert }^{2} + V \(\\mathbf{x}\(t\)\)\\right\)& =& m\\sum _{ j=i}^{n}\\dot{x}_{ j}\(t\)\\ddot{x}_{j}\(t\) +\\sum _{ j=1}^{n} \\frac{\\partial V } {\\partial x_{j}}\\dot{x}_{j}\(t\) {}\\\\ & =& \\mathbf{\\dot{x}}\(t\) \\cdot \\left \[m\\mathbf{\\ddot{x}}\(t\) + \\nabla V \\right\] {}\\\\ & =& \\mathbf{\\dot{x}}\(t\) \\cdot \\left \[\\mathbf{F}\(\\mathbf{x}\) + \\nabla V \(\\mathbf{x}\)\\right\] {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ10.gif)

Thus, dE ∕ dt will always be equal to zero if and only if we have

![
$$\\displaystyle{-\\nabla V \(\\mathbf{x}\) = \\mathbf{F}\(\\mathbf{x}\)}$$
](A272900_1_En_2_Chapter_Equl.gif)

for all x.

We now encounter something that did not occur in the one-dimensional case. In ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_2_Chapter_IEq39.gif) any smooth function can be expressed as the derivative of some other function. In ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq40.gif) however, not every vector-valued function F(x) can be expressed as the (negative of) the gradient of some scalar-valued function V.

Definition 2.6

Suppose F is a smooth, ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq41.gif) -valued function on a domain ![
$$U \\subset {\\mathbb{R}}^{n}.$$
](A272900_1_En_2_Chapter_IEq42.gif) Then F is called conservative if there exists a smooth, real-valued function V on U such that ![
$$\\mathbf{F} = -\\nabla V.$$
](A272900_1_En_2_Chapter_IEq43.gif)

If the domain U is simply connected, then there is a simple local condition that characterizes conservative functions.

Proposition 2.7

Suppose U is a simply connected domain in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq44.gif) and F is a smooth, ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq45.gif) -valued function on U. Then F is conservative if and only if F satisfies

![
$$\\displaystyle{ \\frac{\\partial F_{j}} {\\partial x_{k}} -\\frac{\\partial F_{k}} {\\partial x_{j}} = 0 }$$
](A272900_1_En_2_Chapter_Equ11.gif)

(2.8)

at each point in U.

When n = 3, it is easy to check that the condition (2.8) is equivalent to the curl ∇ × F of F being zero on U. The hypothesis that U be simply connected cannot be omitted; see Exercise 7.

Proof.

If F is conservative, then

![
$$\\displaystyle{\\frac{\\partial F_{j}} {\\partial x_{k}} = - \\frac{{\\partial }^{2}V } {\\partial x_{k}\\partial x_{j}} = - \\frac{{\\partial }^{2}V } {\\partial x_{j}\\partial x_{k}} = \\frac{\\partial F_{k}} {\\partial x_{j}} }$$
](A272900_1_En_2_Chapter_Equm.gif)

at every point in U. In the other direction, if F satisfies (2.8), V can be obtained by integrating F along paths and using the Stokes theorem to establish independence of choice of path. See, for example, Theorem 4.3 on p. 549 of [44] for a proof in the n = 3 case. The proof in higher dimensions is the same, provided one knows the general version of the Stokes theorem.

We may also consider velocity-dependent forces. If, for example, ![
$$\\mathbf{F}\(\\mathbf{x,v}\) = -\\gamma \\mathbf{v} + \\mathbf{F}_{1}\(\\mathbf{x}\),$$
](A272900_1_En_2_Chapter_IEq46.gif) where γ is a positive constant, then we will again have energy that is decreasing with time. There is another new phenomenon, however, in dimension greater than 1, namely the possibility of having a conserved energy even when the force depends on velocity.

Proposition 2.8

Suppose a particle in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq47.gif) moves in the presence of a force F of the form

![
$$\\displaystyle{\\mathbf{F}\(\\mathbf{x},\\mathbf{v}\) = -\\nabla V \(\\mathbf{x}\) + \\mathbf{F}_{2}\(\\mathbf{x},\\mathbf{v}\),}$$
](A272900_1_En_2_Chapter_Equn.gif)

where V is a smooth function and where F 2 satisfies

![
$$\\displaystyle{ \\mathbf{v} \\cdot \\mathbf{F}_{2}\(\\mathbf{x},\\mathbf{v}\) = 0 }$$
](A272900_1_En_2_Chapter_Equ12.gif)

(2.9)

for all x and v in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_2_Chapter_IEq48.gif) Then the energy function ![
$$E\(\\mathbf{x},\\mathbf{v}\) = \\frac{1} {2}m{\\left \\vert \\mathbf{v}\\right\\vert }^{2} + V \(\\mathbf{x}\)$$
](A272900_1_En_2_Chapter_IEq49.gif) is constant along each trajectory.

If, for example, F 2 is the force exerted on a charged particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_2_Chapter_IEq50.gif) by a magnetic field B(x), then

![
$$\\displaystyle{\\mathbf{F}_{2}\(\\mathbf{x},\\mathbf{v}\) = q\\mathbf{v} \\times \\mathbf{B}\(\\mathbf{x}\),}$$
](A272900_1_En_2_Chapter_Equo.gif)

where q is the charge of the particle, which clearly satisfies (2.9).

Proof.

See Exercise 8.

## 2.3 Systems of Particles

If we have a system if N particles, each moving in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq51.gif) then we denote the position of the jth particle by

![
$$\\displaystyle{{\\mathbf{x}}^{j} = \(x_{ 1}^{j},\\ldots,x_{ n}^{j}\).}$$
](A272900_1_En_2_Chapter_Equp.gif)

Thus, in the expression x k j , the superscript j indicates the jth particle, while the subscript k indicates the kth component. Newton's law then takes the form

![
$$\\displaystyle{m_{j}{\\mathbf{\\ddot{x}}}^{j} ={ \\mathbf{F}}^{j}\({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N},{\\mathbf{\\dot{x}}}^{1},\\ldots,{\\mathbf{\\dot{x}}}^{N}\),\\quad j = 1,2,\\ldots,N,}$$
](A272900_1_En_2_Chapter_Equq.gif)

where m j is the mass of the jth particle. Here, F j is the force on the jth particle, which in general will depend on the position and velocity not only of that particle, but also on the position and velocity of the other particles.

### 2.3.1 Conservation of Energy

In a system of particles, we cannot expect that the energy of each individual particle will be conserved, because as the particles interact, they can exchange energy. Rather, we should expect that, under suitable assumptions on the forces F j , we can define a conserved energy function for the whole system (the total energy of the system).

Let us consider forces depending only on the position of the particles, and let us assume that the energy function will be of the form

![
$$\\displaystyle{ E\({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N},{\\mathbf{v}}^{1},\\ldots,{\\mathbf{v}}^{N}\) =\\sum _{ j=1}^{N}\\frac{1} {2}m_{j}{\\left \\vert {\\mathbf{v}}^{j}\\right\\vert }^{2} + V \({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N}\). }$$
](A272900_1_En_2_Chapter_Equ13.gif)

(2.10)

We will now try to see what form for V (if any) will allow E to be constant along each trajectory.

Proposition 2.9

An energy function of the form (2.10) is constant along each trajectory if

![
$$\\displaystyle{ {\\nabla }^{j}V = -{\\mathbf{F}}^{j} }$$
](A272900_1_En_2_Chapter_Equ14.gif)

(2.11)

for each j, where ∇j is the gradient with respect to the variable x j .

Proof.

We compute that

![
$$\\displaystyle\\begin{array}{rcl} \\frac{dE} {dt} & =& \\sum _{j=1}^{N}\\left \[m_{ j}{\\mathbf{\\dot{x}}}^{j} \\cdot {\\mathbf{\\ddot{x}}}^{j} + {\\nabla }^{j}V \\cdot {\\mathbf{\\dot{x}}}^{j}\\right\] {}\\\\ & =& \\sum _{j=1}^{N}{\\mathbf{\\dot{x}}}^{j} \\cdot \\left \[m_{ j}{\\mathbf{\\ddot{x}}}^{j} + {\\nabla }^{j}V \\right\] {}\\\\ & =& \\sum _{j=1}^{N}{\\mathbf{\\dot{x}}}^{j} \\cdot \\left \[{\\mathbf{F}}^{j} + {\\nabla }^{j}V \\right\]. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ15.gif)

If ![
$${\\nabla }^{j}V = -{\\mathbf{F}}^{j},$$
](A272900_1_En_2_Chapter_IEq52.gif) then E will be conserved.

As in the one-particle case, there is a simple condition for the existence of a potential function V satisfying (2.11).

Proposition 2.10

Suppose a force function F = (F 1 ,..., F N) is defined on a simply connected domain U in ![
$${\\mathbb{R}}^{nN}.$$
](A272900_1_En_2_Chapter_IEq53.gif) Then there exists a smooth function V on U satisfying

![
$$\\displaystyle{{\\nabla }^{j}V = -{\\mathbf{F}}^{j}}$$
](A272900_1_En_2_Chapter_Equr.gif)

for all j if and only if we have

![
$$\\displaystyle{ \\frac{\\partial F_{k}^{j}} {\\partial x_{m}^{l}} = \\frac{\\partial F_{m}^{l}} {\\partial x_{k}^{j}} }$$
](A272900_1_En_2_Chapter_Equ16.gif)

(2.12)

for all j, k, l, and m.

Proof.

Apply Proposition 2.7 with n replaced by nN and with j and k replaced by the pairs (j, k) and (l, m).

### 2.3.2 Conservation of Momentum

We now introduce the notion of the momentum of a particle.

Definition 2.11

In an N-particle system, the momentum of the jth particle, denoted p j , is the product of the mass and the velocity of that particle:

![
$$\\displaystyle{{\\mathbf{p}}^{j} = m_{ j}{\\mathbf{\\dot{x}}}^{j}\\mathbf{.}}$$
](A272900_1_En_2_Chapter_Equs.gif)

The total momentum of the system, denoted p, is defined as

![
$$\\displaystyle{\\mathbf{p} =\\sum _{ j=1}^{N}{\\mathbf{p}}^{j}.}$$
](A272900_1_En_2_Chapter_Equt.gif)

Observe that

![
$$\\displaystyle{\\frac{d{\\mathbf{p}}^{j}} {dt} = m_{j}{\\mathbf{\\ddot{x}}}^{j}{\\mathbf{= F}}^{j}.}$$
](A272900_1_En_2_Chapter_Equu.gif)

Thus, Newton's law may be reformulated as saying, "The force is the rate of change of the momentum." This is how Newton originally formulated his second law.

Newton's third law says, "For every action, there is an equal and opposite reaction." This law will apply if all forces are of the "two-particle" variety and satisfy a natural symmetry property. Having two-particle forces means that the force F j on the jth particle is a sum of terms F j, k , j ≠ k, where F j, k depends only x j and x k . The relevant symmetry property is that ![
$${\\mathbf{F}}^{j,k}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\) = -{\\mathbf{F}}^{k,j}\({\\mathbf{x}}^{k},{\\mathbf{x}}^{j}\)$$
](A272900_1_En_2_Chapter_IEq54.gif); that is, the force exerted by the jth particle on the kth particle is the negative (i.e., "equal and opposite") of the force exerted by the kth particle on the jth particle. If the forces are assumed also to be conservative, then the potential energy of the system will be of the form

![
$$\\displaystyle{ V \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\) =\\sum _{ j<k}{V }^{j,k}\({\\mathbf{x}}^{j} -{\\mathbf{x}}^{k}\). }$$
](A272900_1_En_2_Chapter_Equ17.gif)

(2.13)

One important consequence of Newton's third law is conservation of the total momentum of the system.

Proposition 2.12

Suppose that for each j, the force on the jth particle is of the form

![
$$\\displaystyle{{\\mathbf{F}}^{j}\({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\) =\\sum _{ k\\neq j}{\\mathbf{F}}^{j,k}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\),}$$
](A272900_1_En_2_Chapter_Equv.gif)

for certain functions F j,k . Suppose also that we have the "equal and opposite" condition

![
$$\\displaystyle{{\\mathbf{F}}^{j,k}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\) = -{\\mathbf{F}}^{k,j}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\).}$$
](A272900_1_En_2_Chapter_Equw.gif)

Then the total momentum of the system is conserved.

Note that since the rate of change of p j is F j , the force on the jth particle, the momentum of each individual particle is not constant in time, except in the trivial case of a noninteracting system (one in which all forces are zero).

Proof.

Differentiating gives

![
$$\\displaystyle{\\frac{d\\mathbf{p}} {dt} =\\sum _{ j=1}^{N}\\frac{d{\\mathbf{p}}^{j}} {dt} =\\sum _{ j=1}^{N}{\\mathbf{F}}^{j} =\\sum _{ j}\\sum _{k\\neq j}{\\mathbf{F}}^{j,k}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\).}$$
](A272900_1_En_2_Chapter_Equx.gif)

By the equal and opposite condition, ![
$${\\mathbf{F}}^{j,k}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\)$$
](A272900_1_En_2_Chapter_IEq55.gif) cancels with ![
$${\\mathbf{F}}^{k,j}\({\\mathbf{x}}^{j},{\\mathbf{x}}^{k}\),$$
](A272900_1_En_2_Chapter_IEq56.gif) so ![
$$d\\mathbf{p}/dt = 0.$$
](A272900_1_En_2_Chapter_IEq57.gif)

Let us consider, now, a more general situation in which we have conservative forces, but not necessarily of the "two-particle" form. It is still possible to have conservation of momentum, as the following result shows.

Proposition 2.13

If a multiparticle system has a force law coming from a potential V, then the total momentum of the system is conserved if and only if

![
$$\\displaystyle{ V \({\\mathbf{x}}^{1} + \\mathbf{a},{\\mathbf{x}}^{2} + \\mathbf{a},\\ldots,{\\mathbf{x}}^{N} + \\mathbf{a}\) = V \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\) }$$
](A272900_1_En_2_Chapter_Equ18.gif)

(2.14)

for all ![
$$\\mathbf{a} \\in {\\mathbb{R}}^{n}.$$
](A272900_1_En_2_Chapter_IEq58.gif)

Proof.

Apply (2.14) with a = t e k , where e k is the vector with a 1 in the kth spot and zeros elsewhere. Differentiating with respect to t at t = 0 gives

![
$$\\displaystyle{0 =\\sum _{ j=1}^{N} \\frac{\\partial V } {\\partial x_{k}^{j}} = -\\sum _{j=1}^{N}F_{ k}^{j} = -\\sum _{ j=1}^{N}\\frac{dp_{k}^{j}} {dt} = -\\frac{dp_{k}} {dt},}$$
](A272900_1_En_2_Chapter_Equy.gif)

where p k is the kth component of the total momentum p. Thus, if (2.14) holds, p is constant in time.

Conversely, if the momentum is conserved, then the sum of the forces is zero at every point, and so

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{d} {dt}V \({\\mathbf{x}}^{1} + t\\mathbf{a},{\\mathbf{x}}^{2} + t\\mathbf{a},\\ldots,{\\mathbf{x}}^{N} + t\\mathbf{a}\) {}\\\\ & & =\\sum _{ j=1}^{N}{\\nabla }^{j}V \({\\mathbf{x}}^{1} + t\\mathbf{a},{\\mathbf{x}}^{2} + t\\mathbf{a},\\ldots,{\\mathbf{x}}^{N} + t\\mathbf{a}\) \\cdot \\mathbf{a} {}\\\\ & & = -\\left \(\\sum _{j=1}^{N}{\\mathbf{F}}^{j}\({\\mathbf{x}}^{1} + t\\mathbf{a},{\\mathbf{x}}^{2} + t\\mathbf{a},\\ldots,{\\mathbf{x}}^{N} + t\\mathbf{a}\)\\right\) \\cdot \\mathbf{a} {}\\\\ & & = 0 {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ19.gif)

for all t. Thus, the value of the quantity being differentiated is the same at t = 0 as at t = 1, which establishes (2.14).

The moral of the story is that conservation of momentum is a consequence of translation-invariance of the system, where "translation invariance " means invariance under simultaneous translations of every particle by the same amount. (See Exercise 11 for a more general version of this result.) If the potential is of the "two-particle" form (2.13), then it is evident that the condition (2.14) is satisfied.

### 2.3.3 Center of Mass

We now consider an important application of momentum conservation.

Definition 2.14

For a system of N particles moving in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq59.gif) the center of mass of the system at a fixed time is the vector ![
$$\\mathbf{c} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq60.gif) given by

![
$$\\displaystyle{\\mathbf{c} =\\sum _{ j=1}^{N}\\frac{m_{j}} {M}{ \\mathbf{x}}^{j},}$$
](A272900_1_En_2_Chapter_Equz.gif)

where ![
$$M =\\sum _{ j=1}^{N}m_{j}$$
](A272900_1_En_2_Chapter_IEq61.gif) is the total mass of the system.

The center of mass is a weighted average of the positions of the various particles. Differentiating c(t) with respect to t gives

![
$$\\displaystyle{ \\frac{d\\mathbf{c}} {dt} = \\frac{1} {M}\\sum _{j=1}^{N}m_{ j}{\\mathbf{\\dot{x}}}^{j} = \\frac{\\mathbf{p}} {M}, }$$
](A272900_1_En_2_Chapter_Equ20.gif)

(2.15)

where p is the total momentum.

Proposition 2.15

Suppose the total momentum p of a system is conserved. Then the center of mass moves in a straight line at constant speed. Specifically,

![
$$\\displaystyle{\\mathbf{c}\(t\) = \\mathbf{c}\(t_{0}\) + \(t - t_{0}\) \\frac{\\mathbf{p}} {M},}$$
](A272900_1_En_2_Chapter_Equaa.gif)

where c (t 0 ) is the center of mass at some initial time t 0.

Proof.

The result follows easily from (2.15).

The notion of center of mass is particularly useful in a system of two particles in which momentum is conserved. For a system of two particles, if the potential energy V (x 1, x 2) is invariant under simultaneous translations of x 1 and x 2, then it is of the form

![
$$\\displaystyle{V \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\) =\\tilde{ V }\({\\mathbf{x}}^{1} -{\\mathbf{x}}^{2}\),}$$
](A272900_1_En_2_Chapter_Equab.gif)

where ![
$$\\tilde{V }\(\\mathbf{a}\) = V \(\\mathbf{a},0\).$$
](A272900_1_En_2_Chapter_IEq62.gif)

Now, the positions x 1, x 2 of the particles can be recovered from knowledge of the center of mass and the relative position

![
$$\\displaystyle{\\mathbf{y} :={ \\mathbf{x}}^{1} -{\\mathbf{x}}^{2}}$$
](A272900_1_En_2_Chapter_Equac.gif)

as follows:

![
$$\\displaystyle\\begin{array}{rcl}{ \\mathbf{x}}^{1}& =& \\frac{\\mathbf{c} + m_{2}\\mathbf{y}} {m_{1} + m_{2}} {}\\\\ {\\mathbf{x}}^{2}& =& \\frac{\\mathbf{c} - m_{1}\\mathbf{y}} {m_{1} + m_{2}}. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ21.gif)

Meanwhile, we may compute that

![
$$\\displaystyle{\\mathbf{\\ddot{y}}\(t\) ={ \\mathbf{\\ddot{x}}}^{1} -{\\mathbf{\\ddot{x}}}^{2} = - \\frac{1} {m_{1}}\\nabla \\tilde{V }\({\\mathbf{x}}^{1} -{\\mathbf{x}}^{2}\) - \\frac{1} {m_{2}}\\nabla \\tilde{V }\({\\mathbf{x}}^{1} -{\\mathbf{x}}^{2}\).}$$
](A272900_1_En_2_Chapter_Equad.gif)

This calculation gives the following result.

Proposition 2.16

For a two-particle system with potential energy of the form ![
$$V \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\) =\\tilde{ V }\({\\mathbf{x}}^{1} -{\\mathbf{x}}^{2}\),$$
](A272900_1_En_2_Chapter_IEq63.gif) the relative position ![
$$\\mathbf{y} :={ \\mathbf{x}}^{1} -{\\mathbf{x}}^{2}$$
](A272900_1_En_2_Chapter_IEq64.gif) satisfies the differential equation

![
$$\\displaystyle{\\mu \\mathbf{\\ddot{y}} = -\\nabla \\tilde{V }\(\\mathbf{y}\),}$$
](A272900_1_En_2_Chapter_Equae.gif)

where μ is the reduced mass given by

![
$$\\displaystyle{\\mu = \\frac{1} { \\frac{1} {m_{1}} + \\frac{1} {m_{2}} } = \\frac{m_{1}m_{2}} {m_{1} + m_{2}}.}$$
](A272900_1_En_2_Chapter_Equaf.gif)

Thus, when the total momentum of a two-particle system is conserved, the relative position evolves as a one-particle system with "effective" mass μ, while the center of mass moves "trivially," as described in Proposition 2.15.

## 2.4 Angular Momentum

We start by considering angular momentum in the simplest nontrivial case, motion in ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_2_Chapter_IEq65.gif)

Definition 2.17

Consider a particle moving in ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq66.gif) having position x, velocity v, and momentum p = m v. Then the angular momentum of the particle, denoted J, is given by

![
$$\\displaystyle{ J = x_{1}p_{2} - x_{2}p_{1}. }$$
](A272900_1_En_2_Chapter_Equ22.gif)

(2.16)

In more geometric terms, ![
$$J = \\left \\vert \\mathbf{x}\\right\\vert \\left \\vert \\mathbf{p}\\right\\vert \\sin \\phi,$$
](A272900_1_En_2_Chapter_IEq67.gif) where ϕ is the angle (measured counterclockwise) between x and p. We can look at J in yet another way as follows. If θ is the usual angle in polar coordinates on ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq68.gif) then an elementary calculation (Exercise 9) shows that

![
$$\\displaystyle{ J = m{r}^{2} \\frac{d\\theta } {dt}. }$$
](A272900_1_En_2_Chapter_Equ23.gif)

(2.17)

It then follows that

![
$$\\displaystyle{ J = 2m\\frac{dA} {dt}, }$$
](A272900_1_En_2_Chapter_Equ24.gif)

(2.18)

where ![
$$A = \(1/2\)\\int {r}^{2}\\ d\\theta$$
](A272900_1_En_2_Chapter_IEq69.gif) is the area being swept out by the curve x(t). See Fig. 2.1.

Figure 2.1

A(t) is the area of the shaded region.

One significant property of the angular momentum is that it (like the energy) is conserved in certain situations.

Proposition 2.18

Suppose a particle of mass m is moving in ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq70.gif) under the influence of a conservative force with the potential function V (x). If V is invariant under rotations in ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq71.gif) then the angular momentum ![
$$J = x_{1}p_{2} - x_{2}p_{1}$$
](A272900_1_En_2_Chapter_IEq72.gif) is independent of time along any solution of Newton's equation. Conversely, if J is independent of time along every solution of Newton's equation, then V is invariant under rotations.

Proof.

Differentiating (2.16) along a solution of Newton's law gives

![
$$\\displaystyle\\begin{array}{rcl} \\frac{dJ} {dt} & =& \\frac{dx_{1}} {dt} p_{2} + x_{1}\\frac{dp_{2}} {dt} -\\frac{dx_{2}} {dt} p_{1} - x_{2}\\frac{dp_{1}} {dt} {}\\\\ & =& \\frac{1} {m}p_{1}p_{2} - x_{1} \\frac{\\partial V } {\\partial x_{2}} - \\frac{1} {m}p_{2}p_{1} + x_{2} \\frac{\\partial V } {\\partial x_{1}} {}\\\\ & =& x_{2} \\frac{\\partial V } {\\partial x_{1}} - x_{1} \\frac{\\partial V } {\\partial x_{2}}. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ25.gif)

On the other hand, consider rotations R θ in ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq73.gif) given by

![
$$\\displaystyle{R_{\\theta } = \\left \(\\begin{array}{rr} \\cos \\theta &-\\sin \\theta \\\\ \\sin \\theta &\\cos \\theta \\end{array} \\right\).}$$
](A272900_1_En_2_Chapter_Equag.gif)

If we differentiate V along this family of rotations, we obtain

![
$$\\displaystyle{\\left.\\frac{d} {d\\theta }V \\left \(R_{\\theta }\\mathbf{x}\\right\)\\right\\vert _{\\theta =0} = \\frac{\\partial V } {\\partial x} \\frac{dx} {d\\theta } + \\frac{\\partial V } {\\partial y} \\frac{dy} {d\\theta } = -x_{2} \\frac{\\partial V } {\\partial x_{1}} + x_{1} \\frac{\\partial V } {\\partial x_{2}} = -\\frac{dJ} {dt} \(\\mathbf{x}\).}$$
](A272900_1_En_2_Chapter_Equah.gif)

Thus, the angular derivative of V is zero if and only if J is constant.

Conservation of J [together with the relation (2.18)] gives the following result.

Corollary 2.19 (Kepler's Second Law)

Suppose a particle is moving in ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq74.gif) in the presence of a force associated with a rotationally invariant potential. If x (t) is the trajectory of the particle, then the area swept out by x (t) between times t = a and t = b is ![
$$\(b - a\)J/\(2m\),$$
](A272900_1_En_2_Chapter_IEq75.gif) where J is the constant value of the angular momentum along the trajectory. Since the area swept out depends only on b − a, we may say that "equal areas are swept out in equal times."

Kepler, of course, was interested in the motion of planets in ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_2_Chapter_IEq76.gif) not in ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_2_Chapter_IEq77.gif) The motion of a planet moving in the "inverse square" force of a sun will, however, always lie in a plane. (This claim follows from the three-dimensional version of conservation of angular momentum, as explained in Sect. 2.6.1.)

In ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_2_Chapter_IEq78.gif) the angular momentum of the particle is a vector, given by

![
$$\\displaystyle{ \\mathbf{J} = \\mathbf{x} \\times \\mathbf{p}, }$$
](A272900_1_En_2_Chapter_Equ26.gif)

(2.19)

where × denotes the cross product (or vector product). Thus, for example,

![
$$\\displaystyle{ J_{3} = x_{1}p_{2} - x_{2}p_{1}. }$$
](A272900_1_En_2_Chapter_Equ27.gif)

(2.20)

If, then, we have a particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_2_Chapter_IEq79.gif) that just happens to be moving in ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq80.gif) (i.e., x 3 = 0 and p 3 = 0), then the angular momentum will be in the z-direction with z-component given by the quantity J defined in Definition 2.17.

The representation of the angular momentum of a particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_2_Chapter_IEq81.gif) as a vector is a low-dimensional peculiarity. For a particle in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq82.gif) the angular momentum is a skew-symmetric matrix given by

![
$$\\displaystyle{ J_{jk} = x_{j}p_{k} - x_{k}p_{j}. }$$
](A272900_1_En_2_Chapter_Equ28.gif)

(2.21)

In the ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_2_Chapter_IEq83.gif) case, the entries of the 3 × 3 angular momentum matrix are made up by the three components of the angular momentum vector together with their negatives, with zeros along the diagonal. [Compare, e.g., (2.20) and (2.21).]

Definition 2.20

For a system of N particles moving in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq84.gif), the total angular momentum of the system is the skew-symmetric matrix J given by

![
$$\\displaystyle{ J_{jk} =\\sum _{ l=1}^{N}\\left \(x_{ j}^{l}p_{ k}^{l} - x_{ k}^{l}p_{ j}^{l}\\right\). }$$
](A272900_1_En_2_Chapter_Equ29.gif)

(2.22)

Theorem 2.21

Suppose a system of N particles in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq85.gif) is moving under the influence of conservative forces with potential function V. If V satisfies

![
$$\\displaystyle{ V \(R{\\mathbf{x}}^{1},R{\\mathbf{x}}^{2},\\ldots,R{\\mathbf{x}}^{N}\) = V \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\) }$$
](A272900_1_En_2_Chapter_Equ30.gif)

(2.23)

for every rotation matrix R, then the total angular momentum of the system is conserved (constant along each trajectory). Conversely, if the total angular momentum is constant along each trajectory, then V satisfies (2.23).

The proof of this result is similar to that of Proposition 2.18 and is left as an exercise (Exercise 10). We will re-examine the concept of angular momentum in the next section using the language of Poisson brackets and Hamiltonian flows.

## 2.5 Poisson Brackets and Hamiltonian Mechanics

We consider now the Hamiltonian approach to classical mechanics. (There is also the Lagrangian approach, but that approach is not as relevant for our purposes.) The Hamiltonian approach, and in particular the Poisson bracket, will help us to understand the general phenomenon of conserved quantities. The Poisson bracket is also an important source of motivation for the use of commutators in quantum mechanics.

In the Hamiltonian approach to mechanics, we think of the energy function as a function of position and momentum, rather than position and velocity, and we refer to it as the "Hamiltonian." If a particle in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq86.gif) has the usual sort of energy function (kinetic energy plus potential energy), we have

![
$$\\displaystyle{ H\(\\mathbf{x},\\mathbf{p}\) = \\frac{1} {2m}\\sum _{j=1}^{n}p_{ j}^{2} + V \(\\mathbf{x}\). }$$
](A272900_1_En_2_Chapter_Equ31.gif)

(2.24)

Here, as usual, ![
$$p_{j} = m_{j}\\dot{x}_{j}.$$
](A272900_1_En_2_Chapter_IEq87.gif) We now observe that Newton's law can be expressed in the following form:

![
$$\\displaystyle\\begin{array}{rcl} \\frac{dx_{j}} {dt} & =& \\frac{\\partial H} {\\partial p_{j}} \\\\ \\frac{dp_{j}} {dt} & =& -\\frac{\\partial H} {\\partial x_{j}}.{}\\end{array}$$
](A272900_1_En_2_Chapter_Equ32.gif)

(2.25)

After all, with H of the indicated form, these equations read ![
$$dx_{j}/dt = p_{j}/m,$$
](A272900_1_En_2_Chapter_IEq88.gif) which is just the definition of p j , and ![
$$dp_{j}/dt = -\\partial V/\\partial x_{j} = F_{j},$$
](A272900_1_En_2_Chapter_IEq89.gif) which is just Newton's law, in the form originally given by Newton. We refer to Newton's law, in the form (2.25) as Hamilton's equations.

Although it is not obvious at the moment that we have gained anything by writing Newton's law in the form (2.25), let us proceed on a bit further and see. Our next step is to introduce the Poisson bracket.

Definition 2.22

Let f and g be two smooth functions on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_2_Chapter_IEq90.gif) where an element of ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq91.gif) is thought of as a pair (x, p), with ![
$$\\mathbf{x} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq92.gif) representing the position of a particle and ![
$$\\mathbf{p} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq93.gif) representing the momentum of a particle. Then the Poisson bracket of f and g, denoted ![
$$\\left \\{f,g\\right\\},$$
](A272900_1_En_2_Chapter_IEq94.gif) is the function on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq95.gif) given by

![
$$\\displaystyle{\\left \\{f,g\\right\\}\(\\mathbf{x},\\mathbf{p}\) =\\sum _{ j=1}^{n}\\left \( \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial g} {\\partial p_{j}} - \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial g} {\\partial x_{j}}\\right\).}$$
](A272900_1_En_2_Chapter_Equai.gif)

The Poisson bracket has the following properties.

Proposition 2.23

For all smooth functions f, g, and h on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq96.gif) we have the following:

1.

![
$$\\{f,g + ch\\} =\\{ f,g\\} + c\\{f,h\\}$$
](A272900_1_En_2_Chapter_IEq97.gif) for all ![
$$c \\in \\mathbb{R}$$
](A272900_1_En_2_Chapter_IEq98.gif)

2.

![
$$\\{g,f\\} = -\\{f,g\\}$$
](A272900_1_En_2_Chapter_IEq99.gif)

3.

![
$$\\{f,gh\\} =\\{ f,g\\}h + g\\{f,h\\}$$
](A272900_1_En_2_Chapter_IEq100.gif)

4.

![
$$\\{f,\\{g,h\\}\\} =\\{\\{ f,g\\},h\\} +\\{ g,\\{f,h\\}\\}$$
](A272900_1_En_2_Chapter_IEq101.gif)

Properties 1 and 2 of Proposition 2.23 say that the Poisson bracket is bilinear and skew-symmetric. Property 3 says that the operation of "bracket with f" satisfies the derivation property (similar to the product rule for derivatives) with respect to pointwise multiplication of functions, while Property 4 says that "bracket with f" satisfies the derivation property with respect to the Poisson bracket itself. Property 4 is equivalent to the Jacobi identity:

![
$$\\displaystyle{ \\{f,\\{g,h\\}\\} +\\{ h,\\{f,g\\}\\} +\\{ g,\\{h,f\\}\\} = 0, }$$
](A272900_1_En_2_Chapter_Equ33.gif)

(2.26)

as may easily be seen using the skew-symmetry of the Poisson bracket. The Jacobi identity, along with bilinearity and skew-symmetry, means that the space of C ∞ functions on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq102.gif) forms a Lie algebra under the operation of a Poisson bracket. (See Chap.​ 16.)

Proof.

The first two properties of the Poisson bracket are obvious and the third is an easy consequence of the product rule. Let us think about what goes into proving Property 4 by direct computation. (An alternative proof is given in Exercise 15.) We compute that

![
$$\\displaystyle\\begin{array}{rcl} \\{f,\\{g,h\\}\\}& =& \\sum _{j=1}^{n} \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial } {\\partial p_{j}}\\left \( \\frac{\\partial g} {\\partial x_{j}} \\frac{\\partial h} {\\partial p_{j}} - \\frac{\\partial g} {\\partial p_{j}} \\frac{\\partial h} {\\partial x_{j}}\\right\) {}\\\\ & -& \\sum _{j=1}^{n} \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial } {\\partial x_{j}}\\left \( \\frac{\\partial g} {\\partial x_{j}} \\frac{\\partial h} {\\partial p_{j}} - \\frac{\\partial g} {\\partial p_{j}} \\frac{\\partial h} {\\partial x_{j}}\\right\). {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ34.gif)

Just the first term in the expression for {f, {g, h}} generates the following four terms (all summed over j) after we use the product rule:

![
$$\\displaystyle{ \\frac{\\partial f} {\\partial x_{j}} \\frac{{\\partial }^{2}g} {\\partial x_{j}\\partial p_{j}} \\frac{\\partial h} {\\partial p_{j}} + \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial g} {\\partial x_{j}} \\frac{{\\partial }^{2}h} {\\partial p_{j}^{2}} - \\frac{\\partial f} {\\partial x_{j}} \\frac{{\\partial }^{2}g} {\\partial p_{j}^{2}} \\frac{\\partial h} {\\partial x_{j}} - \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial g} {\\partial p_{j}} \\frac{{\\partial }^{2}h} {\\partial x_{j}\\partial p_{j}}. }$$
](A272900_1_En_2_Chapter_Equ35.gif)

(2.27)

We see, then, that the left-hand side of (2.26) will have a total of 24 terms, each summed over j. Each term will have a single derivative on two of the three functions, and two derivatives on the third function. There are three possibilities for which function gets two derivatives. Once that function is chosen, there are four possibilities for which derivatives go on the other two functions, with the function that gets two derivatives getting whatever derivatives remain (for a total of two x-derivatives and two p-derivatives). That makes 12 possible terms. It is a tedious but straightforward exercise to check that each of these 12 possible terms occurs twice in the left-hand side of (2.26), with opposite signs. To check just one case explicitly, in computing {h, {f, g}}, we will get a term like the second term in (2.27), but with (f, g, h) replaced by (h, f, g):

![
$$\\displaystyle{ \\frac{\\partial h} {\\partial x_{j}} \\frac{\\partial f} {\\partial x_{j}} \\frac{{\\partial }^{2}g} {\\partial p_{j}^{2}}.}$$
](A272900_1_En_2_Chapter_Equaj.gif)

This term (in the computation of {h, {f, g}}) cancels with the third term in (2.27) (in the computation of {f, {g, h}}).

The following elementary result will provide a helpful analogy to the "canonical commutation relations" in quantum mechanics.

Proposition 2.24

The position and momentum functions satisfy the following Poisson bracket relations:

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \\{x_{j},x_{k}\\right\\} = 0 {}\\\\ & & \\left \\{p_{j},p_{k}\\right\\} = 0 {}\\\\ & & \\left \\{x_{j},p_{k}\\right\\} =\\delta _{jk}. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ36.gif)

Proof.

Direct calculation.

One of the main reasons for considering the Poisson bracket is the following simple result.

Proposition 2.25

If ( x (t), p (t)) is a solution to Hamilton's equation (2.25) , then for any smooth function f on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq103.gif) we have

![
$$\\displaystyle{ \\frac{d} {dt}f\(\\mathbf{x}\(t\),\\mathbf{p}\(t\)\) = \\left \\{f,H\\right\\}\(\\mathbf{x}\(t\),\\mathbf{p}\(t\)\).}$$
](A272900_1_En_2_Chapter_Equak.gif)

We generally write Proposition 2.25 in a more concise form as

![
$$\\displaystyle{\\frac{df} {dt} = \\left \\{f,H\\right\\},}$$
](A272900_1_En_2_Chapter_Equal.gif)

where the time derivative is understood as being along some trajectory.

Proof.

Using the chain rule and Hamilton's equations, we have

![
$$\\displaystyle\\begin{array}{rcl} \\frac{df} {dt}& =& \\sum _{j=1}^{n}\\left \( \\frac{\\partial f} {\\partial x_{j}} \\frac{dx_{j}} {dt} + \\frac{\\partial f} {\\partial p_{j}} \\frac{dp_{j}} {dt} \\right\) {}\\\\ & =& \\sum _{j=1}^{n}\\left \( \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial H} {\\partial p_{j}} + \\frac{\\partial f} {\\partial p_{j}}\\left \(-\\frac{\\partial H} {\\partial x_{j}}\\right\)\\right\) {}\\\\ & =& \\left \\{f,H\\right\\}, {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ37.gif)

as claimed.

Observe that Proposition 2.25 includes Hamilton's equations themselves as special cases, by taking f(x, p) = x j and by taking f(x, p) = p j . Thus, this proposition gives a more coordinate-independent way of expressing the time-evolution.

Corollary 2.26

Call a smooth function f on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq104.gif) a conserved quantity if f (x (t), p (t)) is independent of t for each solution (x (t), p (t)) of Hamilton's equations. Then f is a conserved quantity if and only if

![
$$\\displaystyle{\\{f,H\\} = 0.}$$
](A272900_1_En_2_Chapter_Equam.gif)

In particular, the Hamiltonian H is a conserved quantity.

Conserved quantities are also called constants of motion. See Conclusion 2.31 for another perspective on this result. Conserved quantities (when one can find them) are useful in that we know that trajectories must lie in the level surfaces of any conserved quantity. Suppose, for example, that we have a particle moving in ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq105.gif) and that the Hamiltonian H and one other independent function f (such as, say, the angular momentum) are conserved quantities. Then, rather than looking for trajectories in the four-dimensional phase space, we look for them inside the joint level sets of H and f (sets of the form H(x, p) = a, f(x, p) = b, for some constants a and b). These joint level sets are (generically) two-dimensional instead of four-dimensional, so using the constants of motion greatly simplifies the problem—from an equation in four variables to one in only two variables.

Solving Hamilton's equations on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq106.gif) gives rise to a flow on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_2_Chapter_IEq107.gif) that is, a family Φ  t of diffeomorphisms of ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq108.gif), where Φ t (x, p) is equal to the solution at time t of Hamilton's equations with initial condition (x, p). Since it is possible (depending on the choice of potential function V) that a particle can escape to infinity in finite time, the maps Φ  t are not necessarily defined on all of ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_2_Chapter_IEq109.gif) but only on some open subset thereof. If Φ  t does happen to be defined on all of ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq110.gif) (for all t), then we say that the flow is complete.

Theorem 2.27 (Liouville's Theorem)

The flow associated with Hamilton's equations, for an arbitrary Hamiltonian function H, preserves the (2n)-dimensional volume measure

![
$$\\displaystyle{dx_{1}dx_{2}\\cdots dx_{n}dp_{1}dp_{2}\\cdots dp_{n}.}$$
](A272900_1_En_2_Chapter_Equan.gif)

What this means, more precisely, is that if a measurable set E is contained in the domain of Φ  t for some ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_2_Chapter_IEq111.gif) then the volume of Φ  t (E) is equal to the volume of E.

Proof.

Hamilton's equations may be written as

![
$$\\displaystyle{ \\frac{d} {dt}\\left \[\\begin{array}{c} x_{1}\\\\ \\vdots \\\\ x_{n} \\\\ p_{1}\\\\ \\vdots \\\\ p_{n} \\end{array} \\right\] = \\left \[\\begin{array}{c} \\frac{\\partial H} {\\partial p_{1}}\\\\ \\vdots \\\\ \\frac{\\partial H} {\\partial p_{n}} \\\\ - \\frac{\\partial H} {\\partial x_{1}}\\\\ \\vdots \\\\ - \\frac{\\partial H} {\\partial x_{n}} \\end{array} \\right\]. }$$
](A272900_1_En_2_Chapter_Equ38.gif)

(2.28)

This means that Hamilton's Equations describe the flow along the vector field on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq112.gif) appearing on the right-hand side of (2.28). By a standard result from vector calculus (see, e.g., Proposition 16.33 in [29]), this flow will be volume-preserving if and only if the divergence of the vector field is zero. We compute this divergence as

![
$$\\displaystyle{ \\frac{\\partial } {\\partial x_{1}} \\frac{\\partial H} {\\partial p_{1}} + \\cdots + \\frac{\\partial } {\\partial x_{n}} \\frac{\\partial H} {\\partial p_{n}} - \\frac{\\partial } {\\partial p_{1}} \\frac{\\partial H} {\\partial x_{1}} -\\cdots - \\frac{\\partial } {\\partial p_{n}} \\frac{\\partial H} {\\partial x_{n}}. }$$
](A272900_1_En_2_Chapter_Equ39.gif)

(2.29)

Since

![
$$\\displaystyle{ \\frac{{\\partial }^{2}H} {\\partial x_{j}\\partial p_{j}} = \\frac{{\\partial }^{2}H} {\\partial p_{j}\\partial x_{j}},}$$
](A272900_1_En_2_Chapter_Equao.gif)

the divergence is zero.

The existence of an invariant volume has important consequences for the dynamics of a system. For example, for "confined" systems, an invariant volume implies that the system exhibits "recurrence," which means (roughly) that for most initial conditions, the particle will eventually come back arbitrarily close to its initial state in phase space. We will not, however, delve into this aspect of the theory.

Note that the divergence of X H , computed in (2.29), vanishes in a very particular way, namely the sum of the jth and (n \+ j)th terms vanishes for all 1 ≤ j ≤ n. This stronger condition turns out to be equivalent to the condition that the Hamiltonian flow Φ  t associated with an arbitrary smooth function on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq113.gif) preserves the symplectic form ω, defined by

![
$$\\displaystyle{\\omega \(\(\\mathbf{x},\\mathbf{p}\),\({\\mathbf{x}}^{{\\prime}},{\\mathbf{p}}^{{\\prime}}\)\) = \\mathbf{x} \\cdot {\\mathbf{p}}^{{\\prime}}-\\mathbf{p} \\cdot {\\mathbf{x}}^{{\\prime}}.}$$
](A272900_1_En_2_Chapter_Equap.gif)

What this means, more precisely, is that for any ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_2_Chapter_IEq114.gif) and any ![
$$\(\\mathbf{x},\\mathbf{p}\) \\in {\\mathbb{R}}^{2n},$$
](A272900_1_En_2_Chapter_IEq115.gif) the matrix of partial derivatives of Φ  t at the point (x, p)—thought of as a linear map of ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq116.gif) to ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq117.gif)—preserves ω. This property of Φ  t , as it turns out, is equivalent to the property that Φ  t preserves Poisson brackets, meaning that

![
$$\\displaystyle{\\{f \\circ \\Phi _{t},g \\circ \\Phi _{t}\\} =\\{ f,g\\} \\circ \\Phi _{t}}$$
](A272900_1_En_2_Chapter_Equaq.gif)

for all ![
$$f,g \\in {C}^{\\infty }\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_2_Chapter_IEq118.gif) A map ![
$$\\Psi : {\\mathbb{R}}^{2n} \\rightarrow {\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq119.gif) that preserves ω is called a symplectomorphism (in mathematics notation) or a canonical transformation (in physics notation). We defer the proofs of these claims until Chap.​ 21, where we can consider them in a more general setting.

Definition 2.28

For any smooth function f on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_2_Chapter_IEq120.gif) the Hamiltonian flow generated by f is the flow obtained by solving Hamilton's equation (2.25) with the Hamiltonian H replaced by f. The function f is called the Hamiltonian generator of the associated flow.

Although any smooth function on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq121.gif) can be inserted into Hamilton's equations to produce a flow, physically one should think that there is a distinguished function, the Hamiltonian H of the system, such that the flow generated by H is the time-evolution of the system. For any other function f, the Hamiltonian flow generated by f should not be thought of as time-evolution, but as some other flow, which might, for example, represent some family of symmetries of our system.

Proposition 2.29

The Hamiltonian flow generated by the function

![
$$\\displaystyle{ f_{\\mathbf{a}}\(\\mathbf{x},\\mathbf{p}\) := \\mathbf{a} \\cdot \\mathbf{p} }$$
](A272900_1_En_2_Chapter_Equ40.gif)

(2.30)

is given by

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{x}\(t\)& =& \\mathbf{x}_{0} + t\\mathbf{a} \\\\ \\mathbf{p}\(t\)& =& \\mathbf{p}_{0},{}\\end{array}$$
](A272900_1_En_2_Chapter_Equ41.gif)

(2.31)

and the Hamiltonian flow generated by the function

![
$$\\displaystyle{ g_{\\mathbf{b}}\(\\mathbf{x},\\mathbf{p}\) := \\mathbf{b} \\cdot \\mathbf{x} }$$
](A272900_1_En_2_Chapter_Equ42.gif)

(2.32)

is given by

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{x}\(t\)& =& \\mathbf{x}_{0} {}\\\\ \\mathbf{p}\(t\)& =& \\mathbf{p}_{0} - t\\mathbf{b}. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ43.gif)

Proof.

Direct calculation.

What this means is that the Hamiltonian flow generated by a linear combination of the momentum functions consists of translations in position of the particle. That is to say, in the flow (2.31) generated by the function f a in (2.30), the particle's initial position x 0 is translated by t a while the particle's momentum is independent of t. Similarly, the Hamiltonian flow generated by a linear combination of the position functions [the function g b in (2.32)] consists of translations in the particle's momentum.

Proposition 2.30

For a particle moving in ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq122.gif) the Hamiltonian flow generated by the angular momentum function

![
$$\\displaystyle{J\(\\mathbf{x},\\mathbf{p}\) = x_{1}p_{2} - x_{2}p_{1}}$$
](A272900_1_En_2_Chapter_Equar.gif)

consists of simultaneous rotations of x and p . That is to say,

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \[\\begin{array}{c} x_{1}\(t\) \\\\ x_{2}\(t\) \\end{array} \\right\] = \\left \[\\begin{array}{rr} \\cos t& -\\sin t\\\\ \\sin t & \\cos t \\end{array} \\right\]\\left \[\\begin{array}{c} x_{1}\(0\) \\\\ x_{2}\(0\) \\end{array} \\right\] \\\\ & & \\left \[\\begin{array}{c} p_{1}\(t\) \\\\ p_{2}\(t\) \\end{array} \\right\] = \\left \[\\begin{array}{rr} \\cos t& -\\sin t\\\\ \\sin t & \\cos t \\end{array} \\right\]\\left \[\\begin{array}{c} p_{1}\(0\) \\\\ p_{2}\(0\) \\end{array} \\right\].{}\\end{array}$$
](A272900_1_En_2_Chapter_Equ44.gif)

(2.33)

Proof.

If we plug the angular momentum function J into Hamilton's equations in place of H, we obtain

![
$$\\displaystyle{\\begin{array}{ccc} \\dfrac{dx_{1}} {dt} = \\dfrac{\\partial J} {\\partial p_{1}} = -x_{2};&&\\dfrac{dp_{1}} {dt} = -\\dfrac{\\partial J} {\\partial x_{1}} = -p_{2} \\\\ & & \\\\ \\dfrac{dx_{2}} {dt} = \\dfrac{\\partial J} {\\partial p_{2}} = x_{1}; && \\dfrac{dp_{2}} {dt} = -\\dfrac{\\partial J} {\\partial x_{2}} = p_{1} \\end{array}.}$$
](A272900_1_En_2_Chapter_Equas.gif)

The solution to this system is given by the expression in the proposition, as is easily verified by differentiation of (2.33).

Note that since the Hamiltonian flow generated by J does not have the interpretation of the time-evolution of the particle, the parameter t in (2.33) should not be interpreted as the physical time; it is just the parameter in a one-parameter group of diffeomorphisms. In this case, t is the angle of rotation. Thus, one answer to the question, "What is the angular momentum?" is that J is the Hamiltonian generator of rotations.

If f is any smooth function, then by the proof of Proposition 2.25, the time derivative of any other function g along the Hamiltonian flow generated by f is given by ![
$$dg/dt =\\{ g,f\\}$$
](A272900_1_En_2_Chapter_IEq123.gif). In particular, the derivative of the Hamiltonian H along the flow generated by f is {H, f}. Thus, f is constant along the flow generated by H if and only if {f, H} = 0, which holds if and only if {f, H} = 0, which holds if and only if H is constant along the flow generated by f. This line of reasoning leads to the following result.

Conclusion 2.31

A function f is a conserved quantity for solutions of Hamilton's equation ( 2.25 ) if and only if H is invariant under the Hamiltonian flow generated by f. In particular, the angular momentum J is conserved if and only if H is invariant under simultaneous rotations of x and p.

We will return to this way of thinking about conserved quantities in Chap.​ 21. Compare Exercise 12.

The Hamiltonian framework can be extended in a straightforward way to systems of particles.

Proposition 2.32

Consider the phase space for a system of N particles moving in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq124.gif) namely ![
$${\\mathbb{R}}^{2nN},$$
](A272900_1_En_2_Chapter_IEq125.gif) thought of as the set of (2N)-tuples of the form

![
$$\\displaystyle{\({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N},{\\mathbf{p}}^{1},\\ldots,{\\mathbf{p}}^{N}\)}$$
](A272900_1_En_2_Chapter_Equat.gif)

with x j and p j belonging to ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_2_Chapter_IEq126.gif) Define the Poisson bracket of two smooth functions f and g on the phase space by

![
$$\\displaystyle{\\{f,g\\} =\\sum _{ j=1}^{N}\\sum _{ k=1}^{n}\\left \( \\frac{\\partial f} {\\partial x_{k}^{j}} \\frac{\\partial g} {\\partial p_{k}^{j}} - \\frac{\\partial f} {\\partial p_{k}^{j}} \\frac{\\partial g} {\\partial x_{k}^{j}}\\right\)}$$
](A272900_1_En_2_Chapter_Equau.gif)

and consider a Hamiltonian function of the form

![
$$\\displaystyle{H\({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N},{\\mathbf{p}}^{1},\\ldots,{\\mathbf{p}}^{N}\) =\\sum _{ j=1}^{N} \\frac{1} {2m_{j}}{\\left \\vert {\\mathbf{p}}^{j}\\right\\vert }^{2} + V \({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N}\).}$$
](A272900_1_En_2_Chapter_Equav.gif)

Then Newton's law in the form ![
$$m_{j}{\\mathbf{\\ddot{x}}}^{j} = -{\\nabla }^{j}V$$
](A272900_1_En_2_Chapter_IEq127.gif) is equivalent to Hamilton's equations in the form

![
$$\\displaystyle\\begin{array}{rcl} \\frac{dx_{k}^{j}} {dt} & =& \\frac{\\partial H} {\\partial p_{k}^{j}} \\\\ \\frac{dp_{k}^{j}} {dt} & =& - \\frac{\\partial H} {\\partial x_{k}^{j}}.{}\\end{array}$$
](A272900_1_En_2_Chapter_Equ45.gif)

(2.34)

For any smooth function f, the derivative of f along a solution of Hamilton's equations is given by

![
$$\\displaystyle{\\frac{df} {dt} =\\{ f,H\\}.}$$
](A272900_1_En_2_Chapter_Equaw.gif)

The proof of these results is entirely similar to the one-particle case and is omitted.

## 2.6 The Kepler Problem and the Runge–Lenz Vector

### 2.6.1 The Kepler Problem

We consider now the classical Kepler problem, that of finding the trajectories of a planet orbiting the sun. Since the sun is very much more massive than any of the planets, we may consider the position of the sun to be fixed at the origin of our coordinate system. The sun exerts a force on a planet given by

![
$$\\displaystyle{ \\mathbf{F} = -k \\frac{\\mathbf{x}} {{\\left \\vert \\mathbf{x}\\right\\vert }^{3}}. }$$
](A272900_1_En_2_Chapter_Equ46.gif)

(2.35)

Here k = GmM, where m is the mass of the planet, M is the mass of the sun, and G is the universal gravitational constant. Note that the magnitude of F is proportional to the reciprocal of the square of the distance from the origin; thus, the force follows an inverse square law. Since k contains a factor of the mass m of the planet, this quantity drops out of the equation of motion, ![
$$m\\mathbf{\\ddot{x}} = \\mathbf{F}.$$
](A272900_1_En_2_Chapter_IEq128.gif) The potential associated with the force (2.35) is easily seen to be

![
$$\\displaystyle{ V \(\\mathbf{x}\) = -\\frac{k} {\\left \\vert \\mathbf{x}\\right\\vert }. }$$
](A272900_1_En_2_Chapter_Equ47.gif)

(2.36)

Since our potential V is invariant under rotations, the angular momentum vector J = x × p is a conserved quantity (Theorem 2.21 with N = 1 and n = 3). If J = 0, the particle is moving along a ray through the origin. In that case, either the particle will pass through the origin at some point in the future (if the initial momentum points toward the origin), or else the particle must have passed through the origin at some point in the past (if the initial momentum points away from the origin). Trajectories of this sort are called collision trajectories, and we will regard such trajectories as pathological.

We will, from now on, consider only trajectories along which the angular momentum vector is nonzero. Fixing the energy and angular momentum of the particle guarantees that the particle stays a certain minimum distance from the origin (Exercise 20). Meanwhile, since J = x × p, the position x(t) of the particle will always be perpendicular to the constant value of J. We will therefore refer to the plane (through the origin) perpendicular to J as the "plane of motion."

### 2.6.2 Conservation of the Runge–Lenz Vector

We are going to obtain a description of the classical trajectories in an indirect way, using something called the Runge–Lenz vector.

Definition 2.33

The Runge–Lenz vector is the vector-valued function on ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\} \\times {\\mathbb{R}}^{3}$$
](A272900_1_En_2_Chapter_IEq129.gif) given by

![
$$\\displaystyle{\\mathbf{A}\(\\mathbf{x},\\mathbf{p}\) = \\frac{1} {mk}\\mathbf{p} \\times \\mathbf{J} -\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }.}$$
](A272900_1_En_2_Chapter_Equax.gif)

Here x represents the position of a classical particle and p its momentum.

The significance of this vector is that it is a conserved quantity for the Kepler problem. Of course, whenever the potential energy is radial (a function of the distance from the origin), the angular momentum vector is a conserved quantity. What is special about the 1 ∕ r potential of the Kepler problem is that there is another conserved vector-valued quantity.

Proposition 2.34

The Runge–Lenz vector is conserved quantity for Newton's law with force given by ( 2.35 ).

Proof.

Since J is conserved, we compute that

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\dot{A}}\(t\)& =& \\frac{1} {mk}\\mathbf{F} \\times \\mathbf{J} - \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert } \\frac{\\mathbf{p}} {m} + \\frac{\\mathbf{x}} {{\\left \\vert \\mathbf{x}\\right\\vert }^{2}}\\sum _{j=1}^{3} \\frac{\\partial \\left \\vert \\mathbf{x}\\right\\vert } {\\partial x_{j}} \\frac{dx_{j}} {dt} {}\\\\ & =& -\\frac{1} {m} \\frac{1} {{\\left \\vert \\mathbf{x}\\right\\vert }^{3}}\\mathbf{x} \\times \(\\mathbf{x} \\times \\mathbf{p}\) - \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert } \\frac{\\mathbf{p}} {m} + \\frac{\\mathbf{x}} {{\\left \\vert \\mathbf{x}\\right\\vert }^{2}}\\sum _{j=1}^{3}\\frac{x_{j}} {\\left \\vert \\mathbf{x}\\right\\vert } \\frac{p_{j}} {m} {}\\\\ & =& \\frac{1} {m}\\left \(- \\frac{1} {{\\left \\vert \\mathbf{x}\\right\\vert }^{3}}\\mathbf{x}\(\\mathbf{x} \\cdot \\mathbf{p}\) + \\frac{1} {{\\left \\vert \\mathbf{x}\\right\\vert }^{3}}\\mathbf{p}\(\\mathbf{x} \\cdot \\mathbf{x}\) -\\frac{\\mathbf{p}} {\\left \\vert \\mathbf{x}\\right\\vert } + \\frac{\\mathbf{x}\(\\mathbf{x} \\cdot \\mathbf{p}\)} {{\\left \\vert \\mathbf{x}\\right\\vert }^{3}} \\right\) {}\\\\ & =& 0. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ48.gif)

Here we have used the identity ![
$$\\mathbf{b} \\times \(\\mathbf{c} \\times \\mathbf{d}\) = \\mathbf{c}\(\\mathbf{b} \\cdot \\mathbf{d}\) -\\mathbf{d}\(\\mathbf{b} \\cdot \\mathbf{c}\)$$
](A272900_1_En_2_Chapter_IEq130.gif), which holds for all vectors ![
$$\\mathbf{b},\\mathbf{c},\\mathbf{d} \\in {\\mathbb{R}}^{3}.$$
](A272900_1_En_2_Chapter_IEq131.gif)

### 2.6.3 Ellipses, Hyperbolas, and Parabolas

We now use the Runge–Lenz vector to determine the trajectories for the Kepler problem.

Proposition 2.35

The magnitude of the Runge–Lenz vector A satisfies

![
$$\\displaystyle{{\\left \\vert \\mathbf{A}\\right\\vert }^{2} = 1 + \\frac{2{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {m{k}^{2}}E,}$$
](A272900_1_En_2_Chapter_Equay.gif)

where ![
$$E ={ \\left \\vert \\mathbf{p}\\right\\vert }^{2}/\(2m\) - k/\\left \\vert \\mathbf{x}\\right\\vert$$
](A272900_1_En_2_Chapter_IEq132.gif) is the energy of the particle. Furthermore, if ![
$$\\mathbf{\\hat{x}} := \\mathbf{x}/\\left \\vert \\mathbf{x}\\right\\vert$$
](A272900_1_En_2_Chapter_IEq133.gif) is the unit vector in the x -direction, we have

![
$$\\displaystyle{ \\mathbf{A} \\cdot \\mathbf{\\hat{x}} = \\frac{{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {mk\\left \\vert \\mathbf{x}\\right\\vert } - 1 }$$
](A272900_1_En_2_Chapter_Equ49.gif)

(2.37)

for all nonzero x . It follows from (2.37) that

![
$$\\displaystyle{\\left \\vert \\mathbf{x}\\right\\vert = \\frac{{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {mk\(1 + \\mathbf{A} \\cdot \\mathbf{\\hat{x}\)}}.}$$
](A272900_1_En_2_Chapter_Equaz.gif)

Note that from (2.37), ![
$$\\mathbf{A} \\cdot \\mathbf{\\hat{x}} > -1$$
](A272900_1_En_2_Chapter_IEq134.gif) for all points (x, p) with x ≠ 0.

Proof.

Using the identity b ⋅(c × d) = d ⋅(b × c), we see that

![
$$\\displaystyle{\\mathbf{\\hat{x}} \\cdot \(\\mathbf{p} \\times \\mathbf{J}\) = \\mathbf{J} \\cdot \(\\mathbf{\\hat{x}} \\times \\mathbf{p}\) ={ \\left \\vert \\mathbf{J}\\right\\vert }^{2}/\\left \\vert \\mathbf{x}\\right\\vert.}$$
](A272900_1_En_2_Chapter_Equba.gif)

Since J and p are orthogonal, we get

![
$$\\displaystyle\\begin{array}{rcl}{ \\left \\vert \\mathbf{A}\\right\\vert }^{2}& =& \\frac{1} {{m}^{2}{k}^{2}}{\\left \\vert \\mathbf{p}\\right\\vert }^{2}{\\left \\vert \\mathbf{J}\\right\\vert }^{2} + 1 - \\frac{2} {mk}\\mathbf{\\hat{x}} \\cdot \(\\mathbf{p} \\times \\mathbf{J}\) {}\\\\ & =& 1 + \\frac{2{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {m{k}^{2}}\\left \( \\frac{{\\left \\vert \\mathbf{p}\\right\\vert }^{2}} {2m} -\\frac{k} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\) {}\\\\ & =& 1 + \\frac{2{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {m{k}^{2}}E. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ50.gif)

Using again the identity for b ⋅(c × d), we next compute that

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{A} \\cdot \\mathbf{x}& =& \\frac{1} {mk}\\mathbf{J} \\cdot \(\\mathbf{x} \\times \\mathbf{p}\) -\\frac{\\mathbf{x} \\cdot \\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert } {}\\\\ & =& \\frac{{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {mk} -\\left \\vert \\mathbf{x}\\right\\vert. {}\\\\ \\end{array}$$
](A272900_1_En_2_Chapter_Equ51.gif)

We may now divide by ![
$$\\left \\vert \\mathbf{x}\\right\\vert$$
](A272900_1_En_2_Chapter_IEq135.gif) to obtain the desired expression for ![
$$\\mathbf{A} \\cdot \\mathbf{\\hat{x}}.$$
](A272900_1_En_2_Chapter_IEq136.gif) It is then straightforward to solve for ![
$$\\left \\vert \\mathbf{x}\\right\\vert.$$
](A272900_1_En_2_Chapter_IEq137.gif)

Corollary 2.36

Choose orthonormal coordinates in the plane of motion so that A lies along the positive x 1 -axis. If r and θ are the polar coordinates associated with this coordinate system, then along each trajectory (r(t), θ(t)), we have

![
$$\\displaystyle{ r\(t\) = \\frac{{\\left \\vert \\mathbf{J}\\right\\vert }^{2}} {mk} \\frac{1} {1 + A\\cos \\theta \(t\)}, }$$
](A272900_1_En_2_Chapter_Equ52.gif)

(2.38)

where ![
$$A = \\left \\vert \\mathbf{A}\\right\\vert.$$
](A272900_1_En_2_Chapter_IEq138.gif)

If A = 0, any orthonormal coordinates can be used.

Proposition 2.37

If ![
$$A := \\left \\vert \\mathbf{A}\\right\\vert < 1,$$
](A272900_1_En_2_Chapter_IEq139.gif) ( 2.38 ) is the equation of an ellipse with eccentricity A and with the origin being one focus of the ellipse. If A > 1, ( 2.38 ) is the equation of a hyperbola, and if A = 1, ( 2.38 ) is the equation of a parabola.

The orbit of the particle in the plane of motion is an ellipse if the energy of the particle is negative, a hyperbola if the energy is positive, and a parabola if the energy is zero.

Kepler's first law is the assertion that planets move in elliptical trajectories with the sun at one focus, as shown in Fig. 2.2. The shaded regions indicate two equal areas that are swept out in equal times, in accordance with Kepler's second law (Corollary 2.19).

Figure 2.2

Elliptical orbit for the Kepler problem, with two equal areas shaded.

Recall that the eccentricity of an ellipse is ![
$$\\sqrt{ 1 - {\(b/a\)}^{2}},$$
](A272900_1_En_2_Chapter_IEq140.gif) where a is half the length of the major axis and b is half the length of the minor axis. Thus, when A = 0, we have b = a, meaning that the ellipse is a circle.

Proof.

We continue to work in a coordinate system in which A is along the positive x 1-axis. Then (2.38) becomes

![
$$\\displaystyle{\\sqrt{{x}^{2 } + {y}^{2}} =\\alpha \\frac{1} {1 + A \\frac{x} {\\sqrt{{x}^{2 } +{y}^{2}}} },}$$
](A272900_1_En_2_Chapter_Equbb.gif)

where ![
$$\\alpha ={ \\left \\vert \\mathbf{J}\\right\\vert }^{2}/\(mk\).$$
](A272900_1_En_2_Chapter_IEq141.gif) From this we obtain

![
$$\\displaystyle{1 = \\frac{1} {\\alpha } \\left \(\\sqrt{{x}^{2 } + {y}^{2}} + Ax\\right\).}$$
](A272900_1_En_2_Chapter_Equbc.gif)

Now we can solve for ![
$$\\sqrt{{x}^{2 } + {y}^{2}},$$
](A272900_1_En_2_Chapter_IEq142.gif) square both sides of the equation, and simplify. Assuming A 2 ≠ 1, we obtain

![
$$\\displaystyle{{ \\alpha }^{2}\\left \( \\frac{1} {1 - {A}^{2}}\\right\) = \(1 - {A}^{2}\){\\left \(x + \\frac{A\\alpha } {1 - {A}^{2}}\\right\)}^{2} + {y}^{2}. }$$
](A272900_1_En_2_Chapter_Equ53.gif)

(2.39)

This is the equation of an ellipse (if A 2 < 1) or a hyperbola (if A 2 > 1), where the center of the ellipse or hyperbola is the point ![
$$\(-\\alpha /\(1 - {A}^{2}\),0\).$$
](A272900_1_En_2_Chapter_IEq143.gif) In light of the formula for ![
$$A := \\left \\vert \\mathbf{A}\\right\\vert$$
](A272900_1_En_2_Chapter_IEq144.gif) in Proposition 2.35, we obtain an ellipse if the energy of the particle is negative and a hyperbola if the energy is positive.

In the case A 2 < 1, we may readily compute the half-lengths a and b of the major and minor axes as

![
$$\\displaystyle{a = \\frac{\\alpha } {1 - {A}^{2}};\\quad b = \\frac{\\alpha } {\\sqrt{1 - {A}^{2}}}.}$$
](A272900_1_En_2_Chapter_Equbd.gif)

From this, we readily calculate that the eccentricity is A. Now, the distance between the foci of an ellipse is the length of the major axis times the eccentricity, in our case, ![
$$2A\\alpha /\(1 - {A}^{2}\).$$
](A272900_1_En_2_Chapter_IEq145.gif) Since the center of the ellipse in (2.39) is at the point ![
$$\(A\\alpha /\(1 - {A}^{2}\),0\),$$
](A272900_1_En_2_Chapter_IEq146.gif) the origin is one focus of the ellipse.

If A 2 = 1, then when we perform the same analysis, x 2 drops out of the equation and we obtain

![
$$\\displaystyle{x = \\frac{1} {2A\\alpha }\\left \(-{y}^{2} {+\\alpha }^{2}\\right\)}$$
](A272900_1_En_2_Chapter_Eqube.gif)

which is the equation of a parabola opening along the x-axis. This case corresponds to energy zero.

Note that Proposition 2.37 does not tell us how the particle moves along the ellipse, hyperbola, or parabola as a function of time. We can, however, determine this, at least in principle, by making use of the angular momentum. After all, applying (2.17) in the plane of motion gives

![
$$\\displaystyle{ \\frac{d\\theta } {dt} = \\frac{1} {m{r}^{2}}\\left \\vert \\mathbf{J}\\right\\vert, }$$
](A272900_1_En_2_Chapter_Equ54.gif)

(2.40)

where θ is the polar angle variable in the plane of motion. Since we have computed r as a function of θ in Corollary 2.36, (2.40) gives us a (first-order, separable) differential equation, from which we can attempt to solve to obtain θ—and thus also r—as a function of t.

### 2.6.4 Special Properties of the Kepler Problem

As we have said, the existence of another conserved vector-valued function—in addition to the conserved energy and angular momentum—is special to a potential of the form ![
$$-k/\\left \\vert \\mathbf{x}\\right\\vert.$$
](A272900_1_En_2_Chapter_IEq147.gif) For a general radial potential, the energy and the angular momentum will be the only conserved quantities. Assuming J ≠ 0, the motion of a particle in any radial potential will always lie in the plane perpendicular to J. Taking this into account, we think of our particle as moving in ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq148.gif) rather than ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_2_Chapter_IEq149.gif) and accordingly think of our phase space as being four-dimensional rather than six-dimensional. From this point of view, there are two remaining conserved quantities, the energy E and the scalar angular momentum J in the plane, as given by Definition 2.17. Thus, each trajectory will lie in a set of the form

![
$$\\displaystyle{\\left \\{\\left.\(\\mathbf{x},\\mathbf{p}\) \\in {\\mathbb{R}}^{2} \\times {\\mathbb{R}}^{2}\\right\\vert E\(\\mathbf{x},\\mathbf{p}\) = a,\\ J\(\\mathbf{x},\\mathbf{p}\) = b\\right\\}.}$$
](A272900_1_En_2_Chapter_Equbf.gif)

We refer to such a set as a joint level set of E and J. These sets are two-dimensional surfaces inside our four-dimensional phase space.

For a general radial potential, a trajectory (x(t), p(t)) in phase space may not be a closed curve, but may fill up a dense subset of the joint level surface on which it lives. In particular, the trajectory x(t) in position space will typically not be a closed curve. For example, x(t) may trace out a roughly elliptical region in the plane, but where the axes of the ellipse "precess," that is, vary with time. Such a trajectory is shown in Fig. 2.3, which should be contrasted with Fig. 2.2.

Figure 2.3

Trajectory in the plane of motion for a typical radial potential.

In the Kepler problem, even after restricting attention to the plane of motion, we still have one conserved quantity in addition to E and J, namely the direction of A, which can be expressed in terms of the angle ϕ between A and the x 1-axis in the plane of motion. (Note that both terms in the definition of A lie in the plane of motion. Note also that the magnitude of A is, by Proposition 2.35, computable in terms of E and J.) The trajectories of the Kepler problem, then, lie in the joint level sets of E and J and ϕ, which are one-dimensional. When E < 0, the joint level sets of E and J are compact, in which case the joint level sets of E and J and ϕ are compact and one-dimensional, that is, simple closed curves.

Another special property of the Kepler problem is that the period of the closed trajectories (the trajectories with negative energy) is the same for all trajectories with the same energy (Exercise 21). This apparent coincidence can be explained by showing that the Hamiltonian flows (Definition 2.28) generated by J and A act transitively on the energy surfaces. These flows commute with the time evolution of the system, because they are all conserved quantities (Conclusion 2.31). Thus, any two points with the same energy are "equivalent" with respect to time evolution. Although we will not go into the details of this analysis, we will gain a better understanding of the flows generated by the components of A in Sect.​ 18.​4.

## 2.7 Exercises

1.

Consider a particle moving in the real line in the presence of a force coming from a potential function V. Given some value E 0 for the energy of the particle, suppose that V (x) < E 0 for all x in some closed interval [x 0, x 1]. Then a particle with initial position x 0 and positive initial velocity will continue to move to the right until it reaches x 1. Using (2.6), show that the time needed to travel from x 0 to x 1 is given by

![
$$\\displaystyle{t =\\int _{ x_{0}}^{x_{1} }\\sqrt{ \\frac{m} {2\(E_{0} - V \(y\)\)}}\\ dy.}$$
](A272900_1_En_2_Chapter_Equbg.gif)

Note: This shows that we can solve Newton's equation in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_2_Chapter_IEq150.gif) more or less explicitly for time as a function of position, which in principle determines the position as a function of time.

2.

In the notation of the previous problem, suppose now that V (x) < E 0 for x 0 ≤ x < x 1, but that V (x 1) = E 0.

(a)

Show that if V ′ (x 1) ≠ 0, then the particle reaches x 1 in a finite time.

(b)

Show that if V ′ (x 1) = 0, then the time it takes the particle to reach x 1 is infinite; that is, the particle approaches but never actual reaches x 1.

Note: In Part (b), the point x 1 is an unstable equilibrium for the system, that is, a critical point for V that is not a local minimum.

3.

Consider the equation of motion of a pendulum of length L,

![
$$\\displaystyle{ \\frac{{d}^{2}\\theta } {d{t}^{2}} + \\frac{g} {L}\\sin \\theta = 0,}$$
](A272900_1_En_2_Chapter_Equbh.gif)

where g is the acceleration of gravity. Here θ is the angle between the pendulum and the negative y-axis in the plane. This system has a stable equilibrium at θ = 0 and an unstable equilibrium at θ = π.

Consider initial conditions of the form ![
$$\\theta \(0\) =\\pi -\\delta,$$
](A272900_1_En_2_Chapter_IEq151.gif) ![
$$\\dot{\\theta }\(0\) = 0$$
](A272900_1_En_2_Chapter_IEq152.gif), for 0 < δ < π ∕ 4. Fix some angle θ 0 and let T(δ) denote the time it takes for the pendulum with the given initial conditions to reach the angle θ 0. (Here θ 0 represents an arbitrarily chosen cutoff point at which the pendulum is no longer "close" to θ = π.) Show that T(δ) grows only logarithmically as δ tends to zero.

Note: Logarithmic growth of T as a function of δ corresponds to exponential decay of δ as a function of T. Thus, if we want T to be large, we must choose δ to be very small.

4.

Consider a particle moving in the real line in the presence of a "repelling potential," such that there is an A with V ′ (x) < 0 for all x > A. Then a particle with initial position x 0 > A and positive initial velocity will have positive velocity for all positive times. Suppose now that ![
$$V \(x\) = -{x}^{a}$$
](A272900_1_En_2_Chapter_IEq153.gif) for all x > 1, for some positive constant a. Suppose also that the particle is given initial position x 0 > 1 and positive initial velocity. Show that for a > 2, the particle escapes to infinity in finite time, but that for a ≤ 2, the position of the particle remains finite for all finite times.

Hint: Use Problem 1.

5.

Consider the equation ![
$$m\\ddot{x} +\\gamma \\dot{ x} + kx = 0,$$
](A272900_1_En_2_Chapter_IEq154.gif) where γ and k are positive constants (the damping constant and spring constant, respectively). Find the critical value γ c of γ (for a fixed m and k) such that for γ < γ c , we get solutions that are sines and cosines times a decaying exponential and for γ > γ c , we get pure decaying exponentials.

6.

Continue with the notation of Exercise 5. Given particular choices for m, γ, and k, let r be the rate of exponential decay of a "generic" solution to the equation of motion. Here, if the solution is of the form ![
$$a{e}^{-rt}\\cos \(\\omega t\) + b{e}^{-rt}\\sin \(\\omega t\),$$
](A272900_1_En_2_Chapter_IEq155.gif) the rate of exponential decay is r. If the solution is of the form ![
$$a{e}^{-r_{1}t} + b{e}^{-r_{2}t},$$
](A272900_1_En_2_Chapter_IEq156.gif) then r = min(r 1, r 2), since the slower-decaying term will dominate as long as a and b are both nonzero.

For a fixed value of m and k, show that the maximum value for r is achieved by taking γ = γ c . (This accounts for the terminology "critical damping" for the case in which γ = γ c .)

7.

Consider the ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq157.gif)-valued function F on ![
$${\\mathbb{R}}^{2} \\setminus \\{ 0\\}$$
](A272900_1_En_2_Chapter_IEq158.gif) given by

![
$$\\displaystyle{\\mathbf{F}\(x_{1},x_{2}\) = \\left \(- \\frac{x_{2}} {x_{1}^{2} + x_{2}^{2}}, \\frac{x_{1}} {x_{1}^{2} + x_{2}^{2}}\\right\).}$$
](A272900_1_En_2_Chapter_Equbi.gif)

Show that ![
$$\\partial F_{1}/\\partial x_{2} - \\partial F_{2}/\\partial x_{1} = 0$$
](A272900_1_En_2_Chapter_IEq159.gif) but that there does not exist any smooth function V on ![
$${\\mathbb{R}}^{2} \\setminus \\{ 0\\}$$
](A272900_1_En_2_Chapter_IEq160.gif) with ![
$$\\mathbf{F} = -\\nabla V.$$
](A272900_1_En_2_Chapter_IEq161.gif)

Hint: If F were of the form − ∇ V, we would have

![
$$\\displaystyle{V \(\\mathbf{x}\(b\)\) - V \(\\mathbf{x}\(a\)\) = -\\int _{a}^{b}\\mathbf{F}\(\\mathbf{x}\(t\)\) \\cdot \\frac{d\\mathbf{x}} {dt} \\ dt}$$
](A272900_1_En_2_Chapter_Equbj.gif)

for every smooth path ![
$$\\mathbf{x}\(\\cdot \) : \[a,b\] \\rightarrow {\\mathbb{R}}^{2}\\setminus \\{0\\},$$
](A272900_1_En_2_Chapter_IEq162.gif) by the fundamental theorem of calculus and the chain rule.

8.

Consider a particle moving in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_2_Chapter_IEq163.gif) with a velocity-dependent force law given by

![
$$\\displaystyle{\\mathbf{F}\(\\mathbf{x},\\mathbf{v}\) = -\\nabla V \(\\mathbf{x}\) + \\mathbf{F}_{2}\(\\mathbf{x},\\mathbf{v}\),}$$
](A272900_1_En_2_Chapter_Equbk.gif)

where the velocity-dependent term F 2 acts perpendicularly to the velocity of the particle. (That is, we assume that v ⋅F 2(x, v) = 0 for all x and v.) Let E denote the usual energy function ![
$$E\(\\mathbf{x},\\mathbf{v}\) = \\frac{1} {2}m{\\left \\vert \\mathbf{v}\\right\\vert }^{2} + V \(\\mathbf{x}\),$$
](A272900_1_En_2_Chapter_IEq164.gif) unmodified by the presence of the velocity-dependent term in the force. Show that E is conserved.

9.

(a)

If r and θ are the usual polar coordinates on ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq165.gif) compute ∂ θ ∕ ∂ x 1 and ∂ θ ∕ ∂ x 2.

(b)

If x(⋅) denotes the trajectory of a particle of mass m moving in ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq166.gif) show that

![
$$\\displaystyle{ \\frac{d} {dt}\\theta \(\\mathbf{x}\(t\)\) = \\frac{1} {m{r}^{2}}J\(\\mathbf{x}\(t\),\\mathbf{p}\(t\)\).}$$
](A272900_1_En_2_Chapter_Equbl.gif)

10.

Prove Theorem 2.21, by imitating the proof of Proposition 2.18. You may assume that every rotation can be built up as a product of repeated rotations in the various coordinate planes (i.e., rotations in the (x j , x k ) plane, for various pairs (j, k), where the same plane may be used more than once).

11.

Consider Hamilton's equations for N particles moving in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq167.gif) as in Proposition 2.32. Show that the total momentum ![
$$\\mathbf{p} =\\sum _{ j=1}^{N}{\\mathbf{p}}^{j}$$
](A272900_1_En_2_Chapter_IEq168.gif) of the system is a conserved quantity if and only if the quantity

![
$$\\displaystyle{H\({\\mathbf{x}}^{1} + \\mathbf{a},\\ldots,{\\mathbf{x}}^{N} + \\mathbf{a},{\\mathbf{p}}^{1} + \\mathbf{a},\\ldots,{\\mathbf{p}}^{N} + \\mathbf{a}\),\\ \\mathbf{a} \\in {\\mathbb{R}}^{n},}$$
](A272900_1_En_2_Chapter_Equbm.gif)

is independent of a for all x 1,..., x N and p 1,..., p N in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_2_Chapter_IEq169.gif)

Hint: Use (the N-particle version of) Conclusion 2.31.

12.

Let J denote the angular momentum of a particle moving in ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_2_Chapter_IEq170.gif) Let R θ denote a counterclockwise rotation by angle θ in ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_2_Chapter_IEq171.gif)

(a)

If f is any smooth function on ![
$${\\mathbb{R}}^{4},$$
](A272900_1_En_2_Chapter_IEq172.gif) show that

![
$$\\displaystyle{\\left \\{f,J\\right\\}\(\\mathbf{x},\\mathbf{p}\) = \\left.\\frac{d} {d\\theta }f\\left \(R_{\\theta }\\mathbf{x},R_{\\theta }\\mathbf{p}\\right\)\\right\\vert _{\\theta =0}.}$$
](A272900_1_En_2_Chapter_Equbn.gif)

(b)

Let H be any smooth function on ![
$${\\mathbb{R}}^{4}$$
](A272900_1_En_2_Chapter_IEq173.gif) and consider Hamilton's equations with this function playing the role of the Hamiltonian. Show that J is conserved (i.e., constant in time along any solution of Hamilton's equations) if and only if

![
$$\\displaystyle{H\(R_{\\theta }\\mathbf{x},R_{\\theta }\\mathbf{p}\) = H\(\\mathbf{x},\\mathbf{p}\)}$$
](A272900_1_En_2_Chapter_Equbo.gif)

for all θ in ![
$$\\mathbb{R}$$
](A272900_1_En_2_Chapter_IEq174.gif) and all x and p in ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_2_Chapter_IEq175.gif) (This argument is a more explicit way to obtain Conclusion 2.31.)

13.

Suppose that f and g are smooth functions on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq176.gif) and that at least one of the two functions has compact support. Show that

![
$$\\displaystyle{\\int _{{\\mathbb{R}}^{n}}\\int _{{\\mathbb{R}}^{n}}\\{f,g\\}\(\\mathbf{x},\\mathbf{p}\)\\ {d}^{n}\\mathbf{x}\\ {d}^{n}\\mathbf{p} = 0.}$$
](A272900_1_En_2_Chapter_Equbp.gif)

Hint: Use integration by parts or Liouville's theorem.

14.

Let X and Y be "vector fields" on ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_2_Chapter_IEq177.gif) viewed as first-order differential operators. This means that X and Y are of the form

![
$$\\displaystyle{X =\\sum _{ j=1}^{n}a_{ j}\(\\mathbf{x}\) \\frac{\\partial } {\\partial x_{j}};\\quad Y =\\sum _{ j=1}^{n}b_{ j}\(\\mathbf{x}\) \\frac{\\partial } {\\partial x_{j}}.}$$
](A272900_1_En_2_Chapter_Equbq.gif)

[If ![
$$\\tilde{X}\(\\mathbf{x}\) = \(a_{1}\(\\mathbf{x}\),\\ldots,a_{n}\(\\mathbf{x}\)\),$$
](A272900_1_En_2_Chapter_IEq178.gif) then the operator X is the directional derivative in the direction of ![
$$\\tilde{X}.$$
](A272900_1_En_2_Chapter_IEq179.gif) It is common to identify the vector-valued function ![
$$\\tilde{X}$$
](A272900_1_En_2_Chapter_IEq180.gif) with the associated first-order differential operator X.]

Show that the commutator [X, Y ] of X and Y, defined by

![
$$\\displaystyle{\[X,Y \] = XY - Y X}$$
](A272900_1_En_2_Chapter_Equbr.gif)

is again a vector field (i.e., a first-order differential operator).

15.

Given a smooth function f on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_2_Chapter_IEq181.gif) define an operator X f , acting on ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_2_Chapter_IEq182.gif) by the formula

![
$$\\displaystyle{X_{f}\(g\) =\\{ f,g\\}.}$$
](A272900_1_En_2_Chapter_Equbs.gif)

That is to say,

![
$$\\displaystyle{X_{f} =\\sum _{ j=1}^{n}\\left \( \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial } {\\partial p_{j}} - \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial } {\\partial x_{j}}\\right\).}$$
](A272900_1_En_2_Chapter_Equbt.gif)

The operator X f is called the Hamiltonian vector field associated with the function f. (Here, as in Exercise 14, we identify vector fields with first-order differential operators.)

(a)

Show that for all ![
$$f,g \\in {C}^{\\infty }\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_2_Chapter_IEq183.gif), we have

![
$$\\displaystyle{X_{\\{f,g\\}} = \[X_{f},X_{g}\],}$$
](A272900_1_En_2_Chapter_Equbu.gif)

where ![
$$\[X_{f},X_{g}\] = X_{f}X_{g} - X_{g}X_{f}.$$
](A272900_1_En_2_Chapter_IEq184.gif)

Hint: By Exercise 14, all terms in the computation of X f , X g  involving second derivatives of h can be neglected, since they will always cancel out to zero.

(b)

Use Part (a) to compute {{f, g}, h} = X {f, g}(h) and thereby obtain another proof of the Jacobi identity for the Poisson bracket.

16.

Recall the definition of a Hamiltonian vector field X f in Exercise 15.

(a)

Consider a smooth vector field X on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq185.gif) (viewed as a first-order differential operator as in Exercise 14) of the form

![
$$\\displaystyle{X\(\\mathbf{x}\) = g_{1}\(x,p\) \\frac{\\partial } {\\partial x} + g_{2}\(x,p\) \\frac{\\partial } {\\partial p}.}$$
](A272900_1_En_2_Chapter_Equbv.gif)

Show that X can be expressed as X = X f , for some ![
$$f \\in {C}^{\\infty }\({\\mathbb{R}}^{2}\),$$
](A272900_1_En_2_Chapter_IEq186.gif) if and only X is divergence free, that is, if and only if

![
$$\\displaystyle{\\nabla \\cdot X := \\frac{\\partial g_{1}} {\\partial x} + \\frac{\\partial g_{2}} {\\partial p} = 0.}$$
](A272900_1_En_2_Chapter_Equbw.gif)

Hint: As in Proposition 2.7, given a pair of functions h 1 and h 2 on ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_2_Chapter_IEq187.gif) there exists a function f with ![
$$\\partial f/\\partial x = h_{1}$$
](A272900_1_En_2_Chapter_IEq188.gif) and ![
$$\\partial f/\\partial p = h_{2}$$
](A272900_1_En_2_Chapter_IEq189.gif) if and only if we have ![
$$\\partial h_{1}/\\partial p = \\partial h_{2}/\\partial x.$$
](A272900_1_En_2_Chapter_IEq190.gif)

(b)

Show that there exists a smooth vector field X on ![
$${\\mathbb{R}}^{4}$$
](A272900_1_En_2_Chapter_IEq191.gif) of the form

![
$$\\displaystyle{X =\\sum _{ j=1}^{2}\\left \(g_{ j}\(\\mathbf{x\)} \\frac{\\partial } {\\partial x_{j}} + g_{j+2}\(\\mathbf{x}\) \\frac{\\partial } {\\partial p_{j}}\\right\)}$$
](A272900_1_En_2_Chapter_Equbx.gif)

such that

![
$$\\displaystyle{\\nabla \\cdot X :=\\sum _{ j=1}^{2}\\left \(\\frac{\\partial g_{j}} {\\partial x_{j}} + \\frac{\\partial g_{j+2}} {\\partial p_{j}} \\right\) = 0}$$
](A272900_1_En_2_Chapter_Equby.gif)

but such that there does not exist ![
$$f \\in {C}^{\\infty }\({\\mathbb{R}}^{4}\)$$
](A272900_1_En_2_Chapter_IEq192.gif) with X = X f .

Hint: You should be able to find a counterexample in which the coefficient functions g j are linear.

17.

Show that the space of homogeneous polynomials of degree 2 on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_2_Chapter_IEq193.gif) is closed under the Poisson bracket.

18.

Determine the Hamiltonian flow on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_2_Chapter_IEq194.gif) generated by the function f(x, p) = xp.

19.

Let J denote the angular momentum vector for a particle moving in ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_2_Chapter_IEq195.gif) namely J = x × p. Show that the components J 1, J 2, and J 3 of J satisfy the following Poisson bracket relations:

![
$$\\displaystyle{\\left \\{J_{1},J_{2}\\right\\} = J_{3};\\quad \\left \\{J_{2},J_{3}\\right\\} = J_{1};\\quad \\left \\{J_{3},J_{1}\\right\\} = J_{2}.}$$
](A272900_1_En_2_Chapter_Equbz.gif)

20.

In the Kepler problem, show that for each real number E and positive number J, there exists ![
$$\\varepsilon > 0$$
](A272900_1_En_2_Chapter_IEq196.gif) such that for all (x, p) with E(x, p) = E and ![
$$\\left \\vert \\mathbf{J}\(\\mathbf{x},\\mathbf{p}\)\\right\\vert = J,$$
](A272900_1_En_2_Chapter_IEq197.gif) we have ![
$$\\left \\vert \\mathbf{x}\\right\\vert \\geq \\varepsilon.$$
](A272900_1_En_2_Chapter_IEq198.gif)

Hint: Suppose that (x n , p n ) is a sequence with ![
$$\\left \\vert \\mathbf{J}\(\\mathbf{x}_{n},\\mathbf{p}_{n}\)\\right\\vert = J$$
](A272900_1_En_2_Chapter_IEq199.gif) and ![
$$\\left \\vert \\mathbf{x}_{n}\\right\\vert$$
](A272900_1_En_2_Chapter_IEq200.gif) tending to zero. Show that E(x n , p n ) tends to + ∞.

21.

(a)

Determine the area of the ellipse in the plane of motion in Proposition 2.37, in the case A < 1.

(b)

Show that the time T it takes the particle to travel once around the ellipse is given by

![
$$\\displaystyle{ \\frac{\\pi } {\\sqrt{2}}GM{\(-\\tilde{E}\)}^{-3/2},}$$
](A272900_1_En_2_Chapter_Equca.gif)

where ![
$$\\tilde{E}$$
](A272900_1_En_2_Chapter_IEq201.gif) is the "massless energy" of the particle, given by

![
$$\\displaystyle{\\tilde{E} = \\frac{E} {m} = \\frac{1} {2}\\left \\vert \\mathbf{\\dot{x}}\\right\\vert -\\frac{GM} {\\left \\vert \\mathbf{x}\\right\\vert }.}$$
](A272900_1_En_2_Chapter_Equcb.gif)

Note in the case where the trajectory in the plane of motion is elliptical, the energy of the particle is negative.

Note: The result of Part (b) is closely related to Kepler's third law.

References

[28].

W.G. Kelley, A.C. Petersen, The Theory of Differential Equations: Classical and Qualitative (Universitext), 2nd edn. (Springer, New York, 2010)

[29].

J. Lee, Introduction to Smooth Manifolds, 2nd edn. (Springer, London, 2006)

[44].

R.E. Williamson, R.H. Crowell, H.F. Trotter, Calculus of Vector Functions, 3rd edn. (Prentice-Hall, Englewood Cliffs, NJ, 1968)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_3

© Springer Science+Business Media New York 2013

# 3. A First Approach to Quantum Mechanics

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In this chapter, we try to understand the main ideas of quantum mechanics. In quantum mechanics, the outcome of a measurement cannot—even in principle—be predicted beforehand; only the probabilities for the outcome of the measurement can be predicted.

In this chapter, we try to understand the main ideas of quantum mechanics. In quantum mechanics, the outcome of a measurement cannot—even in principle—be predicted beforehand; only the probabilities for the outcome of the measurement can be predicted. These probabilities are encoded in a wave function, which is a function of a position variable ![
$$\\mathbf{x} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_3_Chapter_IEq1.gif). The square of the absolute value of the wave function encodes the probabilities for the position of the particle. Meanwhile, the probabilities for the momentum of the particle are encoded in the frequency of oscillation of the wave function. The probabilities can be described using the position operator and the momentum operator. The time-evolution of the wave function is described by the Hamiltonian operator, which is analogous to the Hamiltonian (or energy) function in Hamilton's equations.

## 3.1 Waves, Particles, and Probabilities

There are two key ingredients to quantum theory, both of which arose from experiments. The first ingredient is wave–particle duality, in which objects are observed to have both wavelike and particlelike behavior. Light, for example, was thought to be a wave throughout much of the nineteenth century, but was observed in the early twentieth century to have particle behavior as well. Electrons, meanwhile, were originally thought to be particles, but were then observed to have wave behavior.

The second ingredient of quantum theory is its probabilistic behavior. In the two-slit experiment, for example, electrons that are "identically prepared" do not all hit the screen at the same point. Quantum theory postulates that this randomness is fundamental to the way nature behaves. According to quantum mechanics, it is impossible (theoretically, not just in practice) to predict ahead of time what the outcome of an experiment will be. The best that can be done is to predict the probabilities for the outcome of an experiment.

These two aspects of quantum theory come together in the wave function. The wave function is a function of a variable ![
$$\\mathbf{x} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_3_Chapter_IEq2.gif) which we interpret as describing the possible values of the position of a particle, and it evolves in time according to a wavelike equation (the Schrödinger equation). The wave function and its time-evolution account for the wave aspect of quantum theory. The particle aspect of the theory comes from the interpretation of the wave function. Although it is tempting to interpret the wave function as a sort of cloud, where we have, say, a little bit of electron-cloud over here, and little bit of electron-cloud over there, this interpretation is not consistent with experiment. Whenever we attempt to measure the position of a single electron, we always find the electron at a single point. A single electron in the two-slit experiment is observed at a single point on the screen, not spread out over the screen the way the wave function is. The wave function does not describe something that is directly observable for a single particle; rather, the wave function determines the statistical behavior of a whole sequence of identically prepared particles. See Fig.​ 1.​4 for a dramatic experimental demonstration of this effect.

In the two-slit experiment, for example, it is possible to determine how the wave function behaves as a function of time by solving the (deterministic) Schrödinger equation. Knowledge of the wave function of an individual electron, however, does not determine where that electron will hit the screen. The wave function merely tells us the probability distribution for where the electron might hit the screen, something that is only observable by shooting a whole sequence of electrons at the screen.

It is an oversimplification, but a useful one, to describe the wave–particle aspect of quantum theory in this way: a single electron (or photon, or whatever) acts like a particle, but a large collection of electrons behaves like a wave. A single measurement of a single electron always gives its position as a point, just as we would expect for a particle. This point, however, varies from one electron to the next, even if we shoot each electron toward the screen in precisely the same way. Repeated measurements of identically prepared electrons give a distribution that can, for example, exhibit interference patterns, just as we would expect for a wave. See, again, Fig.​ 1.​4, which should be compared to Figs.​ 1.​1 and 1.​2

It is interesting to note that at the macroscopic scale, where quantum effects are not apparent, light appears to be a wave, whereas electrons appear to be particles. This is the case even though both light and electrons are really wave–particle hybrids, described in probabilistic terms by a wave function. The difference between the two situations is that photons (the particles of light) have mass zero, whereas electrons have positive mass. This means that photons, unlike electrons, can easily be created and destroyed even at low energies. Thus, the discrete aspect of light—namely, that the energy in light comes only in discrete "quanta," namely the photons—is less evident than the corresponding discrete aspect of electrons.

## 3.2 A Few Words About Operators and Their Adjoints

In quantum mechanics, physical quantities—such as position, momentum, and energy—are represented by operators on a certain Hilbert space H. These operators are unbounded operators, reflecting that in classical mechanics, these quantities are unbounded functions on the classical phase space. In this section, we look briefly at some technical issues related to unbounded operators and their adjoints. We will delay a full discussion of these technicalities (Chap.​ 9) until after we have understood the basic ideas of quantum mechanics.

Here and throughout the book, H will represent a Hilbert space over ![
$$\\mathbb{C},$$
](A272900_1_En_3_Chapter_IEq3.gif) always assumed to be separable. We follow the convention in the physics literature that the inner product be linear in the second factor:

![
$$\\displaystyle{\\left \\langle \\phi,\\lambda \\psi \\right\\rangle =\\lambda \\left \\langle \\phi,\\psi \\right\\rangle ;\\quad \\left \\langle \\lambda \\phi,\\psi \\right\\rangle =\\bar{\\lambda } \\left \\langle \\phi,\\psi \\right\\rangle }$$
](A272900_1_En_3_Chapter_Equa.gif)

for all ![
$${\\phi},\\psi\\ \\in\\ \\text{H}$$
](A272900_1_En_3_Chapter_IEq680.gif) and all ![
$$\\lambda \\in \\mathbb{C}.$$
](A272900_1_En_3_Chapter_IEq4.gif)

Recall (Appendix A.3.4) that a linear operator A : H → H is bounded if there is a constant C such that ![
$$\\left \\Vert A\\psi \\right\\Vert \\leq C \\ \\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_3_Chapter_IEq5.gif) for all ![
$$\\psi \\ \\in \\ H$$
](A272900_1_En_3_Chapter_IEq664.gif). For any bounded operator A, there is a unique bounded operator A ∗, called the adjoint of A, such that

![
$$\\displaystyle{\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_3_Chapter_Equb.gif)

for all ![
$${\\phi},\\psi\\ \\in\\ \\text{H}$$
](A272900_1_En_3_Chapter_IEq602.gif). The existence of A ∗ follows from the Riesz theorem (Appendix A.4.3), by observing that for each fixed ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq604.gif), the map ![
$$\\psi \\mapsto \\left \\langle \\phi,A\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq6.gif) is a bounded linear functional on H. A bounded operator is said to be self-adjoint if A ∗ = A.

For various reasons, both physical and mathematical, we want the operators of quantum mechanics operators to be self-adjoint. Once one sees the formulas for these operators, however, one is confronted with a serious technical difficulty: the operators are not bounded.

If A is a linear operator defined on all of H and having the property that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq7.gif) for all ![
$${\\phi},\\psi\\ \\in\\ \\text{H}$$
](A272900_1_En_3_Chapter_IEq658.gif), then A is automatically bounded. (See Corollary 9.9.) To put this fact the other way around, an unbounded self-adjoint operator cannot be defined on the entire Hilbert space. Thus, to deal with the unbounded operators of quantum mechanics, we must deal with operators that are defined only on a subspace of the relevant Hilbert space, called the domain of the operator.

Definition 3.1

An unbounded operator A on H is a linear map from a dense subspace Dom(A) ⊂ H into H.

More precisely, the operator A is "not necessarily bounded," since nothing in the definition prevents us from having Dom(A) = H and having A be bounded.

In defining the adjoint of an unbounded operator, we immediately encounter a difficulty: for a given ![
$$ \\phi \\in \\mathbf{H}$$
](A272900_1_En_3_Chapter_IEq010.gif), the linear functional ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq8.gif) may not be bounded, in which case we cannot use the Riesz theorem to define ![
$$ {A}^*\\phi$$
](A272900_1_En_3_Chapter_IEq350.gif). What this means is that the adjoint of A, like A itself, will be defined not on all of H but only on some subspace thereof.

Definition 3.2

For an unbounded operator A on H, the adjoint A ∗ of A is defined as follows. A vector ![
$$ \\phi \\in \\mathbf{H}$$
](A272900_1_En_3_Chapter_IEq351.gif) belongs to the domain Dom(A ∗) of A ∗ if the linear functional

![
$$\\displaystyle{\\left \\langle \\phi,A\\cdot \\right\\rangle,}$$
](A272900_1_En_3_Chapter_Equc.gif)

defined on Dom(A), is bounded. For ![
$$\\phi \\in $$
](A272900_1_En_3_Chapter_IEq352.gif) Dom(A ∗), let ![
$$ {\\boldsymbol A}^ * \\phi$$
](A272900_1_En_3_Chapter_IEq353.gif) be the unique vector χ such that

![
$$\\displaystyle{\\left \\langle \\chi,\\psi \\right\\rangle = \\left \\langle \\phi,A\\psi \\right\\rangle }$$
](A272900_1_En_3_Chapter_Equd.gif)

for all ![
$$\\psi \\ \\in \\ Dom\(A\)$$
](A272900_1_En_3_Chapter_IEq665.gif)

Saying that the linear functional ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq9.gif) is bounded means that there is a constant C such that ![
$$\\left \\vert \\left \\langle \\phi,A\\psi \\right\\rangle \\right\\vert \\leq C\\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_3_Chapter_IEq10.gif) for all ![
$$\\psi \\ \\in \\ Dom\(A\)$$
](A272900_1_En_3_Chapter_IEq666.gif). If ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq11.gif) is bounded, then since Dom(A) is dense, the BLT theorem (Theorem A.36) tells us that ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq12.gif) has a unique bounded extension to all of H. The Riesz theorem then guarantees the existence and uniqueness of χ. The adjoint of an unbounded linear operator is a linear operator on its domain.

We are now ready to define self-adjointness (and some related notions) for unbounded operators.

Definition 3.3

An unbounded operator A on H is symmetric if

![
$$\\displaystyle{\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_3_Chapter_Eque.gif)

for all ![
$$\\phi, \\psi \\ \\in \\ \\text{Dom\(A\)}$$
](A272900_1_En_3_Chapter_IEq659.gif). The operator A is self-adjoint if Dom(A ∗) = Dom(A) and ![
$$A^*\\phi \\ = \\ A\\phi$$
](A272900_1_En_3_Chapter_IEq631.gif) for all ![
$$\\phi \\ \\in \\ Dom\(A\)$$
](A272900_1_En_3_Chapter_IEq661.gif). Finally, A is essentially self-adjoint if the closure in H × H of the graph of A is the graph of a self-adjoint operator.

That is to say, A is self-adjoint if A ∗ and A are the same operator with the same domain. Every self-adjoint or essentially self-adjoint operator is symmetric, but not every symmetric operator is essentially self-adjoint. For any symmetric operator, Dom(A ∗) ⊃ Dom(A) and A ∗ agrees with A on Dom(A). The reason a symmetric operator may fail to be self-adjoint is that Dom(A ∗) may be strictly larger than Dom(A).

Although the condition of being symmetric is certainly easier to understand (and to verify) than the condition of being self-adjoint, self-adjointness is the "right" condition. In particular, the spectral theorem, which is essential to much of quantum mechanics, applies only to operators that are self-adjoint and not to operators that are merely symmetric. If A is essentially self-adjoint, then we can obtain a self-adjoint operator from A simply by taking the closure of the graph of A, and we can then apply the spectral theorem to this self-adjoint operator. Thus, for may purposes, it is enough to have our operators be essentially self-adjoint rather than self-adjoint.

It is generally easy to verify that the operators of quantum mechanics (those representing position, momentum, and so forth) are symmetric on some suitably chosen domain. Proving that these operators are essentially self-adjoint, however, is substantially more difficult. Although establishing essential self-adjointness is a crucial technical issue, it is best not to worry too much about it on a first encounter with quantum mechanics. In this chapter, we will not concern ourselves overly with technical details concerning essential self-adjointness and the precise choice of domain for our operators, depending on Chap.​ 9 to take care of such matters. For now, we content ourselves with deriving some very elementary properties of symmetric (and thus also self-adjoint) operators.

Proposition 3.4

Suppose A is a symmetric operator on H.

1.

For all ![
$$\\psi \\ \\in \\ Dom\(A\)$$
](A272900_1_En_3_Chapter_IEq667.gif), the quantity ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq13.gif) is real. More generally, if ![
$$\\psi, A\\psi,\\ldots, A^{m-1}\\psi$$
](A272900_1_En_3_Chapter_IEq662.gif) all belong to Dom (A), then ![
$$\\left \\langle \\psi,{A}^{m}\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq14.gif) is real.

2.

Suppose λ is an eigenvector for A, meaning that ![
$$A\\psi\\ = \\ \\lambda \\psi$$
](A272900_1_En_3_Chapter_IEq663.gif) for some nonzero ![
$$\\psi \\ \\in \\ Dom\(A\)$$
](A272900_1_En_3_Chapter_IEq6640.gif). Then ![
$$\\lambda \\in \\mathbb{R}.$$
](A272900_1_En_3_Chapter_IEq15.gif)

Proof.

Since A is symmetric, we have

![
$$\\displaystyle{\\left \\langle \\psi,A\\psi \\right\\rangle = \\left \\langle A\\psi,\\psi \\right\\rangle = \\overline{\\left \\langle \\psi,A\\psi \\right\\rangle }}$$
](A272900_1_En_3_Chapter_Equf.gif)

for all ![
$$\\psi \\ \\in \\ Dom\(A\)$$
](A272900_1_En_3_Chapter_IEq668.gif). If ![
$$\\psi, A\\psi,\\ldots,A^{m-1}\\psi $$
](A272900_1_En_3_Chapter_IEq6607.gif) all belong to the domain of A, we can use the symmetry of A repeatedly to show that

![
$$\\displaystyle{\\left \\langle \\psi,{A}^{m}\\psi \\right\\rangle = \\left \\langle {A}^{m}\\psi,\\psi \\right\\rangle = \\overline{\\left \\langle \\psi,{A}^{m}\\psi \\right\\rangle }.}$$
](A272900_1_En_3_Chapter_Equg.gif)

Meanwhile, if ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq719.gif) is an eigenvector for A with eigenvalue λ, then

![
$$\\displaystyle{\\lambda \\left \\langle \\psi,\\psi \\right\\rangle = \\left \\langle \\psi,A\\psi \\right\\rangle = \\left \\langle A\\psi,\\psi \\right\\rangle =\\bar{\\lambda } \\left \\langle \\psi,\\psi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equh.gif)

Since ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq720.gif) is assumed to be nonzero, this implies that ![
$$\\lambda =\\bar{\\lambda }.$$
](A272900_1_En_3_Chapter_IEq16.gif)

Physically, ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq17.gif) represents—as we will see later in this chapter—the expectation value for measurements of A in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq721.gif), whereas the eigenvalue λ represents one of the possible values for this measurement. On physical grounds, we want both of these numbers to be real. If A is self-adjoint, and not just symmetric, then the spectral theorem will give a canonical way of associating to each ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq722.gif) ∈ H a probability measure on the real line that encodes the probabilities for measurements of A in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq723.gif).

## 3.3 Position and the Position Operator

Let us consider at first a single particle moving on the real line. The wave function for such a particle is a map ![
$$\\psi : {\\mathbb{R}}^{1} \\rightarrow \\mathbb{C}.$$
](A272900_1_En_3_Chapter_IEq18.gif) Although this map will evolve in time, let us think for now that the time is fixed. The function ![
$${\\left \\vert \\psi \(x\)\\right\\vert }^{2}$$
](A272900_1_En_3_Chapter_IEq19.gif) is supposed to be the probability density for the position of the particle. This means that the probability that the position of the particle belongs to some set ![
$$E \\subset {\\mathbb{R}}^{1}$$
](A272900_1_En_3_Chapter_IEq20.gif) is

![
$$\\displaystyle{\\int _{E}{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx.}$$
](A272900_1_En_3_Chapter_Equi.gif)

For this prescription to make sense, ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq724.gif) should be normalized so that

![
$$\\displaystyle{ \\int _{\\mathbb{R}}{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx = 1. }$$
](A272900_1_En_3_Chapter_Equ1.gif)

(3.1)

That is, ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq725.gif) should be a unit vector in the Hilbert space ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq21.gif)

Now, if the function ![
$${\\left \\vert \\psi \(x\)\\right\\vert }^{2}$$
](A272900_1_En_3_Chapter_IEq22.gif) is the probability density for the position of a particle, then according to the standard definitions of probability theory, the expectation value of the position will be

![
$$\\displaystyle{ E\(x\) =\\int _{\\mathbb{R}}x{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx, }$$
](A272900_1_En_3_Chapter_Equ2.gif)

(3.2)

provided that the integral is absolutely convergent. More generally, we can compute any moment of the position (i.e., the expectation value of some power of the position) as

![
$$\\displaystyle{ E\({x}^{m}\) =\\int _{ \\mathbb{R}}{x}^{m}{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx, }$$
](A272900_1_En_3_Chapter_Equ3.gif)

(3.3)

assuming, again, the convergence of the integral.

A key idea in quantum theory is to express expectation values of various quantities (position, momentum, energy, etc.) in terms of operators and the inner product on the relevant Hilbert space, in this case, ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq23.gif). In the case of position, we may introduce the position operator X defined by

![
$$\\displaystyle{\(X\\psi \)\(x\) = x\\psi \(x\).}$$
](A272900_1_En_3_Chapter_Equj.gif)

That is, X is the "multiplication by x" operator. The point of introducing this operator is that the expectation value of the position [defined in (3.2)] may now be expressed as

![
$$\\displaystyle{E\(x\) = \\left \\langle \\psi,X\\psi \\right\\rangle,}$$
](A272900_1_En_3_Chapter_Equk.gif)

where the inner product is the usual one on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq24.gif):

![
$$\\displaystyle{\\left \\langle \\phi,\\psi \\right\\rangle =\\int \\overline{\\phi \(x\)}\\psi \(x\)\\ dx.}$$
](A272900_1_En_3_Chapter_Equl.gif)

(Recall that we are following the physics convention of putting the conjugate on the first factor in the inner product.)

We use the following notation for the expectation value of the operator X in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq681.gif) :

![
$$\\displaystyle{\\left \\langle X\\right\\rangle _{\\psi } := \\left \\langle \\psi,X\\psi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equm.gif)

The higher moments of the position, as defined in (3.3), are also computable in terms of the position operator:

![
$$\\displaystyle{E\({x}^{m}\) = \\left \\langle \\psi,{X}^{m}\\psi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equn.gif)

At this point, it is not clear that we have gained anything by writing our moments in terms of an operator and the inner product instead of in terms of the integral (3.3). The operator description will, however, motivate a parallel description of moments for the momentum, energy, or angular momentum of a particle in terms of corresponding operators.

It should be noted that, for a given ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq25.gif) X ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq6683.gif) might fail to be in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq26.gif) This failure of X to be defined on all of our Hilbert space reflects that X is an unbounded operator, something that we discussed briefly in Sect. 3.2. Even if X ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq684.gif) is in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq27.gif) X m ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq685.gif) might fail to be in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq28.gif) for some m. Nevertheless, for any unit vector ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq686.gif) in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq29.gif) we have a well-defined probability density on ![
$$\\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq30.gif) given by ![
$${\\left \\vert \\psi \(x\)\\right\\vert }^{2}.$$
](A272900_1_En_3_Chapter_IEq31.gif)

## 3.4 Momentum and the Momentum Operator

At any fixed time, the wave function ![
$$\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq687.gif) of a particle (according to the wave theory postulated by Schrödinger) is a function of a "position" variable x only. Although the wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq688.gif) directly encodes the probabilities for the position of the particle, through ![
$${\\left \\vert \\psi \(x\)\\right\\vert }^{2},$$
](A272900_1_En_3_Chapter_IEq32.gif) it is not as clear how information about the particle's momentum is encoded. As it turns out, the momentum is encoded in the oscillations of the wave function. A crucial idea in quantum mechanics is the de Broglie hypothesis, which we introduced in Sect.​ 1.​2.​2 as a way of understanding the allowed energies in the Bohr model of the hydrogen atom. The de Broglie hypothesis proposes a particular relationship between the frequency of oscillation of the wave function—as a function of position at a fixed time—and its momentum.

Proposition 3.5 (de Broglie hypothesis)

If the wave function of a particle has spatial frequency k, then the momentum p of the particle is

![
$$\\displaystyle{ p = \\hslash k, }$$
](A272900_1_En_3_Chapter_Equ4.gif)

(3.4)

where ![
$$\\hslash $$
](A272900_1_En_3_Chapter_IEq33.gif) is Planck's constant.

The Davisson–Germer electron-diffraction experiments, described in Sect.​ 1.​2.​3, strongly support not only the idea that electrons have wavelike behavior, but also the specific relationship (3.4) between the momentum of an electron and the spatial frequency of the associated wave. Of course, Proposition 3.5 is rather vague. To be a bit more precise, Proposition 3.5 is supposed to mean that a wave function of the form ![
$$\\psi\(x\)\\ = \\ e^{ikx}$$
](A272900_1_En_3_Chapter_IEq689.gif) represents a particle with momentum ![
$$p = \\hslash k.$$
](A272900_1_En_3_Chapter_IEq34.gif) Here, as in [Chap.​ 9, "frequency" is in the angular sense. The cycles-per-unit-distance frequency is ![
$$\\nu = k/\(2\\pi \).$$
](A272900_1_En_3_Chapter_IEq35.gif)]

Now, the function e ikx is obviously not square integrable, so it is not strictly possible for the wave function [which is supposed to satisfy (3.1)] to be e ikx . Let us therefore briefly switch to thinking of a particle on a circle, so that we can avoid certain technicalities. We think of the wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq690.gif) for a particle on a circle as a 2π-periodic function on ![
$$\\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq36.gif) satisfying the normalization condition

![
$$\\displaystyle{\\int _{0}^{2\\pi }{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx = 1.}$$
](A272900_1_En_3_Chapter_Equo.gif)

For any integer k, it makes sense to say that the normalized wave function ![
$$\\psi \(x\) = {e}^{ikx}/\\sqrt{2\\pi }$$
](A272900_1_En_3_Chapter_IEq37.gif) represents a particle with momentum ![
$$p = \\hslash k.$$
](A272900_1_En_3_Chapter_IEq38.gif) In this case, we are supposed to think that the momentum of the particle is definite, that is, nonrandom. If the particle's wave function is ![
$${e}^{ikx}/\\sqrt{2\\pi },$$
](A272900_1_En_3_Chapter_IEq39.gif) then a measurement of the particle's momentum should (with probability 1) give the value ![
$$\\hslash k.$$
](A272900_1_En_3_Chapter_IEq40.gif)

Now, the functions ![
$${e}^{ikx}/\\sqrt{2\\pi },$$
](A272900_1_En_3_Chapter_IEq41.gif) ![
$$k \\in \\mathbb{Z},$$
](A272900_1_En_3_Chapter_IEq42.gif) form an orthonormal basis for the Hilbert space of 2π-periodic, square-integrable functions, which may be identified with L 2([0, 2π]). Thus, the typical wave function for a particle on a circle is

![
$$\\displaystyle{ \\psi \(x\) =\\sum _{ k=-\\infty }^{\\infty }a_{ k}\\frac{{e}^{ikx}} {\\sqrt{2\\pi }}, }$$
](A272900_1_En_3_Chapter_Equ5.gif)

(3.5)

where the sum is convergent in L 2([0, 2π]). If ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq691.gif) is normalized to be a unit vector, then we have

![
$$\\displaystyle{ \\sum _{k=-\\infty }^{\\infty }{\\left \\vert a_{ k}\\right\\vert }^{2} = \\left \\Vert \\psi \\right\\Vert _{{ L}^{2}\(\[0,2\\pi \]\)}^{2} = 1. }$$
](A272900_1_En_3_Chapter_Equ6.gif)

(3.6)

For a particle with wave function given by (3.5), the momentum of the particle is no longer definite. Rather, we are supposed to think that a measurement of the particle's momentum will yield one of the values ![
$$\\hslash k,$$
](A272900_1_En_3_Chapter_IEq43.gif) ![
$$k \\in \\mathbb{Z},$$
](A272900_1_En_3_Chapter_IEq44.gif) with the probability of getting a particular value ![
$$\\hslash k$$
](A272900_1_En_3_Chapter_IEq45.gif) being ![
$${\\left \\vert a_{k}\\right\\vert }^{2}.$$
](A272900_1_En_3_Chapter_IEq46.gif) Following elementary probability theory, then, the expectation values for the momentum should be

![
$$\\displaystyle{ E\(p\) =\\sum _{ k=-\\infty }^{\\infty }\\hslash k{\\left \\vert a_{ k}\\right\\vert }^{2}, }$$
](A272900_1_En_3_Chapter_Equ7.gif)

(3.7)

and higher moments for the momentum should be

![
$$\\displaystyle{ E\({p}^{m}\) =\\sum _{ k=-\\infty }^{\\infty }{\(\\hslash k\)}^{m}{\\left \\vert a_{ k}\\right\\vert }^{2}, }$$
](A272900_1_En_3_Chapter_Equ8.gif)

(3.8)

assuming absolute convergence of the sum.

We would like to encode the moment conditions (3.7) and (3.8) in a momentum operator P, which should be defined in such a way that if the particle's wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq692.gif) is given by (3.5), then ![
$$E\({p}^{m}\) = \\left \\langle \\psi,{P}^{m}\\psi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq47.gif) We can achieve this relation if P satisfies

![
$$\\displaystyle{ P{e}^{ikx} = \\hslash k{e}^{ikx}, }$$
](A272900_1_En_3_Chapter_Equ9.gif)

(3.9)

since then,

![
$$\\displaystyle{ \\left \\langle \\psi,{P}^{m}\\psi \\right\\rangle =\\sum _{ k=-\\infty }^{\\infty }{\(\\hslash k\)}^{m}{\\left \\vert a_{ k}\\right\\vert }^{2} = E\({p}^{m}\). }$$
](A272900_1_En_3_Chapter_Equ10.gif)

(3.10)

The (presumably unique) choice for P satisfying (3.9) is

![
$$\\displaystyle{P = -i\\hslash \\frac{d} {dx}.}$$
](A272900_1_En_3_Chapter_Equp.gif)

Returning now to the setting of the real line, it is natural to postulate that the momentum operator P on the line should also be given by ![
$$P = -i\\hslash \\ d/dx.$$
](A272900_1_En_3_Chapter_IEq48.gif) This operator satisfies the relation

![
$$\\displaystyle{P{e}^{ikx} = \(\\hslash k\){e}^{ikx},}$$
](A272900_1_En_3_Chapter_Equq.gif)

which is supposed to capture the idea that the wave function e ikx has momentum ![
$$\\hslash k.$$
](A272900_1_En_3_Chapter_IEq49.gif) Although the function e ikx is not square-integrable with respect to x, the Fourier transform allows us to build up any square-integrable function as a "superposition" of functions of the form e ikx . (Superposition is the term physicists use for a linear combination or the continuous analog thereof, namely an integral.) This means that [by analogy to (3.5)] we have

![
$$\\displaystyle{ \\psi \(x\) = \\frac{1} {\\sqrt{2\\pi }}\\int _{-\\infty }^{\\infty }{e}^{ikx}\\hat{\\psi }\(k\)\\ dk, }$$
](A272900_1_En_3_Chapter_Equ11.gif)

(3.11)

where ![
$$\\hat{\\psi }\(k\)$$
](A272900_1_En_3_Chapter_IEq50.gif) is the Fourier transform of ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq693.gif), defined by

![
$$\\displaystyle{ \\hat{\\psi }\(k\) = \\frac{1} {\\sqrt{2\\pi }}\\int _{-\\infty }^{\\infty }{e}^{-ikx}\\psi \(x\)\\ dx. }$$
](A272900_1_En_3_Chapter_Equ12.gif)

(3.12)

(See Appendix A.3.2 for information about the Fourier transform.)

The Plancherel theorem (Theorem A.19) then tells us that the Fourier transform is a unitary map of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq51.gif) onto ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq52.gif) Thus, for any unit vector ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq53.gif)

![
$$\\displaystyle{\\int _{-\\infty }^{\\infty }{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx =\\int _{ -\\infty }^{\\infty }{\\left \\vert \\hat{\\psi }\(k\)\\right\\vert }^{2}\\ dk = 1.}$$
](A272900_1_En_3_Chapter_Equr.gif)

In light of what we have in the circle case, it is natural to think that ![
$$\\vert \\hat{\\psi }\(k\){\\vert }^{2}$$
](A272900_1_En_3_Chapter_IEq54.gif) is essentially the probability density for the momentum of the particle. (To be precise, ![
$$\\vert \\hat{\\psi }\(k\){\\vert }^{2}$$
](A272900_1_En_3_Chapter_IEq55.gif) is the probability density for ![
$$p/\\hslash.$$
](A272900_1_En_3_Chapter_IEq56.gif))

We can now express the properties of the momentum operator entirely within the Hilbert space ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq57.gif) without making explicit mention of the non–square-integrable functions e ikx .

Proposition 3.6

Define the momentum operator P by

![
$$\\displaystyle{P = -i\\hslash \\frac{d} {dx}.}$$
](A272900_1_En_3_Chapter_Equs.gif)

Then for all sufficiently nice unit vectors ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq694.gif) in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq58.gif) we have

![
$$\\displaystyle{ \\left \\langle \\psi,{P}^{m}\\psi \\right\\rangle =\\int _{ -\\infty }^{\\infty }{\(\\hslash k\)}^{m}{\\left \\vert \\hat{\\psi }\(k\)\\right\\vert }^{2}\\ dk }$$
](A272900_1_En_3_Chapter_Equ13.gif)

(3.13)

for all positive integers m. The quantity in (3.13) is interpreted as the expectation value of the mth power of the momentum, E(p m ).

Equation (3.13) should be compared to (3.10) in the case of the circle.

Proof.

If ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq695.gif) is in, say, the Schwartz space (Definition A.15), then, by applying Proposition A.17 m times, we see that the Fourier transform of the nth derivative of ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq696.gif) is ![
$${\(ik\)}^{m}\\hat{\\psi }\(k\)$$
](A272900_1_En_3_Chapter_IEq59.gif), and so the Fourier transform of ![
$$P^{m}\\psi$$
](A272900_1_En_3_Chapter_IEq697.gif) is ![
$${\(\\hslash k\)}^{m}\\hat{\\psi }\(k\).$$
](A272900_1_En_3_Chapter_IEq60.gif) Meanwhile, since the Fourier transform is unitary, we have

![
$$\\displaystyle{\\left \\langle \\psi,{P}^{m}\\psi \\right\\rangle =\\int _{ -\\infty }^{\\infty }\\overline{\\hat{\\psi }\(k\)}{\(\\hslash k\)}^{m}\\hat{\\psi }\(k\)\\ dk,}$$
](A272900_1_En_3_Chapter_Equt.gif)

which gives (3.13). (The assumption that ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq698.gif) be in the Schwartz space is stronger than necessary. The reader is invited to use integration by parts and the definition of the Fourier transform to find weaker assumptions that allow the same conclusion.)

## 3.5 The Position and Momentum Operators

In the following definition, we summarize what we have learned, in the two previous sections, about the position and momentum operators.

Definition 3.7

For a particle moving in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_3_Chapter_IEq61.gif) let the quantum Hilbert space be ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq62.gif) and define the position and momentum operators X and P by

![
$$\\displaystyle\\begin{array}{rcl} X\\psi \(x\)& =& x\\psi \(x\) {}\\\\ P\\psi \(x\)& =& -i\\hslash \\frac{d\\psi } {dx}. {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ14.gif)

Neither the position nor the momentum operator is defined as mapping the entire Hilbert space ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq63.gif) into itself. After all, for ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq64.gif) the function ![
$$x\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq699.gif) may fail to be in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq65.gif) Similarly, a function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq700.gif) in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq66.gif) may fail to be differentiable, and even if it is differentiable, the derivative may fail to be in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq67.gif) What this means is that X and P are unbounded operators, of the sort discussed briefly in Sect. 3.2. They are defined on suitable dense subspaces Dom(X) and Dom(P) of ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq68.gif) We defer a detailed examination of the domains of these operators until Chap.​ 9.

A vitally important property of this pair of operators is that they do not commute.

Proposition 3.8

The position and momentum operators X and P do not commute, but satisfy the relation

![
$$\\displaystyle{ XP - PX = i\\hslash I, }$$
](A272900_1_En_3_Chapter_Equ15.gif)

(3.14)

This relation is known as the canonical commutation relation.

Proof.

Using the product rule we calculate that

![
$$\\displaystyle\\begin{array}{rcl} PX\\psi & =& -i\\hslash \\frac{d} {dx}\\left \(x\\psi \(x\)\\right\) {}\\\\ & =& -i\\hslash \\psi \(x\) - i\\hslash x \\frac{d\\psi } {dx} {}\\\\ & =& -i\\hslash \\psi \(x\) + XP\\psi, {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ16.gif)

from which (3.14) follows.

There are many important consequences of the relation (3.14), which we will examine at length in Chaps.​ 11–  of the book. For now, we simply note a parallel between (3.14) and the Poisson bracket relationship in classical mechanics: ![
$$\\left \\{x,p\\right\\} = 1,$$
](A272900_1_En_3_Chapter_IEq69.gif) as follows directly from the definition of the Poisson bracket. This hints at an analogy, which we will explore further in Sect. 3.7, between the commutator of two operators A and B on the quantum side (namely, the operator AB − BA) and the Poisson bracket of two functions f and g on the classical side.

Proposition 3.9

For all sufficiently nice functions ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq801.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq701.gif) in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq70.gif) we have

![
$$\\displaystyle{\\left \\langle \\phi,X\\psi \\right\\rangle = \\left \\langle X\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_3_Chapter_Equu.gif)

and

![
$$\\displaystyle{\\left \\langle \\phi,P\\psi \\right\\rangle = \\left \\langle P\\phi,\\psi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equv.gif)

Proof.

Suppose that ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq802.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq702.gif) belong to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq71.gif) and that the functions ![
$$x\\phi\(x\)$$
](A272900_1_En_3_Chapter_IEq806.gif) and ![
$$x\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq807.gif) also belong to ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq72.gif) Then since x is real, we have

![
$$\\displaystyle{\\int _{-\\infty }^{\\infty }\\overline{\\phi \(x\)}x\\psi \(x\)\\ dx =\\int _{ -\\infty }^{\\infty }\\overline{x\\phi \(x\)}\\psi \(x\)\\ dx,}$$
](A272900_1_En_3_Chapter_Equw.gif)

where both integrals are convergent because they are both integrals of the product of two L 2 functions.

Meanwhile, for the second claim, let us assume that ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq803.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq703.gif) are continuously differentiable and that ![
$$\\phi\(x\)$$
](A272900_1_En_3_Chapter_IEq808.gif) and ![
$$\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq809.gif) tend to zero as x tends to ± ∞. Let us also assume that ![
$$\\phi, \\ {\\psi, \\ d{\\phi}/}dx $$
](A272900_1_En_3_Chapter_IEq810.gif) and ![
$$d\\psi/dx $$
](A272900_1_En_3_Chapter_IEq811.gif) belong to ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq73.gif) We note that ![
$$d\\bar{\\phi }/dx$$
](A272900_1_En_3_Chapter_IEq74.gif) is the same as ![
$$\\overline{d\\phi /dx}.$$
](A272900_1_En_3_Chapter_IEq75.gif) Thus, using integration by parts, we obtain

![
$$\\displaystyle{-i\\hslash \\int _{-A}^{A}\\overline{\\phi \(x\)} \\frac{d\\psi } {dx}\\ dx = -i\\hslash \\left.\\overline{\\phi \(x\)}\\psi \(x\)\\right\\vert _{-A}^{A} + i\\hslash \\int _{ -A}^{A}\\overline{ \\frac{d\\phi } {dx}}\\psi \(x\)\\ dx.}$$
](A272900_1_En_3_Chapter_Equx.gif)

Under our assumptions on ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq804.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq704.gif), as A tends to infinity, the boundary terms will vanish and the remaining integrals will tend (by dominated convergence) to integrals over the whole real line. Thus,

![
$$\\displaystyle\\begin{array}{rcl} \\int _{-\\infty }^{\\infty }\\overline{\\phi \(x\)}\\left \(-i\\hslash \\frac{d\\psi } {dx}\\right\)\\ dx& =& i\\hslash \\int _{-\\infty }^{\\infty }\\overline{ \\frac{d\\phi } {dx}}\\psi \(x\)\\ dx {}\\\\ & =& \\int _{-\\infty }^{\\infty }\\overline{\\left \(-i\\hslash \\frac{d\\phi } {dx}\\right\)}\\psi \(x\)\\ dx, {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ17.gif)

which is the second claim in the proposition.

In the language of Definition 3.3, Proposition 3.9 means that X and P are symmetric operators on certain dense subspaces of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq76.gif) (the space of functions for which the proposition is proved). It is actually true that X and P are essentially self-adjoint on these domains. The proof of essential self-adjointness, however, will have to wait until Chap.​ 9.

## 3.6 Axioms of Quantum Mechanics: Operators and Measurements

In this section we consider the general "axioms" of quantum mechanics. These axioms are not to be understood in the mathematical sense as rules from which all other results are derived in a strictly deductive fashion. Rather, the axioms are the main principles of how quantum mechanics works. Here we look at the "kinematic" axioms, those that apply at one fixed time. There is one additional axiom, governing the time-evolution of the system, which we consider in the next section.

Axiom 1

The state of the system is represented by a unit vector ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq705.gif) in an appropriate Hilbert space ![
$$\\mathbf{H}.$$
](A272900_1_En_3_Chapter_IEq77.gif) If ![
$$\\psi_1$$
](A272900_1_En_3_Chapter_IEq706.gif) and ![
$$\\psi_2$$
](A272900_1_En_3_Chapter_IEq821.gif) are two unit vectors in H with ![
$$\\psi_2 \\ = c\\psi_1$$
](A272900_1_En_3_Chapter_IEq822.gif) for some constant ![
$$c \\in \\mathbb{C}$$
](A272900_1_En_3_Chapter_IEq78.gif) , then ![
$$\\psi_1$$
](A272900_1_En_3_Chapter_IEq823.gif) and ![
$$\\psi_2$$
](A272900_1_En_3_Chapter_IEq824.gif) represent the same physical state.

The Hilbert space H is frequently called the "quantum Hilbert space." This does not, however, mean that H is some variant of the notion of a Hilbert space, the way a quantum group is a variant of the notion of a group. Rather, "quantum Hilbert space" means simply, "the Hilbert space associated with a given quantum system."

In Axiom 1, it should be noted that unit vectors in H actually represent only the "pure states" of the theory. There is a more general notion of a "mixed state" (described by a "density matrix") that we will consider in Chap.​ 19. We will follow the custom in most physics texts of considering at first only pure states.

Axiom 2

To each real-valued function f on the classical phase space there is associated a self-adjoint operator ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq79.gif) on the quantum Hilbert space.

In almost all cases, the operator ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq80.gif) is unbounded. This unboundedness is unsurprising when we realize that physically relevant functions f on the classical phase space (e.g., position and momentum) are unbounded functions. In the unbounded case, the notion of self-adjointness is rather technical; see Definition 3.3 in Sect. 3.2. In most applications, it is not really necessary to define ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq81.gif) for all functions on the classical phase space, but only for certain basic functions, such as position, momentum, energy, and angular momentum. We will describe the quantizations of these basic functions in this chapter. If one really needs to define ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq82.gif) for an arbitrary function f (satisfying some regularity assumptions), the standard approach is to use the Weyl quantization scheme, described in Chap.​ 13

For a particle moving in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_3_Chapter_IEq83.gif) the classical phase space is ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_3_Chapter_IEq84.gif) which we think of as pairs (x, p) with x being the particle's position and p being its momentum. The quantum Hilbert space in this case is usually taken to be ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq85.gif) [ not ![
$${L}^{2}\({\\mathbb{R}}^{2}\)$$
](A272900_1_En_3_Chapter_IEq86.gif)]. In that case, if the function f in Axiom 2 is the position function, f(x, p) = x, then the associated operator ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq87.gif) is the position operator X, given by multiplication by x. If f is the momentum function, f(x, p) = p, then ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq88.gif) is the momentum operator ![
$$P = -i\\hslash \\ d/dx.$$
](A272900_1_En_3_Chapter_IEq89.gif)

In the physics literature, a function f on the classical phase space is called a classical observable, meaning that it is some physical quantity that could be observed by taking a measurement of the system. The corresponding operator ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq90.gif) is then called a quantum observable.

Axiom 3

If a quantum system is in a state described by a unit vector ![
$$\\psi \\ \\in \\ \\bf{H}$$
](A272900_1_En_3_Chapter_IEq826.gif) , the probability distribution for the measurement of some observable f satisfies

![
$$\\displaystyle{ E\({f}^{m}\) = \\left \\langle \\psi,{\(\\hat{f}\)}^{m}\\psi \\right\\rangle. }$$
](A272900_1_En_3_Chapter_Equ18.gif)

(3.15)

In particular, the expectation value for a measurement of f is given by

![
$$\\displaystyle{ \\left \\langle \\psi,\\hat{f}\\psi \\right\\rangle. }$$
](A272900_1_En_3_Chapter_Equ19.gif)

(3.16)

Note that we have adopted the point of view that even in a quantum mechanical system, what one is measuring is the classical observable f. In the quantum case, however, f no longer has a definite value, but only probabilities, which are encoded by the quantum observable ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq91.gif) and the vector ![
$$\\psi \\ \\in \\ \\bf{H}$$
](A272900_1_En_3_Chapter_IEq827.gif).

If ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq707.gif) is a nonzero vector in H but not a unit vector, then (3.16) should be replaced by

![
$$\\displaystyle{\\frac{\\left \\langle \\psi,\\hat{f}\\psi \\right\\rangle } {\\left \\langle \\psi,\\psi \\right\\rangle } = \\left \\langle \\tilde{\\psi },\\hat{f}\\tilde{\\psi }\\right\\rangle,}$$
](A272900_1_En_3_Chapter_Equy.gif)

where ![
$$\\tilde{\\psi }:=\\psi /\\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_3_Chapter_IEq92.gif) is the unit vector associated with ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq708.gif). It is convenient to assume that our vectors have been normalized to be unit vectors, simply to avoid having to divide by ![
$$\\left \\langle \\psi,\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq93.gif) in our expectation values.

Since ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq94.gif) is assumed to be self-adjoint and every self-adjoint operator is symmetric, Proposition 3.4 tells us that the moments E(f m ), and in particular the expectation value E(f), are real numbers. Since ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq95.gif) is assumed to be self-adjoint and not just symmetric, the spectral theorem (Chaps.​ 7 and ) will give a canonical way of constructing a probability measure ![
$$\\mu_{A,\\psi}$$
](A272900_1_En_3_Chapter_IEq8264.gif) on ![
$$\\mathbb{R}$$
](A272900_1_En_3_Chapter_IEq96.gif) that may be interpreted as the probability distribution for measurements of A in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq711.gif).

Axiom 3 provides motivation for the idea that two unit vectors that differ by a constant represent the same physical state. If ![
$$\\psi_2\\ = c\\psi1$$
](A272900_1_En_3_Chapter_IEq8271.gif) with ![
$$\\left \\vert c\\right\\vert = 1,$$
](A272900_1_En_3_Chapter_IEq97.gif) then for any operator A, we have

![
$$\\displaystyle{\\left \\langle \\psi _{2},A\\psi _{2}\\right\\rangle = \\left \\langle c\\psi _{1},Ac\\psi _{1}\\right\\rangle ={ \\left \\vert c\\right\\vert }^{2}\\left \\langle \\psi _{ 1},A\\psi _{1}\\right\\rangle = \\left \\langle \\psi _{1},A\\psi _{1}\\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equz.gif)

Thus, the expectation values of all observables are the same in the state ![
$$\\psi_2$$
](A272900_1_En_3_Chapter_IEq851.gif) as in the state ![
$$\\psi_1$$
](A272900_1_En_3_Chapter_IEq852.gif).

Notation 3.10

If A is a self-adjoint operator on H and ![
$$\\psi \\ \\in \\ {\\bf{H}}$$
](A272900_1_En_3_Chapter_IEq853.gif) is a unit vector, the expectation value of A in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq854.gif) is denoted ![
$$\\left \\langle A\\right\\rangle _{\\psi }$$
](A272900_1_En_3_Chapter_IEq98.gif) and is defined (in light of Axiom 3) to be

![
$$\\displaystyle{ \\left \\langle A\\right\\rangle _{\\psi } = \\left \\langle \\psi,A\\psi \\right\\rangle. }$$
](A272900_1_En_3_Chapter_Equ20.gif)

(3.17)

Proposition 3.11 (Eigenvectors)

If a quantum system is in a state described by a unit vector ![
$$\\psi \\ \\in \\ H$$
](A272900_1_En_3_Chapter_IEq401.gif) and for some quantum observable ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq99.gif) we have ![
$$\\hat{f}\\psi =\\lambda \\psi$$
](A272900_1_En_3_Chapter_IEq100.gif) for some ![
$$\\lambda \\in \\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq101.gif) then

![
$$\\displaystyle{ E\({f}^{m}\) = \\left \\langle {\(\\hat{f}\)}^{m}\\right\\rangle _{ \\psi } {=\\lambda }^{m} }$$
](A272900_1_En_3_Chapter_Equ21.gif)

(3.18)

for all positive integers m. The unique probability measure consistent with this condition is the one in which f has the definite value λ, with probability one.

What the proposition means is that if ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq712.gif) is an eigenvector for ![
$$\\hat{f},$$
](A272900_1_En_3_Chapter_IEq102.gif) then measurements of f for a particle in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq713.gif) are not actually random, but rather always give the answer of λ. If ![
$$\\hat{f}\\psi =\\lambda \\psi,$$
](A272900_1_En_3_Chapter_IEq103.gif) then ![
$$\\left \\langle \\psi,{\(\\hat{f}\)}^{m}\\psi \\right\\rangle {=\\lambda }^{m}\\left \\langle \\psi,\\psi \\right\\rangle {=\\lambda }^{m}.$$
](A272900_1_En_3_Chapter_IEq104.gif) Thus, by (3.15), we want to find a probability measure μ on ![
$$\\mathbb{R}$$
](A272900_1_En_3_Chapter_IEq105.gif) such that

![
$$\\displaystyle{ \\int _{\\mathbb{R}}{x}^{m}\\ d\\mu {=\\lambda }^{m}, }$$
](A272900_1_En_3_Chapter_Equ22.gif)

(3.19)

for all non-negative integers m. The proposition is claiming that there is one and only one such measure, namely the δ-measure at the point λ.

Because ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq106.gif) is assumed to be self-adjoint and therefore symmetric, Proposition 3.4 thus tells us that the every eigenvalue for ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq107.gif) is real.

Proof.

The relation (3.18) follows from (3.15) and the fact that ![
$$\\hat{f}\\psi =\\lambda \\psi.$$
](A272900_1_En_3_Chapter_IEq108.gif) Meanwhile, if μ is the δ-measure at λ, then certainly (3.19) holds. Meanwhile, since the mth moment grows only exponentially with m, even the most elementary uniqueness results for the moment problem show that the δ-measure is the only measure with these moments. (See, e.g., Theorem 8.1 in Chap.​ 4 of [18].)

If, more generally, the state of the system is a linear combination of eigenvectors for ![
$$\\hat{f},$$
](A272900_1_En_3_Chapter_IEq109.gif) measurements of f will no longer be deterministic.

Example 3.12

Suppose ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq110.gif) has an orthonormal basis {e j } of eigenvectors with distinct (real) eigenvalues λ j . Suppose also that ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq714.gif) is a unit vector in H with the expansion

![
$$\\displaystyle{ \\psi =\\sum _{ j=1}^{\\infty }a_{ j}e_{j}. }$$
](A272900_1_En_3_Chapter_Equ23.gif)

(3.20)

Then for a measurement in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq715.gif) of the observable f, the observed value of f will always be one of the numbers λ j . Furthermore, the probability of observing the value λ j is given by

![
$$\\displaystyle{ \\mathrm{Prob}\\{f =\\lambda _{j}\\} ={ \\left \\vert a_{j}\\right\\vert }^{2}. }$$
](A272900_1_En_3_Chapter_Equ24.gif)

(3.21)

Assuming that ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq716.gif) is in the domain of ![
$${\(\\hat{f}\)}^{m},$$
](A272900_1_En_3_Chapter_IEq111.gif) it is easy to verify that the probabilities in (3.21) are consistent with the expectation values given in Axiom 3. After all, if ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq717.gif) is given as in (3.20), then we can readily calculate that ![
$$\\langle \\psi,{\(\\hat{f}\)}^{m}\\psi \\rangle$$
](A272900_1_En_3_Chapter_IEq112.gif) equals ![
$$\\sum {\\left \\vert a_{j}\\right\\vert }^{2}\\lambda _{j}^{m},$$
](A272900_1_En_3_Chapter_IEq113.gif) which is nothing but the mth moment associated with the probability distribution in (3.21). In general, we cannot quite derive (3.21) from Axiom 3, since the uniqueness results for the moment problem might not apply. Nevertheless, (3.21) is the most natural candidate for the probabilities, and we will assume that this formula holds.

It is not difficult to extend Example 3.12 to the case where the eigenvalues are not distinct: For any sequence {λ j } of eigenvalues, the probability of observing some value λ will be the sum of ![
$${\\left \\vert a_{j}\\right\\vert }^{2}$$
](A272900_1_En_3_Chapter_IEq114.gif) over all those values of j for which λ j = λ. For any self-adjoint operator A, the spectral theorem implies that A has either an orthonormal basis of eigenvectors or some continuous analog thereof. In particular, given a self-adjoint operator A and a unit vector ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq718.gif) ∈ H, the spectral theorem will give us a probability measure ![
$$\\mu^A_\\psi$$
](A272900_1_En_3_Chapter_IEq440.gif) on ![
$$\\mathbb{R}$$
](A272900_1_En_3_Chapter_IEq115.gif) that we interpret as describing the probabilities for a measurement of A in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq402.gif). See Proposition 7.17 in the bounded case and Definition 10.7 in the unbounded case.

Axiom 4

Suppose a quantum system is initially in a state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq444.gif) and that a measurement of an observable f is performed. If the result of the measurement is the number ![
$$\\lambda \\in \\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq116.gif) then immediately after the measurement, the system will be in a state ![
$$\\psi^{\\prime}$$
](A272900_1_En_3_Chapter_IEq445.gif) that satisfies

![
$$\\displaystyle{\\hat{f}{\\psi}^{\\prime} {=\\lambda \\psi }^{{\\prime}}.}$$
](A272900_1_En_3_Chapter_Equaa.gif)

The passage from ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq446.gif) to ![
$$\\psi^{\\prime}$$
](A272900_1_En_3_Chapter_IEq447.gif) is called the collapse of the wave function. Here ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq117.gif) is the self-adjoint operator associated with f by Axiom 2.

Let us assume again that ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq118.gif) has an orthonormal basis of eigenvectors ![
$$\\left \\{e_{j}\\right\\}$$
](A272900_1_En_3_Chapter_IEq119.gif) with distinct eigenvalues λ j . Then we can say, more specifically, that if we observe the value λ j in a measurement of ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq120.gif) (and we will always observe one of the λ j 's) then ![
$$\\psi^{\\prime}\\ = \\ e_j$$
](A272900_1_En_3_Chapter_IEq448.gif). That is, the measurement "collapses" the wave function by throwing away all the components of ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq403.gif) in the direction of the e k 's, except the one with k = j.

This idea of the collapse of the wave function has generated an enormous amount of discussion and controversy. One way to look at the situation is to think that the wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq404.gif) is not actually the state of the system—although we continue to use the standard physics term, "state." Rather, the wave function is the thing that encodes the probabilities for the state of the system. The collapse of the wave function is then something similar to a conditional probability; the probabilities for future measurements of the system should be consistent with the outcome of the measurement we just made. Paul Dirac has described the collapse of the wave function as being not a discontinuous change in the state of the system, but a discontinuous change in our knowledge of the state of the system.

In any case, Axiom 4 guarantees the following reasonable principle: If we measure f and then measure f again a very short time later, the result of the second measurement will agree with the result of the first measurement. Thus, immediately after the first measurement, the probabilities for a second measurement of f are not those associated with the vector ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq405.gif), but rather those associated with the state ![
$$\\psi^{\\prime}$$
](A272900_1_En_3_Chapter_IEq450.gif). (Since ![
$$\\psi^{\\prime}$$
](A272900_1_En_3_Chapter_IEq451.gif) is an eigenvector for ![
$$\\hat{f}$$
](A272900_1_En_3_Chapter_IEq121.gif) with eigenvalue λ, Proposition 3.11 tells us that measurements of f in the state ![
$$\\psi^{\\prime}$$
](A272900_1_En_3_Chapter_IEq601.gif) always give the value of λ.)

Note that Axiom 4 only tells us something about the state of the system immediately after a measurement. Following the measurement, the state of the system will evolve in time in the usual way (Sect. 3.7). A significant time after the measurement, then, the system will probably no longer be in the state ![
$$\\psi^{\\prime}$$
](A272900_1_En_3_Chapter_IEq464.gif)

Let us conclude this section by considering an example of how one makes a measurement of a real-world physical system, namely, the hydrogen atom. The Hamiltonian operator ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq122.gif) for a hydrogen atom has negative eigenvalues of the form

![
$$\\displaystyle{ -\\frac{R} {{n}^{2}}, }$$
](A272900_1_En_3_Chapter_Equ25.gif)

(3.22)

where R is the Rydberg constant and n = 1, 2, 3,... These energies will be derived in Chap.​ 18. Negative eigenvalues are of greater interest than positive ones, because negative eigenvalues describes states where the electron is bound to the nucleus. If an electron is placed into a state having energy ![
$$-R/n_{1}^{2},$$
](A272900_1_En_3_Chapter_IEq123.gif) with n 1 > 1, it will eventually "decay" into a state with lower energy, say, ![
$$-R/n_{2}^{2},$$
](A272900_1_En_3_Chapter_IEq124.gif) with n 2 < n 1. (The most readily observed cases are those with n 2 = 2 and n 2 = 1. ) In the process of decaying, the electron emits a photon, with the energy of the photon being equal to the change in energy of the electron, namely,

![
$$\\displaystyle{ E_{\\mathrm{photon}} = \\frac{R} {n_{2}^{2}} - \\frac{R} {n_{1}^{2}}. }$$
](A272900_1_En_3_Chapter_Equ26.gif)

(3.23)

Meanwhile, the frequency of the photon is proportional to its energy. Thus, by observing the frequency of the emitted photon, one can determine the change in energy of the electron and thus determine the values of n 1 and n 2.

A general "bound state" of the hydrogen atom (a state in which the electron is bound to the nucleus), will be a linear combination of eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq125.gif) with various different eigenvalues of the form (3.22). To measure the energy of the electron, we simply wait for the electron to decay into a lower-energy state and emit a photon, observe the frequency of the photon, and work backwards to the energy of the electron. If we consider many "identically prepared" electrons, all having the same wave function that is a linear combination of eigenvectors, we will observe many different frequencies for the emitted photons, and thus many different energies for the electron. The probabilities for the observed energies of the electron will follow the principle spelled out in Example 3.12.

In basic probability theory, if Y is a random variable then the variance σ 2 of Y is computed as

![
$${\\displaystyle{\\sigma }^{2} = E\\left \[{\(Y - E\(Y \)\)}^{2}\\right\],}$$
](A272900_1_En_3_Chapter_Equab.gif)

where E denotes the mean or expectation value of a random variable. The standard deviation ![
$$\\sigma := \\sqrt{{\\sigma }^{2}}$$
](A272900_1_En_3_Chapter_IEq126.gif) is a measure of the "typical" deviation from the mean E(X). Observe that the variance may be computed as

![
$$ \\displaystyle\\begin{array}{rcl} {\\sigma }^{2}& =& E\\left \[{Y }^{2} - 2E\(Y \)Y + E{\(Y \)}^{2}\\right\] \\\\ & =& E\({Y }^{2}\) - 2E{\(Y \)}^{2} + E{\(Y \)}^{2} \\\\ & =& E\({Y }^{2}\) - E{\(Y \)}^{2}. {}\\end{array}$$
](A272900_1_En_3_Chapter_Equ27.gif)

(3.24)

Definition 3.13

If A is a self-adjoint operator on a Hilbert space H and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq461.gif) is a unit vector in H, let ![
$$\\Delta_\\psi{A}$$
](A272900_1_En_3_Chapter_IEq463.gif) denote the standard deviation associated with measurements of A in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq462.gif) , which is computed as

![
$$\\displaystyle\\begin{array}{rcl}{ \\left \(\\Delta _{\\psi }A\\right\)}^{2}& =& \\left \\langle {\(A -\\left \\langle A\\right\\rangle _{\\psi }I\)}^{2}\\right\\rangle _{ \\psi } {}\\\\ & =& \\left \\langle {A}^{2}\\right\\rangle _{ \\psi } -{\\left \(\\left \\langle A\\right\\rangle _{\\psi }\\right\)}^{2}. {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ28.gif)

We refer to ![
$$\\Delta_\\psi{A}$$
](A272900_1_En_3_Chapter_IEq655.gif) as the uncertainty of A in the state ![
$$\\Delta_\\psi{A}$$
](A272900_1_En_3_Chapter_IEq656.gif).

For any single observable A, it is possible to choose ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq407.gif) so that ![
$$\\Delta\\psi A$$
](A272900_1_En_3_Chapter_IEq523.gif) is as small as we like. In Chap.​ 12, however, we will see that when two observables A and B do not commute, then ![
$$\\Delta\\psi A$$
](A272900_1_En_3_Chapter_IEq524.gif) and ![
$$\\Delta\\psi B$$
](A272900_1_En_3_Chapter_IEq525.gif) cannot both be made arbitrarily small for the same ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq526.gif). In particular, we will derive there the famous Heisenberg uncertainty principle, which states that

![
$$\\displaystyle{\(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\) \\geq \\frac{\\hslash } {2},}$$
](A272900_1_En_3_Chapter_Equac.gif)

for all ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq408.gif) for which ![
$$\\Delta_\\psi{X}$$
](A272900_1_En_3_Chapter_IEq458.gif) and ![
$$\\Delta_\\psi{P}$$
](A272900_1_En_3_Chapter_IEq459.gif) are defined.

## 3.7 Time-Evolution in Quantum Theory

### 3.7.1 The Schrödinger Equation

Up to now, we have been considering the wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq409.gif) at a fixed time. We now consider the way in which the wave function evolves in time. Recall that in the Hamiltonian formulation of classical mechanics (Sect.​ 2.​5), the time-evolution of the system is governed by the Hamiltonian (energy) function H, through Hamilton's equations. According to Axiom 2, there is a corresponding self-adjoint linear operator ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq127.gif) on the quantum Hilbert space H, which we call the Hamiltonian operator for the system. See Sect. 3.7.4 for an example.

Recall that we motivated the definition of the momentum operator by the de Broglie hypothesis, ![
$$p = \\hslash k,$$
](A272900_1_En_3_Chapter_IEq128.gif) where k is the spatial frequency of the wave function. We can similarly motivate the time-evolution in quantum mechanics by a similar relation between the energy and the temporal frequency of our wave function:

![
$$\\displaystyle{ E = \\hslash \\omega. }$$
](A272900_1_En_3_Chapter_Equ29.gif)

(3.25)

This relationship between energy and temporal frequency is nothing but the relationship proposed by Planck in his model of blackbody radiation (Sect.​ 1.​1.​3). Suppose that a wave function ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq460.gif) has definite energy E, meaning that ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq465.gif) is an eigenvector for ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq129.gif) with eigenvalue E. Then (3.25) means that the time-dependence of the wave function should be purely at frequency ![
$$\\omega = E/\\hslash.$$
](A272900_1_En_3_Chapter_IEq130.gif) That is to say, if the state of the system at time t = 0 is ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq466.gif), then the state of the system at any other time t should be

![
$$\\displaystyle{ \\psi \(t\) = {e}^{-i\\omega t}\\psi _{ 0} = {e}^{-iEt/\\hslash }\\psi _{ 0}. }$$
](A272900_1_En_3_Chapter_Equ30.gif)

(3.26)

We can rewrite (3.26) as a differential equation:

![
$$\\displaystyle{ \\frac{d\\psi } {dt} = -\\frac{iE} {\\hslash } \\psi = \\frac{E} {i\\hslash }\\psi. }$$
](A272900_1_En_3_Chapter_Equ31.gif)

(3.27)

Note that we are taking "temporal frequency ω" to mean that the time-dependence is of the form e − iωt , whereas we took "spatial frequency k" to mean that the space-dependence is of the form e ikx , with no minus sign in the exponent. This curious convention is convenient when we look at pure exponential solutions to the free Schrödinger equation (Chap.​ 4) of the form exp[i(kx − ω t)], which describes a solution moving to the right with speed ω ∕ k.

Equation (3.27) tells us the time-evolution for a particle that is initially in a state of definite energy, that is, an eigenvector for the Hamiltonian operator. A natural way to generalize this equation is to recognize that ![
$$E\\psi$$
](A272900_1_En_3_Chapter_IEq670.gif) is nothing but ![
$$\\hat{H}\\psi,$$
](A272900_1_En_3_Chapter_IEq131.gif) since ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq410.gif) is just a multiple of ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq4630.gif), which is an eigenvector for ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq132.gif) with eigenvalue E. Replacing E by ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq133.gif) in (3.27) leads to the following general prescription for the time-evolution of a quantum system.

Axiom 5

The time-evolution of the wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq441.gif) in a quantum system is given by the Schrödinger equation,

![
$$\\displaystyle{ \\frac{d\\psi } {dt} = \\frac{1} {i\\hslash }\\hat{H}\\psi. }$$
](A272900_1_En_3_Chapter_Equ32.gif)

(3.28)

Here ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq134.gif) is the operator corresponding to the classical Hamiltonian H by means of Axiom 2.

Although both Hamilton's equations and the Schrödinger equation involve a Hamiltonian, the two equations otherwise do not seem parallel. Of course, since quantum mechanics is not classical mechanics, we should not expect the two theories to have the same time-evolution. Nevertheless, we might hope to see some similarities between the time-evolution of a classical system and that of the corresponding quantum system. Such a similarity can be seen when we consider how the expectation values of observables evolve in quantum mechanics.

Proposition 3.14

Suppose ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq671.gif) is a solution of the Schrödinger equation and A is a self-adjoint operator on H. Assuming certain natural domain conditions hold, we have

![
$$\\displaystyle{ \\frac{d} {dt}\\left \\langle A\\right\\rangle _{\\psi \(t\)} = \\left \\langle \\frac{1} {i\\hslash }\[A,\\hat{H}\]\\right\\rangle _{\\psi \(t\)}, }$$
](A272900_1_En_3_Chapter_Equ33.gif)

(3.29)

where ![
$$\\left \\langle A\\right\\rangle _{\\psi }$$
](A272900_1_En_3_Chapter_IEq135.gif) is as in Notation 3.10 and where ![
$$\\left \[\\cdot,\\cdot \\right\]$$
](A272900_1_En_3_Chapter_IEq136.gif) denotes the commutator, defined as

![
$$\\displaystyle{\[A,B\] = AB - BA.}$$
](A272900_1_En_3_Chapter_Equad.gif)

Equation (3.29) should be compared to the way a function f on the classical phase space evolves in time along a solution of Hamilton's equations: ![
$$df/dt =\\{ f,H\\}.$$
](A272900_1_En_3_Chapter_IEq137.gif) We see, then, that the commutator of operators (divided by ![
$$i\\hslash $$
](A272900_1_En_3_Chapter_IEq138.gif)) plays a role in quantum mechanics similar to the role of the Poisson bracket in classical mechanics.

Proof.

Let ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq487.gif) be a solution to the Schrödinger equation and let us compute at first without worrying about domains of the operators involved. If we use the product rule (Exercise 1) for differentiation of the inner product, we obtain

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle \\psi \(t\),A\\psi \(t\)\\right\\rangle & =& \\left \\langle \\frac{d\\psi } {dt},A\\psi \\right\\rangle + \\left \\langle \\psi,A \\frac{d\\psi } {dt}\\right\\rangle {}\\\\ & =& \\frac{i} {\\hslash }\\left \\langle \\hat{H}\\psi,A\\psi \\right\\rangle - \\frac{i} {\\hslash }\\left \\langle \\psi,A\\hat{H}\\psi \\right\\rangle {}\\\\ & =& \\frac{1} {i\\hslash }\\left \\langle \\psi,\[A,\\hat{H}\]\\psi \\right\\rangle, {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ34.gif)

where in the last step we have used the self-adjointness of ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq139.gif) to move it to the other side of the inner product. Recall that we are following the convention of putting the complex conjugate on the first factor in the inner product, which accounts for the plus sign in the first term on the second line. Rewriting this using Notation 3.10 gives the desired result.

If A and ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq140.gif) are (as usual) unbounded operators, then the preceding calculation is not completely rigorous. Since, however, we are deferring a detailed examination of issues of unbounded operators until Chap.​ 9, let us simply state the conditions needed for the calculation to be valid. For every ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq141.gif) we need to have ![
$$\\psi \(t\) \\in \\mathrm{ Dom}\(A\) \\cap \\mathrm{ Dom}\(\\hat{H}\)$$
](A272900_1_En_3_Chapter_IEq142.gif), we need ![
$$A\\psi \(t\) \\in \\mathrm{ Dom}\(\\hat{H}\),$$
](A272900_1_En_3_Chapter_IEq143.gif) and we need ![
$$\\hat{H}\\psi \(t\) \\in \\mathrm{ Dom}\(A\).$$
](A272900_1_En_3_Chapter_IEq144.gif) (These conditions are needed for ![
$$\[A,\\hat{H}\]\\psi \(t\)$$
](A272900_1_En_3_Chapter_IEq145.gif) to be defined.) In addition, we need ![
$$A\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq491.gif) to be a continuous path in H.

Note that to see interesting behavior in the time-evolution of a quantum system, there has to be noncommutativity present. If all the physically interesting operators A commuted with the Hamiltonian operator ![
$$\\hat{H},$$
](A272900_1_En_3_Chapter_IEq146.gif) then ![
$$\[\\hat{H},A\]$$
](A272900_1_En_3_Chapter_IEq147.gif) would be zero and the expectation values of these operators would be constant in time. Noncommutativity of the basic operators is therefore an essential property of quantum mechanics. In the case of a particle in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_3_Chapter_IEq148.gif) noncommutativity is built into the commutation relation for X and P, given in Proposition 3.8.

Although it is not reasonable to have all physically interesting operators commute with ![
$$\\hat{H},$$
](A272900_1_En_3_Chapter_IEq149.gif) there may be some operators with this property. If ![
$$\[A,\\hat{H}\] = 0,$$
](A272900_1_En_3_Chapter_IEq150.gif) then the expectation value of A (and, indeed, all the moments of A) is independent of time along any solution of the Schrödinger equation. We may therefore call such an operator A a conserved quantity(or constant of motion). Just as in the classical setting, conserved quantities (when we can find them) are helpful in understanding how to solve the Schrödinger equation.

Proposition 3.14 suggests that the map

![
$$\\displaystyle{\(A,B\)\\longmapsto \\frac{1} {i\\hslash }\[A,B\],}$$
](A272900_1_En_3_Chapter_Equae.gif)

where A and B are self-adjoint operators, plays a role similar to that of the Poisson bracket in classical mechanics. This analogy is supported by the following list of elementary properties of the commutator, which should be compared to the properties of the Poisson bracket listed in Proposition 2.23.

Proposition 3.15

For any vector space V over ![
$$\\mathbb{C}$$
](A272900_1_En_3_Chapter_IEq151.gif) and linear operators A, B, and C on V, the following relations hold.

1.

![
$$\[A,B +\\alpha C\] = \[A,B\] +\\alpha \[A,C\]$$
](A272900_1_En_3_Chapter_IEq152.gif) for all ![
$$\\alpha \\in \\mathbb{C}$$
](A272900_1_En_3_Chapter_IEq153.gif)

2.

![
$$\[B,A\] = -\[A,B\]$$
](A272900_1_En_3_Chapter_IEq154.gif)

3.

![
$$\[A,BC\] = \[A,B\]C + B\[A,C\]$$
](A272900_1_En_3_Chapter_IEq155.gif)

4.

![
$$\[A,\[B,C\]\] = \[\[A,B\],C\] + \[B,\[A,C\]\]$$
](A272900_1_En_3_Chapter_IEq156.gif)

Property 4 is equivalent to the Jacobi identity,

![
$$\\displaystyle{ \[A,\[B,C\]\] + \[B,\[C,A\]\] + \[C,\[A,B\]\] = 0, }$$
](A272900_1_En_3_Chapter_Equ35.gif)

(3.30)

as can easily be seen using the skew-symmetry of the commutator.

Proof.

The first two properties of the commutator are obvious, and the third is easily verified by writing things out. Property 4 can also be proved by writing things out, but it is slightly messier. Each of the three double commutators on the left-hand side of (3.30) generates four terms, for a total of 12 terms. Each term has the operators A, B, and C multiplied together in some order. It is a straightforward but unenlightening calculation to verify that each of the six possible orderings of A, B, and C occurs twice, with opposite signs.

If A and B are bounded self-adjoint operators on some Hilbert space, then it is straightforward to check that ![
$$\(1/\(i\\hslash \)\)\[A,B\]$$
](A272900_1_En_3_Chapter_IEq157.gif) is again self-adjoint (Exercise 3). If A and B are unbounded self-adjoint operators, then the operator ![
$$\(1/\(i\\hslash \)\)\[A,B\]$$
](A272900_1_En_3_Chapter_IEq158.gif) will be self-adjoint under suitable assumptions on the domains of A and B.

Proposition 3.16

If ![
$$\\phi\(t\)$$
](A272900_1_En_3_Chapter_IEq805.gif) and ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq820.gif) are solutions to the Schrödinger equation ( 3.28 ), the quantity ![
$$\\left \\langle \\phi \(t\),\\psi \(t\)\\right\\rangle$$
](A272900_1_En_3_Chapter_IEq159.gif) is independent of t. In particular, ![
$$\\left \\Vert \\psi \(t\)\\right\\Vert$$
](A272900_1_En_3_Chapter_IEq160.gif) is independent of t, for any solution ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq472.gif) of the Schrödinger equation.

Proof.

Using again the product rule, we have

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle \\phi \(t\),\\psi \(t\)\\right\\rangle & =& \\left \\langle \\frac{1} {i\\hslash }\\hat{H}\\phi \(t\),\\psi \(t\)\\right\\rangle + \\left \\langle \\phi \(t\), \\frac{1} {i\\hslash }\\hat{H}\\psi \(t\)\\right\\rangle {}\\\\ & =& -\\frac{1} {i\\hslash }\\left \\langle \\hat{H}\\phi \(t\),\\psi \(t\)\\right\\rangle + \\frac{1} {i\\hslash }\\left \\langle \\phi \(t\),\\hat{H}\\psi \(t\)\\right\\rangle {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ36.gif)

Since ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq161.gif) is self-adjoint, we can move ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq162.gif) to the other side of the inner product and the derivative is equal to 0.

### 3.7.2 Solving the Schrödinger Equation by Exponentiation

The Schrödinger equation is an example of a equation of the form

![
$$\\displaystyle{ \\frac{dv} {dt} = Av, }$$
](A272900_1_En_3_Chapter_Equ37.gif)

(3.31)

where A is a linear operator on a Hilbert space. (In the Schrödinger case, we have ![
$$A = -\(i/\\hslash \)\\hat{H}.$$
](A272900_1_En_3_Chapter_IEq163.gif)) Let us think of (3.31) in the case where the Hilbert space is the finite-dimensional space ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_3_Chapter_IEq164.gif) In that case, we can think of A as an n × n matrix, in which case (3.31) is the sort of equation encountered in the elementary theory of ordinary differential equations. The solution of this system (in the finite-dimensional case) can be expressed as

![
$$\\displaystyle{v\(t\) = {e}^{tA}v_{ 0},}$$
](A272900_1_En_3_Chapter_Equaf.gif)

where the matrix exponential e tA is defined by a convergent power series and where v 0 = v(0) is the initial condition. If A is diagonalizable, then the exponential can by computed by using a basis of eigenvectors. (See Sect.​ 16.​4 for more information.)

The Schrödinger equation simply replaces ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_3_Chapter_IEq165.gif) by a Hilbert space H and the matrix A by the linear operator ![
$$-\(i/\\hslash \)\\hat{H}.$$
](A272900_1_En_3_Chapter_IEq166.gif)

Claim 3.17

Suppose ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq167.gif) is a self-adjoint operator on H. If a reasonable meaning can be given to the expression ![
$${e}^{-it\\hat{H}/\\hslash },$$
](A272900_1_En_3_Chapter_IEq168.gif) then the Schrödinger equation can be solved by setting

![
$$\\displaystyle{ \\psi \(t\) = {e}^{-it\\hat{H}/\\hslash }\\psi _{ 0}. }$$
](A272900_1_En_3_Chapter_Equ38.gif)

(3.32)

To see why the claim should be true, we expect that we can differentiate the operator-valued expression ![
$${e}^{-it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq169.gif) with respect to t as we would in the finite-dimensional case. The differentiation, then, would pull down a factor of ![
$$-i\\hat{H}/\\hslash,$$
](A272900_1_En_3_Chapter_IEq170.gif) which would indicate that ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq480.gif) indeed solves the Schrödinger equation. Furthermore, when t = 0, ![
$${e}^{-it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq171.gif) should be equal to I, so that ![
$$\\psi_\(0\)$$
](A272900_1_En_3_Chapter_IEq492.gif) is indeed ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq4640.gif).

If ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq172.gif) is a bounded operator (which is rarely the case), then the exponential ![
$${e}^{-it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq173.gif) can be defined by a convergent power series, precisely as in the finite-dimensional case. In that case, Claim 3.17 is an easily proved theorem.

In the more typical case where ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq174.gif) is unbounded, convergence of the series for the exponential is a rather delicate matter, and it is better instead to use the spectral theorem. We leave a general discussion of the spectral theorem to Chaps.​ 7 and , and here consider only the case of a pure point spectrum. A (possibly unbounded) self-adjoint operator ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq175.gif) is said to have a pure point spectrum if there exists an orthonormal basis ![
$$\\left \\{e_{j}\\right\\}$$
](A272900_1_En_3_Chapter_IEq176.gif) for H consisting of eigenvectors for ![
$$\\hat{H}.$$
](A272900_1_En_3_Chapter_IEq177.gif) If ![
$$\\hat{H}e_{j} = E_{j}e_{j}$$
](A272900_1_En_3_Chapter_IEq178.gif) for some ![
$$E_{j} \\in \\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq179.gif) then the exponential can be defined by requiring that

![
$$\\displaystyle{ {e}^{-it\\hat{H}/\\hslash }e_{ j} = {e}^{-itE_{j}/\\hslash }e_{ j}. }$$
](A272900_1_En_3_Chapter_Equ39.gif)

(3.33)

The operator ![
$${e}^{-it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq180.gif) is unitary and thus bounded; it is the unique bounded operator on H satisfying (3.33).

It is not precisely true that every self-adjoint operator has an orthonormal basis of eigenvectors, even if the operator is bounded. Nevertheless, given a self-adjoint operator A, the spectral theorem tells us that there is a decomposition of H into "generalized eigenspaces" for A. It is, however, a bit complicated to state the precise sense of this decomposition, especially in the case of unbounded operators. Still, Claim 3.17 allows us to identify one goal for the spectral theorem: Whatever the spectral theorem says, it ought to allow us to make sense of the expression e iaA , for any self-adjoint operator A and real number a. This goal will indeed be realized, in the bounded case in Chap.​ 7 and in the unbounded case in Chap.​ 10.

We should add two points of clarification regarding the expression (3.32). First, in writing (3.32), we have not "really" solved the Schrödinger equation. For this expression to be useful, we need to compute ![
$${e}^{-it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq181.gif) in some relatively explicit way. If, for example, we can actually compute an orthonormal basis of eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq182.gif), then in light of (3.33), we are on our way to understanding the behavior of the operator ![
$${e}^{-it\\hat{H}/\\hslash }.$$
](A272900_1_En_3_Chapter_IEq183.gif) Second, although ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq184.gif) is an unbounded operator, which is not defined on all of H but only on a dense subspace, the operator ![
$${e}^{-it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq185.gif) is unitary and defined on all of H. Thus, the right-hand side of (3.32) makes sense for any ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq6650.gif) in H. Nevertheless, we cannot expect that ![
$${e}^{-it\\hat{H}/\\hslash }\\psi _{0}$$
](A272900_1_En_3_Chapter_IEq186.gif) actually solves the Schrödinger equation (in the natural Hilbert space sense) unless ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq6660.gif) belongs to the domain of ![
$$\\hat{H}.$$
](A272900_1_En_3_Chapter_IEq187.gif) (See Lemma 10.17 in Sect.​ 10.​2.​)

### 3.7.3 Eigenvectors and the Time-Independent Schrödinger Equation

As we saw in the preceding section, eigenvectors for the Hamiltonian operator are of great importance in solving the Schrödinger equation. In light of this fact, we make the following definition.

Definition 3.18

If ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq188.gif) is the Hamiltonian operator for a quantum system, the eigenvector equation

![
$$\\displaystyle{ \\hat{H}\\psi = E\\psi,\\quad E \\in \\mathbb{R}, }$$
](A272900_1_En_3_Chapter_Equ40.gif)

(3.34)

is called the time-independent Schrödinger equation.

As always in eigenvector equations, we are trying to determine both the numbers E for which (3.34) has a nonzero solution (the eigenvalues) and the corresponding vectors ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq411.gif) (the eigenvectors). When quantum texts speak of "solving," say, the quantum harmonic oscillator, what they usually mean is finding all of the solutions to the time-independent Schrödinger equation. (See, e.g., Chaps.​ 5 and .) If ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq412.gif) is a solution to the time-independent Schrödinger equation, then the solution to the time-dependent Schrödinger equation with initial condition ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq413.gif) is simply ![
$$\\psi \(t\) = {e}^{-itE/\\hslash }\\psi.$$
](A272900_1_En_3_Chapter_IEq189.gif) Since ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq481.gif) is just a constant multiple of ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq414.gif), we see that ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq482.gif) represents the same physical state as ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq415.gif). Thus, a solution to the time-independent Schrödinger equation is sometimes called a stationary state.

### 3.7.4 The Schrödinger Equation in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_3_Chapter_IEq190.gif)

Let us now consider the simplest example for the Hamiltonian operator ![
$$\\hat{H}.$$
](A272900_1_En_3_Chapter_IEq191.gif) For a particle moving in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_3_Chapter_IEq192.gif) recall (Sect. 3.5) that we have identified the position operator X as being multiplication by x and the momentum operator as ![
$$P = -i\\hslash \\ d/dx.$$
](A272900_1_En_3_Chapter_IEq193.gif) The classical Hamiltonian for such a particle is typically taken to be of the form ![
$$H\(x,p\) = {p}^{2}/\(2m\) + V \(x\),$$
](A272900_1_En_3_Chapter_IEq194.gif) where V is the potential energy function. In that case, we may reasonably take

![
$$\\displaystyle{\\hat{H} = \\frac{{P}^{2}} {2m} + V \(X\).}$$
](A272900_1_En_3_Chapter_Equag.gif)

Here the operator V (X) is simply multiplication by the potential energy function V (x). (This operator may also be thought of as the function V applied to the operator X in the sense of the functional calculus coming from the spectral theorem.) We see, then, that

![
$$\\displaystyle{ \\hat{H}\\psi \(x\) = -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi } {d{x}^{2}} + V \(x\)\\psi \(x\). }$$
](A272900_1_En_3_Chapter_Equ41.gif)

(3.35)

An operator of the form (3.35), or an analogously defined operator in higher dimensions, is referred to as a Schrödinger operator. (The term Hamiltonian operator refers more generally to whatever operator governs the time-evolution of a quantum system, regardless of its form.)

If our Hamiltonian is of the form given in (3.35), then the time-dependent Schrödinger equation takes the form

![
$$\\displaystyle{ \\frac{\\partial \\psi \(x,t\)} {\\partial t} = \\frac{i\\hslash } {2m} \\frac{{\\partial }^{2}\\psi \(x,t\)} {\\partial {x}^{2}} - \\frac{i} {\\hslash }V \(x\)\\psi \(x,t\), }$$
](A272900_1_En_3_Chapter_Equ42.gif)

(3.36)

which is a linear partial differential equation. By contrast, Newton's equation for a particle in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_3_Chapter_IEq195.gif) is a typically nonlinear ordinary differential equation.

For a particle in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_3_Chapter_IEq196.gif) the time-independent Schrödinger equation is an ordinary differential equation, one that is linear but that has nonconstant coefficients, unless V happens to be constant. For simple examples of the potential function V, there are relatively standard methods of ordinary differential equations that can be brought to bear on the time-independent Schrödinger equation.

### 3.7.5 Time-Evolution of the Expected Position and Expected Momentum

Since a quantum particle does not have a fixed position or momentum, it does not make sense to ask whether the particle satisfies Newton's equation. It does, however, make sense to ask whether the expected values of the position and momentum satisfy Newton's equation (in the form of Hamilton's equations).

Proposition 3.19

Suppose ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq473.gif) is a solution to the Schrödinger equation (3.36) for a sufficiently nice potential V and for a sufficiently nice initial condition ![
$$\\psi\(0\) \\ = \\ \\psi 0$$
](A272900_1_En_3_Chapter_IEq527.gif) . Then the expected position and expected momentum in the state ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq474.gif) satisfy

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle X\\right\\rangle _{\\psi \(t\)} = \\frac{1} {m}\\left \\langle P\\right\\rangle _{\\psi \(t\)}& &{}\\end{array}$$
](A272900_1_En_3_Chapter_Equ43.gif)

(3.37)

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle P\\right\\rangle _{\\psi \(t\)} = -\\left \\langle {V }^{{\\prime}}\(X\)\\right\\rangle _{\\psi \(t\)}.& &{}\\end{array}$$
](A272900_1_En_3_Chapter_Equ44.gif)

(3.38)

The assumptions in the proposition are there for two reasons: First, to ensure that ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq197.gif) is actually a self-adjoint operator (see Sect.​ 9.​9) and second, to ensure that the domain assumptions in Proposition 3.14 are satisfied. If we assume, for example, that V (x) is a bounded-below polynomial in x and that ![
$$\\psi_0$$
](A272900_1_En_3_Chapter_IEq467.gif) belongs to the Schwartz space (A.15), then both of these concerns will be taken care of. Once these technicalities are addressed, the proof of Proposition 3.19 is a straightforward application of Proposition 3.14; see Exercise 4. Note that (3.37) says that in a certain sense, the velocity of a quantum particle is 1 ∕ m times the momentum, just as in the classical case.

At first glance, it might appear that the pair ![
$$\(\\left \\langle X\\right\\rangle _{\\psi \(t\)},\\left \\langle P\\right\\rangle _{\\psi \(t\)}\)$$
](A272900_1_En_3_Chapter_IEq198.gif) is a solution to Hamilton's equations, and indeed (3.37) is precisely what Hamilton's equations require. To get a solution to Hamilton's equations, however, we would need the right-hand side of (3.38) to equal ![
$$-{V }^{{\\prime}}\(\\left \\langle X\\right\\rangle _{\\psi \(t\)}\)$$
](A272900_1_En_3_Chapter_IEq199.gif). But in general,

![
$$\\displaystyle{\\left \\langle {V }^{{\\prime}}\(X\)\\right\\rangle _{\\psi }\\neq {V }^{{\\prime}}\(\\left \\langle X\\right\\rangle _{\\psi }\).}$$
](A272900_1_En_3_Chapter_Equah.gif)

Consider, for example, the case ![
$${V }^{{\\prime}}\(x\) = {x}^{3} + {x}^{2}.$$
](A272900_1_En_3_Chapter_IEq200.gif) If ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq416.gif) is an even function, then ![
$$\\left \\langle X\\right\\rangle _{\\psi } = 0$$
](A272900_1_En_3_Chapter_IEq201.gif) and so ![
$${V }^{{\\prime}}\(\\left \\langle X\\right\\rangle _{\\psi }\) = 0.$$
](A272900_1_En_3_Chapter_IEq202.gif) But ![
$$\\left \\langle {X}^{3} + {X}^{2}\\right\\rangle _{\\psi }$$
](A272900_1_En_3_Chapter_IEq203.gif) will not be zero, because the X 3 term will be zero and the X 2 term will be positive. We conclude, then, that ![
$$\\left \\langle X\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_3_Chapter_IEq204.gif) and ![
$$\\left \\langle P\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_3_Chapter_IEq205.gif) usually do not evolve along solutions to Hamilton's equations.

There is, however, one case in which ![
$$\\left \\langle {V }^{{\\prime}}\(X\)\\right\\rangle _{\\psi }$$
](A272900_1_En_3_Chapter_IEq206.gif) coincides with ![
$${V }^{{\\prime}}\(\\left \\langle X\\right\\rangle _{\\psi }\),$$
](A272900_1_En_3_Chapter_IEq207.gif) and that is the case in which V is quadratic, in which case V ′ is linear. In that case we have

![
$$\\displaystyle{\\left \\langle {V }^{{\\prime}}\(X\)\\right\\rangle _{\\psi } = \\left \\langle aX + bI\\right\\rangle _{\\psi } = a\\left \\langle X\\right\\rangle _{\\psi } + b = {V }^{{\\prime}}\(\\left \\langle X\\right\\rangle _{\\psi }\).}$$
](A272900_1_En_3_Chapter_Equai.gif)

Thus, the expected position and expected momentum do follow classical trajectories in the case of a quadratic potential. It is not surprising that this case is special in quantum mechanics, since it is also special in classical mechanics; this is the case in which Newton's law is a linear differential equation.

Although the expected position and expected momentum do not (in general) exactly follow classical trajectories, they will do so approximately under certain conditions. If the wave function ![
$$\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq529.gif) is concentrated mostly near a single point x = x 0, then ![
$$\\left \\langle {V }^{{\\prime}}\(X\)\\right\\rangle _{\\psi }$$
](A272900_1_En_3_Chapter_IEq208.gif) and ![
$${V }^{{\\prime}}\(\\left \\langle X\\right\\rangle _{\\psi }\)$$
](A272900_1_En_3_Chapter_IEq209.gif) will both be approximately equal to V ′ (x 0). In that case, the expected position and expected momentum of the particle will approximately follow a classical trajectory, at least for as long as the wave function remains concentrated near a single point.

## 3.8 The Heisenberg Picture

The "Heisenberg picture" of quantum mechanics is based on Heisenberg's matrix model of quantum mechanics (Sect.​ 1.​3). In the Heisenberg picture, one thinks of the operators (quantum observables) as evolving in time, while the vectors in the Hilbert space (quantum states) remain independent of time. This is to be contrasted with the approach to quantum mechanics we have been using up to now (the "Schrödinger picture"), in which the observables are independent of time and the states evolve in time.

Definition 3.20

In the Heisenberg picture, each self-adjoint operator A evolves in time according to the operator-valued differential equation

![
$$\\displaystyle{ \\frac{dA\(t\)} {dt} = \\frac{1} {i\\hslash }\[A\(t\),\\hat{H}\], }$$
](A272900_1_En_3_Chapter_Equ45.gif)

(3.39)

where ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq210.gif) is the Hamiltonian operator of the system, and where ![
$$\\left \[\\cdot,\\cdot \\right\]$$
](A272900_1_En_3_Chapter_IEq211.gif) is the commutator, given by ![
$$\\left \[A,B\\right\] = AB - BA.$$
](A272900_1_En_3_Chapter_IEq212.gif)

Note that since ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq213.gif) commutes with itself, the operator ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq214.gif) remains constant in time, even in the Heisenberg picture. This observation is the quantum counterpart to the fact that the classical Hamiltonian H remains constant along a solution of Hamilton's equations.

Given the self-adjoint operator ![
$$\\hat{H},$$
](A272900_1_En_3_Chapter_IEq215.gif) the spectral theorem will give us a way to construct a family of unitary operators ![
$${e}^{-it\\hat{H}/\\hslash },$$
](A272900_1_En_3_Chapter_IEq216.gif) ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_3_Chapter_IEq217.gif) and this family of operators computes the time-evolution of states in the Schrödinger picture (Sect. 3.7.2). It is easy to check (at least formally) that the solution to (3.39) can be expressed as

![
$$\\displaystyle{ A\(t\) = {e}^{it\\hat{H}/\\hslash }A{e}^{-it\\hat{H}/\\hslash }. }$$
](A272900_1_En_3_Chapter_Equ46.gif)

(3.40)

Now, if ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq417.gif) is the state of the system (now considered to be independent of time), then the expectation of A(t) in the state ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq418.gif) is defined to be ![
$$\\left \\langle A\(t\)\\right\\rangle _{\\psi } = \\left \\langle \\psi,A\(t\)\\psi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq218.gif) We may then compute that

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle A\(t\)\\right\\rangle _{\\psi }& =& \\left \\langle \\psi,{e}^{it\\hat{H}/\\hslash }A{e}^{-it\\hat{H}/\\hslash }\\psi \\right\\rangle {}\\\\ & =& \\left \\langle {e}^{-it\\hat{H}/\\hslash }\\psi,A{e}^{-it\\hat{H}/\\hslash }\\psi \\right\\rangle {}\\\\ & =& \\left \\langle \\psi \(t\),A\\psi \(t\)\\right\\rangle, {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ47.gif)

where ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq483.gif) is time-evolved state of the system in the Schrödinger picture. Here, we have used that the adjoint of ![
$${e}^{it\\hat{H}/\\hslash }$$
](A272900_1_En_3_Chapter_IEq219.gif) is ![
$${e}^{-it\\hat{H}/\\hslash },$$
](A272900_1_En_3_Chapter_IEq220.gif) which is formally clear and which is a consequence of the spectral theorem.

Note that in the Schrödinger picture, ![
$$\\left \\langle \\psi \(t\),A\\psi \(t\)\\right\\rangle$$
](A272900_1_En_3_Chapter_IEq221.gif) is the expectation value of A in the state ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq484.gif). We conclude, then, that the Heisenberg picture and the Schrödinger picture give rise to precisely the same expectation values for observables as a function of time, and are therefore physically equivalent. Although we will work primarily with the Schrödinger picture of quantum mechanics, the Heisenberg picture is also important, for example, in quantum field theory.

Proposition 3.21

Suppose ![
$$\\hat{H} = {P}^{2}/\(2m\) + V \(X\),$$
](A272900_1_En_3_Chapter_IEq222.gif) where V is a bounded-below polynomial. Then for any ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_3_Chapter_IEq223.gif) we have

![
$$\\displaystyle{ \\hat{H} = \\frac{1} {2m}{\\left \(P\(t\)\\right\)}^{2} + V \(X\(t\)\). }$$
](A272900_1_En_3_Chapter_Equ48.gif)

(3.41)

Note that since ![
$$\[\\hat{H},\\hat{H}\] = 0,$$
](A272900_1_En_3_Chapter_IEq224.gif) the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq225.gif) is independent of time, even in the Heisenberg picture. Thus, the right-hand side of (3.41) is actually independent of t, even though P(t) and X(t) depend on t. Equation (3.41) holds also for sufficiently nice nonpolynomial functions V, but some limiting argument would be required in the proof. The assumption that V be bounded below is to ensure that ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq226.gif) is actually an (essentially) self-adjoint operator; compare Sect.​ 9.​10.​

Lemma 3.22

Suppose A is a self-adjoint operator on H and that A(⋅) is a solution to (3.39) with A(0) = A. Then for any positive integer m, the map

![
$$\\displaystyle{t\\mapsto {\\left \(A\(t\)\\right\)}^{m}}$$
](A272900_1_En_3_Chapter_Equaj.gif)

is also a solution to (3.39).

That is to say, the time-evolution of the mth power of A is the same as the mth power of the time-evolution of A; that is, A m (t) = (A(t)) m .

Proof.

If we use (3.40), then the result holds because

![
$$\\displaystyle\\begin{array}{rcl}{ e}^{it\\hat{H}/\\hslash }{A}^{m}{e}^{-it\\hat{H}/\\hslash }& =& {e}^{it\\hat{H}/\\hslash }A{e}^{-it\\hat{H}/\\hslash }{e}^{it\\hat{H}/\\hslash }A{e}^{-it\\hat{H}/\\hslash }\\cdots {e}^{it\\hat{H}/\\hslash }A{e}^{-it\\hat{H}/\\hslash } {}\\\\ & =&{ \\left \({e}^{it\\hat{H}/\\hslash }A{e}^{-it\\hat{H}/\\hslash }\\right\)}^{m}. {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ49.gif)

It is also easy to check that A(t) m satisfies the differential equation (3.39).

With this lemma in hand, it is easy to prove the proposition.

Proof of Proposition 3.21

On the one hand, since ![
$$\[\\hat{H},\\hat{H}\] = 0,$$
](A272900_1_En_3_Chapter_IEq227.gif) the time-evolved operator ![
$$\\hat{H}\(t\)$$
](A272900_1_En_3_Chapter_IEq228.gif) is simply equal to ![
$$\\hat{H}.$$
](A272900_1_En_3_Chapter_IEq229.gif) On the other hand, if we time-evolve ![
$${P}^{2}/\(2m\) + V \(X\)$$
](A272900_1_En_3_Chapter_IEq230.gif) using Lemma 3.22, we obtain the expression on the right-hand side of (3.41).

Proposition 3.23

Suppose the Hamiltonian of a quantum system is as in Proposition 3.21 . Then the operators X(t) and P(t) defined by ( 3.39 ) satisfy the following operator-valued differential equation:

![
$$\\displaystyle\\begin{array}{rcl} \\frac{dX} {dt} & =& \\frac{1} {m}P\(t\) \\\\ \\frac{dP} {dt} & =& -{V }^{{\\prime}}\(X\(t\)\).{}\\end{array}$$
](A272900_1_En_3_Chapter_Equ50.gif)

(3.42)

Proof.

See Exercise 7.

Proposition 3.23 means that the operator-valued functions X(t) and P(t) satisfy the operator analogs of the classical equations of motion ![
$$dx/dt = p\(t\)/m$$
](A272900_1_En_3_Chapter_IEq231.gif) and ![
$$dp/dt = -{V }^{{\\prime}}\(x\(t\)\).$$
](A272900_1_En_3_Chapter_IEq232.gif) Nevertheless, the expectation values of X(t) and P(t) do not satisfy the ordinary equations of motion, as we have already seen by calculating in the Schrödinger picture. If we take expectation values in the system (3.42), we get the same answer as in Proposition 3.19, namely,

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle X\(t\)\\right\\rangle _{\\psi }& =& \\frac{1} {m}\\left \\langle P\(t\)\\right\\rangle _{\\psi } {}\\\\ \\frac{d} {dt}\\left \\langle P\(t\)\\right\\rangle _{\\psi }& =& -\\left \\langle {V }^{{\\prime}}\(X\(t\)\)\\right\\rangle _{\\psi }. {}\\\\ \\end{array}$$
](A272900_1_En_3_Chapter_Equ51.gif)

These are not the classical equations of motion, unless the expectation value of the operator V ′ (X(t)) coincides with V ′ applied to the expectation value of X(t), which is usually not the case.

## 3.9 Example: A Particle in a Box

Let us consider quantum mechanics in one space dimension for a particle that is confined to move in a "box," which we describe as the interval 0 ≤ x ≤ L. Our goal is to find all of the eigenvectors and eigenvalues of the Schrödinger operator, that is, to find solutions of the time-independent Schrödinger equation ![
$$\\hat{H}\\psi = E\\psi.$$
](A272900_1_En_3_Chapter_IEq233.gif) In solving this equation, we may think of the constraint to the box as follows. Imagine a particle moving in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_3_Chapter_IEq234.gif) in the presence of a potential V that is 0 for x between 0 and L and takes some very large constant value C on the rest of the real line. Classically, this would mean that the particle has to have very high energy (greater than C) to escape from the box. Quantum mechanically, if we have a solution of the time-independent Schrödinger equation ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_3_Chapter_IEq235.gif) for this potential (with E ≪ C), then we expect ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq419.gif) to decay rapidly for x outside of the box. (We will see this behavior explicitly in Chap.​ 5.) In the limit as C tends to infinity, we expect solutions of the time-independent Schrödinger equation to be zero outside the box and to tend to zero as we approach the ends of the box.

The upshot of this discussion is that we are looking for smooth functions ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq420.gif) on [0, L] that satisfy the differential equation

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi } {d{x}^{2}} = E\\psi \(x\),\\quad 0 \\leq x \\leq L }$$
](A272900_1_En_3_Chapter_Equ52.gif)

(3.43)

and the boundary conditions

![
$$\\displaystyle{ \\psi \(0\) =\\psi \(L\) = 0. }$$
](A272900_1_En_3_Chapter_Equ53.gif)

(3.44)

For E > 0, the solution space to (3.43) will be the span of two complex exponentials, or equivalently a sine and a cosine function:

![
$$\\displaystyle{ \\psi \(x\) = a\\sin \\left \(\\frac{\\sqrt{2mE}} {\\hslash } x\\right\) + b\\cos \\left \(\\frac{\\sqrt{2mE}} {\\hslash } x\\right\). }$$
](A272900_1_En_3_Chapter_Equ54.gif)

(3.45)

If we now impose the boundary condition ![
$$\\psi\(0\) = 0$$
](A272900_1_En_3_Chapter_IEq501.gif), we get that b = 0, leaving only the sine term. If we then impose the condition ![
$$\\psi\(L\) = 0$$
](A272900_1_En_3_Chapter_IEq502.gif), we will obtain a = 0—which would mean that ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq421.gif) is identically zero—unless

![
$$\\displaystyle{ \\sin \\left \(\\frac{\\sqrt{2mE}} {\\hslash } L\\right\) = 0. }$$
](A272900_1_En_3_Chapter_Equ55.gif)

(3.46)

Since we are interested in solutions to (3.43) where ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq422.gif) is not identically zero, we want (3.46) to hold. Thus, the argument of sine function must be an integer multiple of π. This condition imposes a restriction on the value of E, namely that E should be of the form

![
$$\\displaystyle{ E_{j} := \\frac{{j{}^{2}\\pi }^{2}{\\hslash }^{2}} {2m{L}^{2}}, }$$
](A272900_1_En_3_Chapter_Equ56.gif)

(3.47)

for some positive integer j.

It is a simple exercise (Exercise 8) to verify that for E ≤ 0, the only solution to (3.43) satisfying the boundary conditions (3.44) is the one with ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq423.gif) identically zero.

Proposition 3.24

The following functions are solutions to ( 3.43 ) satisfying the boundary conditions ( 3.44 ):

![
$$\\displaystyle{\\psi _{j}\(x\) = \\sqrt{ \\frac{2} {L}}\\sin \\left \(\\frac{j\\pi x} {L} \\right\),\\quad j = 1,2,3,\\ldots,}$$
](A272900_1_En_3_Chapter_Equak.gif)

and the corresponding eigenvalues E j are given by (3.47) . The functions ![
$$\\psi_j$$
](A272900_1_En_3_Chapter_IEq530.gif) form an orthonormal basis for the Hilbert space L 2 ([0,L]).

Proof.

We have already verified the equation and eigenvalue for each ![
$$\\psi_j$$
](A272900_1_En_3_Chapter_IEq424.gif). It is a simple computation to verify that the ![
$$\\psi_j$$
](A272900_1_En_3_Chapter_IEq503.gif)'s are orthonormal, and the elementary theory of Fourier series (Fourier sine series, in this case) shows that the ![
$$\\psi_j$$
](A272900_1_En_3_Chapter_IEq504.gif)'s form an orthonormal basis for L 2([0, L]).

The Hamiltonian operator for this problem (in which V = 0 inside the box) is given by

![
$$\\displaystyle{\\hat{H}\\psi = -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi } {d{x}^{2}}.}$$
](A272900_1_En_3_Chapter_Equal.gif)

This operator is an unbounded operator and is not defined on the whole Hilbert space L 2([0, L]), but only on a dense subspace ![
$$\\mathrm{Dom}\(\\hat{H}\) \\subset {L}^{2}\(\[0,L\]\).$$
](A272900_1_En_3_Chapter_IEq236.gif) The domain of ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq237.gif) should be chosen in such a way that ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq238.gif) is essentially self-adjoint and, thus, symmetric (Sect. 3.2), meaning that

![
$$\\displaystyle{ \\left \\langle \\phi,\\hat{H}\\psi \\right\\rangle = \\left \\langle \\hat{H}\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_3_Chapter_Equ57.gif)

(3.48)

for all ![
$$\\phi,\\psi$$
](A272900_1_En_3_Chapter_IEq505.gif) in ![
$$\\mathrm{Dom}\(\\hat{H}\)$$
](A272900_1_En_3_Chapter_IEq239.gif). For (3.48) to hold, ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq8110.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq1812.gif) must satisfy appropriate boundary conditions, which will allow the boundary terms in the integration by parts to be zero. (See Exercise 9.)

Mathematically, then, it is necessary to impose some boundary conditions in order for ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq240.gif) to be an essentially self-adjoint operator. The particular choice of boundary conditions (3.44) is based on the idea of approximating the box by a very large "confining" potential outside the box. See Chap.​ 9 for an extensive discussion of domain issues for unbounded operator.

## 3.10 Quantum Mechanics for a Particle in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_3_Chapter_IEq241.gif)

Up to this point, we have been considering a quantum particle moving in ![
$${\\mathbb{R}}^{1}.$$
](A272900_1_En_3_Chapter_IEq242.gif) It is straightforward, however, to generalize to a quantum particle moving in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_3_Chapter_IEq243.gif) The Hilbert space for a particle in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_3_Chapter_IEq244.gif) is ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_3_Chapter_IEq245.gif) rather than ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq246.gif) Instead of single position operator, we have n such operators, given by

![
$$\\displaystyle{X_{j}\\psi \(\\mathbf{x}\) = x_{j}\\psi \(\\mathbf{x}\),\\quad j = 1,\\ldots,n.}$$
](A272900_1_En_3_Chapter_Equam.gif)

Similarly, we have n momentum operators, given by

![
$$\\displaystyle{P_{j}\\psi \(\\mathbf{x}\) = -i\\hslash \\frac{\\partial \\psi } {\\partial x_{j}}.}$$
](A272900_1_En_3_Chapter_Equan.gif)

As in the ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_3_Chapter_IEq247.gif) case, X j does not commute with P j but satisfies ![
$$\[X_{j},P_{j}\] = i\\hslash I.$$
](A272900_1_En_3_Chapter_IEq248.gif) On the other hand, X j commutes with X k and P j commutes with P k . Furthermore, X j commutes with P k for j≠k. These formulas are referred to as the canonical commutation relations.

Proposition 3.25 (Canonical Commutation Relations​)

The position and momentum operators satisfy

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{1} {i\\hslash }\[X_{j},X_{k}\] = 0 \\\\ & & \\frac{1} {i\\hslash }\[P_{j},P_{k}\] = 0 \\\\ & & \\frac{1} {i\\hslash }\[X_{j},P_{k}\] =\\delta _{jk}I{}\\end{array}$$
](A272900_1_En_3_Chapter_Equ58.gif)

(3.49)

for all 1 ≤ j,k ≤ n.

These relations are the quantum counterparts of the Poisson bracket relations among the position and momentum functions in classical mechanics. Specifically, the role of the Poisson bracket in Proposition 2.24 is played in Proposition 3.25 by the quantity ![
$$\(1/\(i\\hslash \)\)\[\\cdot,\\cdot \].$$
](A272900_1_En_3_Chapter_IEq249.gif)

If the classical Hamiltonian for a particle in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_3_Chapter_IEq250.gif) is of the usual form (kinetic energy plus potential energy), then we may analogously define the Hamiltonian operator to be of the form

![
$$\\displaystyle{ \\hat{H} =\\sum _{ j=1}^{n}\\frac{P_{j}^{2}} {2m} + V \(\\mathbf{X}\), }$$
](A272900_1_En_3_Chapter_Equ59.gif)

(3.50)

where V (X) denotes the result of applying the function V to the commuting family of operators X = (X 1,..., X n ). It it natural to identify V (X) with the operator of multiplication by the function V (x). In that case, we may write ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq251.gif) more explicitly as

![
$$\\displaystyle{\\hat{H}\\psi \(\\mathbf{x}\) = - \\frac{\\hslash } {2m}\\Delta \\psi \(\\mathbf{x}\) + V \(\\mathbf{x}\)\\psi \(\\mathbf{x}\),}$$
](A272900_1_En_3_Chapter_Equao.gif)

where Δ is the Laplacian, given by

![
$$\\displaystyle{\\Delta =\\sum _{ j=1}^{n} \\frac{{\\partial }^{2}} {\\partial x_{j}^{2}}.}$$
](A272900_1_En_3_Chapter_Equap.gif)

We refer to an operator of the form (3.50) as a Schrödinger operator.

We may also introduce angular momentum operators defined by analogy to the classical angular momentum functions.

Definition 3.26

For each pair (j, k) with 1 ≤ j, k ≤ n, define the angular momentum operator ![
$$\\hat{J}_{jk}$$
](A272900_1_En_3_Chapter_IEq252.gif) by the formula

![
$$\\displaystyle{\\hat{J}_{jk} = X_{j}P_{k} - X_{k}P_{j}.}$$
](A272900_1_En_3_Chapter_Equaq.gif)

As in the classical case, we have ![
$$\\hat{J}_{jk} = 0$$
](A272900_1_En_3_Chapter_IEq253.gif) when j = k. When j≠k, X j and P k commute, so the order of the factors in the definition of ![
$$\\hat{J}_{jk}$$
](A272900_1_En_3_Chapter_IEq254.gif) is not important. Explicitly, we have

![
$$\\displaystyle{\\hat{J}_{jk} = -i\\hslash \\left \(x_{j} \\frac{\\partial } {\\partial x_{k}} - x_{k} \\frac{\\partial } {\\partial x_{j}}\\right\).}$$
](A272900_1_En_3_Chapter_Equar.gif)

The operator in parentheses is the angular derivative (∂ ∕ ∂θ) in the (x j , x k ) plane.

When n = 3, it is customary to use the quantum counterpart of the classical angular momentum vector, namely,

![
$$\\displaystyle{ \\hat{J}_{1} := X_{2}P_{3} - X_{3}P_{2};\\quad \\hat{J}_{2} := X_{3}P_{1} - X_{1}P_{3};\\quad \\hat{J}_{3} := X_{1}P_{2} - X_{2}P_{1}. }$$
](A272900_1_En_3_Chapter_Equ60.gif)

(3.51)

When n = 3, every ![
$$\\hat{J}_{jk}$$
](A272900_1_En_3_Chapter_IEq255.gif) with j≠k is one of the above three operators or the negative thereof.

## 3.11 Systems of Multiple Particles

Suppose now we have a system of N quantum particles moving in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_3_Chapter_IEq256.gif) If the particles are all of different types (e.g., one electron and one proton), then the Hilbert space for this system is ![
$${L}^{2}\({\\mathbb{R}}^{nN}\).$$
](A272900_1_En_3_Chapter_IEq257.gif) That is, the wave function ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq425.gif) of the system is a function of variables ![
$${\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N},$$
](A272900_1_En_3_Chapter_IEq258.gif) with each x j belonging to ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_3_Chapter_IEq259.gif) If we normalize ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq426.gif) to be a unit vector in ![
$${L}^{2}\({\\mathbb{R}}^{nN}\),$$
](A272900_1_En_3_Chapter_IEq260.gif) then ![
$$\\vert \\psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\){\\vert }^{2}$$
](A272900_1_En_3_Chapter_IEq261.gif) is to be interpreted as the joint probability distribution for the positions of the N particles.

We may introduce position operators X k j (the kth component of the position of the jth particle) and momentum operators P k j in obvious analogy to the definition for a single particle. The typical Hamiltonian operator for such a system is then

![
$$\\displaystyle{\\hat{H}\\psi \({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N}\) = -\\sum _{ j=1}^{N} \\frac{{\\hslash }^{2}} {2m_{j}}\\Delta _{j}\\psi \({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N}\) + V \({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N}\)\\psi \(\\mathbf{x}\),}$$
](A272900_1_En_3_Chapter_Equas.gif)

where m j is the mass of the jth particle. Here Δ j means the Laplacian with respect to the variable ![
$${\\mathbf{x}}^{j} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_3_Chapter_IEq262.gif) with the other variables fixed.

As we will see in Chap.​ 19, the Hilbert space for a composite system, made up of various subsystems, is typically taken to be the (Hilbert) tensor product of the individual Hilbert spaces. In the present context, we may think of our system of being made up of N subsystems, each being one of the individual particles. Fortunately, there is a natural isomorphism (Proposition 19.12) between ![
$${L}^{2}\({\\mathbb{R}}^{nN}\)$$
](A272900_1_En_3_Chapter_IEq263.gif) and the tensor product of N copies of ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_3_Chapter_IEq264.gif) so that the approach we are taking here is consistent with the general philosophy.

If the particles in question are identical (say, all electrons), then there is an additional complication to the description of the Hilbert space for the system. In standard quantum theory, we are supposed to believe that "identical particles are indistinguishable." What this means is that the wave function should have the property that if we interchange, say, x 1 with x 2, then the new wave function should represent the same physical state as the original wave function. Recalling that two unit vectors in the quantum Hilbert space represent the same physical state if and only if they differ by a constant of absolute value 1, this means we should have

![
$$\\displaystyle{\\psi \({\\mathbf{x}}^{2},{\\mathbf{x}}^{1},{\\mathbf{x}}^{3},\\ldots,{\\mathbf{x}}^{N}\) = u\\psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},{\\mathbf{x}}^{3},\\ldots,{\\mathbf{x}}^{N}\),}$$
](A272900_1_En_3_Chapter_Equat.gif)

for some constant u with ![
$$\\left \\vert u\\right\\vert = 1.$$
](A272900_1_En_3_Chapter_IEq265.gif) Applying this rule twice gives that ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq531.gif) is ![
$$u^2{\\psi}$$
](A272900_1_En_3_Chapter_IEq532.gif), so evidently u must be either 1 or − 1.

Particles in quantum mechanics are grouped into two types, according to whether the constant u in the previous paragraph is 1 or − 1. Particles with u = 1 are called bosons and particles with ![
$$u = -1$$
](A272900_1_En_3_Chapter_IEq266.gif) are called fermions. Whether a particle is a boson or a fermion is determined by the spin of the particle, a concept that we have not yet introduced. Nevertheless, we can say that particles without spin are bosons. For a collection of N identical spinless particles moving in ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_3_Chapter_IEq267.gif) the proper Hilbert space is the symmetric subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3N}\),$$
](A272900_1_En_3_Chapter_IEq268.gif) that is, the space of functions in ![
$${L}^{2}\({\\mathbb{R}}^{3N}\)$$
](A272900_1_En_3_Chapter_IEq269.gif) that are invariant under arbitrary permutations of the variables. We will have more to say about spin and systems of identical particles in Chaps.​ 17 and .

## 3.12 Physics Notation

In quantum mechanics, physicists almost invariably use the Dirac notation (or bra-ket notation) introduced by Dirac in 1939 [5]. This notation is made up of Notations 3.27–3.29 below. In this section, we explore the Dirac notation along with a few other notational differences between the mathematics and physics literature.

Before proceeding it is important to point out that when using Dirac notation, it is essential that the complex conjugate in the inner product should go on the first factor.

Notation 3.27

A vector ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq506.gif) in H is referred to as a ket and is denoted ![
$$\\left \\vert \\psi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq270.gif) A continuous linear functional on H is called a bra . For any ![
$$d\\psi \\ \\in \\ \\bf{H} $$
](A272900_1_En_3_Chapter_IEq812.gif) , let ![
$$\\left \\langle \\phi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq271.gif) denote the bra given by

![
$$\\displaystyle{\\left \\langle \\phi \\right\\vert \(\\psi \) = \\left \\langle \\phi,\\psi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equau.gif)

That is to say, ![
$$\\left \\langle \\phi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq272.gif) is the "inner product with ![
$$d\\psi$$
](A272900_1_En_3_Chapter_IEq813.gif)" functional. The bracket (or bra-ket ) of two vectors ![
$$d\\psi \\ \\in \\ \\bf{H} $$
](A272900_1_En_3_Chapter_IEq8193.gif) is the result of applying the bra ![
$$\\left \\langle \\phi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq273.gif) to the ket ![
$$\\left \\vert \\psi \\right\\rangle,$$
](A272900_1_En_3_Chapter_IEq274.gif) namely the inner product of the ![
$$d\\phi$$
](A272900_1_En_3_Chapter_IEq8147.gif) and ![
$$d\\psi$$
](A272900_1_En_3_Chapter_IEq815.gif) , denoted ![
$$\\left \\langle \\phi \\vert \\psi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq275.gif)

If A is an operator on H and ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq782.gif) is a vector in H, then we can form the linear functional ![
$$\\left \\langle \\phi \\right\\vert A,$$
](A272900_1_En_3_Chapter_IEq276.gif) i.e., the linear map ![
$$\\psi \\mapsto \\left \\langle \\phi \\vert A\\psi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq277.gif) Physicists generally write an expression of this form as

![
$$\\displaystyle{\\left \\langle \\phi \\left \\vert A\\right\\vert \\psi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equav.gif)

This notation emphasizes that there are two different ways of thinking of this quantity. We may think of ![
$$\\left \\langle \\phi \\left \\vert A\\right\\vert \\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq278.gif) either as the linear functional ![
$$\\left \\langle \\phi \\right\\vert A$$
](A272900_1_En_3_Chapter_IEq279.gif) applied to the vector ![
$$\\left \\vert \\psi \\right\\rangle,$$
](A272900_1_En_3_Chapter_IEq280.gif) or as the linear functional ![
$$\\left \\langle \\phi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq281.gif) applied to the vector ![
$$A\\left \\vert \\psi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq282.gif)

Notation 3.28

For any ![
$$d\\phi $$
](A272900_1_En_3_Chapter_IEq8713.gif) and ![
$$d\\psi $$
](A272900_1_En_3_Chapter_IEq814.gif) in H , the expression ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq283.gif) denotes the linear operator on H given by

![
$$\\displaystyle{\\left \(\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \\right\)\(\\chi \) = \\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\vert \\chi \\right\\rangle = \\left \\langle \\psi \\vert \\chi \\right\\rangle \\left \\vert \\phi \\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equaw.gif)

That is, in mathematics notation, ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq284.gif) is the operator sending χ to ![
$$\\left \\langle \\psi,\\chi \\right\\rangle \\phi.$$
](A272900_1_En_3_Chapter_IEq285.gif)

The operator ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_3_Chapter_IEq286.gif) associates to each (ket) vector ![
$$\\left \\vert \\chi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq287.gif) a new vector in the only way that makes notational sense: We interpret ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \\left \\vert \\chi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq288.gif) as the vector ![
$$\\left \\vert \\phi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq289.gif) multiplied by the scalar ![
$$\\left \\langle \\psi \\vert \\chi \\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq290.gif)

Notation 3.29

Given a family of vectors in H labeled by, say, three indices n, l, and m, rather than denoting these vectors as ![
$$\\left \\vert \\psi _{n,l,m}\\right\\rangle,$$
](A272900_1_En_3_Chapter_IEq291.gif) a physicist will denote them simply as ![
$$\\left \\vert n, l, m\\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq292.gif)

This notation is not without its pitfalls. If we have two different sets of vectors labeled by the same set of indices, a mathematician can simply label them as ![
$$d\\phi_{n,l,m}$$
](A272900_1_En_3_Chapter_IEq816.gif) and ![
$$d\\psi_{n,l,m}$$
](A272900_1_En_3_Chapter_IEq817.gif), but the physicist has a problem.

As an example of the Dirac notation, suppose that an operator ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq293.gif) has an orthonormal basis of eigenvectors ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq818.gif). A physicist would express the decomposition of a general vector in terms of this basis as

![
$$\\displaystyle{ I =\\sum _{n}\\left \\vert n\\right\\rangle \\left \\langle n\\right\\vert, }$$
](A272900_1_En_3_Chapter_Equ61.gif)

(3.52)

where ![
$$\\psi_n$$
](A272900_1_En_3_Chapter_IEq511.gif) is represented simply as ![
$$\\left \\vert n\\right\\rangle$$
](A272900_1_En_3_Chapter_IEq294.gif) and where ![
$$\\left \\vert n\\right\\rangle \\left \\langle n\\right\\vert$$
](A272900_1_En_3_Chapter_IEq295.gif) is (given that ![
$$\\left \\vert n\\right\\rangle$$
](A272900_1_En_3_Chapter_IEq296.gif) is a unit vector) the orthogonal projection onto the one-dimensional subspace spanned by the vector ![
$$\\left \\vert n\\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq297.gif)

Notation 3.30

In the physics literature, the complex conjugate of a complex number z is denoted as z ∗, rather than ![
$$\\bar{z}$$
](A272900_1_En_3_Chapter_IEq298.gif) , as in the mathematics literature. What a mathematician calls the adjoint of an operator and denotes by A ∗ , a physicist calls the Hermitian conjugate of A and denotes by A † . Physicists refer to self-adjoint operators as Hermitian.

We may express the concept of an adjoint (or Hermitian conjugate) of an operator using Dirac notation, as follows. If A is a bounded operator on H, then A † is the unique bounded operator such that

![
$$\\displaystyle{\\left \\langle \\psi \\right\\vert A = \\left \\langle {A}^{\\dag }\\psi \\right\\vert.}$$
](A272900_1_En_3_Chapter_Equax.gif)

One peculiarity of the physics literature on quantum mechanics is a conspicuous failure of most articles to state what the Hilbert space is. Rather than starting by defining the Hilbert space in which they are working, physicists generally start by writing down the commutation relations that hold among various operators on the space. Thus, for example, a physicist might begin with position and momentum operators X and P, satisfying ![
$$\[X,P\] = i\\hslash I,$$
](A272900_1_En_3_Chapter_IEq299.gif) without ever specifying what space these operators are operating on. The justification for this omission is, presumably, the Stone–von Neumann theorem, which asserts that (provided the operators satisfy the expected "exponentiated" relations) there is, up to unitary equivalence, only one Hilbert space with operators satisfying these relations and on which the operators act irreducibly. (See Chap.​ 14 for a precise statement of the result.) It is, nevertheless, disconcerting for a mathematician to encounter an entire paper full of computations involving certain operators, without any specification of what space these operators are operating on, let alone how the operators act on the space.

This practice among physicists represents something of a role reversal. In the setting of linear algebra, for example, a mathematician might say, "Let V be a n-dimensional vector space over ![
$$\\mathbb{R}.$$
](A272900_1_En_3_Chapter_IEq300.gif)" If a physicist says, "Oh, so it's ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_3_Chapter_IEq301.gif)" the mathematician will reply, "No, no, you don't have to choose a basis." By contrast, in quantum mechanics, it is the physicist who does not want to choose a particular realization of the space. A physicist will simply write down the commutation relations between, say, X and P. If pressed, the physicist might say that he is working in an irreducible representation of those relations. If a mathematician then says, "Oh, so it's ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_3_Chapter_IEq302.gif)" the physicist will reply, "No, no, there is no preferred realization."

Notation 3.31

Given an irreducible representation of the canonical commutation relations, and given a vector ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq443.gif) in the corresponding Hilbert space, a physicist will speak of the position wave function ![
$$\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq512.gif), defined by

![
$$\\displaystyle{ \\psi \(x\) = \\left \\langle x\\vert \\psi \\right\\rangle. }$$
](A272900_1_En_3_Chapter_Equ62.gif)

(3.53)

Here, ![
$$\\left \\langle x\\right\\vert$$
](A272900_1_En_3_Chapter_IEq303.gif) is the bra associated with the ket ![
$$\\left \\vert x\\right\\rangle,$$
](A272900_1_En_3_Chapter_IEq304.gif) where ![
$$\\left \\vert x\\right\\rangle$$
](A272900_1_En_3_Chapter_IEq305.gif) is supposed to be an eigenvector for the position operator with eigenvalue x.

See, again, Chap.​ 14 for the precise notion of "irreducible representation of the canonical commutation relations." One may similarly define the momentum wave function by taking the inner product of ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq427.gif) with the eigenvectors of the momentum operator, which are also non-normalizable. See Sect.​ 6.​6 for details.

A mathematician might find Notation 3.31 objectionable on the grounds that the operator X does not actually have any eigenvectors. After all, it is harmless, in view of the Stone–von Neumann theorem, to work in the "Schrödinger representation," in which our Hilbert space is ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq306.gif) and the position operator X is just multiplication by x. Given a number x 0, there is no nonzero element ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq428.gif) of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq307.gif) for which ![
$$X_\\psi\\ = \\ x_0\\psi$$
](A272900_1_En_3_Chapter_IEq513.gif). After all, any ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq429.gif) satisfying this equation would have to be supported at the point x = x 0, in which case ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq430.gif) would equal zero almost everywhere and would be the zero element of ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq308.gif) A physicist, on the other hand, would say that the desired eigenfunction is ![
$$\\psi \(x\) =\\delta \(x - x_{0}\),$$
](A272900_1_En_3_Chapter_IEq309.gif) where δ is the Dirac delta-"function." The fact that δ(x − x 0) is not actually in the Hilbert space ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq310.gif) does not concern the physicist; it is simply a "non-normalizable state." The mathematical theory of such non-normalizable states comes under the heading "generalized eigenvectors." See Sect.​ 6.​6 for a discussion of this issue in the case of the eigenvectors of the momentum operator.

A more subtle issue regarding the "position eigenvectors" is that each eigenvector is unique only up to multiplication by a constant. If one wants the momentum operator to act on the position wave function, as defined by (3.53), in the usual way, one must make a consistent choice of normalization of the eigenvectors of the position operators. Specifically, one should choose the constants in such a way that the exponentiated momentum operator ![
$$\\exp \(iaP/\\hslash \)$$
](A272900_1_En_3_Chapter_IEq311.gif) maps ![
$$\\left \\vert x\\right\\rangle$$
](A272900_1_En_3_Chapter_IEq312.gif) to ![
$$\\left \\vert x + a\\right\\rangle.$$
](A272900_1_En_3_Chapter_IEq313.gif)

## 3.13 Exercises

1.

Suppose that ![
$$\\phi\(t\)$$
](A272900_1_En_3_Chapter_IEq514.gif) and ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq485.gif) are differentiable functions with values in a Hilbert space H, meaning that the limit

![
$$\\displaystyle{ \\frac{d\\phi } {dt} :=\\lim _{h\\rightarrow 0}\\frac{\\phi \(t + h\) -\\phi \(t\)} {h} }$$
](A272900_1_En_3_Chapter_Equay.gif)

exists in the norm topology of H for each t, and similarly for ![
$$\\psi\(t\)$$
](A272900_1_En_3_Chapter_IEq486.gif). Show that

![
$$\\displaystyle{ \\frac{d} {dt}\\left \\langle \\phi \(t\),\\psi \(t\)\\right\\rangle = \\left \\langle \\frac{d\\phi } {dt},\\psi \(t\)\\right\\rangle + \\left \\langle \\phi \(t\), \\frac{d\\psi } {dt}\\right\\rangle.}$$
](A272900_1_En_3_Chapter_Equaz.gif)

2.

Suppose A and B are operators on a finite-dimensional Hilbert space and suppose that ![
$$AB - BA = cI$$
](A272900_1_En_3_Chapter_IEq314.gif) for some constant c. Show that c = 0.

Note: This shows that the commutation relations in (3.8) are a purely infinite-dimensional phenomenon.

3.

If A is a bounded operator on a Hilbert space H, then there exists a unique bounded operator A ∗ on H satisfying ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\phi,\\psi \\right\\rangle$$
](A272900_1_En_3_Chapter_IEq315.gif) for all ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq515.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq516.gif) in H. (Appendix A.4.3.) The operator A ∗ is called the adjoint of A, and A is called self-adjoint if A ∗ = A.

(a)

Show that for any bounded operator A and constant ![
$$c \\in \\mathbb{C},$$
](A272900_1_En_3_Chapter_IEq316.gif) we have ![
$${\(cA\)}^{{\\ast}} =\\bar{ c}{A}^{{\\ast}},$$
](A272900_1_En_3_Chapter_IEq317.gif) where ![
$$\\bar{c}$$
](A272900_1_En_3_Chapter_IEq318.gif) is the complex conjugate of c.

(b)

Show that if A and B are self-adjoint, then the operator

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[A,B\]}$$
](A272900_1_En_3_Chapter_Equba.gif)

is also self-adjoint.

4.

Verify Proposition 3.19 using Proposition 3.14. Note that the operator V ′ (X) means simply the operator of multiplication by the function V ′ (x).

5.

Suppose that ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq431.gif) is a unit vector in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_3_Chapter_IEq319.gif) such that the functions ![
$$x\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq517.gif) and ![
$$x^2\\psi\(x\)$$
](A272900_1_En_3_Chapter_IEq518.gif) also belong to ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_3_Chapter_IEq320.gif) Show that

![
$$\\displaystyle{\\left \\langle {X}^{2}\\right\\rangle _{ \\psi } >{ \\left \(\\left \\langle X\\right\\rangle _{\\psi }\\right\)}^{2}.}$$
](A272900_1_En_3_Chapter_Equbb.gif)

Hint: Consider the integral

![
$$\\displaystyle{\\int _{-\\infty }^{\\infty }{\(x - a\)}^{2}{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx,}$$
](A272900_1_En_3_Chapter_Equbc.gif)

where ![
$$a = \\left \\langle X\\right\\rangle _{\\psi }.$$
](A272900_1_En_3_Chapter_IEq321.gif)

6.

Consider the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq322.gif) for a quantum harmonic oscillator, given by

![
$$\\displaystyle{\\hat{H} = -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}} {d{x}^{2}} + \\frac{k} {2}{x}^{2},}$$
](A272900_1_En_3_Chapter_Equbd.gif)

where k is the spring constant of the oscillator. Show that the function

![
$$\\displaystyle{\\psi _{0}\(x\) =\\exp \\left \\{-\\frac{\\sqrt{km}} {2\\hslash } {x}^{2}\\right\\}}$$
](A272900_1_En_3_Chapter_Eqube.gif)

is an eigenvector for ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq323.gif) with eigenvalue ![
$$\\hslash \\omega /2,$$
](A272900_1_En_3_Chapter_IEq324.gif) where ![
$$\\omega := \\sqrt{k/m}$$
](A272900_1_En_3_Chapter_IEq325.gif) is the classical frequency of the oscillator.

Note: We will explore the eigenvectors and eigenvalues of ![
$$\\hat{H}$$
](A272900_1_En_3_Chapter_IEq326.gif) in detail in Chap.​ 11.

7.

Prove Proposition 3.23.

Hint: Show that ![
$$\[P\(t\),\\hat{H}\] = \(\[P,\\hat{H}\]\)\(t\)$$
](A272900_1_En_3_Chapter_IEq327.gif) and ![
$$\[X\(t\),\\hat{H}\] = \(\[X,\\hat{H}\]\)\(t\).$$
](A272900_1_En_3_Chapter_IEq328.gif)

8.

(a)

Find the general solution to (3.43), where E is a negative real number. Show that the only such solution that satisfies the boundary conditions (3.44) is identically zero.

(b)

Establish the same result as in Part (a) for E = 0.

9.

(a)

Suppose ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq519.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq520.gif) are smooth functions on [0, L] satisfying the boundary conditions (3.44). Using integration by parts, show that

![
$$\\displaystyle{\\left \\langle \\phi,\\hat{H}\\psi \\right\\rangle = \\left \\langle \\hat{H}\\phi,\\psi \\right\\rangle,}$$
](A272900_1_En_3_Chapter_Equbf.gif)

where ![
$$\\hat{H} = -\({\\hslash }^{2}/2m\)\\ {d}^{2}/d{x}^{2}$$
](A272900_1_En_3_Chapter_IEq329.gif) and where

![
$$\\displaystyle{\\left \\langle \\phi,\\psi \\right\\rangle =\\int _{ 0}^{L}\\overline{\\phi \(x\)}\\psi \(x\)\\ dx.}$$
](A272900_1_En_3_Chapter_Equbg.gif)

(b)

Show that the result of Part (a) fails if ![
$$\\phi$$
](A272900_1_En_3_Chapter_IEq521.gif) and ![
$$\\psi$$
](A272900_1_En_3_Chapter_IEq522.gif) are arbitrary smooth functions (not satisfying the boundary conditions).

10.

Let ![
$$\\hat{J}_{1},$$
](A272900_1_En_3_Chapter_IEq330.gif) ![
$$\\hat{J}_{2},$$
](A272900_1_En_3_Chapter_IEq331.gif) and ![
$$\\hat{J}_{3}$$
](A272900_1_En_3_Chapter_IEq332.gif) be the angular momentum operators for a particle moving in ![
$${\\mathbb{R}}^{3}.$$
](A272900_1_En_3_Chapter_IEq333.gif) Using the canonical commutation relations (Proposition 3.25), show that these operators satisfy the commutation relations

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[\\hat{J}_{1},\\hat{J}_{2}\] =\\hat{ J}_{3};\\quad \\frac{1} {i\\hslash }\[\\hat{J}_{2},\\hat{J}_{3}\] =\\hat{ J}_{1};\\quad \\frac{1} {i\\hslash }\[\\hat{J}_{3},\\hat{J}_{1}\] =\\hat{ J}_{2}.}$$
](A272900_1_En_3_Chapter_Equbh.gif)

This is the quantum mechanical counterpart to Exercise 19 in the previous chapter.

References

[5].

P.A.M. Dirac, A new notation for quantum mechanics. Math. Proc. Cambridge Philosoph. Soc. 35, 416–418 (1939)CrossRefMathSciNet

[18].

A. Gut, Probability: A Graduate Course (Springer, New York, 2005)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_4

© Springer Science+Business Media New York 2013

# 4. The Free Schrödinger Equation

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In this chapter, we consider various methods of solving the free Schrödinger equation in one space dimension. Here "free"means that there is no force acting on the particle, so that we may take the potential V to be identically zero

In this chapter, we consider various methods of solving the free Schrödinger equation in one space dimension. Here "free" means that there is no force acting on the particle, so that we may take the potential V to be identically zero. Thus, the free Schrödinger equation is

![
$$\\displaystyle{ \\frac{\\partial \\psi } {\\partial t} = \\frac{i\\hslash } {2m} \\frac{{\\partial }^{2}\\psi } {\\partial {x}^{2}}, }$$
](A272900_1_En_4_Chapter_Equ1.gif)

(4.1)

subject to an initial condition of the form

![
$$\\displaystyle{\\psi \(x,0\) =\\psi _{0}\(x\).}$$
](A272900_1_En_4_Chapter_Equa.gif)

We will identify some key features of solutions to this equation, such as the "spread of the wave packet" and the distinction between "phase velocity" and "group velocity." In particular, the notion of group velocity will confirm our expectation that a particle of momentum p should travel with velocity ![
$$v = p/m.$$
](A272900_1_En_4_Chapter_IEq1.gif)

Before attempting to solve the free Schrödinger equation, let us make a simple observation about the time evolution of the expected values of the position and momentum. If we apply Proposition 3.18 in the case that V is identically equal to zero, we have

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle X\\right\\rangle _{\\psi \(t\)}& =& \\frac{1} {m}\\left \\langle P\\right\\rangle _{\\psi \(t\)} {}\\\\ \\frac{d} {dt}\\left \\langle P\\right\\rangle _{\\psi \(t\)}& =& 0. {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ2.gif)

Thus, the expectation value of P is independent of time, which then means that the expectation value of X is linear in time:

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle X\\right\\rangle _{\\psi \(t\)}& =& \\left \\langle X\\right\\rangle _{\\psi _{0}} + \\frac{t} {m}\\left \\langle P\\right\\rangle _{\\psi _{0}} {}\\\\ \\left \\langle P\\right\\rangle _{\\psi \(t\)}& =& \\left \\langle P\\right\\rangle _{\\psi _{0}}. {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ3.gif)

Thus, the free Schrödinger equation is one of the special cases in which the expected values of the position and momentum exactly follow classical trajectories (and those classical trajectories are very simple in the case ![
$$V \\equiv 0$$
](A272900_1_En_4_Chapter_IEq2.gif)).

## 4.1 Solution by Means of the Fourier Transform

We look for solutions of the free Schrödinger equation on ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_4_Chapter_IEq3.gif) of the form

![
$$\\displaystyle{ \\psi \(x, t\) = {e}^{i\(kx-\\omega \(k\)t\)}, }$$
](A272900_1_En_4_Chapter_Equ4.gif)

(4.2)

where k is the frequency in space and ω(k) is the frequency in time, which is an as-yet-undetermined function of k. (Of course, such a solution is not square-integrable in x for a fixed t, but we will find our way back to square-integrable solutions eventually.) Plugging this into (4.1) easily gives the formula for ω as a function of k:

![
$$\\displaystyle{ \\omega \(k\) = \\frac{\\hslash {k}^{2}} {2m}. }$$
](A272900_1_En_4_Chapter_Equ5.gif)

(4.3)

A formula of this sort, expressing the temporal frequency ω as a function of the spatial frequency k in a solution of some partial differential equation, is called a dispersion relation.

Observe that (4.2) can be written as

![
$$\\displaystyle{ \\psi \(x, t\) =\\exp \\left \[ik\\left \(x -\\frac{\\omega \(k\)} {k} t\\right\)\\right\]. }$$
](A272900_1_En_4_Chapter_Equ6.gif)

(4.4)

Now, replacing a function f(x) by f(x − a) has the effect of shifting f to the right by a. Thus, the time-evolution has the effect of shifting the initial function to the right by an amount equal to (ω(k) ∕ k)t. This means that the function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq301.gif)(x, t) is moving to the right with speed ω(k) ∕ k. This speed, for reasons that will be clearer in Sect. 4.3, is called the phase velocity.

The phase velocity, then, is the speed at which a pure exponential solution of our equation (the free Schrödinger equation) propagates. We compute the phase velocity as ![
$$\\omega \(k\)/k = \\hslash k/\(2m\).$$
](A272900_1_En_4_Chapter_IEq4.gif) Now, we have said that a wave function of the form e ikx represents a particle with momentum ![
$$p = \\hslash k.$$
](A272900_1_En_4_Chapter_IEq5.gif) We thus arrive at the following curious conclusion.

Proposition 4.1

The phase velocity of a particle with momentum ![
$$p = \\hslash k$$
](A272900_1_En_4_Chapter_IEq6.gif) is

![
$$\\displaystyle{\\text{phase velocity} = \\frac{\\omega \(k\)} {k} = \\frac{\\hslash k} {2m} = \\frac{p} {2m}.}$$
](A272900_1_En_4_Chapter_Equb.gif)

This velocity is half the velocity of a classical particle of momentum p.

Proposition 4.1 might make us think that our basic relation ![
$$p = \\hslash k$$
](A272900_1_En_4_Chapter_IEq7.gif) is off by a factor of 2. We will see, however, that the phase velocity, that is, the velocity of a pure exponential solution, is not the "real" velocity of a particle with momentum p. The real velocity is the "group velocity," which will turn out to be, as expected, p ∕ m.

Leaving aside for now the question of the velocity, let us build up a general solution to (4.1) from solutions of the form (4.2). We make use of the Fourier transform, discussed in Appendix A.3. We can then express the solution to the free Schrödinger equation, for "nice" initial conditions, as a "superposition" of these pure exponential solutions.

Proposition 4.2

Suppose that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq521.gif) 0 is a "nice" function, for example, a Schwartz function (Definition A.15 ). Let ![
$$\\hat{\\psi }_{0}$$
](A272900_1_En_4_Chapter_IEq8.gif) denote the Fourier transform of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq522.gif) 0 and define ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq523.gif) (x, t) by

![
$$\\displaystyle{ \\psi \(x, t\) = \\frac{1} {\\sqrt{2\\pi }}\\int _{-\\infty }^{\\infty }\\hat{\\psi }_{ 0}\(k\){e}^{i\(kx-\\omega \(k\)t\)}\\ dk, }$$
](A272900_1_En_4_Chapter_Equ7.gif)

(4.5)

where ω(k) is defined by ( 4.3 ). Then ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq524.gif) (x, t) solves the free Schrödinger equation with initial condition ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq525.gif) 0

The assumption that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq302.gif) be a Schwartz function is stronger than necessary. The reader is invited to trace through the argument and find suitable weaker conditions.

Proof.

Since the Fourier transform of a Schwartz function is a Schwartz function, ![
$$\\hat{\\psi }_{0}\(k\)$$
](A272900_1_En_4_Chapter_IEq9.gif) will decay faster than 1 ∕ k 4 as k tends to ± ∞. Meanwhile, by integrating the derivative of the function e ikx , we obtain the estimate

![
$$\\displaystyle{\\left \\vert \\frac{{e}^{ik\(x+h\)} - {e}^{ikx}} {h} \\right\\vert \\leq \\left \\vert k\\right\\vert.}$$
](A272900_1_En_4_Chapter_Equc.gif)

We can then apply dominated convergence, using ![
$$\\left \\vert k\\right\\vert \\left \\vert \\hat{\\psi }_{0}\(k\)\\right\\vert$$
](A272900_1_En_4_Chapter_IEq10.gif) as our dominating function, to move a derivative with respect to x under the integral sign in the formula for ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq303.gif)(x, t). This derivative pulls down a factor of ik inside the integral. The decay of ![
$$\\hat{\\psi }_{0}$$
](A272900_1_En_4_Chapter_IEq11.gif) allows us to repeat this argument to move a second derivative with respect inside the integral. We can also move a derivative with respect to t inside the integral, by a similar argument.

Since exp{i(kx − ω(k)t)} satisfies the Schrödinger equation for each fixed k, differentiation under the integral shows that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq305.gif)(x, t) satisfies the Schrödinger equation as well. The Fourier inversion formula shows that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq27.gif)(x, 0) = ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq312.gif) 0(x).

Proposition 4.3

If ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq526.gif) (x, t) is as in Proposition 4.2 , then the Fourier transform of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq527.gif) (x, t), with respect to x with t fixed, is given by

![
$$\\displaystyle{ \\hat{\\psi }\(k,t\) =\\hat{\\psi } _{0}\(k\)\\exp \\left \[-i\\frac{\\hslash {k}^{2}t} {2m} \\right\]. }$$
](A272900_1_En_4_Chapter_Equ8.gif)

(4.6)

Proof.

We can write (4.5) as

![
$$\\displaystyle{\\psi \(x, t\) = \\frac{1} {\\sqrt{2\\pi }}\\int _{-\\infty }^{\\infty }{e}^{ikx}\\left \[\\hat{\\psi }_{ 0}\(k\){e}^{-i\\omega \(k\)t}\\right\]\\ dk.}$$
](A272900_1_En_4_Chapter_Equd.gif)

By the uniqueness of the Fourier decomposition (i.e., the injectivity of the inverse Fourier transform, which follows from the Plancherel formula), the Fourier transform of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq324.gif)(x, t) (with respect to x) must be the function in square brackets. Putting in the expression (4.3) for ω(k) establishes the desired result.

Now, the Fourier transform is a unitary map from ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_4_Chapter_IEq12.gif) onto ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_4_Chapter_IEq13.gif). Thus, for any ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq528.gif) 0 in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq14.gif) ![
$$\\hat{\\psi }_{0}$$
](A272900_1_En_4_Chapter_IEq15.gif) also belongs to ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_4_Chapter_IEq16.gif) Since the quantity multiplying ![
$$\\hat{\\psi }_{0}\(k\)$$
](A272900_1_En_4_Chapter_IEq17.gif) in (4.6) has absolute value 1, the right-hand side of (4.6) is a well-defined square-integrable function of k, for any ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq334.gif) 0 in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq18.gif) which has a well-defined inverse Fourier transform in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_4_Chapter_IEq19.gif)

Definition 4.4

For any ![
$$\\psi _{0} \\in {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq20.gif) define, for each ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_4_Chapter_IEq21.gif) ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq331.gif)(x, t) to be the unique element of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_4_Chapter_IEq22.gif) that has a Fourier transform (with respect to x) given by ( 4.6 ).

Definition 4.4 defines a time-evolution for arbitrary initial conditions in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_4_Chapter_IEq23.gif). For general ![
$$\\psi _{0} \\in {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq24.gif) however, ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq332.gif)(x, t) may not satisfy the Schrödinger equation in the classical, pointwise sense, simply because ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq333.gif)(x, t) may fail to be differentiable, either in x or in t. Nevertheless, ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq350.gif)(x, t), as defined by Definition 4.4, always satisfies the Schrödinger equation in the weak (distributional) sense. See Exercise 1.

## 4.2 Solution as a Convolution

According to Proposition 4.3, we see that the Fourier transform of the time-t wave function is the product of the Fourier transform of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq352.gif) 0 and the function ![
$$\\exp \[-it\\hslash {k}^{2}/\(2m\)\].$$
](A272900_1_En_4_Chapter_IEq25.gif) According to Proposition A.21, the inverse Fourier transform of a product of two sufficiently nice functions is ![
$$1/\\sqrt{2\\pi }$$
](A272900_1_En_4_Chapter_IEq26.gif) times the convolution of the two separate inverse Fourier transforms. Here the convolution ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq127.gif) ∗ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq353.gif) of two functions ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq356.gif) and ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq412.gif) is defined to be

![
$$\\displaystyle{\(\\phi {\\ast}\\psi \)\(x\) =\\int _{ -\\infty }^{\\infty }\\phi \(x - y\)\\psi \(y\)\\ dy,}$$
](A272900_1_En_4_Chapter_Eque.gif)

whenever the integral is convergent for all x.

Formally, then, we ought to have

![
$$\\displaystyle{ \\psi \(x, t\) =\\psi _{0} {\\ast} K_{t}, }$$
](A272900_1_En_4_Chapter_Equ9.gif)

(4.7)

where

![
$$\\displaystyle{K_{t} = \\frac{1} {\\sqrt{2\\pi }}{\\mathcal{F}}^{-1}\\left \\{\\exp \\left \[-i\\frac{\\hslash {k}^{2}t} {2m} \\right\]\\right\\}.}$$
](A272900_1_En_4_Chapter_Equf.gif)

The problem with is idea is that the function ![
$$\\exp \[-it\\hslash {k}^{2}/\(2m\)\]$$
](A272900_1_En_4_Chapter_IEq403.gif) is not a "nice" function in the usual sense. Certainly, this function is not the Fourier transform of some function in ![
$${L}^{1}\(\\mathbb{R}\) \\cap {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq28.gif) because if it were, then the function would have to tend to zero at infinity (Proposition A.14). Therefore, we cannot directly apply Proposition A.21, even if ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq357.gif) 0 is in ![
$${L}^{1}\(\\mathbb{R}\) \\cap {L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_4_Chapter_IEq29.gif)

Fortunately, the desired inverse Fourier transform can be computed as a convergent improper integral (Exercise 2), with the following result:

![
$$\\displaystyle{ K_{t}\(x\) := \\frac{1} {2\\pi }\\int _{-\\infty }^{\\infty }{e}^{ikx}\\exp \\left \[-i\\frac{\\hslash {k}^{2}t} {2m} \\right\]\\ dk = \\sqrt{ \\frac{m} {i2\\pi \\hslash t}}\\exp \\left \\{i\\frac{m{x}^{2}} {2t\\hslash } \\right\\}. }$$
](A272900_1_En_4_Chapter_Equ10.gif)

(4.8)

Here, the square root is the one with positive real part. The function K t is called the fundamental solution of the free Schrödinger equation. (See Fig. 4.1.) This function does indeed satisfy the free Schrödinger equation, as we can easily verify by direct differentiation.

Figure 4.1

The real part of K t (x), for t = 1 (top) and t = 0. 2 (bottom).

The preceding discussion should make the following result plausible.

Theorem 4.5

Suppose ![
$$\\psi _{0} \\in {L}^{2}\(\\mathbb{R}\) \\cap {L}^{1}\(\\mathbb{R}\).$$
](A272900_1_En_4_Chapter_IEq30.gif) Then ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq529.gif) (x, t), as defined by ( 4.5 ), may be computed for all t≠0 as

![
$$\\displaystyle{\\psi \(x, t\) = \\sqrt{ \\frac{m} {2\\pi it\\hslash }}\\int _{-\\infty }^{\\infty }\\exp \\left \\{i \\frac{m} {2t\\hslash }{\(x - y\)}^{2}\\right\\}\\psi _{ 0}\(y\)\\ dy.}$$
](A272900_1_En_4_Chapter_Equg.gif)

The expression for ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq535.gif) (x, t) is ![
$${\(2\\pi \)}^{-1/2}K_{t} {\\ast}\\psi _{0},$$
](A272900_1_En_4_Chapter_IEq31.gif) where K t is as in ( 4.8 ).

Proof.

For any set ![
$$E \\subset \\mathbb{R},$$
](A272900_1_En_4_Chapter_IEq32.gif) let 1 E denote the indicator function of E, that is, the function that is 1 on E and 0 elsewhere. Then K t 1[ − n, n] belongs to ![
$${L}^{1}\(\\mathbb{R}\) \\cap {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_4_Chapter_IEq33.gif) for any positive integer n. By Proposition A.21, then, we have

![
$$\\displaystyle{ \\mathcal{F}\\left \(\(K_{t}1_{\[-n,n\]}\) {\\ast}\\psi _{0}\\right\) = \\sqrt{2\\pi }\\mathcal{F}\(K_{t}1_{\[-n,n\]}\)\\mathcal{F}\(\\psi _{0}\). }$$
](A272900_1_En_4_Chapter_Equ11.gif)

(4.9)

Because ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq358.gif) 0 is in ![
$${L}^{1}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq34.gif) it is easy to see that ![
$$K_{t}1_{\[-n,n\]} {\\ast}\\psi _{0}$$
](A272900_1_En_4_Chapter_IEq35.gif) converges pointwise to K t ∗ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq359.gif) 0. On the other hand, using the argument in Exercise 2, we can see that ![
$$\\mathcal{F}\(K_{t}1_{\[-n,n\]}\)$$
](A272900_1_En_4_Chapter_IEq36.gif) is bounded by a constant independent of n and converges pointwise to the function

![
$$\\displaystyle{ \\frac{1} {\\sqrt{2\\pi }}\\exp \\left \[-i\\frac{\\hslash {k}^{2}t} {2m} \\right\]. }$$
](A272900_1_En_4_Chapter_Equ12.gif)

(4.10)

Equation (4.10) is enough to show that the right-hand side of (4.9) converges in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_4_Chapter_IEq37.gif) to the function

![
$$\\displaystyle{\\exp \\left \[-i\\frac{\\hslash {k}^{2}t} {2m} \\right\]\\hat{\\psi }_{0}\(k\).}$$
](A272900_1_En_4_Chapter_Equh.gif)

By the Plancherel theorem, ![
$$K_{t}1_{\[-n,n\]} {\\ast}\\psi _{0}$$
](A272900_1_En_4_Chapter_IEq38.gif) must also be converging in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq39.gif) and the L 2 limit must coincide with the pointwise limit, which is K t ∗ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq340.gif) 0. Thus, taking limits on both sides of (4.9) shows that the Fourier transform of K t ∗ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq341.gif) 0 is what we want it to be.

In general, to be considered the fundamental solution of a certain equation, a function should converge to a Dirac δ-function (Example A.26), in the distribution sense, as t tends to zero. Since ![
$$\\left \\vert K_{t}\(x\)\\right\\vert$$
](A272900_1_En_4_Chapter_IEq40.gif) is independent of x for each t, it might seem doubtful that K t has this property. On the other hand, we can see K t (x) oscillates very rapidly except near x = 0. (See Fig. 4.1.) This oscillation causes the integral of K t (x) against some nice function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq342.gif)(x) to be small, except for the part of the integral near x = 0. Indeed, because the Fourier transform of K t converges to the constant function ![
$$1/\\sqrt{2\\pi }$$
](A272900_1_En_4_Chapter_IEq41.gif) (which is what we get by formally taking the Fourier transform of the δ-function) as t tends to zero, it is not hard to show that K t does, in fact, converge to a δ-function. The details of this verification are left to the reader.

## 4.3 Propagation of the Wave Packet: First Approach

Let us consider the Schrödinger equation in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_4_Chapter_IEq42.gif) with an initial condition ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq343.gif) 0 that is a "wave packet," meaning a complex exponential multiplied by some function that localizes ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq344.gif) 0 in space. Specifically, we take

![
$$\\displaystyle{ \\psi _{0}\(x\) = {e}^{ip_{0}x/\\hslash }A_{ 0}\(x\), }$$
](A272900_1_En_4_Chapter_Equ13.gif)

(4.11)

where A 0 is some real, positive function and p 0 is a nonzero real number. (The case p 0 = 0 should be treated separately.) We also assume that A 0 is "slowly varying" compared to ![
$${e}^{ip_{0}x/\\hslash },$$
](A272900_1_En_4_Chapter_IEq43.gif) meaning that A 0 is approximately constant over many periods of the function ![
$${e}^{ip_{0}x/\\hslash }.$$
](A272900_1_En_4_Chapter_IEq44.gif) (We will give a more precise meaning to the "slowly varying" condition shortly.) Thus, if we look at ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq345.gif) 0(x) on a distance scale of a small number of periods of the function ![
$${e}^{ip_{0}x/\\hslash },$$
](A272900_1_En_4_Chapter_IEq45.gif) then ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq346.gif) 0 will look like a constant times ![
$${e}^{ip_{0}x/\\hslash },$$
](A272900_1_En_4_Chapter_IEq46.gif) which, as we have seen, represents a particle with momentum p 0. We expect, then, that the wave function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq347.gif) 0 represents a particle with momentum approximately equal to p 0.

Let us now try to solve the free Schrödinger equation in terms of the amplitude and phase of the wave function. We write

![
$$\\displaystyle{\\psi \(x, t\) = A\(x, t\){e}^{i\\theta \(x, t\)}}$$
](A272900_1_En_4_Chapter_Equi.gif)

where A and θ are real-valued functions. If we plug this expression for ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq348.gif) into the free Schrödinger equation and then cancel a factor of e iθ(x, t) from every term, we obtain the equation

![
$$\\displaystyle{ \\frac{\\partial A} {\\partial t} + i \\frac{\\partial \\theta } {\\partial t}A = \\frac{i\\hslash } {2m} \\frac{{\\partial }^{2}A} {\\partial {x}^{2}} - \\frac{\\hslash } {m} \\frac{\\partial A} {\\partial x} \\frac{\\partial \\theta } {\\partial x} - \\frac{i\\hslash } {2m}A{\\left \( \\frac{\\partial \\theta } {\\partial x}\\right\)}^{2} - \\frac{\\hslash } {2m}A \\frac{{\\partial }^{2}\\theta } {\\partial {x}^{2}}. }$$
](A272900_1_En_4_Chapter_Equ14.gif)

(4.12)

Since A and θ are real-valued, we may separately equate the real and imaginary parts of (4.12), giving

![
$$\\displaystyle{ \\frac{\\partial A} {\\partial t} = -\\frac{\\hslash } {m} \\frac{\\partial A} {\\partial x} \\frac{\\partial \\theta } {\\partial x} - \\frac{\\hslash } {2m}A \\frac{{\\partial }^{2}\\theta } {\\partial {x}^{2}} }$$
](A272900_1_En_4_Chapter_Equ15.gif)

(4.13)

and (after dividing the imaginary part of (4.12) by A)

![
$$\\displaystyle{ \\frac{\\partial \\theta } {\\partial t} = \\frac{\\hslash } {2m} \\frac{1} {A} \\frac{{\\partial }^{2}A} {\\partial {x}^{2}} - \\frac{\\hslash } {2m}{\\left \( \\frac{\\partial \\theta } {\\partial x}\\right\)}^{2}. }$$
](A272900_1_En_4_Chapter_Equ16.gif)

(4.14)

Any solution to this system of partial differential equations will yield a solution ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq349.gif)(x, t) = A(x, t)e iθ(x, t) to the free Schrödinger equation.

Since we are assuming A is "slowly varying" compared to θ, it is reasonable to think that the first term on the right-hand side of (4.14) will be small compared to the second term. That is to say, we interpret the slowly varying condition to mean

![
$$\\displaystyle{ \\frac{1} {A} \\frac{{\\partial }^{2}A} {\\partial {x}^{2}} \\ll {\\left \( \\frac{\\partial \\theta } {\\partial x}\\right\)}^{2}, }$$
](A272900_1_En_4_Chapter_Equ17.gif)

(4.15)

where the symbol ≪ means "much smaller than." We will take initial conditions such that (4.15) holds at t = 0, and then we will assume that (4.15) continues to hold at least for small positive times. We may then (to first approximation) drop the first term on the right-hand side of (4.14), giving the following simplified version of (4.14):

![
$$\\displaystyle{ \\frac{\\partial \\theta } {\\partial t} = - \\frac{\\hslash } {2m}{\\left \( \\frac{\\partial \\theta } {\\partial x}\\right\)}^{2}. }$$
](A272900_1_En_4_Chapter_Equ18.gif)

(4.16)

We now look for a solution to the pair of equations (4.13) and (4.16) with initial conditions corresponding to (4.11).

Proposition 4.6

A solution to the approximate equations ( 4.13 ) and ( 4.16 ) with initial condition ![
$$\\theta \(x,0\) = p_{0}x/\\hslash $$
](A272900_1_En_4_Chapter_IEq47.gif) is given by

![
$$\\displaystyle{ \\theta \(x, t\) = \\frac{p_{0}} {\\hslash } \\left \(x - \\frac{p_{0}} {2m}t\\right\) }$$
](A272900_1_En_4_Chapter_Equ19.gif)

(4.17)

and

![
$$\\displaystyle{ A\(x, t\) = A_{0}\\left \(x -\\frac{p_{0}} {m}t\\right\). }$$
](A272900_1_En_4_Chapter_Equ20.gif)

(4.18)

This yields an approximate solution to the free Schrödinger equation given by

![
$$\\displaystyle{ \\psi \(x, t\) = A_{0}\\left \(x -\\frac{p_{0}} {m}t\\right\)\\exp \\left \[i\\frac{p_{0}} {\\hslash } \\left \(x - \\frac{p_{0}} {2m}t\\right\)\\right\]. }$$
](A272900_1_En_4_Chapter_Equ21.gif)

(4.19)

Note from (4.17) and (4.18) that if the "slowly varying" condition (4.15) holds at time 0, it will continue to hold for all positive times in our approximate solution.

Proof.

Although (4.16) is a nonlinear equation, we can find a solution to it with the simple initial conditions ![
$$\\theta \(x,0\) = p_{0}x/\\hslash,$$
](A272900_1_En_4_Chapter_IEq48.gif) namely,

![
$$\\displaystyle\\begin{array}{rcl} \\theta \(x, t\)& =& \\frac{p_{0}x} {\\hslash } - \\frac{p_{0}^{2}} {2m\\hslash }t \\\\ & =& \\frac{p_{0}} {\\hslash } \\left \(x - \\frac{p_{0}} {2m}t\\right\).{}\\end{array}$$
](A272900_1_En_4_Chapter_Equ22.gif)

(4.20)

Since ![
$$\\partial \\theta /\\partial x = p_{0}/\\hslash $$
](A272900_1_En_4_Chapter_IEq49.gif) and ![
$${\\partial }^{2}\\theta /\\partial {x}^{2} = 0,$$
](A272900_1_En_4_Chapter_IEq50.gif) if we plug (4.20) back into (4.13) we obtain

![
$$\\displaystyle{\\frac{\\partial A} {\\partial t} = -\\frac{p_{0}} {m} \\frac{\\partial A} {\\partial x}.}$$
](A272900_1_En_4_Chapter_Equj.gif)

The (presumably unique) solution to this linear equation with initial condition A(x, 0) = A 0(x) is

![
$$\\displaystyle{ A\(x, t\) = A_{0}\\left \(x -\\frac{p_{0}} {m}t\\right\), }$$
](A272900_1_En_4_Chapter_Equ23.gif)

(4.21)

as claimed.

We hope that the solution (4.19) to the system of equations (4.13) and (4.16) is a close approximation to the solution to the original pair of equations (4.13) and (4.14)—assuming, of course, that A 0 is slowly varying compared to ![
$$\\theta _{0}\(x\) = p_{0}x/\\hslash.$$
](A272900_1_En_4_Chapter_IEq51.gif) It is not especially easy to estimate directly how rapidly solutions to (4.13) and (4.16) diverge from solutions to (4.13) and (4.14). We will therefore leave an estimate of the error in our approximation until the next section, where we will obtain the same approximate solution by a different method.

Note that a function of the form ![
$$f\(x, t\) =\\phi \(x - vt\)$$
](A272900_1_En_4_Chapter_IEq52.gif) is moving to the right with constant velocity v. (If v is negative, then, of course, this means the function is moving to the left.) Observe that both the amplitude A(x, t) and the phase exp{iθ(x, t)} are of this form, but with two different velocities.

Conclusion 4.7

In the approximate solution ( 4.19 ) to the free Schrödinger equation, the amplitude A(x, t) is moving with velocity p 0 ∕m, whereas the phase θ(x, t) is moving with velocity p 0 ∕(2m). These two velocities are called the group velocity and the phase velocity, respectively:

![
$$\\displaystyle\\begin{array}{rcl} {phase \\ velocity}& =& \\frac{p_{0}} {2m} {}\\\\ {group \\ velocity}& =& \\frac{p_{0}} {m}. {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ24.gif)

Note that the formula for the phase velocity agrees with the one given previously in Sect. 4.1, the velocity of propagation of a pure exponential solution to the free Schrödinger equation. Indeed, nothing prevents us from taking ![
$$A_{0} \\equiv 1,$$
](A272900_1_En_4_Chapter_IEq53.gif) in which case the left-hand side of (4.15) is actually identically zero, so that a solution to (4.13) and (4.16) is actually a solution to (4.13) and (4.14).

Which of the velocities is the "real" velocity of the particle? The answer is: the group velocity. After all, the probability distribution for the particle's position is determined by the amplitude of the wave function and is unaffected by the phase. It is the amplitude that determines (as much as it can be determined) where the particle is. Thus, the true velocity of the particle should be the velocity at which the amplitude propagates. Figure 4.2 shows the propagation of the real part of a wave packet, with the motion of a single peak indicated by the shaded region. The phase velocity determines the speed at which the individual peaks in the real part of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq450.gif) move, whereas the group velocity determines the speed of the packet as a whole. Since the peak we are tracking lags well behind the motion of the whole packet, we see that the phase velocity is smaller than the group velocity.

Figure 4.2

Propagation of Re[![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq351.gif)], with motion of a single peak shaded.

We should expect that solutions to our approximate equations (4.13) and (4.16) will diverge slowly over time from solutions to the free Schrödinger equation (4.13) and (4.14). For sufficiently long times, there may be a significant difference between approximate and true solutions. This expectation is confirmed in Sect. 4.5, where we investigate the spread of the wave packet, a phenomenon that is not seen in our approximation.

## 4.4 Propagation of the Wave Packet: Second Approach

We have seen that the general solution of the free Schrödinger equation can be obtained by means of the Fourier transform as

![
$$\\displaystyle{ \\psi \(x, t\) = \\frac{1} {\\sqrt{2\\pi }}\\int _{-\\infty }^{\\infty }\\hat{\\psi }_{ 0}\(k\)\\exp \\left \[i\\left \(kx -\\omega \(k\)t\\right\)\\right\]\\ dk, }$$
](A272900_1_En_4_Chapter_Equ25.gif)

(4.22)

where

![
$$\\displaystyle{ \\omega \(k\) = \\frac{\\hslash {k}^{2}} {2m}. }$$
](A272900_1_En_4_Chapter_Equ26.gif)

(4.23)

Let us assume that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq452.gif) 0 has approximate momentum equal to p 0. Thus, we expect that ![
$$\\hat{\\psi }_{0}\(k\)$$
](A272900_1_En_4_Chapter_IEq54.gif) will be concentrated near ![
$$k_{0} := p_{0}/\\hslash.$$
](A272900_1_En_4_Chapter_IEq55.gif) If that is the case, then only the values of k close to k 0 are important. For k close to k 0, we use the first-order Taylor expansion

![
$$\\displaystyle{ \\omega \(k\) \\approx \\omega \(k_{0}\) {+\\omega }^{{\\prime}}\(k_{ 0}\)\(k - k_{0}\), }$$
](A272900_1_En_4_Chapter_Equ27.gif)

(4.24)

where for now we do not put in the explicit formula for ω ′ (k 0).

Inserting (4.24) into (4.22), we get two factors that are independent of k and come outside the integral, leaving us with

![
$$\\displaystyle\\begin{array}{rcl} \\psi \(x, t\)& \\approx & \\frac{1} {\\sqrt{2\\pi }}{e}^{{i\\omega }^{{\\prime}}\(k_{ 0}\)k_{0}t}{e}^{-i\\omega \(k_{0}\)t}\\int _{-\\infty }^{\\infty }\\hat{\\psi }_{0}\(k\)\\exp \\left \[ik\(x {-\\omega }^{{\\prime}}\(k_{0}\)t\)\\right\]\\ dk \\\\ & =& {e}^{{i\\omega }^{{\\prime}}\(k_{ 0}\)k_{0}t}{e}^{-i\\omega \(k_{0}\)t}\\psi _{0}\(x {-\\omega }^{{\\prime}}\(k_{0}\)t\). {}\\end{array}$$
](A272900_1_En_4_Chapter_Equ28.gif)

(4.25)

Note that the factors in front of ![
$$\\psi _{0}\(x {-\\omega }^{{\\prime}}\(k_{0}\)t\)$$
](A272900_1_En_4_Chapter_IEq56.gif) are simply constants, that is, independent of x. These constants do not affect the "state" of the system, in that we have said that two vectors in the quantum Hilbert space that differ by a constant represent the same physical state. Ignoring these constants, we are left with the factor of ![
$$\\psi _{0}\(x {-\\omega }^{{\\prime}}\(k_{0}\)t\),$$
](A272900_1_En_4_Chapter_IEq57.gif) which is simply shifting to the right at speed ω ′ (k 0). Thus, the (approximate) velocity at which our wave packet is moving is

![
$$\\displaystyle{\\text{velocity } {\\approx \\omega }^{{\\prime}}\(k_{ 0}\) = \\frac{\\hslash k_{0}} {m} = \\frac{p_{0}} {m}.}$$
](A272900_1_En_4_Chapter_Equk.gif)

Let us consider the special case in which ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq453.gif) 0 is of the form

![
$$\\displaystyle{\\psi _{0}\(x\) = {e}^{ik_{0}x}A_{ 0}\(x\),}$$
](A272900_1_En_4_Chapter_Equl.gif)

where A 0 is real and positive. Then (4.25) becomes

![
$$\\displaystyle{{e}^{{i\\omega }^{{\\prime}}\(k_{ 0}\)k_{0}t}{e}^{-i\\omega \(k_{0}\)t}{e}^{ik_{0}\(x{-\\omega }^{{\\prime}}\(k_{ 0}\)t\)}A_{0}\(x {-\\omega }^{{\\prime}}\(k_{0}\)t\).}$$
](A272900_1_En_4_Chapter_Equm.gif)

After canceling the terms involving ![
$${\\omega }^{{\\prime}}\(k_{0}\)k_{0}t$$
](A272900_1_En_4_Chapter_IEq58.gif) in the exponent, we obtain

![
$$\\displaystyle{\\psi \(x, t\) \\approx {e}^{i\(k_{0}x-\\omega \(k_{0}\)t\)}A_{ 0}\(x {-\\omega }^{{\\prime}}\(k_{ 0}\)t\).}$$
](A272900_1_En_4_Chapter_Equn.gif)

Recalling that ![
$$p_{0} = \\hslash k_{0}$$
](A272900_1_En_4_Chapter_IEq59.gif) and putting in the formula for ω, we see that this approximation to ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq354.gif)(x, t) is precisely the same as the one we obtained, by a different method, in Proposition 4.6.

As in Sect. 4.3, we see that the velocity at which a pure exponential solution of the free Schrödinger equation propagates [namely, ![
$$\\omega \(k_{0}\)/k_{0} = \\hslash k_{0}/\(2m\)$$
](A272900_1_En_4_Chapter_IEq60.gif)] is not the same as the velocity at which the overall wave packet propagates. Rather, as seen in (4.25), the wave packet propagates at a velocity given by ![
$${\\omega }^{{\\prime}}\(k_{0}\) = \\hslash k_{0}/m$$
](A272900_1_En_4_Chapter_IEq61.gif). We may summarize this conclusion in the following proposition.

Proposition 4.8

The speed at which a pure exponential solution of the free Schrödinger equation propagates is

![
$$\\displaystyle{{phase \\ velocity} = \\frac{\\omega \(k_{0}\)} {k_{0}} = \\frac{\\hslash k_{0}} {2m} = \\frac{p_{0}} {2m}.}$$
](A272900_1_En_4_Chapter_Equo.gif)

By contrast, the (approximate) speed at which the wave packet propagates is

![
$$\\displaystyle{{group \\ velocity} = \\left. \\frac{d\\omega } {dk}\\right\\vert _{k=k_{0}} = \\frac{\\hslash k_{0}} {m} = \\frac{p_{0}} {m}.}$$
](A272900_1_En_4_Chapter_Equp.gif)

The disadvantage of the method we used in Sect. 4.3 is that it does not easily yield estimates on how big an error there is in our approximation. In the current section, however, we can estimate the error by comparing the Fourier transforms of the exact solution and the approximate solution. Our error estimate will involve a quantity κ defined as follows:

![
$$\\displaystyle{ \\kappa ={ \\left \[\\int _{-\\infty }^{\\infty }{\\left \\vert \\hat{\\psi }_{ 0}\(k\)\\right\\vert }^{2}{\(k - k_{ 0}\)}^{4}\\ dk\\right\]}^{1/4}. }$$
](A272900_1_En_4_Chapter_Equ29.gif)

(4.26)

The quantity κ is, roughly, half the width of the interval around k 0 on which most of ![
$$\\hat{\\psi }\(k\)$$
](A272900_1_En_4_Chapter_IEq62.gif) is concentrated. If, for example, ![
$$\\hat{\\psi }$$
](A272900_1_En_4_Chapter_IEq63.gif) is supported in the interval ![
$$\[k_{0}-\\varepsilon,k_{0}+\\varepsilon \],$$
](A272900_1_En_4_Chapter_IEq64.gif) then ![
$$\\kappa \\leq \\varepsilon,$$
](A272900_1_En_4_Chapter_IEq65.gif) assuming that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq355.gif)—and therefore ![
$$\\hat{\\psi }$$
](A272900_1_En_4_Chapter_IEq66.gif)—is a unit vector. (A more common measure of concentration would replace (k − k 0)4 by (k − k 0)2 and the fourth root of the integral by the square root. But the "quartic" measure of concentration in (4.26) is the one that arises in estimating the error of our approximations in this section.)

Proposition 4.9

Let ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq327.gif) (x, t) be the exact solution to the free Schrödinger equation with initial condition ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq531.gif) 0 , and let ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq326.gif) (x, t) be the approximate solution given by the right-hand side of ( 4.25 ). Then the following L 2 estimate holds:

![
$$\\displaystyle{ \\left \\Vert \\psi \(x, t\) -\\phi \(x, t\)\\right\\Vert _{{L}^{2}\(\\mathbb{R}\)} \\leq \\frac{\\left \\vert t\\right\\vert {\\hslash \\kappa }^{2}} {2m} = \\left \\vert t\\right\\vert \\omega \(\\kappa \), }$$
](A272900_1_En_4_Chapter_Equ30.gif)

(4.27)

where the L 2 norm is with respect to x with t fixed and where ω(⋅) is defined by ( 4.23 ).

Equation (4.27) means that the L 2 norm of the error will be small, provided that

![
$$\\displaystyle{\\left \\vert t\\right\\vert \\ll \\frac{1} {\\omega \(\\kappa \)}.}$$
](A272900_1_En_4_Chapter_Equq.gif)

If κ is much smaller than k 0, then 1 ∕ ω(κ) will be much larger than 1 ∕ ω(k 0). That means that the timescale on which the true and approximate solutions diverge will be long compared to the timescale on which our approximate solution is oscillating.

Proof.

Let ![
$$\\hat{\\psi }\(k,t\)$$
](A272900_1_En_4_Chapter_IEq67.gif) and ![
$$\\hat{\\phi }\(k,t\)$$
](A272900_1_En_4_Chapter_IEq68.gif) denote the Fourier transforms of ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq126.gif) and ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq456.gif) with respect to x, with t fixed. From (4.22) we can read off that

![
$$\\displaystyle{\\hat{\\psi }\(k,t\) = {e}^{-i\\omega \(k\)t}\\hat{\\psi }_{ 0}\(k\).}$$
](A272900_1_En_4_Chapter_Equr.gif)

Meanwhile, ![
$$\\hat{\\phi }\(k,t\)$$
](A272900_1_En_4_Chapter_IEq69.gif) is obtained from ![
$$\\hat{\\psi }\(k,t\)$$
](A272900_1_En_4_Chapter_IEq70.gif) by replacing ω(k) by the right-hand side of (4.24). Now, direct calculation shows that

![
$$\\displaystyle{\\omega \(k\) - \(\\omega \(k_{0}\) {+\\omega }^{{\\prime}}\(k_{ 0}\)\(k - k_{0}\)\) = \\frac{\\hslash } {2m}{\(k - k_{0}\)}^{2}.}$$
](A272900_1_En_4_Chapter_Equs.gif)

From this expression and the elementary estimate ![
$$\\left \\vert {e}^{i\\theta } - {e}^{i\\phi }\\right\\vert \\leq \\left \\vert \\theta -\\phi \\right\\vert$$
](A272900_1_En_4_Chapter_IEq71.gif), we obtain

![
$$\\displaystyle{ \\left \\vert \\hat{\\psi }\(k,t\) -\\hat{\\phi } \(k,t\)\\right\\vert \\leq \\frac{\\left \\vert t\\right\\vert \\hslash } {2m}{\\left \(k - k_{0}\\right\)}^{2}\\left \\vert \\hat{\\psi }_{ 0}\(k\)\\right\\vert. }$$
](A272900_1_En_4_Chapter_Equ31.gif)

(4.28)

The estimate (4.27) then follows by the Plancherel theorem and the definition of κ.

For a more detailed version of the approach used in this section, see Sect.​ 5.​6 of [30].

## 4.5 Spread of the Wave Packet

We use the uncertainty (Definition 3.13) ![
$$\\Delta_{\\psi}X$$
](A272900_1_En_4_Chapter_IEq457.gif) in the position of the particle as a measure of the "width" of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq458.gif)(x) as a function of x. At the level of approximation considered in the previous two sections, the uncertainty in the position of a free particle is independent of time. After all, in the approximate solution (4.19), the amplitude of the wave function simply shifts to the right at a speed equal to the group velocity, without changing shape. A more precise calculation, however, shows that after sufficiently long times, the wave packet spreads out in space. (Exercise 7 gives an idea of the time scale on which this spread takes place.)

We can compute the time-evolution of the uncertainty in the particle's position without having to solve the full Schrödinger equation, by using Proposition 3.14 from Chap.​ 3. We start by observing that for a free particle, our Hamiltonian is simply P 2 ∕ (2m), which commutes with P. It follows that the expected value and uncertainty for the particle's momentum (and, indeed, the entire probability distribution of the momentum) are independent of time. Meanwhile, to compute the time-dependence of ![
$$\\left \\langle X\\right\\rangle$$
](A272900_1_En_4_Chapter_IEq72.gif) and ![
$$\\left \\langle {X}^{2}\\right\\rangle,$$
](A272900_1_En_4_Chapter_IEq73.gif) we use Proposition 3.14 along with the commutation relation ![
$$\\left \[X,P\\right\] = i\\hslash I$$
](A272900_1_En_4_Chapter_IEq74.gif) (Proposition 3.8).

Proposition 4.10

For a wave function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq530.gif)(x, t) evolving according to the free Schrödinger equation on ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_4_Chapter_IEq75.gif) the expectation values for X and X 2 evolve as follows:

![
$$\\displaystyle{\\left \\langle X\\right\\rangle _{\\psi \(t\)} = \\left \\langle X\\right\\rangle _{\\psi _{0}} + \\frac{t} {m}\\left \\langle P\\right\\rangle _{\\psi _{0}}}$$
](A272900_1_En_4_Chapter_Equt.gif)

and

![
$$\\displaystyle{\\left \\langle {X}^{2}\\right\\rangle _{ \\psi \(t\)} = \\left \\langle {X}^{2}\\right\\rangle _{ \\psi _{0}} + \\frac{t} {m}\\left \\langle XP + PX\\right\\rangle _{\\psi _{0}} + \\frac{{t}^{2}} {{m}^{2}}\\left \\langle {P}^{2}\\right\\rangle _{ \\psi \(0\)}.}$$
](A272900_1_En_4_Chapter_Equu.gif)

These relations imply the following result:

![
$$\\displaystyle\\begin{array}{rcl} & &{ \\left \(\\Delta _{\\psi \(t\)}X\\right\)}^{2} {}\\\\ & & = \\frac{{t}^{2}} {{m}^{2}}{\\left \(\\Delta _{\\psi _{0}}P\\right\)}^{2} + \\frac{t} {m}\\left \(\\left \\langle XP + PX\\right\\rangle _{\\psi _{0}} - 2\\left \\langle X\\right\\rangle _{\\psi _{0}}\\left \\langle P\\right\\rangle _{\\psi _{0}}\\right\) +{ \\left \(\\Delta _{\\psi _{0}}X\\right\)}^{2}. {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ32.gif)

For a unit vector ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq459.gif) 0 in ![
$${L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq76.gif) the uncertainty ![
$$\\Delta _{\\psi _{0}}P$$
](A272900_1_En_4_Chapter_IEq77.gif) in the momentum cannot be zero, because the uncertainty would be zero only if ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq360.gif) 0 is an eigenvector for the momentum operator. But the eigenvectors for P are the functions of the form e ikx , which are not in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_4_Chapter_IEq78.gif) Thus, the leading coefficient in the expression for (Δ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq461.gif)(t) X)2 is never zero, and thus Δ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq362.gif)(t) X tends to infinity as t tends to infinity.

Proof.

We compute that

![
$$\\displaystyle\\begin{array}{rcl} \\left \[{P}^{2},X\\right\]& =& {P}^{2}X - PXP + PXP - X{P}^{2} {}\\\\ & =& P\\left \[P,X\\right\] + \\left \[P,X\\right\]P {}\\\\ & =& -2i\\hslash P. {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ33.gif)

Thus (as we have already noted in Sect.​ 3.​7.​5),

![
$$\\displaystyle{ \\frac{d} {dt}\\left \\langle X\\right\\rangle _{\\psi \(t\)} = \\left \\langle \\frac{i} {\\hslash }\(-2i\\hslash P\)\\right\\rangle _{\\psi \(t\)} = \\frac{\\left \\langle P\\right\\rangle _{\\psi \(t\)}} {m} = \\frac{\\left \\langle P\\right\\rangle _{\\psi _{0}}} {m}, }$$
](A272900_1_En_4_Chapter_Equ34.gif)

(4.29)

where we have used in the last equality that the expected momentum is independent of time. Since the derivative of ![
$$\\left \\langle X\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_4_Chapter_IEq79.gif) is constant, ![
$$\\left \\langle X\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_4_Chapter_IEq80.gif) itself is a linear function of t, which gives the first result in the proposition.

Meanwhile, a little algebra shows that

![
$$\\displaystyle\\begin{array}{rcl} \\left \[{P}^{2},{X}^{2}\\right\]& =& P\\left \[P,X\\right\]X + \\left \[P,X\\right\]PX + XP\\left \[P,X\\right\] + X\\left \[X,P\\right\]P {}\\\\ & =& -2i\\hslash \\left \(PX + XP\\right\), {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ35.gif)

and

![
$$\\displaystyle{\\left \[{P}^{2},PX + XP\\right\] = P\\left \[{P}^{2},X\\right\] + \\left \[{P}^{2},X\\right\]P = -4i\\hslash {P}^{2}.}$$
](A272900_1_En_4_Chapter_Equv.gif)

Thus

![
$$\\displaystyle{ \\frac{d} {dt}\\left \\langle {X}^{2}\\right\\rangle _{ \\psi \(t\)} = \\frac{i} {2m\\hslash }\\left \\langle \\left \[{P}^{2},{X}^{2}\\right\]\\right\\rangle _{\\psi \(t\)} = \\frac{1} {m}\\left \\langle XP + PX\\right\\rangle _{\\psi \(t\)}}$$
](A272900_1_En_4_Chapter_Equw.gif)

and

![
$$\\displaystyle\\begin{array}{rcl} \\frac{{d}^{2}} {d{t}^{2}}\\left \\langle {X}^{2}\\right\\rangle _{ \\psi \(t\)}& =& \\frac{i} {\\hslash } \\frac{1} {m} \\frac{1} {2m}\\left \\langle \\left \[{P}^{2},XP + PX\\right\]\\right\\rangle _{\\psi \(t\)} {}\\\\ & =& \\frac{2} {{m}^{2}}\\left \\langle {P}^{2}\\right\\rangle _{ \\psi \(t\)} = \\frac{2} {{m}^{2}}\\left \\langle {P}^{2}\\right\\rangle _{ \\psi _{0}}. {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ36.gif)

Since the second derivative of ![
$$\\left \\langle {X}^{2}\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_4_Chapter_IEq81.gif) is independent of t, ![
$$\\left \\langle {X}^{2}\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_4_Chapter_IEq82.gif) itself is a quadratic polynomial in t, the coefficients of which are determined by the value of ![
$$\\left \\langle X\\right\\rangle _{\\psi \(t\)}$$
](A272900_1_En_4_Chapter_IEq83.gif) and its first two time-derivatives at t = 0. This leads to the second result in the proposition. The last result follows by direct calculation.

## 4.6 Exercises

1.

A locally integrable function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq363.gif)(x, t) satisfies the free Schrödinger equation in the weak (or distributional) sense if for each smooth compactly supported function χ, we have

![
$$\\displaystyle{ \\int _{{\\mathbb{R}}^{2}}\\psi \(x, t\)\\left \[ \\frac{\\partial \\chi } {\\partial t} + \\frac{i\\hslash } {2m} \\frac{{\\partial }^{2}\\chi } {\\partial {x}^{2}}\\right\]\\ dx\\ dt = 0. }$$
](A272900_1_En_4_Chapter_Equ37.gif)

(4.30)

[One obtains (4.30) by assuming ![
$$\\partial \\psi /\\partial t - \(i\\hslash /2m\){\\partial }^{2}\\psi /\\partial {x}^{2}$$
](A272900_1_En_4_Chapter_IEq84.gif) is zero, integrating against χ(x, t), and then formally integrating by parts.]

(a)

Show that if ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq364.gif)(x, t) is smooth as a function of x and t then ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq365.gif) satisfies the free Schrödinger equation in the pointwise sense if and only if ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq366.gif) satisfies the free Schrödinger equation in the weak sense.

Hint: Proposition A.23 may be useful.

(b)

For any ![
$$\\psi _{0} \\in {L}^{2}\(\\mathbb{R}\),$$
](A272900_1_En_4_Chapter_IEq85.gif) define ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq367.gif)(x, t) by Definition 4.4. Show that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq368.gif) satisfies the free Schrödinger equation in the weak sense.

First show that the function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq369.gif) A given by

![
$$\\displaystyle{\\psi _{A}\(x, t\) = \\frac{1} {\\sqrt{2\\pi }}\\int _{-A}^{A}\\hat{\\psi }_{ 0}\(k\){e}^{i\(kx-\\omega \(k\)t\)}\\ dk}$$
](A272900_1_En_4_Chapter_Equx.gif)

satisfies the free Schrödinger equation in the weak sense, for each A.

2.

(a)

Show that for any ![
$$a \\in \\mathbb{C}$$
](A272900_1_En_4_Chapter_IEq86.gif) with Re(a) > 0,

![
$$\\displaystyle\\begin{array}{rcl}{ \\left \(\\int _{-\\infty }^{\\infty }{e}^{-{x}^{2}/\(2a\) }\\ dx\\right\)}^{2}& =& \\int _{{ \\mathbb{R}}^{2}}{e}^{-\({x}^{2}+{y}^{2}\)/\(2a\) }\\ dx\\ dy {}\\\\ & =& 2\\pi a, {}\\\\ \\end{array}$$
](A272900_1_En_4_Chapter_Equ38.gif)

where the integral over ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_4_Chapter_IEq87.gif) can be evaluated using polar coordinates. Conclude that

![
$$\\displaystyle{ \\int _{-\\infty }^{\\infty }{e}^{-{x}^{2}/\(2a\) }\\ dx = \\sqrt{2\\pi a}, }$$
](A272900_1_En_4_Chapter_Equ39.gif)

(4.31)

where the square root is the one with positive real part.

(b)

Show that for all A, B > 0 we have

![
$$\\displaystyle{\\int _{A}^{B}{e}^{-{x}^{2}/\(2a\) }\\ dx = \\left.-\\frac{a} {x}{e}^{-{x}^{2}/\(2a\) }\\right\\vert _{A}^{B} +\\int _{ A}^{B} \\frac{a} {{x}^{2}}{e}^{-{x}^{2}/\(2a\) }\\ dx}$$
](A272900_1_En_4_Chapter_Equy.gif)

for any nonzero complex number a. Using this, show that the integral in (4.31) is convergent for all nonzero a with Re a ≥ 0, provided the integral is interpreted as an improper integral (i.e., the limit as A tends to infinity of an integral from − A to A).

(c)

Now show that the result of Part (a) is valid also for nonzero values of a with Re a = 0.

Hint: Given β≠0, show that the (improper) integral from A to ∞ of ![
$$\\exp \[-{x}^{2}/\(2\(\\alpha +i\\beta \)\)\]$$
](A272900_1_En_4_Chapter_IEq88.gif) is small for large A, uniformly in ![
$$\\alpha \\in \[0,1\].$$
](A272900_1_En_4_Chapter_IEq89.gif)

(d)

Show that

![
$$\\displaystyle{\\frac{1} {2\\pi }\\int _{-\\infty }^{\\infty }{e}^{ikx}{e}^{-it\\hslash {k}^{2}/\(2m\) }\\ dk = \\sqrt{ \\frac{m} {2\\pi i\\hslash t}}{e}^{im{x}^{2}/\(2t\\hslash \) },}$$
](A272900_1_En_4_Chapter_Equz.gif)

where the integral is interpreted as an improper integral and the square root is the one with positive real part.

3.

Suppose ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq229.gif) is a Schwartz function (Definition A.15) and ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq370.gif) belongs to ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_4_Chapter_IEq90.gif) Show that the convolution ![
$$ {\\phi} $$
](A272900_1_En_4_Chapter_IEq129.gif) ∗ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq371.gif) is smooth (infinitely differentiable).

4.

Consider the heat equation for a function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq372.gif)(x, t), given by

![
$$\\displaystyle{ \\frac{\\partial \\psi } {\\partial t} =\\alpha \\frac{{\\partial }^{2}\\psi } {\\partial {x}^{2}},}$$
](A272900_1_En_4_Chapter_Equaa.gif)

where α is a constant, subject to the initial condition ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq373.gif)(x, 0) = ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq374.gif) 0(x).

(a)

Derive a differential equation for ![
$$\\hat{\\psi }\(k,t\),$$
](A272900_1_En_4_Chapter_IEq91.gif) the Fourier transform of a solution of the heat equation with respect to x, with t fixed, assuming that ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq375.gif)(x, t) is a "nice" function of x for each t. Solve this equation subject to the initial condition ![
$$\\hat{\\psi }\(k,0\) =\\hat{\\psi } _{0}\(k\).$$
](A272900_1_En_4_Chapter_IEq92.gif)

(b)

Obtain an expression for the solution to the heat equation as a convolution of ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq376.gif) 0 with a "fundamental solution" to the heat equation.

Note: As we will discuss in Chap.​ 20, the heat equation can be thought of as a sort of "imaginary time" version of the free Schrödinger equation.

5.

Suppose we take an initial condition in the free Schrödinger equation with initial phase given by ![
$$\\theta _{0}\(x\) = p_{0}x/\\hslash $$
](A272900_1_En_4_Chapter_IEq93.gif) and initial amplitude given by A 0(x), as in (4.11). Suppose also that the initial amplitude is of the form

![
$$\\displaystyle{A_{0}\(x\) =\\exp \\left \\{-\\frac{1} {2}{\\left \(\\frac{x - x_{0}} {L} \\right\)}^{2}\\right\\}.}$$
](A272900_1_En_4_Chapter_Equab.gif)

Note that A 0 is centered around the point x 0 and that the parameter L is a measure of the "width" in space of our initial wave packet. A function of the form ![
$$\\psi _{0}\(x\) = {e}^{ip_{0}x/\\hslash }A_{0}\(x\),$$
](A272900_1_En_4_Chapter_IEq94.gif) with A 0 as above, is called a Gaussian wave packet.

Compute the quantity

![
$$\\displaystyle{ \\frac{1} {{\\left \(\\frac{\\partial \\theta _{0}} {\\partial x}\\right\)}^{2}}\\left \( \\frac{1} {A_{0}} \\frac{{\\partial }^{2}A_{0}} {\\partial {x}^{2}} \\right\). }$$
](A272900_1_En_4_Chapter_Equ40.gif)

(4.32)

Assuming that ![
$$\\hslash $$
](A272900_1_En_4_Chapter_IEq95.gif) is small compared to Lp 0, show that (4.32) is small, except at points where our initial wave packet is very small.

Note: This shows that our "slowly varying" assumption (4.15) is reasonable for the case of Gaussian wave packets.

6.

The Klein–Gordon equation, a proposed relativistic alternative to the Schrödinger equation, is the equation

![
$$\\displaystyle{ \\frac{1} {{c}^{2}} \\frac{{\\partial }^{2}\\psi } {\\partial {t}^{2}} = \\frac{{\\partial }^{2}\\psi } {\\partial {x}^{2}} -\\frac{{m}^{2}{c}^{2}} {{\\hslash }^{2}} \\psi,}$$
](A272900_1_En_4_Chapter_Equac.gif)

where m > 0 is the mass of the particle and c is the speed of light.

(a)

Obtain the dispersion relation for the Klein–Gordon equation, that is, the expression for ω(k) that makes the function exp[i(kx − ω(k)t] a solution to the Klein–Gordon equation.

(b)

Show that the phase velocity ω(k) ∕ k satisfies ![
$$\\left \\vert \\omega \(k\)/k\\right\\vert > c,$$
](A272900_1_En_4_Chapter_IEq96.gif) that the group velocity d ω(k) ∕ dk satisfies ![
$$\\left \\vert d\\omega /dk\\right\\vert < c,$$
](A272900_1_En_4_Chapter_IEq97.gif) and that

![
$$\\displaystyle{\(\\text{phase velocity}\)\(\\text{group velocity}\) = {c}^{2}.}$$
](A272900_1_En_4_Chapter_Equad.gif)

Note: Since the Klein–Gordon equation is second order in time, there will be two possible values for ω(k) for each k, one positive and one negative. The results of Part (b) hold for both of the two "branches" of ω(k).

7.

Consider the uncertainty Δ ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq377.gif)(t) X of a wave function ![
$$ {\\psi} $$
](A272900_1_En_4_Chapter_IEq378.gif)(t) evolving according to the free Schrödinger equation. Show that

![
$$\\displaystyle{ \\left \\vert \\frac{d} {dt}\\left \(\\Delta _{\\psi \(t\)}X\\right\)\\right\\vert \\leq \\frac{\\Delta _{\\psi _{0}}P} {m} }$$
](A272900_1_En_4_Chapter_Equ41.gif)

(4.33)

for all t and that

![
$$\\displaystyle{\\lim _{t\\rightarrow +\\infty }\\frac{d} {dt}\\left \(\\Delta _{\\psi \(t\)}X\\right\) = \\frac{\\Delta _{\\psi _{0}}P} {m}.}$$
](A272900_1_En_4_Chapter_Equae.gif)

Note: By comparison,

![
$$\\displaystyle{ \\frac{d} {dt}\\left \\langle X\\right\\rangle _{\\psi \(t\)} = \\frac{\\left \\langle P\\right\\rangle _{\\psi _{0}}} {m}. }$$
](A272900_1_En_4_Chapter_Equ42.gif)

(4.34)

If ![
$$\\hat{\\psi }_{0}\(k\)$$
](A272900_1_En_4_Chapter_IEq98.gif) is concentrated in a sufficiently small region around a nonzero number ![
$$k_{0} = p_{0}/\\hslash,$$
](A272900_1_En_4_Chapter_IEq99.gif) then ![
$$\\Delta _{\\psi _{0}}P$$
](A272900_1_En_4_Chapter_IEq100.gif) will be small compared to ![
$$\\left \\langle P\\right\\rangle _{\\psi _{0}}.$$
](A272900_1_En_4_Chapter_IEq101.gif) In that case, by comparing (4.33) to (4.34), we see that the rate at which the wave packet spreads out is small compared to the rate at which the wave packet moves.

References

[30].

P. Miller, Applied Asymptotic Analysis (American Mathematical Society, Providence, RI, 2006)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_5

© Springer Science+Business Media New York 2013

# 5. A Particle in a Square Well

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

It is difficult to solve the time-dependent Schrödinger equation explicitly, even in relatively simple cases. (Even for the free Schrödinger equation, we made do in Chap.4 with solutions that are either approximate or that involve an integral that is not explicitly evaluated.) Usually, then, one analyzes the time-independent Schrödinger equation (the eigenvector equation for ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq01.gif)) and then attempts to infer something about the time-dependent problem from the results. There are a number of problems, including the harmonic oscillator and the hydrogen atom, in which the time-independent Schrödinger equation can be solved explicitly.

## 5.1 The Time-Independent Schrödinger Equation

It is difficult to solve the time-dependent Schrödinger equation explicitly, even in relatively simple cases. (Even for the free Schrödinger equation, we made do in Chap.​ 4 with solutions that are either approximate or that involve an integral that is not explicitly evaluated.) Usually, then, one analyzes the time-independent Schrödinger equation (the eigenvector equation for ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq1.gif)) and then attempts to infer something about the time-dependent problem from the results. There are a number of problems, including the harmonic oscillator and the hydrogen atom, in which the time-independent Schrödinger equation can be solved explicitly.

In this section, we will consider a simple but instructive example, which can be solved by elementary methods. We consider the time-independent Schrödinger equation in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_5_Chapter_IEq2.gif), with a potential of the form

![
$$\\displaystyle{ V \(x\) = \\left \\{\\begin{array}{c} - C,\\quad - A \\leq x \\leq A\\\\ 0, \\quad \\left \\vert x\\right\\vert > A \\end{array},\\right. }$$
](A272900_1_En_5_Chapter_Equ1.gif)

(5.1)

where A and C are positive constants. The region − A ≤ x ≤ A is the "square well" for the potential (Fig. 5.1).

Let us think first for a moment about the behavior of a classical particle in a square well. If we think of V as the limit of a sequence of potentials that change linearly from − 1 to 0 in a small interval around ± 1, we may expect the following behavior for a particle in a square well. If the energy of the particle is negative, then the particle must be in the well. In that case, it will move with constant speed until it hits the edge of the well, at which point it will reflect instantaneously off the wall and move with the same speed in the opposite direction. If the energy of the particle is positive, it will move always in the same direction, with speed equal to one constant when it is not in the well and speed equal to a different constant when it is in the well.

Figure 5.1

A square well potential.

In the quantum case, we will be interested mainly in eigenvectors for the Schrödinger operator with negative eigenvalues (E < 0). Of course, on the quantum side of things, energy eigenvectors do not change in time, except for an overall phase factor. Nevertheless, since the classical particle with E < 0 spends the same amount of time in each part of the well, we may expect that the quantum particle will have approximately equal probability of being found in each part of the well. This expectation will be fulfilled for "highly excited states," such as the one in Fig. 5.7. For the quantum particle, however, there is a small but nonzero probability of finding the particle outside the well, which is impossible classically.

Our goal is to study the time-independent Schrödinger equation, that is, the eigenvalue equation

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi } {d{x}^{2}} + V \(x\)\\psi \(x\) = E\\psi \(x\), }$$
](A272900_1_En_5_Chapter_Equ2.gif)

(5.2)

where both the eigenvalues E and the associated eigenvectors ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq001.gif) (or "eigenfunctions," in physics terminology) are as yet unknown. As a second-order linear ordinary differential equation, this equation always has (for any value of E) a two-dimensional solution space. We are, however, looking for solutions that lie in the quantum Hilbert space ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq3.gif). We will see there are actually only a finitely many E's, all of them with E < 0, for which (5.2) has a nonzero solution in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq4.gif). In this case, then, the Schrödinger operator ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq5.gif) has a discrete spectrum below zero and a continuous spectrum above zero.

## 5.2 Domain Questions and the Matching Conditions

Before starting to solve (5.2), we must give some heed to the unbounded nature of the Hamiltonian operator. The Schrödinger operator

![
$$\\displaystyle{\\hat{H} = -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}} {d{x}^{2}} + V \(X\)}$$
](A272900_1_En_5_Chapter_Equa.gif)

on the left-hand side of (5.2) is an unbounded operator, meaning that there is no constant C such that ![
$$\\Vert \\hat{H}\\psi \\Vert \\ \\leq C\\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_5_Chapter_IEq6.gif), where ![
$$\\left \\Vert \\cdot \\right\\Vert$$
](A272900_1_En_5_Chapter_IEq7.gif) is the L 2 norm. On the other hand, we want to define ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq8.gif) in such a way that it is self-adjoint. But according to Corollary 9.9, a self-adjoint operator that is defined on the whole Hilbert space must be bounded.

We conclude, then, that ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq9.gif) is not going to be defined on the entire Hilbert space ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq10.gif), but only on a dense subspace thereof. In practical terms, saying that ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq11.gif) is not defined on the whole Hilbert space means simply that for many functions ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq02.gif) in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq12.gif), the second derivative ![
$$d^2\\psi/dx^2$$
](A272900_1_En_5_Chapter_IEq03.gif) does not exist, or exists but fails to be in L 2. (In our example, the potential V is bounded, and so ![
$$V\\psi$$
](A272900_1_En_5_Chapter_IEq04.gif) will always be in L 2 provided that ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq05.gif) is in L 2.)

Since the potential V for a square well is bounded, the domain of the Hamiltonian ![
$$\\hat{H} = {P}^{2}/\(2m\) + V \(X\)$$
](A272900_1_En_5_Chapter_IEq13.gif) is the same as the domain of the kinetic energy operator ![
$${P}^{2}/\(2m\) = -\({\\hslash }^{2}/2m\){d}^{2}/d{x}^{2}$$
](A272900_1_En_5_Chapter_IEq14.gif). As we will see in Sect.​ 9.​7, the domain of the kinetic energy operator may be described as the space of L 2 functions ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq06.gif) for which ![
$$d^2\\psi/dx^2$$
](A272900_1_En_5_Chapter_IEq07.gif), computed in the weak or distributional sense (Appendix A.3.3), again belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq15.gif). This condition is equivalent to the statement that there exists some L 2 function ![
$$\\phi$$
](A272900_1_En_5_Chapter_IEq08.gif) such that ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq09.gif) is the second integral of ![
$$\\phi$$
](A272900_1_En_5_Chapter_IEq010.gif) (for some choice of the constants of integration).

Meanwhile, since our potential is piecewise constant, any solution ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq011.gif) to (5.2) will be smooth except possibly at the transition points x = ±A, and both ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq012.gif) and ![
$$\\psi^\\prime$$
](A272900_1_En_5_Chapter_IEq013.gif) will have left and right limits at A and − A. Indeed, on each of the intervals ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq16.gif), (− A, A), and (A, ∞), any solution to (5.2) will be simply a linear combination of (real or complex) exponentials. For functions of this sort, it is not hard to see when we are in the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq17.gif).

Proposition 5.1

Suppose ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq014.gif) is smooth on each of the intervals ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq18.gif) , (−A, A), and (A, ∞). Then ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq015.gif) belongs to the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq19.gif) [with potential function given by ( 5.1 )] if and only if the (1) ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq016.gif) and ![
$$d\\psi/dx$$
](A272900_1_En_5_Chapter_IEq017.gif) are continuous at x = ±A, and (2) ![
$$d^2\\psi/dx^2$$
](A272900_1_En_5_Chapter_IEq018.gif) belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq20.gif)

Proof.

Suppose first that ![
$$\\psi$$
](A272900_1_En_5_Chapter_IEq019.gif) satisfies the conditions (1) and (2). Then it is not hard to see (Exercise 1) that the second derivative of   in the distribution sense is simply the function  , computed in the ordinary pointwise sense for x ≠ ±A. (The second derivative may not exist at x = ± A, but we simply leave   undefined at these two points, which form a set of measure zero.) Thus,  , computed in the distribution sense, is an element of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq21.gif).

On the other hand, if either   of   has a discontinuity at x = A or at ![
$$x = -A$$
](A272900_1_En_5_Chapter_IEq22.gif), then (Exercise 1 again) the distributional derivative will contain either a multiple or a δ-function of a multiple of the derivative of δ-function at one of these points. But neither a δ-function nor the derivative of δ-function is a square-integrable function.

Let us think about what the continuity condition on   and   means in practical terms. Since V is constant on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq23.gif), we can easily solve (5.2) on that interval, obtaining a two-dimensional solution space. Once we choose a solution from this solution space, then the values of   and   as x approaches − A from the left will serve as the initial conditions for solving (5.2) on (− A, A). Thus, the requirement of continuity for   and   serve as a "matching condition" between the solution on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq24.gif) and the solution on (− A, A). We cannot just separately pick any solution to (5.2) on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq25.gif) and any solution on (− A, A); at the boundary, the values of   and   must match. (This same matching condition appears in elementary treatments of ordinary differential equations with discontinuous coefficients.)

Once we pick a solution on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq26.gif) we get a unique solution on (− A, A)—and then the values of   and   as we approach A from the left will serve as the initial conditions for solving (5.2) on (A, ∞). The conclusion is that once we pick a solution to (5.2) on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq27.gif) (from the two-dimensional solution space), we have no additional choices to make; the differential equation along with the matching conditions give a unique way to extend the solution from ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq28.gif) to the whole real line.

## 5.3 Finding Square-Integrable Solutions

If E > 0, then any solution to (5.2) will be a combination of two complex exponentials in the range x < − A; such a function cannot be square-integrable unless it is identically zero. If, however, we take   to be identically zero in the region x < − A, then our continuity condition requires that   and   approach 0 as x approaches − A from the right. Thus, the matching conditions at − A force the solution to be identically zero in [−A, A] as well. Finally, by matching across x = A, we get an identically zero solution on [A, ∞). Thus, for E > 0, any solution to (5.2) satisfying the continuity conditions in Proposition 5.1 must be identically zero. A similar analysis applies when E = 0, where the solutions to (5.2) on (− ∞, A] would be of the form c 1 \+ c 2 x, which is square-integrable only if ![
$$c_{1} = c_{2} = 0$$
](A272900_1_En_5_Chapter_IEq29.gif).

The conclusion, then, is that to have a chance to get a solution to (5.2) that is square-integrable and in the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq30.gif), we must take E < 0. For E < 0, the solution to (5.2) on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq31.gif) will be a linear combination of the two exponentials exp(α x) and exp(− α x), where

![
$$\\displaystyle{ \\alpha = \\frac{\\sqrt{2m\\left \\vert E\\right\\vert }} {\\hslash }. }$$
](A272900_1_En_5_Chapter_Equ3.gif)

(5.3)

For   to be square-integrable over ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq32.gif), the coefficient of exp(− α x) must be zero, since this term grows exponentially as x tends to − ∞. Thus, the value of   on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq33.gif) must be c exp(α x). Once we choose a value for c, we get a unique solution on (− A, A) by matching   and   across ![
$$x = -A$$
](A272900_1_En_5_Chapter_IEq34.gif). We then get a unique solution on (A, ∞) by matching across x = A. The solution on (A, ∞) will be again be a linear combination of exp(α x) and exp(− α x). For   to be in L 2, we need the coefficient of exp(α x) on (A, ∞) to be zero. We have no choice, however, about what   is on (A, ∞); the coefficient of exp(α x) either comes out to be zero or it does not.

The conclusion, then, is that for any E < 0, there is a unique (up to a constant) solution to (5.2) that is square-integrable on the interval ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq35.gif). This solution then gives rise to a unique solution on (− A, A) and then to a unique solution on (A, ∞), up to a constant. Unless we are lucky, the solution on (A, ∞) will grow exponentially and thus fail to be in L 2. Therefore, in most cases there will be no nonzero solution to (5.2) that satisfies the continuity condition and is square-integrable over the whole real line. The hope is that for certain special values of E, we will be able to find a solution that decays exponentially both on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq36.gif) and on (A, ∞), in which case the solution will belong to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq37.gif).

It can be shown (Exercise 6) that there are no nonzero square-integrable solutions with E ≤ − C. Therefore, any square-integrable solutions to (5.2) that may exist must come from the range − C < E < 0. To analyze this range, let us rewrite the time-independent Schrödinger equation by dividing through by ![
$$-{\\hslash }^{2}/\(2m\)$$
](A272900_1_En_5_Chapter_IEq38.gif), yielding the equation

![
$$\\displaystyle{ \\frac{{d}^{2}\\psi } {d{x}^{2}} = \\left \\{\\begin{array}{ccc} \\varepsilon \\psi &&\\left \\vert x\\right\\vert > A\\\\ & & \\\\ - \(c-\\varepsilon \)\\psi & &\\left \\vert x\\right\\vert < A \\end{array} \\right.. }$$
](A272900_1_En_5_Chapter_Equ4.gif)

(5.4)

where

![
$$\\displaystyle\\begin{array}{rcl} \\varepsilon & =& -\\frac{2mE} {{\\hslash }^{2}} \\\\ c& =& \\frac{2mC} {{\\hslash }^{2}}.{}\\end{array}$$
](A272900_1_En_5_Chapter_Equ5.gif)

(5.5)

Note that although E is assumed to be negative, we have normalized ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq39.gif) to be positive; the condition − C < E < 0 corresponds to ![
$$0 <\\varepsilon < c$$
](A272900_1_En_5_Chapter_IEq40.gif).

Because our potential function V is even, it is easy to see that for any solution   to (5.4), the even and odd parts of   are also solutions. We can, therefore, analyze even solutions and odd solutions separately. We begin with the even case. For x < − A, every solution to (5.4) that is square-integrable over (− ∞, A) is of the form

![
$$\\displaystyle{ \\psi \(x\) = a{e}^{\\sqrt{\\varepsilon }x},\\quad x \\leq -A. }$$
](A272900_1_En_5_Chapter_Equ6.gif)

(5.6)

Since we assume that   is even, we then have

![
$$\\displaystyle{ \\psi \(x\) = a{e}^{-\\sqrt{\\varepsilon }x},\\quad x \\geq A. }$$
](A272900_1_En_5_Chapter_Equ7.gif)

(5.7)

Meanwhile, for − A < x < A, every even solution is of the form

![
$$\\displaystyle{ \\psi \(x\) = b\\cos \\left \(\\sqrt{c-\\varepsilon }x\\right\). }$$
](A272900_1_En_5_Chapter_Equ8.gif)

(5.8)

Proposition 5.2

Let   be the function defined in ( 5.6 ) – ( 5.8 ). Then there exist nonzero constants a and b so that   belongs to the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq41.gif) if and only if the following matching condition holds:

![
$$\\displaystyle{ \\sqrt{\\varepsilon } = \\sqrt{c-\\varepsilon }\\tan \\left \(\\sqrt{c-\\varepsilon }A\\right\). }$$
](A272900_1_En_5_Chapter_Equ9.gif)

(5.9)

Proof.

Clearly both   and   belong to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq42.gif). Thus, in light of Proposition 5.1, we need only ensure that   and  (x) are continuous at x = ± A. Since the exponential functions are never zero, we may always ensure that   itself is continuous by taking any value we like for b and then choosing a appropriately Once   has been made to be continuous,   will be continuous provided that   has the same value as we approach ± A from inside the well or from the outside. To obtain the condition (5.9), we compute   from (5.6) and then from (5.8), evaluate both quantities at ![
$$x = -A$$
](A272900_1_En_5_Chapter_IEq43.gif), and then equate the two values of  . Because we have made our solution an even function, we get the same matching condition at x = A as at ![
$$x = -A$$
](A272900_1_En_5_Chapter_IEq44.gif).

Now, in deriving (5.9), we implicitly assumed that   is nonzero at x = ± A. We do not, however, get any nonzero solutions in which  . After all, at points where the cosine function in (5.8) is zero, its derivative is nonzero. But no choice of the constant in front of the exponentials (5.6) and (5.7) will produce a function that is zero but has a derivative that is nonzero.

Proposition 5.3

For all positive values of c and A, there exists at least one ![
$$\\varepsilon \\in \(0,c\)$$
](A272900_1_En_5_Chapter_IEq45.gif) such that ( 5.9 ) holds.

Proof.

Case 1: ![
$$\\sqrt{c}A <\\pi /2$$
](A272900_1_En_5_Chapter_IEq46.gif). In this case, as ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq47.gif) varies between 0 and c, the left-hand side of (5.9) will vary between 0 and some positive number, whereas the right-hand side of (5.9) will vary between some positive number and 0. By the intermediate value theorem, there must exist ![
$$\\varepsilon \\in \(0,c\)$$
](A272900_1_En_5_Chapter_IEq48.gif) for which (5.9) holds. See Fig. 5.2.

Case 2: ![
$$\\sqrt{c}A \\geq \\pi /2$$
](A272900_1_En_5_Chapter_IEq49.gif). In this case, there is ![
$$\\varepsilon _{0} \\in \[0,c\]$$
](A272900_1_En_5_Chapter_IEq50.gif) for which ![
$$\\sqrt{c -\\varepsilon _{0}}A =\\pi /2$$
](A272900_1_En_5_Chapter_IEq51.gif). As ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq52.gif) decreases from c to ![
$$\\varepsilon _{0}$$
](A272900_1_En_5_Chapter_IEq53.gif), the right-hand side of (5.9) will vary from 0 to + ∞. Thus, for ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq54.gif) slightly larger than ![
$$\\varepsilon _{0}$$
](A272900_1_En_5_Chapter_IEq55.gif), the right-hand side of (5.9) will be larger than the left-hand side. By the intermediate value theorem, there must exist ![
$$\\varepsilon \\in \(\\varepsilon _{0},c\)$$
](A272900_1_En_5_Chapter_IEq56.gif) for which (5.9) holds. See Fig. 5.3 for a case ![
$$\\sqrt{c}A$$
](A272900_1_En_5_Chapter_IEq57.gif) slightly larger than π ∕ 2 and Fig. 5.4 for a case with ![
$$\\sqrt{c}A$$
](A272900_1_En_5_Chapter_IEq58.gif) much larger than π ∕ 2.

Figure 5.2

Solving the matching condition, Case 1.

Figure 5.3

Solving the matching condition, Case 2a.

Figure 5.4

Solving the matching conditions, Case 2b.

Note that if ![
$$\\sqrt{c}A$$
](A272900_1_En_5_Chapter_IEq59.gif) is much larger than π ∕ 2, then there will be multiple solutions of (5.9), as can be seen in Fig. 5.4.

We have found, then, at least one solution   to (5.4) that satisfies the matching condition and for which both   and   decay exponentially at infinity. Since this   belongs to the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq60.gif), we have established the following result.

Proposition 5.4

For any positive values of A and C, there exists at least one value of E in the range − C < E < 0 for which ( 5.2 ) has a nonzero solution in the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq61.gif) , given by the formula

![
$$\\displaystyle{\\psi \(x\) = \\left \\{\\begin{array}{lll} \\cos \\left \(\\sqrt{c-\\varepsilon }x\\right\) && - A \\leq x \\leq A\\\\ & & \\\\ \\cos \\left \(\\sqrt{c-\\varepsilon }A\\right\)\\exp \[-\\sqrt{\\varepsilon }\(\\left \\vert x\\right\\vert - A\)\]&&\\left \\vert x\\right\\vert \\geq A \\end{array} \\right.,}$$
](A272900_1_En_5_Chapter_Equb.gif)

where c and ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq62.gif) are defined in ( 5.5 ) and where ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq63.gif) satisfies ( 5.9 ).

In Proposition 5.4, we have not normalized   to be a unit vector in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq64.gif), but rather have normalized   to equal 1 at the origin. In Figs. 5.5–5.7, we plot our eigenfunction in several different cases. In Fig. 5.5, we have a "shallow" well, with ![
$$\\sqrt{c}A = 1$$
](A272900_1_En_5_Chapter_IEq65.gif). In that case, we obtain only one even eigenvector, which is the ground state of the system (i.e., the eigenvector with the smallest eigenvalue). Next, we consider a "deep" well, with ![
$$\\sqrt{c}A = 30$$
](A272900_1_En_5_Chapter_IEq66.gif). For this well, the ground state is shown in Fig. 5.5 and an "excited state" (i.e., an eigenvector with an eigenvalue that is not the smallest) is shown in Fig. 5.7.

Figure 5.5

Ground state for a shallow potential well.

Figure 5.6

Ground state for a deep potential well.

Figure 5.7

Excited state for a deep potential well.

Note that in the shallow well, the ground state extends quite a bit beyond the interval [ − A, A], whereas in the deep well, the ground state goes to zero very quickly as soon as we move outside the well. On the other hand, the excited state in Fig. 5.7 extends comparatively far outside the well.

It is straightforward to adapt the preceding analysis to the odd case. The matching condition (5.9) is replaced by

![
$$\\displaystyle{ \\sqrt{\\varepsilon } = -\\sqrt{c-\\varepsilon }\\cot \\left \(\\sqrt{c-\\varepsilon }A\\right\) }$$
](A272900_1_En_5_Chapter_Equ10.gif)

(5.10)

(Exercise 2) and the formula for the eigenvectors is now

![
$$\\displaystyle{\\psi \(x\) = \\left \\{\\begin{array}{lll} \\sin \\left \(\\sqrt{c-\\varepsilon }x\\right\) && - A \\leq x \\leq A\\\\ & & \\\\ \\pm \\sin \\left \(\\sqrt{c-\\varepsilon }A\\right\)\\exp \[-\\sqrt{\\varepsilon }\(\\left \\vert x\\right\\vert - A\)\]&&\\left \\vert x\\right\\vert \\geq A \\end{array} \\right.,}$$
](A272900_1_En_5_Chapter_Equc.gif)

where we take the + sign for x > A and the − sign for x < − A.

If ![
$$\\sqrt{c}A <\\pi /2$$
](A272900_1_En_5_Chapter_IEq67.gif), then the matching condition (5.10) will have no solutions, since the right-hand side of (5.10) will be negative for all ![
$$\\varepsilon \\in \(0,c\)$$
](A272900_1_En_5_Chapter_IEq68.gif). For large values of ![
$$\\sqrt{c}A$$
](A272900_1_En_5_Chapter_IEq69.gif), there will be several solutions to (5.10). A typical matching scenario and an associated eigenfunction are plotted in Figs. 5.8 and 5.9.

Figure 5.8

Matching condition for odd solutions.

Figure 5.9

An odd solution.

## 5.4 Tunneling and the Classically Forbidden Region

Let us now briefly compare the classical situation to the quantum one. Classically, if a particle has energy E, then since the kinetic energy p 2 ∕ (2m) is always non-negative, the particle simply cannot be located at a point x with V (x) > E. Thus, the region V (x) ≤ E may be called the "classically allowed" region and the region V (x) > E the "classically forbidden" region. In the case of a square well potential (5.1), if − C < E < 0, then the "well" itself (i.e., the region with − A ≤ x ≤ A) is the classically allowed region and the outside of the well (i.e., the region with ![
$$\\left \\vert x\\right\\vert > A$$
](A272900_1_En_5_Chapter_IEq70.gif)) is the classically forbidden region.

Quantum mechanically, if ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_5_Chapter_IEq71.gif), then the particle has a definite value for the energy, namely E. We see, however, that such a particle has a nonzero probability of being located in the classically forbidden region. Note that although the wave function is not zero in the classically forbidden region, it does decay exponentially with the distance from the classically allowed region. That is to say, the quantum particle can penetrate some distance into the classically forbidden region. Note, however, that if E is much less than zero—i.e., ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq72.gif) is large—then a state with ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_5_Chapter_IEq73.gif) will decay very rapidly outside the well (like ![
$$\\exp \[-\\sqrt{\\varepsilon }\(\\vert x\\vert - A\)\]$$
](A272900_1_En_5_Chapter_IEq74.gif)).

More generally, we can think about the time-dependent Schrödinger equation for a particle with energy approximately equal to E. If we require that the energy be exactly equal to E, then there is no interesting time-dependence, since the solution to the time-dependent Schrödinger equation is simply a constant time  . We can, however, think of a particle where the uncertainty in the energy is nonzero but small. Suppose such a particle is traveling through a region with V < E and then approaches a region with V > E (a "potential barrier"). Classically, the particle would just reflect off of this barrier and go back in the other direction. Quantum mechanically, though, it is possible for the particle to "tunnel" through the potential barrier and come out the other side. That is to say, at some later time, there will be some non-negligible portion of the wave function on the far side of the barrier.

## 5.5 Discrete and Continuous Spectrum

Our analysis of the eigenvector equation (5.2) for − C < E < 0 shows that there are only finitely many values of E in this range for which we get square-integrable solutions. It is not hard to analyze the case E ≤ − C with the result that all nonzero solutions grow exponentially in at least one direction (Exercise 6). Meanwhile, for E > 0, any solution to (5.2) on ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq75.gif) has sinusoidal behavior and is not square-integrable unless it is identically zero, in which case (by our matching condition) the solution must be zero everywhere.

The upshot is that we obtain only finitely many square-integrable solutions to (5.2), up to multiplying each solution by a constant. Clearly, then, the "true" eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq76.gif) [i.e., the ones that actually belong to the Hilbert space ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq77.gif)] cannot form an orthonormal basis for ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq78.gif). Nevertheless, the spectral theorem (Chap.​ 7) provides something like a orthonormal-basis decomposition of elements of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq79.gif) in terms of the solutions to (5.2). A general element   of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_5_Chapter_IEq80.gif) will be a sum of two terms. The first term is a linear combination of the true (L 2) eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq81.gif), which have E < 0. The second term is a continuous superposition (i.e., an integral) of the non–square-integrable "generalized eigenvectors" with E > 0.

In Chap.​ 9, we will introduce the notion of the spectrum of a (possibly unbounded) self-adjoint operator A. We will see that a number λ belongs to the spectrum of A if for all ![
$$\\varepsilon > 0$$
](A272900_1_En_5_Chapter_IEq82.gif) there exists a unit vector   in the domain of A for which ![
$$\\left \\Vert A\\psi -\\lambda \\psi \\right\\Vert <\\varepsilon$$
](A272900_1_En_5_Chapter_IEq83.gif). In the case of the Hamiltonian operator ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq84.gif) with a square well potential, it is not hard to show that every real number E with E ≥ 0 belongs to the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq85.gif) (Exercise 4.).

It can be shown that if a number E < 0 is not an eigenvalue (i.e., if there are no nonzero L 2 solutions to ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_5_Chapter_IEq86.gif)), then E is not an element of the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq87.gif). This result is hinted at by Exercise 5. Thus, the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq88.gif) consists of a finite number of points in (− C, 0) (at least one), together with the whole half line [0, ∞).

## 5.6 Exercises

1.

(a)

Suppose   is a smooth function on each of the intervals ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq89.gif), (− A, A), and (A, ∞) and that both   and   are continuous at x = A and at ![
$$x = -A$$
](A272900_1_En_5_Chapter_IEq90.gif). Show that for any smooth function χ with compact support, we have

![
$$\\displaystyle{ \\int _{-\\infty }^{\\infty }{\\chi }^{{\\prime\\prime}}\(x\)\\psi \(x\)\\ dx =\\int _{ -\\infty }^{\\infty }\\chi {\(x\)\\psi }^{{\\prime\\prime}}\(x\)\\ dx, }$$
](A272900_1_En_5_Chapter_Equ11.gif)

(5.11)

where we leave  (x) undefined at x = ± A if the second derivative does not exist at those points. (In light of Definition A.28, (5.11) means that the second derivative of  , in the distribution sense, is simply the function  .)

Hint: Choose some interval [ − R, R] with R > A containing the support of χ. Now use integration by parts separately on each of the intervals ![
$$\[-R,-A\]$$
](A272900_1_En_5_Chapter_IEq91.gif), [ − A, A], and [A, R], paying careful attention to the boundary terms.

(b)

Suppose now that   is a smooth function on each of the intervals ![
$$\(-\\infty,-A\)$$
](A272900_1_En_5_Chapter_IEq92.gif), (− A, A), and (A, ∞), and that both   and   have left and right limits at x = ± A, but that, say,   has a discontinuity at ![
$$x = -A$$
](A272900_1_En_5_Chapter_IEq93.gif). Show that (5.11) has to be modified by adding a nonzero multiple of χ(− A) to the right-hand side.

2.

Verify the matching condition (5.10) for odd solutions of the time-independent Schrödinger equation.

3.

Let ω be a nonzero real number and consider a function of the form

![
$$\\displaystyle{\\psi \(x\) = a\\cos \(\\omega x\) + b\\sin \(\\omega x\),}$$
](A272900_1_En_5_Chapter_Equd.gif)

for real numbers a and b. If a and b are not both zero, show that for any ![
$$A \\in \\mathbb{R}$$
](A272900_1_En_5_Chapter_IEq94.gif), we have

![
$$\\displaystyle{\\lim _{B\\rightarrow +\\infty }\\int _{A}^{B}\\psi {\(x\)}^{2}\\ dx = +\\infty.}$$
](A272900_1_En_5_Chapter_Eque.gif)

4.

Let f be a C ∞ function on the interval (0, 1) with the property that f(x) = 1 for 0 < x < 1 ∕ 3 and f(x) = 0 for 2 ∕ 3 < x < 1. Then define a family of "cutoff" functions χ n on ![
$$\\mathbb{R}$$
](A272900_1_En_5_Chapter_IEq95.gif) by the formula

![
$$\\displaystyle{\\chi _{n}\(x\) = \\left \\{\\begin{array}{cc} 0 & \\left \\vert x\\right\\vert \\geq n + 1 \\\\ 1 & \\left \\vert x\\right\\vert \\leq n \\\\ f\(-x - n\)& - \(n + 1\) < x < -n \\\\ f\(x - n\) & n < x < n + 1\\end{array} \\right..}$$
](A272900_1_En_5_Chapter_Equf.gif)

Given any E > 0, let   be a nonzero solution to (5.2) for which   and  (x) are continuous at x = ± A. Let  . Show that   belongs to the domain of ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq96.gif) and that

![
$$\\displaystyle{\\lim _{n\\rightarrow \\infty }\\frac{\\left \\Vert \\hat{H}\\psi _{n} - E\\psi _{n}\\right\\Vert } {\\left \\Vert \\psi _{n}\\right\\Vert } = 0.}$$
](A272900_1_En_5_Chapter_Equg.gif)

Note: As we will see in Chap.​ 9, this implies that every real number E with E > 0 belongs to the spectrum of the operator ![
$$\\hat{H}$$
](A272900_1_En_5_Chapter_IEq97.gif).

Hint: In estimating ![
$$\\left \\Vert \\psi _{n}\\right\\Vert$$
](A272900_1_En_5_Chapter_IEq98.gif), it may be helpful to apply Exercise 3 to the real and imaginary parts of   outside the well.

5.

Suppose E < 0 and suppose that there exists no nonzero square-integrable solutions to (5.2) for which   and   are continuous. Let   be a nonzero solution of (5.2) for which   and  (x) are continuous at x = ± A and let   be as in Exercise 4. Show that

![
$$\\displaystyle{\\frac{\\left \\Vert \\hat{H}\\psi _{n} - E\\psi _{n}\\right\\Vert } {\\left \\Vert \\psi _{n}\\right\\Vert } }$$
](A272900_1_En_5_Chapter_Equh.gif)

does not tend to zero as n tends to infinity.

6.

(a)

Show that for E < − C, there are no nonzero square-integrable solutions to (5.2) for which   and   are continuous.

(b)

Obtain the result of Part (a) when ![
$$E = -C$$
](A272900_1_En_5_Chapter_IEq99.gif).

Hint: Analyze the even and odd cases separately.

7.

Let the ground state for a particle in a square well denote the eigenvector with the lowest (most negative) eigenvalue, which corresponds to the largest value for ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq100.gif).

(a)

Show that the ground state is always an even function. That is to say, show that the largest value of ![
$$\\varepsilon$$
](A272900_1_En_5_Chapter_IEq101.gif) satisfying (5.9) is always larger than any solution to (5.10).

(b)

Show that the ground state is a nowhere-zero function.
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_6

© Springer Science+Business Media New York 2013

# 6. Perspectives on the Spectral Theorem

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

Suppose A is a self-adjoint n × n matrix, meaning that ![
$$A_{kj} = \\overline{A_{jk}}$$
](A272900_1_En_6_Chapter_IEq001.gif) for all 1≤ j, k ≤ n. Then a standard result in linear algebra asserts that there exist an orthonormal basis ![
$$\\{\\mathbf{v}_{j}\\}_{j=1}^{n}$$
](A272900_1_En_6_Chapter_IEq002.gif) for ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_6_Chapter_IEq003.gif) and real numbers λ 1,...,λ n such that ![
$$A\\mathbf{v}_{j} =\\lambda _{j}\\mathbf{v}_{j}$$
](A272900_1_En_6_Chapter_IEq004.gif). (See Theorem 18 in Chap. 8 of [24] and Exercise 4 in Chap. 7)

## 6.1 The Difficulties with the Infinite-Dimensional Case

Suppose A is a self-adjoint n × n matrix, meaning that ![
$$A_{kj} = \\overline{A_{jk}}$$
](A272900_1_En_6_Chapter_IEq1.gif) for all 1 ≤ j, k ≤ n. Then a standard result in linear algebra asserts that there exist an orthonormal basis ![
$$\\{\\mathbf{v}_{j}\\}_{j=1}^{n}$$
](A272900_1_En_6_Chapter_IEq2.gif) for ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_6_Chapter_IEq3.gif) and real numbers λ 1,..., λ n such that ![
$$A\\mathbf{v}_{j} =\\lambda _{j}\\mathbf{v}_{j}$$
](A272900_1_En_6_Chapter_IEq4.gif). (See Theorem 18 in Chap.​ 8 of 24] and Exercise 4 in [Chap.​ 7)

We may state the same result in basis-independent language as follows. Suppose H is a finite-dimensional Hilbert space and A is a self-adjoint linear operator on H, meaning that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_6_Chapter_IEq5.gif) for all ![
$$\\phi\\psi$$
](A272900_1_En_6_Chapter_IEq01.gif) ∈ H. Then there exists an orthonormal basis of H consisting of eigenvectors for A with real eigenvalues.

Since there is a standard notion of orthonormal bases for general Hilbert spaces, we might hope that a similar result would hold for self-adjoint operators on infinite-dimensional Hilbert spaces. Simple examples, however, show that a self-adjoint operator may not have any eigenvectors. Consider, for example, H = L 2([0, 1]) and an operator A on H defined by

![
$$\\displaystyle{ \(A\\psi \)\(x\) = x\\psi \(x\). }$$
](A272900_1_En_6_Chapter_Equ1.gif)

(6.1)

Then A satisfies ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_6_Chapter_IEq6.gif) for all   ∈ L 2([0, 1]), and yet A has no eigenvectors. After all, if ![
$$x\\psi\(x\) = \\lambda\\psi\(x\)$$
](A272900_1_En_6_Chapter_IEq03.gif), then ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq04.gif) would have to be supported on the set where x = λ, which is a set of measure zero. Thus, only the zero element of L 2([0, 1]) satisfies ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_6_Chapter_IEq05.gif).

Now, a physicist would say that the operator A in (6.1) does have eigenvectors, namely the distributions δ(x − λ). (See Appendix A.3.3.) These distributions indeed satisfy ![
$$x\\delta \(x-\\lambda \) =\\lambda \\delta \(x-\\lambda \)$$
](A272900_1_En_6_Chapter_IEq7.gif), but they do not belong to the Hilbert space L 2([0, 1]). Such "eigenvectors," which belong to some larger space than H, are known as generalized eigenvectors. Even though these generalized eigenvectors are not actually in the Hilbert space, we may hope that there is some sense in which they form something like a orthonormal basis. See Sect. 6.6 for an example of how such a "basis" might function.

Let us mention in passing that our simple expectation of a true orthonormal basis of eigenvectors is realized for compact self-adjoint operators, where an operator A on H is said to be compact if the image under A of every bounded set in H has compact closure; see Theorem VI.16 in Volume I of 34]. The operators of interest in quantum mechanics, however, are not compact. (Of course, even if a self-adjoint operator is not compact, it might still have an orthonormal basis of eigenvectors, as, e.g., in the case of the Hamiltonian operator for a harmonic oscillator. See [Chap.​ 11)

Meanwhile, there is another serious difficulty that arises with self-adjoint operators in the infinite-dimensional case. Most of the self-adjoint operators A of quantum mechanics are unbounded operators, meaning that there is no constant C such that ![
$$\\left \\Vert A\\psi \\right\\Vert \\leq C\\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_6_Chapter_IEq8.gif) for all ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq06.gif). Suppose, for example, that A is the position operator X on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq9.gif), given by ![
$$\(X\\psi\)\(x\) = x\\psi\(x\)$$
](A272900_1_En_6_Chapter_IEq07.gif). If 1 E denotes the indicator function of E (the function that is 1 on E and 0 elsewhere), then it is apparent that

![
$$\\displaystyle{\\left \\Vert X1_{\[n,n+1\]}\\right\\Vert \\geq n\\left \\Vert 1_{\[n,n+1\]}\\right\\Vert }$$
](A272900_1_En_6_Chapter_Equa.gif)

for every positive integer n, and, thus, X cannot be bounded. Now, using the closed graph theorem and elementary results from Sect.​ 9.​3, it can be shown that if A is defined on all of H and satisfies ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_6_Chapter_IEq10.gif) for all ![
$$\\phi, \\psi$$
](A272900_1_En_6_Chapter_IEq08.gif) ∈ H, then A must be bounded. (See Corollary 9.9.) Thus, if A is unbounded and self-adjoint, it cannot be defined on all of H.

We define, then, an "unbounded operator on H " to be a linear operator from a dense subspace of H—known as the domain of A—to H. The notion of self-adjointness for such operators is more complicated than in the bounded case. The obvious condition, that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle$$
](A272900_1_En_6_Chapter_IEq11.gif) should equal ![
$$\\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_6_Chapter_IEq12.gif) for all ![
$$\\phi$$
](A272900_1_En_6_Chapter_IEq09.gif) and ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq010.gif) in the domain of A, is not the "right" condition. Specifically, that condition is not sufficient to guarantee that the spectral theorem applies to A. Rather, for any unbounded operator A, we will define the adjoint A ∗ of A, which will be an unbounded operator with its own domain. An unbounded operator is then defined to be self-adjoint if the domains of A and A ∗ are the same and A and A ∗ agree on their common domain. That is to say, self-adjointness means not only that A and A ∗ agree whenever they are both defined, but also that the domains of A and A ∗ agree.

## 6.2 The Goals of Spectral Theory

Before getting into the details of the spectral theory, let us think for a moment about what it is we want the spectral theorem to do for us. In the first place, we would like the spectral theorem to allow us to apply various functions to an operator. We saw, for example, that the time-dependent Schrödinger equation can be "solved" by setting ![
$$\\psi \(t\) =\\exp \\{ -it\\hat{H}/\\hslash \\}\\psi _{0}$$
](A272900_1_En_6_Chapter_IEq13.gif). Because the Hamiltonian operator ![
$$\\hat{H}$$
](A272900_1_En_6_Chapter_IEq14.gif) is unbounded, it is not convenient to use power series to define the exponential. If, however, ![
$$\\hat{H}$$
](A272900_1_En_6_Chapter_IEq15.gif) has a true orthonormal basis {e k } of eigenvectors with corresponding eigenvalues λ n , then we can define ![
$$\\exp \\{-it\\hat{H}/\\hslash \\}$$
](A272900_1_En_6_Chapter_IEq16.gif) to be the unique bounded operator with the property that

![
$$\\displaystyle{{e}^{-it\\hat{H}/\\hslash }e_{ k} = {e}^{-it\\lambda _{k}/\\hslash }e_{ k}}$$
](A272900_1_En_6_Chapter_Equb.gif)

for all k.

In cases where ![
$$\\hat{H}$$
](A272900_1_En_6_Chapter_IEq17.gif) does not have a true orthonormal basis of eigenvectors, we would like the spectral theorem to provide a "functional calculus" for ![
$$\\hat{H}$$
](A272900_1_En_6_Chapter_IEq18.gif), that is, a system for applying functions (including exponentials) to ![
$$\\hat{H}$$
](A272900_1_En_6_Chapter_IEq19.gif). This functional calculus should have properties similar to what we have in the case of a true orthonormal basis of eigenvectors.

In the second place, we would like the spectral theorem to provide a probability distribution for the result of measuring a self-adjoint operator A. Let us recall how measurement probabilities work in the case that A has a true orthonormal basis {e j } of eigenvectors with eigenvalues λ j . Building on Example 3.12, we may compute the probabilities in such a case as follows. Given any Borel set E of ![
$$\\mathbb{R}$$
](A272900_1_En_6_Chapter_IEq20.gif), let V E be the closed span of all the eigenvectors for A with eigenvalues in E, and let P E be the orthogonal projection onto V E . Then for any unit vector ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq011.gif), we have

![
$$\\displaystyle{ \\mathrm{prob}_{\\psi }\(A \\in E\) = \\left \\langle \\psi,P_{E}\\psi \\right\\rangle. }$$
](A272900_1_En_6_Chapter_Equ2.gif)

(6.2)

In particular, if the eigenvalues are distinct and ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq012.gif) decomposes as ![
$$\\psi =\\sum _{j}c_{j}e_{j}$$
](A272900_1_En_6_Chapter_IEq21.gif), the probability of observing the value λ j will be ![
$${\\left \\vert c_{j}\\right\\vert }^{2}$$
](A272900_1_En_6_Chapter_IEq22.gif) (as in Example 3.12), since ![
$$P_{\\{\\lambda _{j}\\}}$$
](A272900_1_En_6_Chapter_IEq23.gif) is just the projection onto e j .

In cases where A does not have a true orthonormal basis of eigenvectors, we would like the spectral theorem to provide a family of projection operators P E , one for each Borel subset ![
$$E \\subset \\mathbb{R}$$
](A272900_1_En_6_Chapter_IEq24.gif), which will allow us to define probabilities as in (6.2). We will call these projection operators spectral projections and the associated subspaces V E spectral subspaces. (Thus, P E is the orthogonal projection onto V E .) Intuitively, V E may be thought of as the closed span of all the generalized eigenvectors with eigenvalues in E.

In the first version of the spectral theorem, both these goals will be achieved, with the spectral projections being provided by a projection-valued measure and the functional calculus being provided by integration with respect to this measure. Although having (generalized) eigenvectors for a self-adjoint operator is, from a practical standpoint, of secondary importance, we provide a framework for understanding such eigenvectors, using the concept of a direct integral. The second version of the spectral theorem decomposes the Hilbert space H as a direct integral, with respect to a certain measure μ, of generalized eigenspaces for a self-adjoint operator A. The generalized eigenspace for a particular eigenvalue λ will not actually be a subspace of H, unless μ({λ}) > 0. Thus, the notion of a direct integral gives a rigorous meaning to the notion of "eigenvectors" that are not actually in the Hilbert space.

## 6.3 A Guide to Reading

Although the portion of this book devoted to spectral theory is unavoidably technical in places, it has been designed so that the reader can take in as much or as little as desired. The reader who is willing to take things on faith can simply take in the examples of the position and momentum operators in Sects. 6.4 and 6.6 and accept these as prototypes of how the spectral theorem works. The reader who wants more details can find the statement of the spectral theorem for bounded operators, in two different forms, in Chap.​ 7, and can find the basics of unbounded self-adjoint operators in Chap.​ 9 Finally, the reader who wants a complete treatment of the subject can find full proofs of the spectral theorem in both forms, first for bounded operators in Chap.​ 8, and then for unbounded operators in Chap.​ 10

## 6.4 The Position Operator

As our first example, let us consider the position operator X, given by ![
$$\(X\\psi\)\(x\) = x\\psi\(x\)$$
](A272900_1_En_6_Chapter_IEq015.gif), acting on the Hilbert space ![
$$\\mathbf{H} = {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq25.gif). As for the similar operator in Sect. 6.1, X has no true eigenvectors, that is, no eigenvectors that are actually in H. If we think that the generalized eigenvectors for X are the distributions δ(x − λ), ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_6_Chapter_IEq26.gif), then we may make an educated guess that the spectral subspace V E should consist of those functions that "supported" on E, that is, those that are zero almost everywhere on the complement of E. (A superposition of the "functions" δ(x − λ), with λ ∈ E, should be a function supported on E.)

The spectral projection P E is then the orthogonal projection onto V E , which may be computed as

![
$$\\displaystyle{P_{E}\\psi = 1_{E}\\psi,}$$
](A272900_1_En_6_Chapter_Equc.gif)

where 1 E is the indicator function of E. In that case, we have, following (6.2),

![
$$\\displaystyle{\\mathrm{prob}_{\\psi }\\left \(X \\in E\\right\) = \\left \\langle \\psi,P_{E}\\psi \\right\\rangle =\\int _{E}{\\left \\vert \\psi \(x\)\\right\\vert }^{2}\\ dx.}$$
](A272900_1_En_6_Chapter_Equd.gif)

This formula is just what we would have expected from our discussion in Chap.​ 3, where we claimed that the probability distribution for the position of the particle is ![
$${\\left \\vert \\psi \(x\)\\right\\vert }^{2}$$
](A272900_1_En_6_Chapter_IEq27.gif).

Meanwhile, let us consider the functional calculus for X. If f(λ) = λ m , then f(X) should be just the mth power of X, which is multiplication by x m . It seems reasonable, then, to think that for any function f, we should define f(X) to be simply multiplication by f(x). In particular, the operator e iaX should be simply multiplication by e iax , which is a bounded operator on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq28.gif).

## 6.5 Multiplication Operators

Since the position operator acts simply as multiplication by the function x, it is straightforward to find the spectral subspaces and also to construct the functional calculus for X. We may consider multiplication operators in a more general setting. If H = L 2(X, μ) and h is a real-valued measurable function on X, then we may define the multiplication operator M h on L 2(X, μ) by

![
$$\\displaystyle{M_{h}\\psi = h\\psi.}$$
](A272900_1_En_6_Chapter_Eque.gif)

We can then construct spectral subspaces as

![
$$\\displaystyle{V _{E} =\\{\\psi \\left \\vert \\psi \\text{ is supported on }\\ {h}^{-1}\(E\)\\right.\\}}$$
](A272900_1_En_6_Chapter_Equf.gif)

and define a functional calculus by

![
$$\\displaystyle{f\(A\) = \\text{multiplication by }\\ f \\circ h.}$$
](A272900_1_En_6_Chapter_Equg.gif)

One form of spectral theorem may now be stated simply as follows: A self-adjoint operator A on a separable Hilbert space is unitarily equivalent to a multiplication operator. That is to say, there is some σ-finite measure space (X, μ) and some measurable function h on X such that A is unitarily equivalent to multiplication by h. (See Theorem 7.20.) Although this version of the spectral theorem is compellingly easy to state, there is slight modification of it, involving direct integrals, that is in some ways even better. See Sect.​ 7.​3 for more information.

## 6.6 The Momentum Operator

Let us now see how the spectral theorem works out in the case of the momentum operator, ![
$$P = -i\\hslash \\ d/dx$$
](A272900_1_En_6_Chapter_IEq29.gif) on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq30.gif). The "eigenvectors" for P are the functions e ikx , ![
$$k \\in \\mathbb{R}$$
](A272900_1_En_6_Chapter_IEq31.gif), with the corresponding eigenvalues being ![
$$\\hslash k$$
](A272900_1_En_6_Chapter_IEq32.gif). Although the functions e ikx are not in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq33.gif), the Fourier transform shows that any function in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq34.gif) can be expanded as a superposition (i.e., continuous version of a linear combination) of these functions. (See Appendix A.3.2.) Indeed, the Fourier transform is very much like the decomposition of a vector in an orthonormal basis, in that the Fourier coefficients ![
$$\\hat{\\psi }\(k\)$$
](A272900_1_En_6_Chapter_IEq35.gif) can be expressed in terms of the "inner product" of a function ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq016.gif) with e ikx :

![
$$\\displaystyle{\\hat{\\psi }\(k\) = {\(2\\pi \)}^{-1/2}\\int _{ -\\infty }^{\\infty }{e}^{-ikx}\\psi \(x\)\\ dx = {\(2\\pi \)}^{-1/2}\\left \\langle {e}^{ikx},\\psi \\right\\rangle _{{ L}^{2}\(\\mathbb{R}\)},}$$
](A272900_1_En_6_Chapter_Equh.gif)

if we ignore the fact that e ikx is not actually in L 2.

Indeed, physicists frequently understand the Fourier transform by asserting that the functions ![
$${e}^{ikx}/\\sqrt{2\\pi }$$
](A272900_1_En_6_Chapter_IEq36.gif) form an "orthonormal basis in the continuous sense" for ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq37.gif). Orthonormality in the continuous sense is supposed to mean that one replaces the usual Kronecker delta in the definition of an orthonormal set by the Dirac δ -function

![
$$\\displaystyle{ \\left \\langle \\frac{{e}^{ikx}} {\\sqrt{2\\pi }}, \\frac{{e}^{ilx}} {\\sqrt{2\\pi }} \\right\\rangle _{{L}^{2}\(\\mathbb{R}\)} =\\delta \(k - l\), }$$
](A272900_1_En_6_Chapter_Equ3.gif)

(6.3)

where δ is supposed to satisfy

![
$$\\displaystyle{\\int _{-\\infty }^{\\infty }f\(k\)\\delta \(k - l\)\\ dk = f\(l\)}$$
](A272900_1_En_6_Chapter_Equi.gif)

for all continuous functions f. (Rigorously, δ(k − l) is a distribution; see Appendix A.3.3.)

To give some rigorous meaning to (6.3), note that although the inner product of e ikx and e ilx is not defined, we may approximate this inner product by the expression

![
$$\\displaystyle{\\frac{1} {2\\pi }\\int _{-A}^{A}{e}^{-ikx}{e}^{ilx}\\ dx = \\left.\\frac{1} {2\\pi } \\frac{{e}^{-i\(k-l\)x}} {-i\(k - l\)}\\right\\vert _{-A}^{A} = \\frac{A} {\\pi } \\frac{\\sin \\left \[A\(k - l\)\\right\]} {A\(k - l\)}.}$$
](A272900_1_En_6_Chapter_Equj.gif)

It is possible to show that the above function, viewed as a function of k for fixed A and l, behaves like δ(k − l) in the limit as A tends to infinity. That is to say, for all sufficiently nice functions ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq017.gif), we have

![
$$\\displaystyle{ \\lim _{A\\rightarrow \\infty }\\int _{-\\infty }^{\\infty }\\psi \(k\)\\frac{A} {\\pi } \\frac{\\sin \\left \[A\(k - l\)\\right\]} {A\(k - l\)} dk =\\psi \(l\). }$$
](A272900_1_En_6_Chapter_Equ4.gif)

(6.4)

Here is a heuristic argument for (6.4). By making the change of variable ![
$${k}^{{\\prime}} = k - l$$
](A272900_1_En_6_Chapter_IEq38.gif), we may reduce the general problem to the case l = 0. If we then make the change of variable κ = Ak, the desired result is equivalent to

![
$$\\displaystyle{ \\lim _{A\\rightarrow +\\infty }\\int _{-\\infty }^{\\infty }\\frac{1} {\\pi } \\frac{\\sin \\kappa } {\\kappa }f\\left \( \\frac{\\kappa } {A}\\right\)\\ d\\kappa = f\(0\). }$$
](A272900_1_En_6_Chapter_Equ5.gif)

(6.5)

Now, if we can bring the limit inside the integral, f(κ ∕ A) will tend to f(0) as A tends to infinity. Since the rest of the integrand on the right-hand side of (6.5) is already independent of A, the result would then follow if we could show that

![
$$\\displaystyle{ \\int _{-\\infty }^{\\infty }\\frac{1} {\\pi } \\frac{\\sin \\kappa } {\\kappa }\\ d\\kappa = 1. }$$
](A272900_1_En_6_Chapter_Equ6.gif)

(6.6)

Even though the integral in (6.6) is not absolutely convergent, it is a convergent improper integral. The value of the integral can be obtained by the method of contour integration (or the method of consulting a table of integrals), and indeed (6.6) holds. Since (6.3) is, in any case, only a heuristic way of thinking about the Fourier transform, we will not take the time to develop a rigorous version of the preceding argument.

It is possible to derive, at least formally, many of the standard properties of the Fourier transform by using (6.3), just as one can obtain properties of Fourier series by using the orthonormality of the functions e 2πinx in L 2([0, 1]). More importantly, the Fourier transform is precisely the unitary transformation that changes the momentum operator into a multiplication operator. To see this property of the Fourier transform more clearly, we introduce a simple rescaling of it.

Definition 6.1

For any ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq39.gif), define ![
$$\\tilde{\\psi }$$
](A272900_1_En_6_Chapter_IEq40.gif) by

![
$$\\displaystyle{\\tilde{\\psi }\(p\) = \\frac{1} {\\sqrt{\\hslash }}\\hat{\\psi }\\left \(\\frac{p} {\\hslash }\\right\),}$$
](A272900_1_En_6_Chapter_Equk.gif)

so that

![
$$\\displaystyle{\\tilde{\\psi }\(p\) = \\frac{1} {\\sqrt{2\\pi \\hslash }}\\int _{-\\infty }^{\\infty }{e}^{-ipx/\\hslash }\\psi \(x\)\\ dx.}$$
](A272900_1_En_6_Chapter_Equl.gif)

The function ![
$$\\tilde{\\psi }\(p\)$$
](A272900_1_En_6_Chapter_IEq41.gif) is the momentum wave function associated with ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq018.gif).

By the Plancherel theorem (Theorem A.19) and a change of variable, if ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq019.gif) is a unit vector, then so is ![
$$\\hat{\\psi }$$
](A272900_1_En_6_Chapter_IEq42.gif) and also ![
$$\\tilde{\\psi }$$
](A272900_1_En_6_Chapter_IEq43.gif). For any unit vector ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq020.gif), we interpret ![
$$\\vert \\tilde{\\psi }\(p\){\\vert }^{2}$$
](A272900_1_En_6_Chapter_IEq44.gif) as the probability density for the momentum of the particle, just as ![
$${\\left \\vert \\psi \(x\)\\right\\vert }^{2}$$
](A272900_1_En_6_Chapter_IEq45.gif) is the probability distribution of the position of the particle. Using Proposition A.17, we may readily verify that for nice enough ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq021.gif), we have

![
$$\\displaystyle{ \\widetilde{P\\psi }\(p\) = p\\tilde{\\psi }\(p\). }$$
](A272900_1_En_6_Chapter_Equ7.gif)

(6.7)

Equation (6.7) means that the unitary map ![
$$\\psi \\rightarrow \\tilde{\\psi }$$
](A272900_1_En_6_Chapter_IEq46.gif) turns the momentum operator P into multiplication by p. That is to say, the spectral theorem, in its "multiplication operator" form, is accomplished in this case by the Fourier transform (scaled as in Definition 6.1).

In terms of the momentum wave function, we may define spectral projections and a functional calculus for P, just as in Sect. 6.5. For any Borel set ![
$$E \\subset \\mathbb{R}$$
](A272900_1_En_6_Chapter_IEq47.gif), we may define a projection P E to be the orthogonal projection onto to the space of functions ![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq022.gif) for which ![
$$\\tilde{\\psi }\(p\)$$
](A272900_1_En_6_Chapter_IEq48.gif) is zero almost everywhere outside of E. If f is any bounded measurable function on ![
$$\\mathbb{R}$$
](A272900_1_En_6_Chapter_IEq49.gif), we can define an operator f(P) by defining f(P)![
$$\\psi$$
](A272900_1_En_6_Chapter_IEq023.gif) to be the unique element of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_6_Chapter_IEq50.gif) for which

![
$$\\displaystyle{\\widetilde{f\(P\)\\psi }\(p\) = f\(p\)\\tilde{\\psi }\(p\).}$$
](A272900_1_En_6_Chapter_Equm.gif)

References

[24].

K. Hoffman, R. Kunze, Linear Algebra, 2nd edn. (Prentice-Hall, Englewood Cliffs, NJ, 1971)

[34].

M. Reed, B. Simon, Methods of Modern Mathematical Physics. Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_7

© Springer Science+Business Media New York 2013

# 7. The Spectral Theorem for Bounded Self-Adjoint Operators: Statements

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In the present chapter, we will consider the spectral theorem for bounded self-adjoint operators, leaving a discussion of unbounded operators to Chaps. 9 and 10. The proofs of the main theorems (two different versions of the spectral theorem) are moderately long and are deferred to Chap. 8.

In the present chapter, we will consider the spectral theorem for bounded self-adjoint operators, leaving a discussion of unbounded operators to Chaps.​ 9 and . The proofs of the main theorems (two different versions of the spectral theorem) are moderately long and are deferred to Chap.​ 8. After some elementary definitions and results in Sect. 7.1, we come to the main results in Sects. 7.2 and 7.3. Throughout the chapter, H will, as usual, denote a separable Hilbert space over ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq1.gif).

## 7.1 Elementary Properties of Bounded Operators

As usual, we will let H denote a separable complex Hilbert space. Recall from Appendix A.3.4 that a linear operator A on H is said to be bounded if the operator norm of A,

![
$$\\displaystyle{ \\left \\Vert A\\right\\Vert :=\\sup _{\\psi \\in \\mathbf{H}\\setminus \\{0\\}}\\frac{\\left \\Vert A\\psi \\right\\Vert } {\\left \\Vert \\psi \\right\\Vert } }$$
](A272900_1_En_7_Chapter_Equ1.gif)

(7.1)

is finite. The space of bounded operators on H forms a Banach space under the operator norm, and we have the inequality

![
$$\\displaystyle{ \\left \\Vert AB\\right\\Vert \\leq \\left \\Vert A\\right\\Vert \\left \\Vert B\\right\\Vert }$$
](A272900_1_En_7_Chapter_Equ2.gif)

(7.2)

for all bounded operators A and B.

Definition 7.1.

The Banach space of bounded operators on H, with respect to the operator norm (7.1), is denoted ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq2.gif).

Recall (Appendix A.4.3) that for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq3.gif) there is a unique operator ![
$${A}^{{\\ast}}\\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq4.gif), called the adjoint of A, such that

![
$$\\displaystyle{\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_7_Chapter_Equa.gif)

for all  . An operator ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq5.gif) is called self-adjoint if A ∗ = A. We say that ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq6.gif) is non-negative if

![
$$\\displaystyle{ \\left \\langle \\psi,A\\psi \\right\\rangle \\geq 0 }$$
](A272900_1_En_7_Chapter_Equ3.gif)

(7.3)

for all ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq02.gif) ∈ H.

Proposition 7.2.

For all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq7.gif) , we have

![
$$\\displaystyle{\\left \\Vert {A}^{{\\ast}}\\right\\Vert = \\left \\Vert A\\right\\Vert }$$
](A272900_1_En_7_Chapter_Equb.gif)

and

![
$$\\displaystyle{\\left \\Vert {A}^{{\\ast}}A\\right\\Vert ={ \\left \\Vert A\\right\\Vert }^{2}.}$$
](A272900_1_En_7_Chapter_Equc.gif)

In particular, if A is self-adjoint, we have the useful result that ![
$$\\left \\Vert {A}^{2}\\right\\Vert ={ \\left \\Vert A\\right\\Vert }^{2}$$
](A272900_1_En_7_Chapter_IEq8.gif).

Proof.

The operator norm of A can also be computed as

![
$$\\displaystyle{\\left \\Vert A\\right\\Vert =\\sup _{\\left \\Vert \\psi \\right\\Vert =1}\\left \\Vert A\\psi \\right\\Vert.}$$
](A272900_1_En_7_Chapter_Equd.gif)

Furthermore, for any vector ![
$$\\phi \\in \\bf{H}, \\left \\Vert \\phi \\right\\Vert =\\sup _{\\left \\Vert \\chi \\right\\Vert =1}\\left \\vert \\left \\langle \\chi,\\phi \\right\\rangle \\right\\vert$$
](A272900_1_En_7_Chapter_IEq9.gif). (Inequality one direction is by the Cauchy–Schwarz inequality, and inequality the other direction is by taking ![
$$\\chi$$
](A272900_1_En_7_Chapter_IEq03.gif) to be a multiple of ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq04.gif).) Thus,

![
$$\\displaystyle{\\left \\Vert A\\right\\Vert =\\sup _{\\left \\Vert \\phi \\right\\Vert =\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle \\phi,A\\psi \\right\\rangle \\right\\vert.}$$
](A272900_1_En_7_Chapter_Eque.gif)

From this, we get

![
$$\\displaystyle\\begin{array}{rcl} \\left \\Vert {A}^{{\\ast}}\\right\\Vert & =& \\sup _{\\left \\Vert \\phi \\right\\Vert =\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle \\phi,{A}^{{\\ast}}\\psi \\right\\rangle \\right\\vert {}\\\\ & =& \\sup _{\\left \\Vert \\phi \\right\\Vert =\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle A\\phi,\\psi \\right\\rangle \\right\\vert {}\\\\ & =& \\sup _{\\left \\Vert \\phi \\right\\Vert =\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle \\psi,A\\phi \\right\\rangle \\right\\vert {}\\\\ & =& \\left \\Vert A\\right\\Vert. {}\\\\ \\end{array}$$
](A272900_1_En_7_Chapter_Equ4.gif)

Meanwhile, ![
$$\\left \\Vert {A}^{{\\ast}}A\\right\\Vert \\leq \\left \\Vert {A}^{{\\ast}}\\right\\Vert \\left \\Vert A\\right\\Vert ={ \\left \\Vert A\\right\\Vert }^{2}$$
](A272900_1_En_7_Chapter_IEq10.gif). On the other hand,

![
$$\\displaystyle\\begin{array}{rcl} \\left \\Vert {A}^{{\\ast}}A\\right\\Vert & =& \\sup _{\\left \\Vert \\phi \\right\\Vert =\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle \\phi,{A}^{{\\ast}}A\\psi \\right\\rangle \\right\\vert {}\\\\ & =& \\sup _{\\left \\Vert \\phi \\right\\Vert =\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle A\\phi,A\\psi \\right\\rangle \\right\\vert {}\\\\ & \\geq & \\sup _{\\left \\Vert \\psi \\right\\Vert =1}\\left \\vert \\left \\langle A\\psi,A\\psi \\right\\rangle \\right\\vert {}\\\\ & =&{ \\left \\Vert A\\right\\Vert }^{2}, {}\\\\ \\end{array}$$
](A272900_1_En_7_Chapter_Equ5.gif)

which establishes the inequality in the other order.

We now record an elementary but very useful result.

Proposition 7.3.

For all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq11.gif) , we have

![
$$\\displaystyle{{\\left \[\\mathrm{Range}\(A\)\\right\]}^{\\perp } =\\ker \({A}^{{\\ast}}\),}$$
](A272900_1_En_7_Chapter_Equf.gif)

where for any ![
$$B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq12.gif), ker (B) denotes the kernel of B.

Proof.

Suppose first that ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq05.gif) belongs to ![
$${\\left \[\\mathrm{Range}\(A\)\\right\]}^{\\perp }$$
](A272900_1_En_7_Chapter_IEq13.gif). Then for all  , we have

![
$$\\displaystyle{ 0 = \\left \\langle \\psi,A\\phi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\psi,\\phi \\right\\rangle. }$$
](A272900_1_En_7_Chapter_Equ6.gif)

(7.4)

This implies that ![
$$A^\\ast\\psi = 0$$
](A272900_1_En_7_Chapter_IEq07.gif) and thus that ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq08.gif) ∈ ker(A ∗). Conversely, suppose ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq09.gif) ∈ ker(A ∗). Then for all  , (7.4) holds (reading the equation from right to left). This shows that ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq011.gif) is orthogonal to every element of the form A ϕ, meaning that ![
$$\\psi \\in {\\left \[\\mathrm{Range}\(A\)\\right\]}^{\\perp }$$
](A272900_1_En_7_Chapter_IEq14.gif).

Next, we define the spectrum of a bounded operator, which plays the same role as the set of eigenvalues in the finite-dimensional case.

Definition 7.4.

For ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq15.gif), the resolvent set of A, denoted ρ(A) is the set of all ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq16.gif) such that the operator (A − λI) has a bounded inverse. The spectrum of A, denoted by σ(A), is the complement in ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq17.gif) of the resolvent set. For λ in the resolvent set of A, the operator (A − λI)− 1 is called the resolvent of A at λ.

Saying that (A − λI) has a bounded inverse means that there exists a bounded operator B such that

![
$$\\displaystyle{\(A -\\lambda I\)B = B\(A -\\lambda I\) = I.}$$
](A272900_1_En_7_Chapter_Equg.gif)

If A is bounded and A − λI is one-to-one and maps H onto H, then it follows from the closed graph theorem (Theorem A.39) that the inverse map must be bounded. Thus, the resolvent set of A can alternatively be described as the set of ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq18.gif) for which A − λI is one-to-one and onto.

Proposition 7.5.

For all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq19.gif) , the following results hold.

1.

The spectrum σ(A) of A is a closed, bounded, and nonempty subset of ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq20.gif).

2.

If ![
$$\\left \\vert \\lambda \\right\\vert > \\left \\Vert A\\right\\Vert$$
](A272900_1_En_7_Chapter_IEq21.gif) , then λ is in the resolvent set of A.

Lemma 7.6.

Suppose ![
$$X \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq22.gif) satisfies ![
$$\\left \\Vert X\\right\\Vert < 1$$
](A272900_1_En_7_Chapter_IEq23.gif) . Then the operator I − X is invertible, with the inverse given by the following convergent series in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq24.gif):

![
$$\\displaystyle{ {\(I - X\)}^{-1} = I + X + {X}^{2} + {X}^{3} + \\cdots }$$
](A272900_1_En_7_Chapter_Equ7.gif)

(7.5)

Proof.

As a consequence of (7.2), we have ![
$$\\left \\Vert {X}^{m}\\right\\Vert \\leq {\\left \\Vert X\\right\\Vert }^{m}$$
](A272900_1_En_7_Chapter_IEq25.gif). The (geometric) series on the right-hand side of (7.5) is therefore absolutely convergent and thus convergent in the Banach space ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq26.gif) (Appendix A.3.4). If we multiply this series on either side by (I − X), everything will cancel except I, showing that the sum of the series is the inverse of (I − X).

Proof of Proposition 7.5.

For any nonzero ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq27.gif), consider the operator

![
$$\\displaystyle{A -\\lambda I = -\\lambda \\left \(I -\\frac{A} {\\lambda } \\right\).}$$
](A272900_1_En_7_Chapter_Equh.gif)

If ![
$$\\left \\vert \\lambda \\right\\vert > \\left \\Vert A\\right\\Vert$$
](A272900_1_En_7_Chapter_IEq28.gif), then ![
$$\\left \\Vert A/\\lambda \\right\\Vert < 1$$
](A272900_1_En_7_Chapter_IEq29.gif), and I − A ∕ λ is invertible by the lemma. It then follows that A − λI is invertible, with

![
$$\\displaystyle{ {\(A -\\lambda I\)}^{-1} = -\\frac{1} {\\lambda } \\left \(I + \\frac{A} {\\lambda } +\\frac{A^2} {\\lambda^2} + \\cdots \\,\\right\). }$$
](A272900_1_En_7_Chapter_Equ8.gif)

(7.6)

Thus, λ is in the resolvent set of A. This establishes Point 2 in the proposition and shows that σ(A) is bounded.

Suppose now that ![
$$\\lambda _{0} \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq30.gif) is in the resolvent set of A. Then for another number ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq31.gif), we have

![
$$\\displaystyle\\begin{array}{rcl} A -\\lambda I& =& A -\\lambda _{0}I - \(\\lambda -\\lambda _{0}\)I \\\\ & =& \(A -\\lambda _{0}I\)\\left \(I - \(\\lambda -\\lambda _{0}\\right\){\(A -\\lambda _{0}I\)}^{-1}\).{}\\end{array}$$
](A272900_1_En_7_Chapter_Equ9.gif)

(7.7)

Thus, if

![
$$\\displaystyle{\\left \\vert \\lambda -\\lambda _{0}\\right\\vert < \\frac{1} {\\left \\Vert {\(A -\\lambda _{0}I\)}^{-1}\\right\\Vert },}$$
](A272900_1_En_7_Chapter_Equi.gif)

both factors on the right-hand side of (7.7) will be invertible, so that A − λI is also invertible. Thus, the resolvent set of A is open and the spectrum is closed.

To show that σ(A) is nonempty, note that A − λI may be computed as follows:

![
$$\\displaystyle\\begin{array}{rcl}{ \(A -\\lambda I\)}^{-1}& =& {\(I - \(\\lambda -\\lambda _{ 0}\){\(A -\\lambda _{0}I\)}^{-1}\)}^{-1}{\(A -\\lambda _{ 0}I\)}^{-1} \\\\ & =& \\left \(\\sum _{m=0}^{\\infty }{\(\\lambda -\\lambda _{ 0}\)}^{m}{\({\(A -\\lambda _{ 0}I\)}^{-1}\)}^{m}\\right\){\(A -\\lambda _{ 0}I\)}^{-1}.{}\\end{array}$$
](A272900_1_En_7_Chapter_Equ10.gif)

(7.8)

Thus, near any point λ 0 in the resolvent set of A, the resolvent (A − λI)− 1 can be computed by the locally convergent series (7.8) in powers of λ − λ 0, with the coefficients of the series being elements of ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq32.gif). For any  , the map

![
$$\\displaystyle{ \\lambda \\mapsto \\left \\langle \\phi,{\(A -\\lambda I\)}^{-1}\\psi \\right\\rangle }$$
](A272900_1_En_7_Chapter_Equ11.gif)

(7.9)

will be given by a locally convergent power series with coefficients in ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq33.gif), meaning that the function (7.9) is a holomorphic function on the resolvent set of A. Furthermore, from (7.6) we can see that ![
$$\\left \\Vert {\(A -\\lambda I\)}^{-1}\\right\\Vert$$
](A272900_1_En_7_Chapter_IEq34.gif) tends to zero as ![
$$\\left \\vert \\lambda \\right\\vert$$
](A272900_1_En_7_Chapter_IEq35.gif) tends to infinity, and so also does the right-hand side of (7.9).

If σ(A) were the empty set, the function (7.9) would be holomorphic on all of ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq36.gif) and tending to zero at infinity. By Liouville's theorem, the right-hand side of (7.9) would have to be identically zero for all ![
$$\\phi$$
](A272900_1_En_7_Chapter_IEq013.gif) and ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq014.gif), which would mean that (A − λI)− 1 is the zero operator. But since (A − λI)(A − λI)− 1 = I, the operator (A − λI)− 1 cannot be zero.

If ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_7_Chapter_IEq015.gif) for some ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq37.gif) and some nonzero  , then (A − λI) has a nonzero kernel and so λ is in the spectrum of A. Thus, any eigenvalue for A is contained in the spectrum of A. In the infinite-dimensional case, however, the converse is not true: A point in the spectrum may not be an eigenvalue for A. Nevertheless, for a bounded self-adjoint operator A, the spectrum of A may be described in a way that is not too far removed from what we have in the finite-dimensional case.

Proposition 7.7.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq38.gif) is self-adjoint, then the following results hold.

1.

The spectrum of A is contained in the real line.

2.

A number ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq39.gif) belongs to the spectrum of A if and only if there exists a sequence ![
$$\\psi_n$$
](A272900_1_En_7_Chapter_IEq017.gif) of nonzero vectors in H such that

![
$$\\displaystyle{ \\lim _{n\\rightarrow \\infty }\\frac{\\left \\Vert A\\psi _{n} -\\lambda \\psi _{n}\\right\\Vert } {\\left \\Vert \\psi _{n}\\right\\Vert } = 0. }$$
](A272900_1_En_7_Chapter_Equ12.gif)

(7.10)

Condition 2 in the proposition says that ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq40.gif) belongs to the spectrum if and only if λ is "almost an eigenvalue," meaning that there exists ![
$$\\psi \\neq 0$$
](A272900_1_En_7_Chapter_IEq018.gif) for which ![
$$A\\psi$$
](A272900_1_En_7_Chapter_IEq019.gif) is equal to ![
$$\\lambda\\psi$$
](A272900_1_En_7_Chapter_IEq020.gif) plus an error that is small compared to the size of ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq021.gif).

Lemma 7.8.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq41.gif) is self-adjoint, then for all ![
$$\\lambda = a + ib \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq42.gif) , we have

![
$$\\displaystyle{ \\left \\langle \(A -\\lambda I\)\\psi,\(A -\\lambda I\)\\psi \\right\\rangle \\geq {b}^{2}\\left \\langle \\psi,\\psi \\right\\rangle. }$$
](A272900_1_En_7_Chapter_Equ13.gif)

(7.11)

Proof.

We compute that

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \\langle \(A - \(a + ib\)I\)\\psi,\(A - \(a + ib\)I\)\\psi \\right\\rangle \\\\ & & = \\left \\langle \(A - aI\)\\psi,\(A - aI\)\\psi \\right\\rangle + ib\\left \\langle \\psi,\(A - aI\)\\psi \\right\\rangle \\\\ & & -ib\\left \\langle \(A - aI\)\\psi,\\psi \\right\\rangle + {b}^{2}\\left \\langle \\psi,\\psi \\right\\rangle. {}\\end{array}$$
](A272900_1_En_7_Chapter_Equ14.gif)

(7.12)

Since A is self-adjoint, so is A − aI, from which we see that the second and third terms on the right-hand side of (7.12) cancel, leaving us with

![
$$\\displaystyle{\\left \\langle \(A -\\lambda I\)\\psi,\(A -\\lambda I\)\\psi \\right\\rangle = \\left \\langle \(A - aI\)\\psi,\(A - aI\)\\psi \\right\\rangle + {b}^{2}\\left \\langle \\psi,\\psi \\right\\rangle,}$$
](A272900_1_En_7_Chapter_Equj.gif)

from which the desired inequality follows.

Proof of Proposition 7.7.

For Point 1, we need to show that any complex number λ = a \+ ib with b ≠ 0 belongs to the resolvent set of A. Since b ≠ 0, (7.11) shows that A − λI is injective. Meanwhile, by Proposition 7.3, ![
$$\\mathrm{Range}{\(A -\\lambda I\)}^{\\perp } =\\ker \(A -\\bar{\\lambda } I\)$$
](A272900_1_En_7_Chapter_IEq43.gif). Since ![
$$\\bar{\\lambda }$$
](A272900_1_En_7_Chapter_IEq44.gif) also has nonzero imaginary part, ![
$$A -\\bar{\\lambda } I$$
](A272900_1_En_7_Chapter_IEq45.gif) is injective, and so the range of A − λI is dense in H. To show that the range is all of H, consider any   and choose a sequence ![
$$\\phi_n = \(A - \\lambda I\)\\psi_n$$
](A272900_1_En_7_Chapter_IEq023.gif) in Range(A − λI) with ![
$$\\phi_n \\rightarrow \\phi$$
](A272900_1_En_7_Chapter_IEq024.gif). Applying (7.11) with ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq025.gif) replaced by ![
$$\\psi_n - \\psi_m$$
](A272900_1_En_7_Chapter_IEq026.gif) shows that ![
$$\\left \\langle \\psi _{n}\\right\\rangle$$
](A272900_1_En_7_Chapter_IEq46.gif) is a Cauchy sequence. Thus, ![
$$\\psi_n \\rightarrow \\psi$$
](A272900_1_En_7_Chapter_IEq027.gif) for some  . Since A is bounded,

![
$$\\displaystyle{\(A -\\lambda I\)\\psi =\\lim _{n\\rightarrow \\infty }\(A -\\lambda I\)\\psi _{n} =\\lim _{n\\rightarrow \\infty }\\phi _{n} =\\phi.}$$
](A272900_1_En_7_Chapter_Equk.gif)

We conclude, then, that A − λI is one-to-one and onto. The inverse operator (A − λI)− 1 is bounded, by (7.11) (or by the closed graph theorem).

For Point 2, assume there exists a sequence as in (7.10), and suppose that A − λI had an inverse. Letting ![
$$\\phi _{n} = {\(A -\\lambda I\)}\\psi _{n}$$
](A272900_1_En_7_Chapter_IEq047.gif), we have ![
$$\\psi _{n} = {\(A -\\lambda I\)}^{-1}\\phi _{n}$$
](A272900_1_En_7_Chapter_IEq47.gif) and so (7.10) says that

![
$$\\displaystyle{\\lim _{n\\rightarrow \\infty } \\frac{\\left \\Vert \\phi _{n}\\right\\Vert } {\\left \\Vert {\(A -\\lambda I\)}^{-1}\\phi _{n}\\right\\Vert } = 0,}$$
](A272900_1_En_7_Chapter_Equl.gif)

which shows that (A − λI)− 1 is actually unbounded. Thus, A − λI cannot have a bounded inverse.

Conversely, if, for some ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq48.gif), no such sequence exists, then there exists some ![
$$\\varepsilon > 0$$
](A272900_1_En_7_Chapter_IEq49.gif) such that

![
$$\\displaystyle{ \\left \\Vert \(A -\\lambda I\)\\psi \\right\\Vert \\geq \\varepsilon \\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_7_Chapter_Equ15.gif)

(7.13)

for all  . Then A − λI is injective and Proposition 7.3 tells us that the range of the self-adjoint operator A − λI is dense in H. Arguing as in the preceding paragraphs with (7.13) in place of (7.11), we can see that the range of A − λI is also closed, hence all of H. This shows that A − λI has an inverse.

Example 7.9.

Let H = L 2([0, 1]) and let A be the operator on H defined by

![
$$\\displaystyle{\(A\\psi \)\(x\) = x\\psi \(x\).}$$
](A272900_1_En_7_Chapter_Equm.gif)

Then this operator is bounded and self-adjoint, and its spectrum is given by

![
$$\\displaystyle{\\sigma \(A\) = \[0,1\].}$$
](A272900_1_En_7_Chapter_Equn.gif)

As we have already noted in Sect.​ 6.​1, the operator A does not have any (true) eigenvectors.

Proof.

It is apparent that ![
$$\\left \\Vert A\\psi \\right\\Vert \\leq \\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_7_Chapter_IEq50.gif) and that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_7_Chapter_IEq51.gif) for all  , so that A is bounded and self-adjoint. Given λ ∈ (0, 1), consider the functions ![
$$\\psi_n := 1 _{\[\\lambda\\lambda+1/n\]}$$
](A272900_1_En_7_Chapter_IEq031.gif), which satisfy ![
$${\\left \\Vert \\psi _{n}\\right\\Vert }^{2} = 1/n$$
](A272900_1_En_7_Chapter_IEq52.gif). On the other hand, since ![
$$\\left \\vert x-\\lambda \\right\\vert \\leq 1/n$$
](A272900_1_En_7_Chapter_IEq53.gif) on [λ, λ \+ 1 ∕ n], we have

![
$$\\displaystyle{{\\left \\Vert \(A -\\lambda I\)\\psi _{n}\\right\\Vert }^{2} \\leq 1/{n}^{3}.}$$
](A272900_1_En_7_Chapter_Equo.gif)

Thus, by Proposition 7.7, λ belongs to the spectrum of A. Since this holds for all λ ∈ (0, 1) and the spectrum of A is closed, ![
$$\\sigma \(A\) \\supset \[0,1\]$$
](A272900_1_En_7_Chapter_IEq54.gif).

Meanwhile, if ![
$$\\lambda \\notin \[0,1\]$$
](A272900_1_En_7_Chapter_IEq55.gif), then the function 1 ∕ (x − λ) is bounded on [0, 1], and so A − λI has a bounded inverse, consisting of multiplication by 1 ∕ (x − λ). Thus, σ(A) = [0, 1].

## 7.2 Spectral Theorem for Bounded Self-Adjoint Operators, I

### 7.2.1 Spectral Subspaces

Given a bounded (for now) self-adjoint operator A, we hope to associate with each Borel set E ⊂ σ(A) a closed subspace V E of H, where we think intuitively that V E is the closed span of the generalized eigenvectors for A with eigenvalues in E. [We could do this more generally for any ![
$$E \\subset \\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq56.gif), but we do not expect any contribution from ![
$$\\mathbb{R}\\setminus \\sigma \(A\)$$
](A272900_1_En_7_Chapter_IEq57.gif).] We would expect the collection of these subspaces to have the following properties.

1.

V σ(A) = H and ![
$$V _{\\varnothing } =\\{ 0\\}$$
](A272900_1_En_7_Chapter_IEq58.gif).

2.

If E and F are disjoint, then V E ⊥ V F .

3.

For any E and F, ![
$$V _{E\\cap F} = V _{E} \\cap V _{F}$$
](A272900_1_En_7_Chapter_IEq59.gif).

4.

If E 1, E 2,... are disjoint and E = ∪ j E j , then

![
$$\\displaystyle{V _{E} = \\bigoplus \\limits _{j}V _{E_{j}}.}$$
](A272900_1_En_7_Chapter_Equp.gif)

5.

For any E, V E is invariant under A.

6.

If ![
$$E \\subset \[\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \]$$
](A272900_1_En_7_Chapter_IEq60.gif) and ![
$$\\psi \\in V_E$$
](A272900_1_En_7_Chapter_IEq032.gif), then

![
$$\\displaystyle{\\left \\Vert \(A -\\lambda _{0}I\)\\psi \\right\\Vert \\leq \\varepsilon \\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_7_Chapter_Equq.gif)

The condition V σ(A) = H captures the idea that our generalized eigenvectors should span H, while Property 2 captures the idea that our generalized eigenvectors should have some sort of orthogonality for distinct eigenvalues, even if they are not actually in the Hilbert space. In Property 4, there may be infinitely many of the E j 's, in which case, the direct sum is in the Hilbert space sense (Definition A.45). Properties 5 and 6 capture the idea that V E is made up of generalized eigenvectors for A with eigenvalues in E.

### 7.2.2 Projection-Valued Measures

It is convenient to describe closed subspaces of a Hilbert space H in terms of the associated orthogonal projection operators. Recall (Proposition A.57) that, given a closed subspace V of H, there exists a unique bounded operator P that equals the identity on V and equals zero on the orthogonal complement V ⊥ of V. This operator is called the orthogonal projection onto V and satisfies P 2 = P and P ∗ = P. The following definition expresses the first four properties of our spectral subspaces—the ones that do not involve the operator A—in terms of the corresponding orthogonal projections. Since those properties are similar to those of a measure, we use the term projection-valued measure.

Definition 7.10.

Let X be a set and Ω a σ-algebra in X. A map ![
$$\\mu : \\Omega \\rightarrow \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq61.gif) is called a projection-valued measure if the following properties are satisfied.

1.

For each E ∈Ω, μ(E) is an orthogonal projection.

2.

![
$$\\mu \(\\varnothing \) = 0$$
](A272900_1_En_7_Chapter_IEq62.gif) and μ(X) = I.

3.

If ![
$$E_{1},E_{2},E_{3},\\ldots$$
](A272900_1_En_7_Chapter_IEq63.gif) in Ω are disjoint, then for all v ∈ H, we have

![
$$\\displaystyle{\\mu \\left \(\\bigcup \\limits _{j=1}^{\\infty }E_{ j}\\right\)v =\\sum _{ j=1}^{\\infty }\\mu \(E_{ j}\)v,}$$
](A272900_1_En_7_Chapter_Equr.gif)

where the convergence of the sum is in the norm topology on H.

4.

For all E 1, E 2 ∈ Ω, we have ![
$$\\mu \(E_{1} \\cap E_{2}\) =\\mu \(E_{1}\)\\mu \(E_{2}\)$$
](A272900_1_En_7_Chapter_IEq64.gif).

Note that if E 1 and E 2 are disjoint, then Properties 2 and 4 tell us that μ(E 1)μ(E 2) = 0, from which it follows (Exercise 10) that the range of μ(E 1) and the range of μ(E 2) are perpendicular. It is then not hard to verify that μ(E 1)μ(E 2) is the projection onto the intersection of the ranges of μ(E 1) and μ(E 2) (Exercise 11). Thus, if we define, for each E ∈ Ω, a closed subspace V E : = Range(μ(E)), then the collection of V E 's satisfy the first four properties that we anticipated for spectral subspaces.

In the next subsection, we will associate a projection-valued measure μ A with each bounded self-adjoint operator A. In that case, the projection μ A (E) will be thought of as a projection onto the spectral subspace corresponding to E. We are about to introduce the notion of operator-valued integration with respect to a projection-valued measure. In the case of the projection-valued measure μ A associated with A, this operator-valued integral will be the functional calculus for A.

Observe that, for any projection-valued measure μ and  , we can form an ordinary (positive) real-valued measure ![
$$\\mu_\\psi$$
](A272900_1_En_7_Chapter_IEq034.gif) by setting

![
$$\\displaystyle{ \\mu _{\\psi }\(E\) = \\left \\langle \\psi,\\mu \(E\)\\psi \\right\\rangle }$$
](A272900_1_En_7_Chapter_Equ16.gif)

(7.14)

for all E ∈ Ω. This observation provides a link between integration with respect to a projection-valued measure and integration with respect to an ordinary measure.

Proposition 7.11 (Operator-Valued Integration).

Let Ω be a σ-alge- bra in a set X and let ![
$$\\mu : \\Omega \\rightarrow \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq65.gif) be a projection-valued measure. Then there exists a unique linear map, denoted f↦∫ Ω f dμ, from the space of bounded, measurable, complex-valued functions on Ω into ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq66.gif) with the property that

![
$$\\displaystyle{ \\left \\langle \\psi,\\left \(\\int _{X}f\\ d\\mu \\right\)\\psi \\right\\rangle =\\int _{X}f\\ d\\mu _{\\psi } }$$
](A272900_1_En_7_Chapter_Equ17.gif)

(7.15)

for all f and all ![
$$\\psi \\in \\bf{H}$$
](A272900_1_En_7_Chapter_IEq035.gif), ![
$$\\mu_\\psi$$
](A272900_1_En_7_Chapter_IEq036.gif) (7.14) . This integral has the following additional properties.

1.

For all E ∈ Ω, we have

![
$$\\displaystyle{\\int _{X}1_{E}\\ d\\mu =\\mu \(E\).}$$
](A272900_1_En_7_Chapter_Equs.gif)

In particular, the integral of the constant function 1 is I.

2.

For all f, we have

![
$$\\displaystyle{ \\left \\Vert \\int _{X}f\\ d\\mu \\right\\Vert \\leq \\sup _{\\lambda \\in X}\\left \\vert f\(\\lambda \)\\right\\vert. }$$
](A272900_1_En_7_Chapter_Equ18.gif)

(7.16)

3.

Integration is multiplicative : For all f and g, we have

![
$$\\displaystyle{ \\int _{X}fg\\ d\\mu = \\left \(\\int _{X}f\\ d\\mu \\right\)\\left \(\\int _{X}g\\ d\\mu \\right\). }$$
](A272900_1_En_7_Chapter_Equ19.gif)

(7.17)

4.

For all f, we have

![
$$\\displaystyle{\\int _{X}\\bar{f}\\ d\\mu ={ \\left \(\\int _{X}f\\ d\\mu \\right\)}^{{\\ast}}.}$$
](A272900_1_En_7_Chapter_Equt.gif)

In particular, if f is real-valued, then ∫ X f dμ is self-adjoint.

By Property 1 and linearity, integration with respect to μ has the expected behavior on simple functions. It then follows from Property 2 that the integral of an arbitrary bounded measurable function f can be computed as follows. Take a sequence s n of simple functions converging uniformly to f; the integral of f is then the limit, in the operator norm topology, of the integral of the s n 's.

Although the multiplicative property of the integral may seem surprising at first, observe that for any E 1, E 2 ∈ Ω, Property 3 in Definition 7.10 tells us that

![
$$\\displaystyle\\begin{array}{rcl} \\left \(\\int _{X}1_{E_{1}}\\ d\\mu \\right\)\\left \(\\int _{X}1_{E_{2}}\\ d\\mu \\right\)& =& \\mu \(E_{1}\)\\mu \(E_{2}\) =\\mu \(E_{1} \\cap E_{2}\) {}\\\\ & =& \\int _{X}1_{E_{1}} \\cdot 1_{E_{2}}\\ d\\mu. {}\\\\ \\end{array}$$
](A272900_1_En_7_Chapter_Equ20.gif)

Thus, multiplicativity of the integral at the level of indicator functions is built into the definition of a projection-valued measure.

If one wanted to make a real-valued measure for which the corresponding integral was multiplicative, then since ![
$$1_{E} \\cdot 1_{E} = 1_{E}$$
](A272900_1_En_7_Chapter_IEq67.gif), the integral of 1 E —namely, μ(E)—would have to satisfy μ(E)2 = μ(E). This would mean that μ(E) is 0 or 1 for all E. For such measures, one would indeed obtain multiplicativity of the integral, but measures with this property are not very interesting. For operator-valued measures, we can have interesting examples where the integral is multiplicative, simply because there are many more idempotents (elements A with A 2 = A) in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq68.gif) than in ![
$$\\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq69.gif).

Proof of Proposition 7.11.

Given a projection-valued measure μ and a bounded measurable function f on X, define a map ![
$$Q_{f} : \\mathbf{H} \\rightarrow \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq70.gif) by

![
$$\\displaystyle{Q_{f}\(\\psi \) =\\int _{X}f\\ d\\mu _{\\psi },}$$
](A272900_1_En_7_Chapter_Equu.gif)

where ![
$$\\mu_\\psi$$
](A272900_1_En_7_Chapter_IEq037.gif) is given by (7.14). If f is an indicator function, then ![
$$Q_{f}\(\\psi \) = \\left \\langle \\psi,\\mu \(E\)\\psi \\right\\rangle$$
](A272900_1_En_7_Chapter_IEq71.gif) is a bounded quadratic form. (See Definition A.60.) It is straightforward to show, passing from indicator functions to simple functions and then to general functions, that for any bounded measurable f, Q f is a bounded quadratic form, with

![
$$\\displaystyle{ \\left \\vert Q_{f}\(\\psi \)\\right\\vert \\leq \\left \(\\sup _{\\lambda \\in X}\\vert f\(\\lambda \)\\vert \\right\){\\left \\Vert \\psi \\right\\Vert }^{2}. }$$
](A272900_1_En_7_Chapter_Equ21.gif)

(7.18)

It then follows from Proposition A.63 that there is a unique bounded operator A f such that

![
$$\\displaystyle{Q_{f}\(\\psi \) = \\left \\langle \\psi,A_{f}\\psi \\right\\rangle }$$
](A272900_1_En_7_Chapter_Equv.gif)

for all  . We set ∫ X f dμ = A f . From the way A f is defined, it satisfies (7.15). The uniqueness of the linear map ![
$$f\\mapsto \\int _{X}f\\ d\\mu$$
](A272900_1_En_7_Chapter_IEq72.gif) follows from the uniqueness in Proposition A.63.

If f = 1 E , then ![
$$Q_{f}\(\\psi \) =\\mu _{\\psi }\(E\) = \\left \\langle \\psi,\\mu \(E\)\\psi \\right\\rangle$$
](A272900_1_En_7_Chapter_IEq73.gif), in which case the unique associated operator A f is μ(E). This establishes Property 1. Property 2 follows from (7.18).

For Property 3, we have already observed that multiplicativity of the integral, at the level of indicator functions, is built into the definition of a projection-valued measure. Since both sides of (7.17) are bilinear in ![
$$\\phi, \\psi$$
](A272900_1_En_7_Chapter_IEq0056.gif), we have (7.17) for simple functions. Using Property 2, we can then obtain (7.17) for all bounded measurable functions by taking limits.

Finally, if f is real valued, then ![
$$Q_f\(\\psi\)$$
](A272900_1_En_7_Chapter_IEq039.gif) will be real for all  . Thus, by Proposition A.63, the associated operator A f will be self-adjoint. Property 4 then follows by linearity.

### 7.2.3 The Spectral Theorem

We are ready to state one version of the spectral theorem for bounded self-adjoint operators.

Theorem 7.12 (Spectral Theorem, First Form).

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq74.gif) is self-adjoint, then there exists a unique projection-valued measure μ A on the Borel σ-algebra in σ(A), with values in projections on H , such that

![
$$\\displaystyle{ \\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A. }$$
](A272900_1_En_7_Chapter_Equ22.gif)

(7.19)

Since the spectrum σ(A) of A is bounded, the function f(λ) : = λ is bounded on σ(A). The proof of this theorem is given in Chap.​ 8.

Definition 7.13 (Functional Calculus).

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq75.gif) is self-adjoint and ![
$$f :\\sigma \(A\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq76.gif) is a bounded measurable function, define an operator f(A) by setting

![
$$\\displaystyle{f\(A\) =\\int _{\\sigma \(A\)}f\(\\lambda \)\\ {d\\mu }^{A}\(\\lambda \),}$$
](A272900_1_En_7_Chapter_Equw.gif)

where μ A is the projection-valued measure in Theorem 7.12.

We may extend the projection-valued measure μ A from σ(A) to all of ![
$$\\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq77.gif) by assigning measure 0 to ![
$$\\mathbb{R} \\setminus \\sigma \(A\)$$
](A272900_1_En_7_Chapter_IEq78.gif). Then, roughly speaking, f(A) is the operator that is equal to f(λ)I on the range of the projection operator μ A ([λ, λ \+ d λ)).

Since the integral with respect to μ A is multiplicative, it follows from (7.19) that if f(λ) = λ m for some positive integer m, then f(A) is the mth power of A. Further, since the series ![
$${e}^{a\\lambda } =\\sum _{ m=0}^{\\infty }{\(a\\lambda \)}^{m}/m!$$
](A272900_1_En_7_Chapter_IEq79.gif) converges uniformly on the compact set σ(A), the operator e aA (computed using the functional calculus for the function f(λ) = e a λ ) may be computed as a power series.

Definition 7.14 (Spectral Subspaces).

For ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq80.gif), let μ A be the associated projection-valued measure, extended to be a measure on ![
$$\\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq81.gif) by setting ![
$${\\mu }^{A}\(\\mathbb{R} \\setminus \\sigma \(A\)\) = 0$$
](A272900_1_En_7_Chapter_IEq82.gif). Then for each Borel set ![
$$E \\subset \\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq83.gif), define the spectral subspace V E of H by

![
$$\\displaystyle{V _{E} =\\mathrm{ Range}{\(\\mu }^{A}\(E\)\).}$$
](A272900_1_En_7_Chapter_Equx.gif)

The definition of a projection-valued measure implies that these spectral subspaces satisfy the first four properties listed in Sect. 7.2.1. We now show that (7.19) implies the remaining two properties we anticipated for the spectral subspaces.

Proposition 7.15.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq84.gif) is self-adjoint, the spectral subspaces associated with A have the following properties.

1.

Each spectral subspace V E is invariant under A.

2.

If ![
$$E \\subset \[\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \]$$
](A272900_1_En_7_Chapter_IEq85.gif) then for all ![
$$\\psi \\in V_E$$
](A272900_1_En_7_Chapter_IEq041.gif) , we have

![
$$\\displaystyle{\\left \\Vert \(A -\\lambda _{0}I\)\\psi \\right\\Vert \\leq \\varepsilon \\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_7_Chapter_Equy.gif)

3.

The spectrum of ![
$$\\left.A\\right\\vert _{V _{E}}$$
](A272900_1_En_7_Chapter_IEq86.gif) is contained in the closure of E.

4.

If λ 0 is in the spectrum of A, then for every neighborhood U of λ 0 , we have V U ≠ {0}, or, equivalently, μ(U) ≠ 0.

Proof.

For Point 1, observe that for any bounded measurable functions f and g on σ(A), the operators f(A) and g(A) commute, since the product in either order is equal to the integral of the function fg = gf with respect to μ A . In particular, A, which is the integral of the function f(λ) = λ, commutes with μ A (E), which is the integral of the function 1 E . Thus, given a vector μ A (E)![
$$\\phi$$
](A272900_1_En_7_Chapter_IEq042.gif) in the range of μ A (E), we have

![
$$\\displaystyle{{A\\mu }^{A}\(E\)\\phi {=\\mu }^{A}\(E\)A\\phi,}$$
](A272900_1_En_7_Chapter_Equz.gif)

which is again in the range of μ A (E), establishing the invariance of the spectral subspace.

For Point 2, suppose that ![
$$\\psi \\in V_E$$
](A272900_1_En_7_Chapter_IEq043.gif), where ![
$$E \\subset \[\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \]$$
](A272900_1_En_7_Chapter_IEq87.gif). Then ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq044.gif) is in the range of μ A (E), and so

![
$$\\displaystyle{\(A -\\lambda _{0}I\)\\psi = {\(A -\\lambda _{0}I\)\\mu }^{A}\(E\)\\psi.}$$
](A272900_1_En_7_Chapter_Equaa.gif)

But μ A (E) = 1 E (A) and A − λ 0 I = f(A), where f(λ) = λ − λ 0. By the multiplicativity of the integral, then,

![
$$\\displaystyle{\(A -\\lambda _{0}I\)\\psi = \(f1_{E}\)\(A\)\\psi.}$$
](A272900_1_En_7_Chapter_Equab.gif)

But ![
$$\\left \\vert f\(\\lambda \)1_{E}\(\\lambda \)\\right\\vert \\leq \\varepsilon$$
](A272900_1_En_7_Chapter_IEq88.gif) and so by (7.16), the operator (f1 E )(A) has norm at most ![
$$\\varepsilon$$
](A272900_1_En_7_Chapter_IEq89.gif).

For Point 3, if λ 0 is not in ![
$$\\bar{E}$$
](A272900_1_En_7_Chapter_IEq90.gif), then the function ![
$$g\(\\lambda \) := 1_{E}\(\\lambda \)\(1/\(\\lambda -\\lambda _{0}\)\)$$
](A272900_1_En_7_Chapter_IEq91.gif) is bounded. Thus, g(A) is a bounded operator and

![
$$\\displaystyle{g\(A\)\(A -\\lambda _{0}I\) = \(A -\\lambda _{0}I\)g\(A\) = 1_{E}\(A\).}$$
](A272900_1_En_7_Chapter_Equac.gif)

This shows that the restriction to V E of g(A) is the inverse of the restriction to V E of A. Thus, λ 0 is not in the spectrum of ![
$$\\left.A\\right\\vert _{V _{E}}$$
](A272900_1_En_7_Chapter_IEq92.gif).

For Point 4, fix λ 0 ∈ σ(A) and suppose for some ![
$$\\varepsilon > 0$$
](A272900_1_En_7_Chapter_IEq93.gif), we have ![
$$\\mu \(\(\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \)\) = 0$$
](A272900_1_En_7_Chapter_IEq94.gif). Consider, then, the bounded function f defined by

![
$$\\displaystyle{f\(\\lambda \) = \\left \\{\\begin{array}{ccc} \\frac{1} {\\lambda -\\lambda _{0}} & & \\left \\vert \\lambda -\\lambda _{0}\\right\\vert \\geq \\varepsilon \\\\ 0 &&\\left \\vert \\lambda -\\lambda _{0}\\right\\vert <\\varepsilon \\end{array} \\right..}$$
](A272900_1_En_7_Chapter_Equad.gif)

Since f(λ) ⋅(λ − λ 0) equals 1 except on ![
$$\(\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \)$$
](A272900_1_En_7_Chapter_IEq95.gif), the equation f(λ) ⋅(λ − λ 0) = 1 holds μ-almost everywhere. Thus, the integral of this function coincides with the integral of the constant function 1, which is I. Since the integral is multiplicative, we see that

![
$$\\displaystyle{f\(A\)\(A -\\lambda _{0}I\) = \(A -\\lambda _{0}I\)f\(A\) = I,}$$
](A272900_1_En_7_Chapter_Equae.gif)

showing that the bounded operator f(A) is the inverse of (A − λ 0 I). This contradicts the assumption that λ 0 ∈ σ(A).

Proposition 7.16.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq96.gif) is self-adjoint and ![
$$B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq97.gif) commutes with A, the following results hold.

1.

For all bounded measurable functions f on σ(A), the operator f(A) commutes with B.

2.

Each spectral subspace for A is invariant under B.

The proof of this proposition is deferred until Chap.​ 8. We conclude this section by fulfilling (at least for bounded self-adjoint operators) one of the goals of the spectral theorem, namely to give a probability measure describing the probabilities for measurements of a self-adjoint operator A in the state ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq045.gif).

Proposition 7.17.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq98.gif) is self-adjoint and ![
$$\\psi \\in \\bf{H}$$
](A272900_1_En_7_Chapter_IEq046.gif) is a unit vector. Then there exists a unique probability measure ![
$$\\mu_{\\psi}^{A}$$
](A272900_1_En_7_Chapter_IEq0047.gif) on ![
$$\\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq99.gif) such that

![
$$\\displaystyle{\\int {_{\\mathbb{R}}\\lambda }^{m}\\ d\\mu _{\\psi }^{A}\(\\lambda \) = \\left \\langle \\psi,{A}^{m}\\psi \\right\\rangle }$$
](A272900_1_En_7_Chapter_Equaf.gif)

for all non-negative integers m.

We will prove a version of Proposition 7.17 for unbounded self-adjoint operators in Chap.​ 9. In the unbounded case, however, we will not obtain uniqueness of the probability measure, even if ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq048.gif) is in the domain of A m for all m. Even in the unbounded case, however, the spectral theorem provides a canonical choice of the probability measure.

Proof.

We define a measure ![
$$\\mu_{\\psi}^{A}$$
](A272900_1_En_7_Chapter_IEq049.gif) on σ(A) as in Sect. 7.2.2 by

![
$$\\displaystyle{\\mu _{\\psi }^{A}\(E\) = \\left \\langle \\psi {,\\mu }^{A}\(E\)\\psi \\right\\rangle.}$$
](A272900_1_En_7_Chapter_Equag.gif)

The properties of integration with respect to μ A then tell us that

![
$$\\displaystyle{\\left \\langle \\psi,{A}^{m}\\psi \\right\\rangle = \\left \\langle \\psi,\\left \(\\int {_{\\sigma \(A\)}\\lambda }^{m}\\ {d\\mu }^{A}\(\\lambda \)\\right\)\\psi \\right\\rangle =\\int { _{\\sigma \(A\)}\\lambda }^{m}\\ d\\mu _{\\psi }^{A}\(\\lambda \).}$$
](A272900_1_En_7_Chapter_Equah.gif)

We then extend ![
$$\\mu_{\\psi}^{A}$$
](A272900_1_En_7_Chapter_IEq050.gif) to ![
$$\\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq100.gif) by setting it equal to zero on ![
$$\\mathbb{R}\\setminus \\sigma \(A\)$$
](A272900_1_En_7_Chapter_IEq101.gif), establishing the existence of the desired probability measure on ![
$$\\mathbb{R}$$
](A272900_1_En_7_Chapter_IEq102.gif). Since

![
$$\\displaystyle{\\left \\vert \\left \\langle \\psi,{A}^{m}\\psi \\right\\rangle \\right\\vert \\leq {\\left \\Vert \\psi \\right\\Vert }^{2}\\left \\Vert {A}^{m}\\right\\Vert \\leq {\\left \\Vert \\psi \\right\\Vert }^{2}{\\left \\Vert A\\right\\Vert }^{m},}$$
](A272900_1_En_7_Chapter_Equai.gif)

the moments grow only exponentially with m. Thus, standard uniqueness results for the moment problem (e.g., Theorem 8.1 in Chap.​ 4 of [18]) give the uniqueness of ![
$$\\mu_{\\psi}^{A}$$
](A272900_1_En_7_Chapter_IEq051.gif).

## 7.3 Spectral Theorem for Bounded Self-Adjoint Operators, II

As we have already noted in Sect.​ 6.​5, one version of the spectral theorem asserts that every self-adjoint operator is unitarily equivalent to a multiplication operator. In the case of a bounded self-adjoint operator A, on a separable Hilbert space H, this result means that A is unitarily equivalent to the operator M h on L 2(X, μ), where (X, μ) is a σ-finite measure space, h is a measurable, real-valued function, and M h is the operator of multiplication by h:

![
$$\\displaystyle{\(M_{h}\\psi \)\(\\lambda \) = h\(\\lambda \)\\psi \(\\lambda \).}$$
](A272900_1_En_7_Chapter_Equaj.gif)

Although the "multiplication operator" form of the spectral theorem (Theorem 7.20) has the advantage of being easy to state, there is an even better version involving the concept of a direct integral. It is straightforward to extend the notion of an L 2 space to an L 2 space with values in a Hilbert space H. In a direct integral, we extend the concept one step further, by allowing the Hilbert space to depend on the point. We begin with a measure space (X, μ) and then have one Hilbert space H λ for each λ in X. An element of the direct integral is a function s on X such that s(λ) belongs to H λ for each λ ∈ X. Given a real-valued measurable function h on X, it makes sense to multiply an element s of the direct integral by h.

The direct integral form of the spectral theorem says a bounded self-adjoint operator A is unitarily equivalent to a multiplication operator on a direct integral. By extending multiplication operators to the more general setting of direct integrals (instead of just ordinary L 2 spaces), we gain several benefits. First, the set X and the function h become canonical: The set X is simply the spectrum of A and the function h is simply h(λ) = λ. Second, the direct integral approach carries with it a notion of "generalized eigenvectors," since the space H λ can be thought of as the space of generalized eigenvectors with eigenvalue λ. (The spaces H λ are not, in general, contained in the direct integral Hilbert space. Thus, direct integrals give a rigorous meaning to the idea of "eigenvectors" that are not in the Hilbert space on which the operator acts.) Third, the direct integral approach gives a simple way to classify self-adjoint operators up to unitary equivalence: Two self-adjoint operators are unitarily equivalent if and only if their direct integral representations are equivalent in a natural sense (Proposition 7.24).

If one really wants the simplicity of the (ordinary) multiplication operator version of the spectral theorem, it is a simple matter to prove this result using precisely the same methods as in the proof of the direct integral version. (See Theorem 7.20.) Nevertheless, the direct integral version is, arguably, the most definitive version of the spectral theorem for a single self-adjoint operator.

We turn now to the definition of a direct integral. Suppose μ is a σ-finite measure on a σ-algebra Ω of sets in X. Suppose also that for each λ ∈ X, we have a separable Hilbert space H λ with inner product ![
$$\\left \\langle \\cdot,\\cdot \\right\\rangle _{\\lambda }$$
](A272900_1_En_7_Chapter_IEq103.gif). We want to define the direct integral of the H λ 's with respect to μ. Elements of the direct integral will be sections s, meaning that s is a function on X with values in the union of the H λ 's, having the property that

![
$$\\displaystyle{s\(\\lambda \) \\in \\mathbf{H}_{\\lambda }}$$
](A272900_1_En_7_Chapter_Equak.gif)

for each λ in X. We would like to define the norm of a section s by the formula

![
$$\\displaystyle{{\\left \\Vert s\\right\\Vert }^{2} =\\int _{ X}\\left \\langle s\(\\lambda \),s\(\\lambda \)\\right\\rangle _{\\lambda }d\\mu \(\\lambda \),}$$
](A272900_1_En_7_Chapter_Equal.gif)

provided that the integral on the right-hand side is finite. The inner product of two sections s 1 and s 2 (with finite norm) should then be given by the formula

![
$$\\displaystyle{\\left \\langle s_{1},s_{2}\\right\\rangle :=\\int _{X}\\left \\langle s_{1}\(\\lambda \),s_{2}\(\\lambda \)\\right\\rangle _{\\lambda }d\\mu \(\\lambda \).}$$
](A272900_1_En_7_Chapter_Equam.gif)

The problem with this description of the norm and inner product on the direct integral is that we have not said anything about measurability. As things stand, it does not make sense to ask whether a section s is measurable, since the space in which s(λ) takes its values is different for each λ. We must, therefore, introduce some additional structure that gives rise to a notion of measurability. (The measurability issue is a technicality that can be ignored on a first reading.)

One way to address the measurability issue is to choose a simultaneous orthonormal basis for each of the Hilbert spaces H λ . To deal with the possibility that different spaces can have different dimensions, we slightly modify the concept of an orthonormal basis. We say that a family {e j } of vectors is an orthonormal basis for a Hilbert space H if ![
$$\\left \\langle e_{j},e_{k}\\right\\rangle = 0$$
](A272900_1_En_7_Chapter_IEq104.gif) for j ≠ k, the norm of each e j is either 0 or 1, and the closure of the span of the e j 's is all of H. This just means that we allow some of the vectors in our basis to be zero, with the nonzero vectors forming an orthonormal basis in the usual sense.

We now define a simultaneous orthonormal basis for a family {H λ } of separable Hilbert spaces to be a collection ![
$$\\{e_{j}\(\\cdot \)\\}_{j=1}^{\\infty }$$
](A272900_1_En_7_Chapter_IEq105.gif) of sections with the property that for each λ, ![
$$\\{e_{j}\(\\lambda \)\\}_{j=1}^{\\infty }$$
](A272900_1_En_7_Chapter_IEq106.gif) is an orthonormal basis for H λ . Provided that the function ![
$$\\lambda \\mapsto \\dim \\mathbf{H}_{\\lambda }$$
](A272900_1_En_7_Chapter_IEq107.gif) is a measurable function from X into [0, ∞], it is possible to choose a simultaneous orthonormal basis {e j ( ⋅ )} such that ![
$$\\left \\langle e_{j}\(\\lambda \),e_{k}\(\\lambda \)\\right\\rangle$$
](A272900_1_En_7_Chapter_IEq108.gif) is measurable for all j and k. Having chosen a simultaneous orthonormal basis with this property, we define a section s to be measurable if the function

![
$$\\displaystyle{\\lambda \\mapsto \\left \\langle e_{j}\(\\lambda \),s\(\\lambda \)\\right\\rangle _{\\lambda }}$$
](A272900_1_En_7_Chapter_Equan.gif)

is a measurable complex-valued function for each j. Our assumption on the e j 's means that the e j 's themselves are measurable sections.

We refer to a choice of simultaneous orthonormal basis, chosen so that ![
$$\\left \\langle e_{j}\(\\lambda \),e_{k}\(\\lambda \)\\right\\rangle$$
](A272900_1_En_7_Chapter_IEq109.gif) is measurable, as a measurability structure on the collection of H λ 's. Given two measurable sections s 1 and s 2, the function

![
$$\\displaystyle{\\lambda \\mapsto \\left \\langle s_{1}\(\\lambda \),s_{2}\(\\lambda \)\\right\\rangle _{\\lambda } =\\sum _{ j=1}^{\\infty }\\left \\langle s_{ 1}\(\\lambda \),e_{j}\(\\lambda \)\\right\\rangle _{\\lambda }\\left \\langle e_{j}\(\\lambda \),s_{2}\(\\lambda \)\\right\\rangle _{\\lambda }}$$
](A272900_1_En_7_Chapter_Equao.gif)

is also measurable.

Definition 7.18.

Suppose the following structures are given: (1) a σ-finite measure space (X, Ω, μ), (2) a collection {H λ } λ ∈ X of separable Hilbert spaces for which the dimension function is measurable, and (3) a measurability structure on {H λ } λ ∈ X . Then the direct integral of the H λ 's with respect to μ, denoted

![
$$\\displaystyle{\\int _{X}^{\\oplus }\\mathbf{H}_{\\lambda }\\ d\\mu \(\\lambda \),}$$
](A272900_1_En_7_Chapter_Equap.gif)

is the space of equivalence classes of almost-everywhere-equal measurable sections s for which

![
$$\\displaystyle{{\\left \\Vert s\\right\\Vert }^{2} :=\\int _{ X}\\left \\langle s\(\\lambda \),s\(\\lambda \)\\right\\rangle _{\\lambda }\\ d\\mu \(\\lambda \) < \\infty.}$$
](A272900_1_En_7_Chapter_Equaq.gif)

The inner product ![
$$\\left \\langle s_{1},s_{2}\\right\\rangle$$
](A272900_1_En_7_Chapter_IEq110.gif) of two such sections s 1 and s 2 is given by the formula

![
$$\\displaystyle{\\left \\langle s_{1},s_{2}\\right\\rangle :=\\int _{X}\\left \\langle s_{1}\(\\lambda \),s_{2}\(\\lambda \)\\right\\rangle _{\\lambda }\\ d\\mu \(\\lambda \).}$$
](A272900_1_En_7_Chapter_Equar.gif)

To see that the integral defining the inner product of two finite-norm sections is finite, note that ![
$$\\left \\vert \\left \\langle s_{1}\(\\lambda \),s_{2}\(\\lambda \)\\right\\rangle _{\\lambda }\\right\\vert \\leq \\left \\Vert s_{1}\(\\lambda \)\\right\\Vert _{\\lambda }\\left \\Vert s_{2}\(\\lambda \)\\right\\Vert _{\\lambda }$$
](A272900_1_En_7_Chapter_IEq111.gif). By assumption, ![
$$\\left \\Vert s_{j}\(\\lambda \)\\right\\Vert _{\\lambda }$$
](A272900_1_En_7_Chapter_IEq112.gif) is a square-integrable function of λ for j = 1, 2, and the product of two square-integrable functions is integrable. Thus, the integrand in the definition of ![
$$\\left \\langle s_{1},s_{2}\\right\\rangle$$
](A272900_1_En_7_Chapter_IEq113.gif) is also integrable. It is not hard to show, using an argument similar to the proof of completeness of L 2 spaces, that a direct integral of Hilbert spaces is a Hilbert space.

Let us think of two important special cases of the direct integral construction. First, if each of the H λ 's is simply ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq114.gif), then the direct integral (with the obvious measurability structure) is simply L 2(X, μ). Second, suppose that X = {λ 1, λ 2,...} is countable, Ω is the σ-algebra of all subsets of X, and μ is the counting measure on X. Then the direct integral is the Hilbert space direct sum (Definition A.45).

Given a direct integral, suppose we have some λ 0 ∈ X for which {λ 0} is measurable and such that c : = μ({λ 0}) > 0. Then we can embed ![
$$\\mathbf{H}_{\\lambda _{0}}$$
](A272900_1_En_7_Chapter_IEq115.gif) isometrically into the direct integral by mapping each ![
$$\\psi \\in \\mathbf{H}_{\\lambda _{0}}$$
](A272900_1_En_7_Chapter_IEq116.gif) to the section s given by

![
$$\\displaystyle{s\(\\lambda \) = \\left \\{\\begin{array}{c} \\frac{1} {\\sqrt{c}}\\psi,\\quad \\lambda =\\lambda _{0} \\\\ 0,\\quad \\lambda \\neq \\lambda _{0} \\end{array}.\\right.}$$
](A272900_1_En_7_Chapter_Equas.gif)

Even if μ({λ 0}) = 0, we may still think that ![
$$\\mathbf{H}_{\\lambda _{0}}$$
](A272900_1_En_7_Chapter_IEq117.gif) is a sort of "generalized subspace" of the direct integral.

Theorem 7.19 (Spectral Theorem, Second Form).

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq118.gif) is self-adjoint, then there exists a σ-finite measure μ on σ(A), a direct integral

![
$$\\displaystyle{\\int _{\\sigma \(A\)}^{\\oplus }\\mathbf{H}_{\\lambda }\\ d\\mu \(\\lambda \),}$$
](A272900_1_En_7_Chapter_Equat.gif)

and a unitary map U between H and the direct integral such that

![
$$\\displaystyle{ \\left \[UA{U}^{-1}\(s\)\\right\]\(\\lambda \) =\\lambda s\(\\lambda \) }$$
](A272900_1_En_7_Chapter_Equ23.gif)

(7.20)

for all sections s in the direct integral.

The proof of Theorem 7.19 is given in the next chapter, along with the proof of our first version of the spectral theorem. In the meantime, let us think about what this version of the spectral theorem is saying. We may think that the unitary map U is an identification of our original Hilbert space H with a certain direct integral over the spectrum of A. Under this identification, the self-adjoint operator A becomes the operator of multiplication by λ, that is, the map sending the section s(λ) to λ s(λ). Roughly speaking, then, the operator A acts (under our identification) as λI on each space H λ . Thus, we may think of H λ as being something like an "eigenspace" for A, for each element λ of the spectrum of A. Of course, unless μ({λ}) > 0, the Hilbert space H λ is not actually contained in H. Nevertheless, we may think of elements of a given H λ as "generalized eigenvectors" for the operator A.

The direct integral formulation of the spectral theorem leads readily to a classification result for bounded self-adjoint operators. See Proposition 7.24 later in this section. Meanwhile, as we noted earlier in this section, the method of proof for Theorem 7.19 also yields a version of the spectral theorem involving multiplication operators on ordinary L 2 spaces.

Theorem 7.20 (Spectral​ Theorem, Multiplication​ Operator​ Form).

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq119.gif) is self-adjoint. Then there exists a σ-finite measure space (X,μ), a bounded, measurable, real-valued function h on X, and a unitary map U : H → L 2 (X,μ) such that

![
$$\\displaystyle{\[UA{U}^{-1}\(\\psi \)\]\(\\lambda \) = h\(\\lambda \)\\psi \(\\lambda \)}$$
](A272900_1_En_7_Chapter_Equau.gif)

for all ![
$$\\psi$$
](A272900_1_En_7_Chapter_IEq052.gif) ∈ L 2 (X,μ).

We return now to a discussion of the direct integral version of the spectral theorem. This version gives a simple description of the functional calculus.

Proposition 7.21.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq120.gif) is self-adjoint and U is a unitary map as in Theorem 7.19 . Then for any bounded measurable function f on σ(A), we have

![
$$\\displaystyle{\[Uf\(A\){U}^{-1}\(s\)\]\(\\lambda \) = f\(\\lambda \)s\(\\lambda \).}$$
](A272900_1_En_7_Chapter_Equav.gif)

Thus, roughly speaking, f(A) is defined to be f(λ)I on each "generalized eigenspace" H λ . Proposition 7.21 follows directly from (7.20) if f is a polynomial; the result for continuous f then follows by taking uniform limits. The result for general f is then easily established by using the limiting arguments of Chap.​ 8, especially Exercise 3.

Let us now consider what sort of uniqueness there should be in the second version of the spectral theorem. There is a "trivial" source of nonuniqueness coming from the possibility that some of the H λ 's may have dimension 0. Let E 0 denote the set of λ for which ![
$$\\dim \\mathbf{H}_{\\lambda } = 0$$
](A272900_1_En_7_Chapter_IEq121.gif). Even if μ(E 0) > 0, the set E 0 makes no contribution to the norm of a section, since every section is automatically zero on E 0. Thus, we may define a new measure ![
$$\\tilde{\\mu }$$
](A272900_1_En_7_Chapter_IEq122.gif) by setting ![
$$\\tilde{\\mu }\(E\) =\\mu \(E \\cap E_{0}^{c}\)$$
](A272900_1_En_7_Chapter_IEq123.gif), so that ![
$$\\tilde{\\mu }$$
](A272900_1_En_7_Chapter_IEq124.gif) agrees with μ on E 0 c but is zero on E 0. Then the direct integrals of the H λ 's with respect to μ and with respect to ![
$$\\tilde{\\mu }$$
](A272900_1_En_7_Chapter_IEq125.gif) are "indistinguishable." Thus, we can always modify a direct integral so as to assume that ![
$$\\dim \\mathbf{H}_{\\lambda } > 0$$
](A272900_1_En_7_Chapter_IEq126.gif) for almost every λ.

Meanwhile, unlike the projection-valued measure μ A in Theorem 7.12, the measure μ in Theorem 7.19 is not unique, but only unique up to equivalence, where two σ-finite measures on a given measurable space are equivalent if they have precisely the same sets of measure zero. For a given measure μ, the Hilbert spaces H λ are unique only up to unitary equivalence, meaning that only the dimension of the spaces is uniquely determined. Even the dimension of H λ is uniquely determined only up to a set of μ-measure zero. As it turns out, the sources of nonuniqueness in this paragraph and the previous paragraph are all that exist.

Proposition 7.22 (Uniqueness in Theorem 7.19).

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq127.gif) is self-adjoint and consider two different direct integrals as in Theorem 7.19 , one with measure μ (1) and Hilbert spaces H λ (1) and the other with measure μ (2) and Hilbert spaces H λ (2) . If ![
$$\\dim \\mathbf{H}_{\\lambda }^{\(j\)} > 0$$
](A272900_1_En_7_Chapter_IEq128.gif) for μ (j) -almost every λ (j = 1,2), then μ (1) and μ (2) are mutually absolutely continuous and

![
$$\\displaystyle{\\dim \\mathbf{H}_{\\lambda }^{\(1\)} =\\dim \\mathbf{H}_{\\lambda }^{\(2\)}}$$
](A272900_1_En_7_Chapter_Equaw.gif)

for μ (j) -almost every λ (j = 1,2).

See the end of the next chapter for a sketch of the proof of this uniqueness result.

Theorem 7.19 should be thought of as a refinement of our earlier form (Theorem 7.12) of the spectral theorem, in the sense that we can easily recover Theorem 7.12 from Theorem 7.19. In the setting of Theorem 7.19, and given a measurable set E ⊂ σ(A), let V E denote the space of (equivalence classes) of sections s that are supported on E, that is, for which s(λ) = 0 for μ-almost every λ in E c . This is easily seen to be a closed subspace. Let P E denote the orthogonal projection onto V E , and define

![
$$\\displaystyle{{ \\mu }^{A}\(E\) = {U}^{-1}P_{ E}U. }$$
](A272900_1_En_7_Chapter_Equ24.gif)

(7.21)

It is straightforward to check that μ A is a projection-valued measure on σ(A), with values in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq129.gif), and that ![
$$\\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A$$
](A272900_1_En_7_Chapter_IEq130.gif).

Note that both versions of the spectral theorem for A involve a measure, the first, denoted μ A , being a projection-valued measure, and the second, denoted μ, being an ordinary measure with values in the non-negative real numbers. The following result shows the relationship between the two measures.

Proposition 7.23.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq131.gif) is self-adjoint, μ A is the projection-valued measure given by Theorem 7.12 and μ is a real-valued measure as in Theorem 7.19 . If ![
$$\\dim \\mathbf{H}_{\\lambda } > 0$$
](A272900_1_En_7_Chapter_IEq132.gif) for μ-almost every λ, then for any Borel set E ⊂σ(A), μ A (E) = 0 if and only if μ(E) = 0.

Of course, the 0 in the expression μ A (E) = 0 is the zero operator, whereas the 0 in the expression μ(E) = 0 is the number 0. Nevertheless, we may think of Proposition 7.23 as saying that μ A and μ are equivalent in the usual measure-theoretic sense, having precisely the same sets of measure zero.

Proof.

As we have remarked, given a direct integral as in Theorem 7.19, we can construct a projection-valued measure by means of (7.21), and this projection-valued measure satisfies ![
$$\\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A$$
](A272900_1_En_7_Chapter_IEq133.gif). This projection-valued measure must coincide with the one in Theorem 7.12, by the uniqueness in that theorem.

Now, if μ(E) = 0, then any section supported on E is zero almost everywhere and thus represents the zero element of the direct integral. In that case, V E = 0 and so μ A (E) = 0 by (7.21). In the other direction, suppose μ(E) > 0. Since μ is σ-finite, E will contain a measurable subset F such that 0 < μ(F) < ∞. Then let s be the section given by

![
$$\\displaystyle{s\(\\lambda \) =\\sum _{ j=1}^{\\infty } \\frac{1} {{2}^{j}}e_{j}\(\\lambda \)}$$
](A272900_1_En_7_Chapter_Equax.gif)

for λ ∈ F and s(λ) = 0 for λ ∈ F c , where ![
$$\\left \\{e_{j}\(\\cdot \)\\right\\}$$
](A272900_1_En_7_Chapter_IEq134.gif) is our measurability structure for the direct integral. Then

![
$$\\displaystyle{\\left \\langle s\(\\lambda \),e_{j}\(\\lambda \)\\right\\rangle _{\\lambda } = \\frac{1} {{2}^{j}}\\left \\langle e_{j}\(\\lambda \),e_{j}\(\\lambda \)\\right\\rangle _{\\lambda }1_{F}\(\\lambda \),}$$
](A272900_1_En_7_Chapter_Equay.gif)

which is a measurable function of λ for all j, so that s is measurable. Since we assume that H λ has nonzero dimension for μ-almost every λ, s will be nonzero almost everywhere on F and thus will have positive norm. The norm of s is finite because ![
$$\\left \\Vert s\(\\lambda \)\\right\\Vert \\leq 1$$
](A272900_1_En_7_Chapter_IEq135.gif) and F has finite measure. Thus, V E ≠ 0 and μ A (E) ≠ 0.

We say that self-adjoint operators A 1 and A 2 on Hilbert spaces H 1 and H 2 are unitarily equivalent if there exists a unitary map U : H 1 → H 2 such that

![
$$\\displaystyle{A_{2} = UA_{1}{U}^{-1}.}$$
](A272900_1_En_7_Chapter_Equaz.gif)

Using Proposition 7.22, we can give a classification of bounded self-adjoint operators on separable Hilbert spaces up to unitary equivalence. For a given bounded self-adjoint operator A, we call the function ![
$$\\lambda \\mapsto \\dim \\mathbf{H}_{\\lambda }$$
](A272900_1_En_7_Chapter_IEq136.gif) the multiplicity function for A. It is well defined (independent of the choice of direct integral decomposition) up to a set of measure zero. It turns out that bounded self-adjoint operators are characterized, up to unitary equivalence, by the spectrum of A as a set, the equivalence class of the measure μ in Theorem 7.19, and the multiplicity function.

Proposition 7.24.

Suppose A 1 and A 2 are bounded self-adjoint operators on separable Hilbert spaces H 1 and H 2 , respectively. Choose direct integral representations for A 1 and A 2 as in Theorem 7.19 , with the associated measures μ 1 and μ 2 chosen so that ![
$$\\dim \\mathbf{H}_{\\lambda } > 0$$
](A272900_1_En_7_Chapter_IEq137.gif) for μ j -almost every λ (j = 1,2). Then A 1 and A 2 are unitarily equivalent if and only if the following conditions are satisfied.

1.

σ(A 1 ) = σ(A 2).

2.

The measures μ 1 and μ 2 are mutually absolutely continuous.

3.

The multiplicity functions of A 1 and A 2 coincide up to a set of measure zero.

See Exercise 12 for a proof of this result.

## 7.4 Exercises

1.

Suppose A and B are commuting linear operators on a nonzero finite-dimensional vector space.

(a)

Show that each eigenspace for A is invariant under B.

(b)

Show that A and B have at least one simultaneous eigenvector, that is, a nonzero vector v with Av = λ v and Bv = μ v, for some constants ![
$$\\lambda,\\mu \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq138.gif).

2.

Suppose that ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq139.gif) is normal, meaning that AA ∗ = A ∗ A. Suppose that for some   and ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq140.gif) we have ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_7_Chapter_IEq054.gif). Show that ![
$${A}^{{\\ast}}\\psi =\\bar{\\lambda }\\psi$$
](A272900_1_En_7_Chapter_IEq141.gif).

Hint: Compute ![
$$\\left \\Vert \({A}^{{\\ast}}-\\bar{\\lambda }\)\\psi \\right\\Vert$$
](A272900_1_En_7_Chapter_IEq142.gif).

3.

Suppose a closed subspace V of H is invariant under a bounded operator A, meaning that ![
$$A\\psi \\in V$$
](A272900_1_En_7_Chapter_IEq055.gif) for all ![
$$\\psi \\in V$$
](A272900_1_En_7_Chapter_IEq056.gif). Show that the orthogonal complement V ⊥ of V is invariant under A ∗.

4.

(a)

Suppose that H is a finite-dimensional Hilbert space over ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq143.gif) and A is a normal linear operator on H in the sense of Exercise 2. Show that there exists an orthonormal basis for V consisting of simultaneous eigenvectors for A and A ∗.

Hint: Use Exercises 1 and 3.

(b)

Suppose A is a linear operator on a finite-dimensional Hilbert space H over ![
$$\\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq144.gif) and suppose there exists an orthonormal basis for V consisting of eigenvectors of A. Show that A commutes with A ∗.

5.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq145.gif) has an inverse A − 1 in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq146.gif). Show that ![
$${\({A}^{-1}\)}^{{\\ast}}{A}^{{\\ast}} = {A}^{{\\ast}}{\({A}^{-1}\)}^{{\\ast}} = I$$
](A272900_1_En_7_Chapter_IEq147.gif). Conclude that A ∗ is invertible and ![
$${\({A}^{{\\ast}}\)}^{-1}={\({A}^{-1}\)}^{{\\ast}}$$
](A272900_1_En_7_Chapter_IEq148.gif).

6.

Suppose U is a unitary operator on H (Definition A.55). Show that the spectrum of U is contained in the unit circle.

Hint: By writing U − λI as (− λ)(I − U ∕ λ) or as U(I − λ U − 1), show that any λ with ![
$$\\left \\vert \\lambda \\right\\vert \\neq 1$$
](A272900_1_En_7_Chapter_IEq149.gif) is in the resolvent set of λ.

7.

Suppose that ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq150.gif) is self-adjoint and non-negative, that is, that A satisfies (7.3). Show that the spectrum of A is contained in the interval [0, ∞).

Note: Conversely, if ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq151.gif) is self-adjoint and ![
$$\\sigma \(A\) \\subset \[0,\\infty \)$$
](A272900_1_En_7_Chapter_IEq152.gif), then A is non-negative. See Exercise 2 in Chap.​ 8.

8.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq153.gif) is invertible. Show that there exists ![
$$\\varepsilon > 0$$
](A272900_1_En_7_Chapter_IEq154.gif) such that for all ![
$$B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq155.gif) with ![
$$\\left \\Vert B - A\\right\\Vert <\\varepsilon$$
](A272900_1_En_7_Chapter_IEq156.gif), B is also invertible.

Hint: Use a power series argument as in the proof of Proposition 7.5.

9.

Assume ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_7_Chapter_IEq157.gif) is self-adjoint.

(a)

Suppose ![
$$\\lambda _{0} \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq158.gif) is a point in the resolvent set of A. Show that

![
$$\\displaystyle{\\left \\Vert {\(A -\\lambda _{0}I\)}^{-1}\\right\\Vert = \\frac{1} {d\(\\lambda _{0},\\sigma \(A\)\)},}$$
](A272900_1_En_7_Chapter_Equba.gif)

where ![
$$d\(\\lambda _{0},\\sigma \(A\)\) =\\inf _{\\lambda \\in \\sigma \(A\)}\\left \\vert \\lambda -\\lambda _{0}\\right\\vert$$
](A272900_1_En_7_Chapter_IEq159.gif).

Hint: Think of (A − λ 0 I)− 1 as a function of A in the sense of the functional calculus for A.

(b)

Given ![
$$\\lambda _{0} \\in \\mathbb{C}$$
](A272900_1_En_7_Chapter_IEq160.gif), suppose that there exists some nonzero   such that

![
$$\\displaystyle{\\left \\Vert A\\psi -\\lambda _{0}\\psi \\right\\Vert <\\varepsilon \\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_7_Chapter_Equbb.gif)

Show that there exists ![
$$\\lambda \\in \\sigma \(A\)$$
](A272900_1_En_7_Chapter_IEq161.gif) such that ![
$$\\left \\vert \\lambda -\\lambda _{0}\\right\\vert <\\varepsilon$$
](A272900_1_En_7_Chapter_IEq162.gif).

10.

Suppose V 1 and V 2 are two closed subspaces of H, with associated orthogonal projections P 1 and P 2. Show that V 1 and V 2 are orthogonal if and only if P 1 P 2 = 0.

11.

Suppose μ is a projection-valued measure on (X, Ω). Show that for any E 1, E 2 ∈ Ω, μ(E 1)μ(E 2) is the projection onto the closed subspace ![
$$\\mathrm{Range}\(\\mu \(E_{1}\)\) \\cap \\mathrm{ Range}\(\\mu \(E_{2}\)\)$$
](A272900_1_En_7_Chapter_IEq163.gif).

Hint: Write E 1 as ![
$$E_{1} = \(E_{1} \\cap E_{2}\) \\cup \(E_{1}\\setminus E_{2}\)$$
](A272900_1_En_7_Chapter_IEq164.gif) and use Exercise 10.

12.

Prove Proposition 7.24.

Hint: Use Proposition 7.22 and the Radon–Nikodym theorem (Theorem A.6).

References

[18].

A. Gut, Probability: A Graduate Course (Springer, New York, 2005)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_8

© Springer Science+Business Media New York 2013

# 8. The Spectral Theorem for Bounded Self-Adjoint Operators: Proofs

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In this chapter we give proofs of all versions of the spectral theorem stated in the previous chapter.

In this chapter we give proofs of all versions of the spectral theorem stated in the previous chapter.

## 8.1 Proof of the Spectral Theorem, First Version

A proof of the spectral theorem, in its projection-valued measure form, can be obtained in two main stages. The first stage of the proof is to define a continuous functional calculus, meaning we associate with each continuous function f on σ(A) an operator f(A). The map ![
$$f\\mapsto f\(A\)$$
](A272900_1_En_8_Chapter_IEq1.gif) should have the property that if f is the function f(λ) = λ m , then f(A) = A m . The continuous functional calculus is then constructed by approximating continuous functions on σ(A) by polynomials. The Stone–Weierstrass theorem tells us that polynomials are dense in the continuous functions on σ(A); it remains only to show that if a sequence p n of polynomials converges uniformly to some continuous function f on σ(A), then the operators p n (A) converge to some operator, which we will then call f(A).

The second stage of the proof is to show that the continuous functional calculus can be represented as integration against a projection-valued measure. This result is just an operator-valued version of the Riesz representation theorem from measure theory (Theorem 8.5). Indeed, we will see that this operator-valued version of the Riesz representation theorem can be reduced to the usual form of the theorem.

### 8.1.1 Stage 1: The Continuous Functional Calculus

We begin by defining, for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq2.gif), the spectral radius R(A) by

![
$$\\displaystyle{R\(A\) =\\sup _{\\lambda \\in \\sigma \(A\)}\\left \\vert \\lambda \\right\\vert.}$$
](A272900_1_En_8_Chapter_Equa.gif)

(By Propositions 7.5 and 7.7, σ(A) is a nonempty, bounded subset of ![
$$\\mathbb{R}$$
](A272900_1_En_8_Chapter_IEq3.gif).) According to Point 2 of Proposition 7.5, we have

![
$$\\displaystyle{R\(A\) \\leq \\left \\Vert A\\right\\Vert }$$
](A272900_1_En_8_Chapter_Equb.gif)

for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq4.gif). In general, ![
$$\\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq5.gif) can be much bigger than R(A). For example, if A is a nilpotent matrix, then R(A) = 0 but ![
$$\\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq6.gif) can be arbitrarily large.

Lemma 8.1.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq7.gif) is self-adjoint, the norm and the spectral radius of A are equal:

![
$$\\displaystyle{\\left \\Vert A\\right\\Vert = R\(A\).}$$
](A272900_1_En_8_Chapter_Equc.gif)

In preparation for the proof, we determine the radius of convergence of the power series for the resolvent given in the proof of Proposition 7.5. According to Proposition 7.2, we have

![
$$\\displaystyle{\\left \\Vert {A}^{{\\ast}}A\\right\\Vert ={ \\left \\Vert A\\right\\Vert }^{2}}$$
](A272900_1_En_8_Chapter_Equd.gif)

for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq8.gif). If A is self-adjoint, we obtain

![
$$\\displaystyle{\\left \\Vert {A}^{2}\\right\\Vert ={ \\left \\Vert A\\right\\Vert }^{2}.}$$
](A272900_1_En_8_Chapter_Eque.gif)

Iterating this relation gives

![
$$\\displaystyle{ \\left \\Vert {A}^{{2}^{n} }\\right\\Vert ={ \\left \\Vert A\\right\\Vert }^{{2}^{n} } }$$
](A272900_1_En_8_Chapter_Equ1.gif)

(8.1)

for all n.

Consider, for a bounded self-adjoint operator A, the following formal expression for the resolvent of A:

![
$$\\displaystyle\\begin{array}{rcl}{ \(A -\\lambda I\)}^{-1}& =& -\\frac{1} {\\lambda }{ \\left \(I -\\frac{A} {\\lambda } \\right\)}^{-1} \\\\ & =& -\\sum \\limits_{m=0}^{\\infty }\\frac{{A}^{m}} {\\lambda ^{m+1}}.{}\\end{array}$$
](A272900_1_En_8_Chapter_Equ2.gif)

(8.2)

If ![
$$\\left \\vert \\lambda \\right\\vert > \\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq9.gif), then the proof of Proposition 7.5 shows that the series (8.2) converges in the operator norm topology and that the sum of the series is indeed the inverse of (A − λI). If, on the other hand, ![
$$\\left \\vert \\lambda \\right\\vert \\leq \\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq10.gif), it follows from (8.1) that the norms of the terms in (8.2) do not tend to zero, and so the series cannot converge in the operator norm topology. We may say, then, that the series (8.2) has radius of convergence equal to ![
$$\\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq11.gif).

Proof of Lemma 8.1.

We know that ![
$$R\(A\) \\leq \\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq12.gif). To show that ![
$$R\(A\) = \\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq13.gif), we wish to argue that ![
$${\(A -\\lambda I\)}^{-1}$$
](A272900_1_En_8_Chapter_IEq14.gif) is a holomorphic operator-valued function of λ on the set ![
$$\\left \\vert \\lambda \\right\\vert > R\(A\)$$
](A272900_1_En_8_Chapter_IEq15.gif), and therefore the Laurent series of ![
$${\(A -\\lambda I\)}^{-1}$$
](A272900_1_En_8_Chapter_IEq16.gif) must converge for ![
$$\\left \\vert \\lambda \\right\\vert > R\(A\)$$
](A272900_1_En_8_Chapter_IEq17.gif). But the Laurent series of ![
$${\(A -\\lambda I\)}^{-1}$$
](A272900_1_En_8_Chapter_IEq18.gif) is just the series in (8.2), and we have shown that the series diverges when ![
$$\\left \\vert \\lambda \\right\\vert \\leq \\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq19.gif). This would be a contradiction if R(A) were less than ![
$$\\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq20.gif).

To flesh out the argument, recall the formula (7.​8) in the proof of Proposition 7.5 for the resolvent of A.

That formula expresses the map ![
$$\\lambda \\mapsto {\(A -\\lambda I\)}^{-1}$$
](A272900_1_En_8_Chapter_IEq21.gif) as a convergent power series in powers of λ − λ 0, near any point λ 0 in the resolvent set of A. It follows that for any bounded linear functional ![
$$\\xi \\in \\mathcal{B}{\(\\mathbf{H}\)}^{{\\ast}}$$
](A272900_1_En_8_Chapter_IEq22.gif), the complex-valued function

![
$$\\displaystyle{\\lambda \\mapsto \\xi \({\(A -\\lambda I\)}^{-1}\)}$$
](A272900_1_En_8_Chapter_Equf.gif)

is holomorphic on the resolvent set of A. This function has a unique Laurent series, which is given by applying ξ term by term to (8.2). The series will converge on the largest annulus contained in the resolvent set of A, namely the set of λ with ![
$$\\left \\vert \\lambda \\right\\vert > R\(A\)$$
](A272900_1_En_8_Chapter_IEq23.gif).

Convergence of (8.2) means that ![
$$\\left \\vert \\xi \({A}^{m}{/\\lambda }^{m+1}\)\\right\\vert$$
](A272900_1_En_8_Chapter_IEq24.gif) is bounded as function of m, for each ξ and each λ with ![
$$\\left \\vert \\lambda \\right\\vert > R\(A\)$$
](A272900_1_En_8_Chapter_IEq25.gif). Thus, by (a corollary of) the uniform boundedness principle (Appendix A.3.4), the set ![
$$\\{{A}^{m}{/\\lambda }^{m+1}\\}_{m=0}^{\\infty }$$
](A272900_1_En_8_Chapter_IEq26.gif) is bounded in the Banach space ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq27.gif), for all λ with ![
$$\\left \\vert \\lambda \\right\\vert > R\(A\)$$
](A272900_1_En_8_Chapter_IEq28.gif). In particular, for each λ with ![
$$\\left \\vert \\lambda \\right\\vert > R\(A\)$$
](A272900_1_En_8_Chapter_IEq29.gif), there is a constant C such that

![
$$\\displaystyle{\\frac{\\left \\Vert {A}^{{2}^{n} }\\right\\Vert } {{\\left \\vert \\lambda \\right\\vert }^{{2}^{n} }} = \\frac{{\\left \\Vert A\\right\\Vert }^{{2}^{n} }} {{\\left \\vert \\lambda \\right\\vert }^{{2}^{n} }} \\leq C.}$$
](A272900_1_En_8_Chapter_Equg.gif)

If ![
$$\\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq30.gif) were greater than R(A), this inequality would be false for λ satisfying ![
$$R\(A\) < \\left \\vert \\lambda \\right\\vert < \\left \\Vert A\\right\\Vert$$
](A272900_1_En_8_Chapter_IEq31.gif).

The next key step in Stage 1 of the proof is to understand how the spectrum of a self-adjoint operator transforms under application of a polynomial.

Lemma 8.2 (Spectral Mapping Theorem).

For all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq32.gif) and all polynomials p, we have

![
$$\\displaystyle{\\sigma \(p\(A\)\) = p\(\\sigma \(A\)\).}$$
](A272900_1_En_8_Chapter_Equh.gif)

That is to say, the spectrum of p(A) consists precisely of the numbers of the form p(λ), with λ in the spectrum of A.

Proof.

The result is trivial if p is constant. When deg p ≥ 1, let p given by

![
$$\\displaystyle{p\(z\) = a_{n}{z}^{n} + a_{ n-1}{z}^{n-1} + \\cdots + a_{ 0}}$$
](A272900_1_En_8_Chapter_Equi.gif)

be an arbitrary polynomial. We first show that ![
$$p\(\\sigma \(A\)\) \\subset \\sigma \(p\(A\)\)$$
](A272900_1_En_8_Chapter_IEq33.gif). Suppose, then, that λ ∈ σ(A). Observe that

![
$$\\displaystyle{p\(A\) - p\(\\lambda \)I = a_{n}\({A}^{n} {-\\lambda }^{n}I\) + a_{ n-1}\({A}^{n-1} {-\\lambda }^{n-1}I\) + \\cdots + a_{ 0}I - a_{0}I.}$$
](A272900_1_En_8_Chapter_Equj.gif)

Now,

![
$$\\displaystyle{{A}^{k} {-\\lambda }^{k}I = \(A -\\lambda I\)\({A}^{k-1} +\\lambda {A}^{k-2} {+\\lambda }^{2}{A}^{k-3} + \\cdots {+\\lambda }^{k-1}I\).}$$
](A272900_1_En_8_Chapter_Equk.gif)

Thus, we can pull out a factor of (A − λI) from each nonzero term in p(A) − p(λ)I, giving

![
$$\\displaystyle{p\(A\) - p\(\\lambda \)I = \(A -\\lambda I\)q\(A\)}$$
](A272900_1_En_8_Chapter_Equl.gif)

where q is a polynomial (depending on λ). Since, by assumption, A − λI is not invertible, and since (A − λI) commutes with q(A), (A − λI)q(A) cannot be invertible (Exercise 1). This shows that p(λ) belongs to the spectrum of p(A).

We now show that σ(p(A)) ⊂ p(σ(A)). Suppose, then, that γ ∈ σ(p(A)). Since ![
$$\\mathbb{C}$$
](A272900_1_En_8_Chapter_IEq34.gif) is algebraically closed, we can factor the polynomial p(z) − γ, as a function of z, as

![
$$\\displaystyle{ p\(z\)-\\gamma = c\(z - b_{1}\)\(z - b_{2}\)\\cdots \(z - b_{n}\). }$$
](A272900_1_En_8_Chapter_Equ3.gif)

(8.3)

Thus,

![
$$\\displaystyle{p\(A\) -\\gamma I = c\(A - b_{1}I\)\(A - b_{2}I\)\\cdots \(A - b_{n}I\).}$$
](A272900_1_En_8_Chapter_Equm.gif)

Since p(A) − γ I is assumed to be noninvertible, there must be some j such that (A − b j I) is noninvertible, that is, for which b j ∈ σ(A). Then (8.3) tells us that ![
$$p\(b_{j}\)-\\gamma = 0$$
](A272900_1_En_8_Chapter_IEq35.gif), meaning that γ = p(b j ). Thus, γ is of the form p(λ) for some λ ( = b j ) in σ(A).

The last step in Stage 1 of our proof is to apply the Stone–Weierstrass theorem to show that polynomials are dense in ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq36.gif) (the space of continuous, real-valued functions on σ(A)) with respect to the supremum norm.

Proposition 8.3.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq37.gif) is self-adjoint. Then there exists a unique bounded linear map from ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq38.gif) into ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq39.gif) , denoted by ![
$$f\\mapsto f\(A\)$$
](A272900_1_En_8_Chapter_IEq40.gif) , such that when f(λ) = λ m , we have f(A) = A m . The map ![
$$f\\mapsto f\(A\)$$
](A272900_1_En_8_Chapter_IEq41.gif), ![
$$f \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq42.gif) , is called the (real-valued) functional calculus for A.

Proof.

Note that if A is self-adjoint, then p(A) is self-adjoint provided that p is a real-valued polynomial (i.e., one where all the coefficients are real numbers). Thus, combining the spectral mapping theorem with the equality of the norm and spectral radius, we have the following: If A is a self-adjoint operator and p is a real-valued polynomial, then

![
$$\\displaystyle{ \\left \\Vert p\(A\)\\right\\Vert =\\sup _{\\lambda \\in \\sigma \(A\)}\\left \\vert p\(\\lambda \)\\right\\vert. }$$
](A272900_1_En_8_Chapter_Equ4.gif)

(8.4)

Thus, the map p → p(A) is an isometric linear map from the space of polynomials on σ(A) (with the supremum norm) into the space of bounded operators on H.

According to the Stone–Weierstrass theorem polynomials are dense in ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq43.gif). Thus, by the BLT theorem (Theorem A.36), we can extend the map ![
$$p\\mapsto p\(A\)$$
](A272900_1_En_8_Chapter_IEq44.gif) uniquely to a bounded linear map of ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq45.gif) into ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq46.gif).

Proposition 8.4.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq47.gif) is self-adjoint, the (real-valued) continuous functional calculus for A, mapping ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq48.gif) into ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq49.gif) , has the following properties.

1.

Multiplicativity: For all f,g, we have

![
$$\\displaystyle{\(fg\)\(A\) = f\(A\)g\(A\),}$$
](A272900_1_En_8_Chapter_Equn.gif)

where fg denotes the pointwise product of f and g.

2.

Self-adjointness: For all f, the operator f(A) is self-adjoint.

3.

Non-negativity: For all f, if f is non-negative, then f(A) is a non-negative operator.

4.

Norm and spectrum properties: For all f, we have

![
$$\\displaystyle{ \\left \\Vert f\(A\)\\right\\Vert =\\sup _{\\lambda \\in \\sigma \(A\)}\\left \\vert f\(\\lambda \)\\right\\vert }$$
](A272900_1_En_8_Chapter_Equ5.gif)

(8.5)

and

![
$$\\displaystyle{ \\sigma \(f\(A\)\) = \\left \\{f\(\\lambda \)\\left \\vert \\lambda \\in \\sigma \(A\)\\right.\\right\\}. }$$
](A272900_1_En_8_Chapter_Equ6.gif)

(8.6)

Proof.

Point 1 holds for polynomials and thus, by taking limits, for all ![
$$f \\in C\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq50.gif). Furthermore, if p is a real-valued polynomial and A is self-adjoint, then p(A) is self-adjoint. From this, we get Point 2 by taking limits. If ![
$$f \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq51.gif) is non-negative, then f = g 2, where ![
$$g = \\sqrt{f}$$
](A272900_1_En_8_Chapter_IEq52.gif) is real-valued. Thus, g(A) is self-adjoint and for all ![
$$\\psi \\in \\mathbf{H}$$
](A272900_1_En_8_Chapter_IEq53.gif), Point 1 tells us that

![
$$\\displaystyle{ \\left \\langle \\psi,f\(A\)\\psi \\right\\rangle = \\left \\langle \\psi,g{\(A\)}^{2}\\psi \\right\\rangle = \\left \\langle g\(A\)\\psi,g\(A\)\\psi \\right\\rangle \\geq 0, }$$
](A272900_1_En_8_Chapter_Equ7.gif)

(8.7)

which establishes Point 3. We have already established (8.5) in (8.4) for polynomials; the result for general ![
$$f \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq54.gif) follows by taking limits.

To establish (8.6), suppose first that ![
$$\\lambda _{0} \\in \\mathbb{C}$$
](A272900_1_En_8_Chapter_IEq55.gif) is not in the range of f. Then the function ![
$$g\(\\lambda \) := 1/\(f\(\\lambda \) -\\lambda _{0}\)$$
](A272900_1_En_8_Chapter_IEq56.gif) is continuous on σ(A) and the operator g(A) will be the inverse of f(A) − λ 0 I, showing that λ 0 is not in the spectrum of f(A).

In the other direction, suppose that λ 0 = f(μ) for some μ ∈ σ(A); we want to show that f(μ) ∈ σ(f(A)). Suppose now that f(A) − f(μ)I were invertible and choose a sequence p n of polynomials converging uniformly to f on σ(A). By Exercise 8 in Chap.​ 7, any operator sufficiently close to f(A) − f(μ)I in the operator norm topology would also be invertible. In particular, p n (A) − p n (μ)I would have to be invertible for all sufficiently large n, contradicting the spectral mapping theorem.

### 8.1.2 Stage 2: An Operator-Valued Riesz Representation Theorem

We turn now to Stage 2 of the proof of the spectral theorem. We will make use of the Riesz representation theorem from measure theory (not the result about continuous linear functionals on a Hilbert space). The following form of this result is sufficient for our purposes.

Theorem 8.5 (Riesz Representation Theorem).

Let X be a compact metric space and let ![
$$\\mathcal{C}\(X; \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq57.gif) denote the space of continuous, real-valued functions on X. Suppose ![
$$\\Lambda : \\mathcal{C}\(X; \\mathbb{R}\) \\rightarrow \\mathbb{R}$$
](A272900_1_En_8_Chapter_IEq58.gif) is a linear functional with the property that Λ(f) is non-negative whenever all the values of f are non-negative. Then there exists a unique (real-valued, positive) measure μ on the Borel σ-algebra in X for which

![
$$\\displaystyle{\\Lambda \(f\) =\\int _{X}f\\ d\\mu }$$
](A272900_1_En_8_Chapter_Equo.gif)

for all ![
$$f \\in \\mathcal{C}\(X; \\mathbb{R}\).$$
](A272900_1_En_8_Chapter_IEq59.gif)

See pp. 353–354 of Volume I of [34] for a short proof in the case in which X is a compact subset of ![
$$\\mathbb{R}$$
](A272900_1_En_8_Chapter_IEq60.gif), which is all we really require. For the full result stated above, see Theorems 7.2 and 7.8 in [12]. Observe that μ is a finite measure, with μ(X) = Λ(1), where 1 is the constant function.

Given a bounded self-adjoint operator ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq61.gif), we have constructed, in the previous subsection, a continuous functional calculus for A. This calculus is a map, denoted ![
$$f\\mapsto f\(A\)$$
](A272900_1_En_8_Chapter_IEq62.gif), from ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq63.gif) into ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq64.gif). If ![
$$f \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq65.gif) is non-negative, then (Point 3 of Proposition 8.4) f(A) is a non-negative operator. Thus, given ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq01.gif) ∈ H, if we define a linear functional ![
$$\\Lambda_{\\psi}$$
](A272900_1_En_8_Chapter_IEq012.gif) on ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq66.gif) by the formula

![
$$\\displaystyle{\\Lambda _{\\psi }\(f\) = \\left \\langle \\psi,f\(A\)\\psi \\right\\rangle,}$$
](A272900_1_En_8_Chapter_Equp.gif)

![
$$\\Lambda_{\\psi}$$
](A272900_1_En_8_Chapter_IEq03.gif) will satisfy the hypotheses of the Riesz representation theorem. Thus, for each ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq04.gif) ∈ H, we obtain a unique measure ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq05.gif) such that

![
$$\\displaystyle{ \\left \\langle \\psi,f\(A\)\\psi \\right\\rangle =\\int _{\\sigma \(A\)}f\(\\lambda \)\\ d\\mu _{\\psi }\(\\lambda \) }$$
](A272900_1_En_8_Chapter_Equ8.gif)

(8.8)

for all ![
$$f \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq67.gif). Note that

![
$$\\displaystyle{ \\mu _{\\psi }\(\\sigma \(A\)\) = \\Lambda _{\\psi }\(\\mathbf{1}\) ={ \\left \\Vert \\psi \\right\\Vert }^{2}. }$$
](A272900_1_En_8_Chapter_Equ9.gif)

(8.9)

Definition 8.6.

If f is a bounded measurable (complex-valued) function on σ(A), define a map ![
$$Q_{f} : \\mathbf{H} \\rightarrow \\mathbb{C}$$
](A272900_1_En_8_Chapter_IEq68.gif) by the formula

![
$$\\displaystyle{Q_{f}\(\\psi \) =\\int _{\\sigma \(A\)}f\(\\lambda \)\\ d\\mu _{\\psi }\(\\lambda \),}$$
](A272900_1_En_8_Chapter_Equq.gif)

where ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq070.gif) is the measure in (8.8).

If f happens to be real valued and continuous, then ![
$$Q_f\(\\psi\)$$
](A272900_1_En_8_Chapter_IEq06.gif) is equal ![
$$\\left \\langle \\psi,f\(A\)\\psi \\right\\rangle$$
](A272900_1_En_8_Chapter_IEq69.gif), in which case Q f is a bounded quadratic form. (See Definition A.60 and Example A.62.) It turns out that Q f is a bounded quadratic form for any bounded measurable f, in which case Proposition A.63 allows us to associate with Q f a bounded operator, which we denote by f(A). Once the relevant properties of f(A) are established, we will construct the desired projection-valued measure by setting μ A (E) = 1 E (A).

Proposition 8.7.

For any bounded measurable function f on σ(A), the map Q f in Definition  8.6 is a bounded quadratic form.

Proof.

Let ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq70.gif) denote the space of all bounded, Borel-measurable functions f for which Q f is a quadratic form. Then ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq71.gif) is a vector space and contains ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq72.gif). Furthermore, ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq73.gif) is closed under uniformly bounded pointwise limits, because ![
$$Q_f\(\\psi\)$$
](A272900_1_En_8_Chapter_IEq07.gif) is continuous with respect to such limits, by dominated convergence. Standard measure-theoretic techniques (Exercise 3) then show that ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq74.gif) is the space of all bounded Borel-measurable functions on X.

Meanwhile, it follows from (8.9) that

![
$$\\displaystyle{\\left \\vert Q_{f}\(\\psi \)\\right\\vert \\leq \\sup _{\\lambda \\in \\sigma \(A\)}\\left \\vert f\(\\lambda \)\\right\\vert \\ {\\left \\Vert \\psi \\right\\Vert }^{2},}$$
](A272900_1_En_8_Chapter_Equr.gif)

showing that Q f is always a bounded quadratic form.

Definition 8.8.

For a bounded measurable function f on σ(A), let f(A) be the operator associated to the quadratic form Q f by Proposition A.63. This means that f(A) is the unique operator such that

![
$$\\displaystyle{\\left \\langle \\psi,f\(A\)\\psi \\right\\rangle = Q_{f}\(\\psi \) =\\int _{\\sigma \(A\)}f\\ d\\mu _{\\psi }}$$
](A272900_1_En_8_Chapter_Equs.gif)

for all ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq071.gif) ∈ H.

Observe that if f is real valued, then ![
$$Q_f\(\\psi\)$$
](A272900_1_En_8_Chapter_IEq08.gif) is real for all ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq09.gif) ∈ H, which means (Proposition A.63) that the associated operator f(A) is self-adjoint. We will shortly associate with A a projection-valued measure μ A , and we will show that f(A), as given by Definition 8.8, agrees with f(A) as given by ![
$$\\int _{\\sigma \(A\)}f\(\\lambda \)\\ {d\\mu }^{A}\(\\lambda \)$$
](A272900_1_En_8_Chapter_IEq75.gif). [See (8.10) and compare Definition 7.13.]

Proposition 8.9.

For any two bounded measurable functions f and g, we have

![
$$\\displaystyle{\(fg\)\(A\) = f\(A\)g\(A\).}$$
](A272900_1_En_8_Chapter_Equt.gif)

Proof.

Let ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq76.gif) denote the space of bounded measurable functions f such that (fg)(A) = f(A)g(A) for all ![
$$g \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq77.gif). Then ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq78.gif) is a vector space and contains ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq79.gif). We have already noted that dominated convergence guarantees that the map ![
$$f\\mapsto Q_{f}\(\\psi \)$$
](A272900_1_En_8_Chapter_IEq80.gif), ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq010.gif) ∈ H, is continuous under uniformly bounded pointwise convergence. By the polarization identity (Proposition A.59), the same is true for the map ![
$$f\\mapsto L_{f}\(\\phi,\\psi \)$$
](A272900_1_En_8_Chapter_IEq81.gif), where L f is the sesquilinear form associated to Q f . Now, by the polarization identity, f will be in ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq82.gif) provided that

![
$$\\displaystyle{\\left \\langle \\psi,\(fg\)\(A\)\\psi \\right\\rangle = \\left \\langle \\psi,f\(A\)g\(A\)\\psi \\right\\rangle }$$
](A272900_1_En_8_Chapter_Equu.gif)

or, equivalently,

![
$$\\displaystyle{Q_{fg}\(\\psi \) = L_{f}\(\\psi,g\(A\)\\psi \)}$$
](A272900_1_En_8_Chapter_Equv.gif)

for all ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq011.gif) ∈ H and all ![
$$g \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq83.gif). From this, we can see that ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq84.gif) is closed under uniformly bounded pointwise limits. Thus, by Exercise 3, ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq85.gif) consists of all bounded, Borel-measurable functions.

We now let ![
$$\\mathcal{F}_{2}$$
](A272900_1_En_8_Chapter_IEq86.gif) denote the space of all bounded, Borel-measurable functions f such that (fg)(A) = f(A)g(A) for all bounded Borel-measurable functions g. Our result for ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq87.gif) shows that ![
$$\\mathcal{F}_{2}$$
](A272900_1_En_8_Chapter_IEq88.gif) contains ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq89.gif). Thus, the same argument as for ![
$$\\mathcal{F}_{1}$$
](A272900_1_En_8_Chapter_IEq90.gif) shows that ![
$$\\mathcal{F}_{2}$$
](A272900_1_En_8_Chapter_IEq91.gif) consists of all bounded, Borel-measurable functions.

Theorem 8.10.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq92.gif) is self-adjoint. For any measurable set E ⊂σ(A), define an operator μ A (E) by

![
$${\\displaystyle{\\mu }^{A}\(E\) = 1_{ E}\(A\),}$$
](A272900_1_En_8_Chapter_Equw.gif)

where 1 E (A) is given by Definition  8.8 . Then μ A is a projection-valued measure on σ(A) and satisfies

![
$$\\displaystyle{\\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A.}$$
](A272900_1_En_8_Chapter_Equx.gif)

Theorem 8.10 establishes the existence of the projection-valued measure in our first version of the spectral theorem (Theorem 7.12).

Proof.

Since 1 E is real-valued and satisfies ![
$$1_{E} \\cdot 1_{E} = 1_{E}$$
](A272900_1_En_8_Chapter_IEq93.gif), Proposition 8.4 tells us that 1 E (A) is self-adjoint and satisfies ![
$$1_{E}{\(A\)}^{2} = 1_{E}\(A\)$$
](A272900_1_En_8_Chapter_IEq94.gif). Thus, μ A (E) is an orthogonal projection (Proposition A.57), for any measurable set E ⊂ X. If E 1 and E 2 are measurable sets, then ![
$$1_{E_{1}\\cap E_{2}} = 1_{E_{1}} \\cdot 1_{E_{2}}$$
](A272900_1_En_8_Chapter_IEq95.gif) and so

![
$${\\displaystyle{\\mu }^{A}\(E_{ 1} \\cap E_{2}\) {=\\mu }^{A}{\(E_{ 1}\)\\mu }^{A}\(E_{ 2}\).}$$
](A272900_1_En_8_Chapter_Equy.gif)

If E 1, E 2,... are disjoint measurable sets, then ![
$${\\mu }^{A}{\(E_{j}\)\\mu }^{A}\(E_{k}\){=\\mu }^{A}\(\\varnothing \)=0$$
](A272900_1_En_8_Chapter_IEq96.gif), for j ≠ k, and so the ranges of the projections μ A (E j ) and μ A (E k ) are orthogonal. It then follows by an elementary argument that, for all ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq0012.gif) ∈ H, we have

![
$$\\displaystyle{\\sum _{j=1}^{\\infty }{\\mu }^{A}\(E_{ j}\)\\psi = P\\psi,}$$
](A272900_1_En_8_Chapter_Equz.gif)

where the sum converges in the norm topology of H and where P is the orthogonal projection onto the smallest closed subspace containing the range of μ A (E j ) for every j. On the other hand, if ![
$$E := \\cup _{j=1}^{\\infty }E_{j}$$
](A272900_1_En_8_Chapter_IEq97.gif), then the sequence ![
$$f_{N} :=\\sum _{ j=1}^{N}1_{E_{j}}$$
](A272900_1_En_8_Chapter_IEq98.gif) is uniformly bounded (by 1) and converges pointwise to 1 E . Thus, using again dominated convergence in (8.8),

![
$$\\displaystyle{\\lim _{N\\rightarrow \\infty }\\left \\langle \\psi,\\sum _{j=1}^{N}1_{ E_{j}}\(A\)\\psi \\right\\rangle = \\left \\langle \\psi,1_{E}\(A\)\\psi \\right\\rangle.}$$
](A272900_1_En_8_Chapter_Equaa.gif)

It follows that 1 E (A) coincides with P, which establishes the desired countable additivity for μ A .

Finally, if f = 1 E for some Borel set E, then

![
$$\\displaystyle{ \\int _{\\sigma \(A\)}f\(\\lambda \)\\ {d\\mu }^{A}\(\\lambda \) = f\(A\), }$$
](A272900_1_En_8_Chapter_Equ10.gif)

(8.10)

where f(A) is given by Definition 8.8. [The integral is equal to μ A (E), which is, by definition, equal to 1 E (A).] The equality (8.10) then holds for simple functions by linearity and for all bounded, Borel-measurable functions by taking limits. In particular, if f(λ) = λ, then the integral of f against μ A agrees with f(A) as defined in Definition 8.8, which agrees with f(A) as defined in the continuous functional calculus, which in turn agrees with f(A) as defined for polynomials—namely, f(A) = A. This means that

![
$$\\displaystyle{\\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A}$$
](A272900_1_En_8_Chapter_Equab.gif)

as desired.

We have now completed the existence of the projection-valued measure μ A in Theorem 7.12. The uniqueness of μ A is left as an exercise (Exercise 4). We close this section by proving Proposition 7.16, which states that if a bounded operator B commutes with a bounded self-adjoint operator A, then B commutes with f(A), for all bounded, Borel-measurable functions f on σ(A).

Proof of Proposition 7.16.

If B commutes with A, then B commutes with p(A), for any polynomial p. Thus, by taking limits as in the construction of the continuous functional calculus, B will commute with f(A) for any continuous real-valued function f on σ(A). We now let ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq99.gif) denote the space of all bounded, Borel-measurable functions f on σ(A) for which f(A) commutes with B, so that ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq100.gif).

To show that a bounded measurable f belongs to ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq101.gif), it suffices to show that for all ![
$$\\phi, \\psi$$
](A272900_1_En_8_Chapter_IEq013.gif) ∈ H we have ![
$$\\left \\langle \\phi,f\(A\)B\\psi \\right\\rangle = \\left \\langle \\phi,Bf\(A\)\\psi \\right\\rangle$$
](A272900_1_En_8_Chapter_IEq102.gif), or, equivalently, ![
$$\\left \\langle \\phi,f\(A\)B\\psi \\right\\rangle = \\left \\langle {B}^{{\\ast}}\\phi,f\(A\)\\psi \\right\\rangle$$
](A272900_1_En_8_Chapter_IEq103.gif). That is, we want

![
$$\\displaystyle{L_{f}\(\\phi,B\\psi \) = L_{f}\({B}^{{\\ast}}\\phi,\\psi \).}$$
](A272900_1_En_8_Chapter_Equac.gif)

But we have seen that for fixed vectors ![
$$\\psi_1, \\psi_2$$
](A272900_1_En_8_Chapter_IEq014.gif) ∈ H, the map ![
$$f\\mapsto L_{f}\(\\psi _{1},\\psi _{2}\)$$
](A272900_1_En_8_Chapter_IEq104.gif) is continuous under uniformly bounded pointwise limits. Thus, ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq105.gif) is closed under such limits, which implies (Exercise 3) that ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq106.gif) contains all bounded, Borel-measurable functions.

## 8.2 Proof of the Spectral Theorem, Second Version

We now turn to the proof of Theorem 7.19. As in the proof of Theorem 7.12, we will make use of continuous functional calculus for a bounded self-adjoint operator A and the Riesz representation theorem. We begin by establishing the special case in which A has a cyclic vector, that is, a vector ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq015.gif) with the property that the vectors A k ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq072.gif), k = 0, 1, 2,..., span a dense subspace of H. In that case, the direct integral will be simply an L 2 space (i.e., the Hilbert spaces H λ are equal to ![
$$\\mathbb{C}$$
](A272900_1_En_8_Chapter_IEq107.gif) for all λ). Thus, in this special case, the direct integral and multiplication operator versions of the spectral theorem coincide.

Lemma 8.11.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq108.gif) is self-adjoint and ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq016.gif) is a cyclic vector for A. Let ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq017.gif) be the unique measure on σ(A), given by Theorem  8.5 , for which

![
$$\\displaystyle{ \\left \\langle \\psi,f\(A\)\\psi \\right\\rangle =\\int _{\\sigma \(A\)}f\(\\lambda \)\\ d\\mu _{\\psi }\(\\lambda \) }$$
](A272900_1_En_8_Chapter_Equ11.gif)

(8.11)

for all ![
$$f \\in \\mathcal{C}\(\\sigma \(A\); \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq109.gif) . Then there exists a unitary map

![
$$\\displaystyle{U : \\mathbf{H} \\rightarrow {L}^{2}\(\\sigma \(A\),\\mu _{\\psi }\)}$$
](A272900_1_En_8_Chapter_Equad.gif)

such that

![
$$\\displaystyle{\\left \[UA{U}^{-1}\\phi \\right\]\(\\lambda \) =\\lambda \\phi \(\\lambda \)}$$
](A272900_1_En_8_Chapter_Equae.gif)

for all ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq018.gif) ∈ L 2(σ(A),![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq019.gif)).

Proof.

We start by defining U on the complex vector space of vectors of the form p(A)![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq073.gif), where p is a complex-valued polynomial, as follows:

![
$$\\displaystyle{U\[p\(A\)\\psi \] = p.}$$
](A272900_1_En_8_Chapter_Equaf.gif)

To show that U is well defined, write p as ![
$$p = p_{1} + ip_{2}$$
](A272900_1_En_8_Chapter_IEq110.gif), where p 1 and p 2 are real-valued polynomials. Since p 1(A) and p 2(A) are self-adjoint and commuting, we obtain

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle p\(A\)\\psi,p\(A\)\\psi \\right\\rangle & =& \\left \\langle \\psi,\\left \[p_{1}{\(A\)}^{2} + p_{ 2}{\(A\)}^{2}\\right\]\\psi \\right\\rangle \\\\ & =& \\int _{\\sigma \(A\)}\\left \[p_{1}{\(\\lambda \)}^{2} + p_{ 2}{\(\\lambda \)}^{2}\\right\]\\ d\\mu _{\\psi }\(\\lambda \),{}\\end{array}$$
](A272900_1_En_8_Chapter_Equ12.gif)

(8.12)

by canceling cross terms and applying (8.11). Thus, if ![
$$p\(A\)\\psi = 0$$
](A272900_1_En_8_Chapter_IEq020.gif) in H, then p(λ) = 0 for ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq021.gif)-almost every λ in σ(A), so that p represents the zero element of L 2(σ(A), ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq022.gif)).

Equation (8.12) shows also that the map U is isometric on its initial domain. This initial domain is dense in H since it contains the vectors A k ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq023.gif) and ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq024.gif) is cyclic. Thus, the BLT theorem (Theorem A.36) tells us that U extends uniquely to an isometric map of H into L 2(σ(A), ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq025.gif)). Since polynomials are dense in L 2(σ(A), ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq026.gif)) (by the Stone–Weierstrass theorem and Theorem A.10), U actually is unitary.

Now, since U takes A k ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq027.gif) to the function ![
$$\\lambda {\\mapsto \\lambda }^{k}$$
](A272900_1_En_8_Chapter_IEq111.gif) in L 2(σ(A), μ ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq028.gif)), we have that ![
$$UA{U}^{-1}{\(\\lambda }^{k}\) {=\\lambda }^{k+1}$$
](A272900_1_En_8_Chapter_IEq112.gif). Thus,

![
$$\\displaystyle{\[UA{U}^{-1}p\]\(\\lambda \) =\\lambda p\(\\lambda \)}$$
](A272900_1_En_8_Chapter_Equag.gif)

for all polynomials p. Since polynomials are dense in L 2(σ(A), ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq029.gif)), we have ![
$$\[UA{U}^{-1}\\phi \]\(\\lambda \) =\\lambda \\phi \(\\lambda \)$$
](A272900_1_En_8_Chapter_IEq113.gif) for all ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq030.gif) ∈ L 2(σ(A), ![
$$\\mu_\\psi$$
](A272900_1_En_8_Chapter_IEq031.gif)), as claimed.

Lemma 8.12.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq114.gif) is self-adjoint and μ A is the associated projection-valued measure on σ(A), as in Theorem  8.10 . Then there exists a non-negative real-valued measure μ on σ(A) such that for all Borel sets E ⊂σ(A), we have μ A (E) = 0 if and only if μ(E) = 0.

Proof.

Let {e j } be an orthonormal basis for H and let ![
$$\\mu _{e_{j}}$$
](A272900_1_En_8_Chapter_IEq115.gif) be the associated real-valued measures, given by ![
$$\\mu _{e_{j}}\(E\) = \\left \\langle e_{j}{,\\mu }^{A}\(E\)e_{j}\\right\\rangle$$
](A272900_1_En_8_Chapter_IEq116.gif). Then ![
$$\\mu _{e_{j}}\(\\sigma \(A\)\) = \\left \\langle e_{j},Ie_{j}\\right\\rangle = 1$$
](A272900_1_En_8_Chapter_IEq117.gif) for all j. Thus, the formula

![
$$\\displaystyle{\\mu :=\\sum _{j} \\frac{1} {{j}^{2}}\\mu _{e_{j}}}$$
](A272900_1_En_8_Chapter_Equah.gif)

defines a finite measure on σ(A). Given some Borel set E ⊂ σ(A), if μ A (E) = 0, then ![
$$\\mu _{e_{j}}\(E\) = 0$$
](A272900_1_En_8_Chapter_IEq118.gif) for all j and so μ(E) = 0. Conversely, if μ(E) = 0, then

![
$$\\displaystyle{0 = \\left \\langle e_{j}{,\\mu }^{A}\(E\)e_{ j}\\right\\rangle = \\left \\langle{ \\mu }^{A}\(E\)e_{ j}{,\\mu }^{A}\(E\)e_{ j}\\right\\rangle }$$
](A272900_1_En_8_Chapter_Equai.gif)

for all j, since μ A (E) is self-adjoint and ![
$${\\mu }^{A}{\(E\)}^{2} {=\\mu }^{A}\(E\)$$
](A272900_1_En_8_Chapter_IEq119.gif). Thus, μ A (E)e j = 0 for all j, which means that μ A (E) = 0.

Lemma 8.13.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq120.gif) is self-adjoint, then H can be decomposed as an orthogonal direct sum of closed nonzero subspaces W j , where each W j is invariant under A and where the restriction of A to W j has a cyclic vector ![
$$\\phi_j$$
](A272900_1_En_8_Chapter_IEq032.gif). The number of W j 's is either finite or countably infinite.

Proof.

Recall our standing assumption that H is separable, and let {![
$$\\phi_j$$
](A272900_1_En_8_Chapter_IEq033.gif)} be a countable dense subset of H. Let W 1 be the closed subspace of H spanned by ![
$$\\phi_1, A\\phi_1, A^2\\phi_1$$
](A272900_1_En_8_Chapter_IEq034.gif),.... Then W 1 is invariant under A and ![
$$\\psi_1 := \\phi_1$$
](A272900_1_En_8_Chapter_IEq035.gif) is a cyclic vector for ![
$$\\left.A\\right\\vert _{W_{1}}$$
](A272900_1_En_8_Chapter_IEq121.gif). If W 1 = H then we are done. If not, let j be the smallest number such that ![
$$\\phi_j$$
](A272900_1_En_8_Chapter_IEq036.gif) is not contained in W 1. Let ![
$$\\psi_2$$
](A272900_1_En_8_Chapter_IEq037.gif) be the orthogonal projection of ![
$$\\phi_j$$
](A272900_1_En_8_Chapter_IEq038.gif) onto the orthogonal complement of W 1, and let W 2 be the closed span of ![
$$\\phi_2, A\\phi_2, A^2\\phi_2$$
](A272900_1_En_8_Chapter_IEq039.gif),.... Then W 2 is invariant under A and ![
$$\\psi_2$$
](A272900_1_En_8_Chapter_IEq040.gif) is a cyclic vector for ![
$$\\left.A\\right\\vert _{W_{2}}$$
](A272900_1_En_8_Chapter_IEq122.gif). Furthermore, since A is self-adjoint and leaves W 1 invariant, it also leaves W 1 ⊥ invariant, which means that A k ![
$$\\psi_2$$
](A272900_1_En_8_Chapter_IEq041.gif) is orthogonal to W 1 for all k, so that W 2 is orthogonal to W 1.

If, now, W 1 ⊕ W 2 = H, we are done. If not, we let k be the smallest number such that ![
$$\\phi_k$$
](A272900_1_En_8_Chapter_IEq042.gif) is not in W 1 ⊕ W 2 and we let ![
$$\\psi_3$$
](A272900_1_En_8_Chapter_IEq043.gif) be the projection of ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq074.gif) k onto the orthogonal complement of W 1 ⊕ W 2, and so on. Continuing on in this way, we obtain an orthogonal collection of closed subspaces that are invariant under A, each of which has a cyclic vector. Either the process terminates with finitely many of these subspaces spanning H, or we get an infinite family. In the latter case, each ![
$$\\phi_j$$
](A272900_1_En_8_Chapter_IEq044.gif) belongs to the span of the W j 's and hence the (Hilbert space) direct sum of the W j 's is all of H.

We are now ready for the proof of our second form of the spectral theorem.

Proof of Theorem 7.19.

Let {![
$$W_j, \\psi_j$$
](A272900_1_En_8_Chapter_IEq045.gif)} be as in Lemma 8.13, and let A j denote the restriction of A to W j , which is a bounded self-adjoint operator on the Hilbert space W j . For each A j , we can obtain a unitary map U j as in Lemma 8.11, and we wish to piece these maps together for different values of j to obtain a direct integral decomposition for all of H. To facilitate piecing the maps together, we will modify the U j 's so that they all map to L 2 spaces over a subset of σ(A) with respect to the same measure μ.

If we apply Lemma 8.11 to A j , we get a unitary map

![
$$\\displaystyle{U_{j} : W_{j} \\rightarrow {L}^{2}\(\\sigma \(A_{ j}\),\\mu _{\\psi _{j}}\)}$$
](A272900_1_En_8_Chapter_Equaj.gif)

such that ![
$$U_{j}AU_{j}^{-1}$$
](A272900_1_En_8_Chapter_IEq123.gif) is the operator of multiplication by λ. Here, ![
$$\\mu _{\\psi _{j}}$$
](A272900_1_En_8_Chapter_IEq124.gif) is the measure on σ(A j ) given by ![
$$\\mu _{\\psi _{j}}\(E\) = \\left \\langle \\psi _{j}{,\\mu }^{A_{j}}\(E\)\\psi _{j}\\right\\rangle$$
](A272900_1_En_8_Chapter_IEq125.gif). Now, according to Exercise 5, the spectrum of A j is contained in the spectrum of A. Furthermore, if E is a measurable subset of σ(A j ) ⊂ σ(A), then 1 E may be thought of as a measurable function either on σ(A j ) or on σ(A). Exercise 5 tells us that 1 E (A j ), as defined by the functional calculus for A j , coincides with the restriction to W j of 1 E (A). Thus, if 1 E (A) = 0 then 1 E (A j ) = 0 as well. Equivalently, if μ A (E) = 0 then ![
$${\\mu }^{A_{j}}\(E\) = 0$$
](A272900_1_En_8_Chapter_IEq126.gif), where ![
$${\\mu }^{A_{j}}$$
](A272900_1_En_8_Chapter_IEq127.gif) is the projection-valued measure associated to the self-adjoint operator A j .

Let us now choose a measure μ as in Lemma 8.12. Any set of measure zero for μ is a set of measure zero for μ A and thus also for ![
$${\\mu }^{A_{j}}$$
](A272900_1_En_8_Chapter_IEq128.gif) and then for ![
$$\\mu_{\\psi _{j}}$$
](A272900_1_En_8_Chapter_IEq129.gif). Thus, if we extend ![
$$\\mu _{\\psi _{ j}}$$
](A272900_1_En_8_Chapter_IEq130.gif) to a measure on σ(A) by making it zero on σ(A) ∖ σ(A j ), we have that ![
$$\\mu _{\\psi _{ j}}$$
](A272900_1_En_8_Chapter_IEq131.gif) is absolutely continuous with respect to μ. By the Radon–Nikodym theorem (Theorem A.6), each ![
$$\\mu _{\\psi _{ j}}$$
](A272900_1_En_8_Chapter_IEq132.gif) has a density ρ j with respect to μ, and this density is nonzero ![
$$\\mu _{\\psi _{j}}$$
](A272900_1_En_8_Chapter_IEq133.gif)-almost everywhere.

Now, the map

![
$$\\displaystyle{f\\mapsto \\rho _{j}^{1/2}f}$$
](A272900_1_En_8_Chapter_Equak.gif)

is easily seen to be a unitary map of ![
$${L}^{2}\(\\sigma \(A_{j}\),\\mu _{\\psi _{j}}\)$$
](A272900_1_En_8_Chapter_IEq134.gif) to L 2(σ(A j ), μ). Thus, we can define a unitary map

![
$$\\displaystyle{\\tilde{U}_{j} : W_{j} \\rightarrow {L}^{2}\(\\sigma \(A_{ j}\),\\mu \)}$$
](A272900_1_En_8_Chapter_Equal.gif)

by setting

![
$$\\displaystyle{\(\\tilde{U}_{j}\\psi \)\(\\lambda \) =\\rho _{j}{\(\\lambda \)}^{1/2}\(U_{ j}\\psi \)\(\\lambda \).}$$
](A272900_1_En_8_Chapter_Equam.gif)

Since multiplication by (ρ j )1 ∕ 2 commutes with multiplication by λ, we have

![
$$\\displaystyle{\\left \(\\tilde{U}_{j}A_{j}\\tilde{U}_{j}^{-1}\\right\)\(\\psi \)\(\\lambda \) =\\lambda \\psi \(\\lambda \).}$$
](A272900_1_En_8_Chapter_Equan.gif)

Now, L 2(σ(A j ), μ) can be thought of as a direct integral over σ(A) with respect to μ, where we take ![
$$\\mathbf{H}_{\\lambda }^{j} = \\mathbb{C}$$
](A272900_1_En_8_Chapter_IEq135.gif) for λ ∈ σ(A j ) and we take H λ j = { 0} if λ ∈ σ(A j ) c . We now define another direct integral over σ(A) in which the Hilbert spaces H λ , λ ∈ σ(A), are defined by

![
$$\\displaystyle{\\mathbf{H}_{\\lambda } = \\bigoplus \\limits _{j}\\mathbf{H}_{\\lambda }^{j}.}$$
](A272900_1_En_8_Chapter_Equao.gif)

Here the measurable structure on the direct integral is defined by setting

![
$$\\displaystyle{e_{j}\(\\lambda \) = \\left \\{\\begin{array}{c} \(0,0,\\ldots,1,0,0,\\ldots \),\\quad \\lambda \\in E_{j} \\\\ \(0,0,\\ldots,0,0,0,\\ldots \),\\quad \\lambda \\in E_{j}^{c} \\end{array} \\right.,}$$
](A272900_1_En_8_Chapter_Equap.gif)

where the 1 is in the jth slot. Since each H λ is a direct sum of the H λ j 's, the direct integral of the H λ 's is the Hilbert space direct sum of the direct integral of the H λ j 's, which is just L 2(σ(A j ), μ).

Meanwhile, H is the direct sum of the W j 's, and we have unitary maps ![
$$\\tilde{U}_{j}$$
](A272900_1_En_8_Chapter_IEq136.gif) of W j to L 2(σ(A j ), μ) such that ![
$$\\tilde{U}_{j}A\\tilde{U}_{j}^{-1}$$
](A272900_1_En_8_Chapter_IEq137.gif) is just multiplication by λ on L 2(E j , μ). Thus, we can assemble the ![
$$\\tilde{U}_{j}$$
](A272900_1_En_8_Chapter_IEq138.gif)'s into a single unitary map U of H to the integral of the H λ 's, and we will have U AU − 1 equal to multiplication by λ, as desired.

In the interest of brevity, we will not give a complete proof of Proposition 7.22 (uniqueness in Theorem 7.19), but only indicate the main ideas. To establish the equivalence of μ (1) and μ (2), we observe that both measures have the same sets of measure zero as the projection-valued measure μ A (Proposition 7.23). Meanwhile, if we have two different direct integrals, each unitarily equivalent to H as in (7.​20), then there will be a unitary map V between the two direct integrals that commutes with the operator ![
$$s\(\\lambda \)\\mapsto \\lambda s\(\\lambda \)$$
](A272900_1_En_8_Chapter_IEq139.gif). Using an argument similar to that in Exercise 7, we can show that there must be bounded maps ![
$$V _{\\lambda } : \\mathbf{H}_{\\lambda }^{\(1\)} \\rightarrow \\mathbf{H}_{\\lambda }^{\(2\)}$$
](A272900_1_En_8_Chapter_IEq140.gif) such that (Vs)(λ) = V λ s(λ) for almost every λ. Then we argue that the only way V can be unitary is if V λ is unitary for almost every λ. This implies that ![
$$\\dim \\mathbf{H}_{\\lambda }^{\(1\)} =\\dim \\mathbf{H}_{\\lambda }^{\(2\)}$$
](A272900_1_En_8_Chapter_IEq141.gif) for almost every λ.

Finally, we briefly indicate the proof of the multiplication operator form of the spectral theorem.

Proof of Theorem 7.20.

Let W j be as in Lemma 8.13 and let A j be the restriction of A to W j . By the proof of Theorem 7.19, each A j is unitarily equivalent to multiplication by λ on the Hilbert space ![
$${L}^{2}\(\\sigma \(A_{j}\),\\mu _{j}\)$$
](A272900_1_En_8_Chapter_IEq142.gif), for some finite measure μ j on σ(A j ). Let X be the disjoint union of the sets σ(A j ), let μ be the sum of the measures μ j , and let h be the function whose restriction to each σ(A j ) is the function ![
$$\\lambda \\mapsto \\lambda$$
](A272900_1_En_8_Chapter_IEq143.gif). Then L 2(X, μ) is the orthogonal direct sum of the Hilbert spaces ![
$${L}^{2}\(\\sigma \(A_{j}\),\\mu _{j}\)$$
](A272900_1_En_8_Chapter_IEq144.gif), which means that L 2(X, μ) may be identified unitarily with ![
$$\\mathbf{H} = \\oplus W_{j}$$
](A272900_1_En_8_Chapter_IEq145.gif) in an obvious way. Under this identification, the operator A corresponds to multiplication by h.

## 8.3 Exercises

1.

(a)

Suppose ![
$$A,B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq146.gif) commute and A is not invertible. Show that AB is not invertible.

Hint: First show that if AB were invertible, then A would have both a left inverse and a right inverse. Then show that the left inverse and right inverse would need to be equal.

(b)

Show that the result of Part (a) is false if we omit the assumption that A and B commute.

2.

(a)

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq147.gif) is self-adjoint and ![
$$\\sigma \(A\) \\subset \[0,\\infty \)$$
](A272900_1_En_8_Chapter_IEq148.gif). Show that A has a self-adjoint square root in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq149.gif) and therefore that A is a non-negative operator (i.e., ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle \\geq 0$$
](A272900_1_En_8_Chapter_IEq150.gif) for all ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq046.gif) ∈ H).

(b)

Give an example of a bounded operator A on a Hilbert space such that ![
$$\\sigma \(A\) \\subset \[0,\\infty \)$$
](A272900_1_En_8_Chapter_IEq151.gif) but A is not non-negative.

3.

Let X be a compact metric space and let ![
$$\\mathcal{C}\(X; \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq152.gif) denote the space of continuous real-valued functions on X. Suppose that ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq153.gif) is a set of bounded, measurable, complex-valued functions on X with the following properties: (1) ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq154.gif) is a complex vector space, (2) ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq155.gif) contains ![
$$\\mathcal{C}\(X; \\mathbb{R}\)$$
](A272900_1_En_8_Chapter_IEq156.gif), and (3) ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq157.gif) is closed under pointwise limits of uniformly bounded sequences. (A sequence f n is uniformly bounded if there exists a constant C such that ![
$$\\left \\vert f_{n}\(x\)\\right\\vert \\leq C$$
](A272900_1_En_8_Chapter_IEq158.gif) for all n and x).

(a)

Let ![
$$\\mathcal{L}_{0}$$
](A272900_1_En_8_Chapter_IEq159.gif) denote the collection of those measurable sets E for which 1 E is a uniformly bounded limit of a sequence of continuous functions. Show that ![
$$\\mathcal{L}_{0}$$
](A272900_1_En_8_Chapter_IEq160.gif) is an algebra and contains all open sets in X.

(b)

Let ![
$$\\mathcal{L}_{1}$$
](A272900_1_En_8_Chapter_IEq161.gif) denote the collection of all measurable sets in E for which 1 E belongs to ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq162.gif). Using the monotone class lemma (Theorem A.8), show that ![
$$\\mathcal{L}_{1}$$
](A272900_1_En_8_Chapter_IEq163.gif) consists of all Borel sets in X.

(c)

Show that ![
$$\\mathcal{F}$$
](A272900_1_En_8_Chapter_IEq164.gif) consists of all bounded, Borel-measurable functions on X.

4.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq165.gif) is self-adjoint μ A and ν A are two projection-valued measures on σ(A) such that

![
$$\\displaystyle{\\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) =\\int _{\\sigma \(A\)}\\lambda \\ {d\\nu }^{A}\(\\lambda \) = A.}$$
](A272900_1_En_8_Chapter_Equaq.gif)

Show that integration with respect to μ A agrees with integration with respect to ν A , first on polynomials, then on continuous functions, and finally on bounded measurable functions. Conclude that μ A = ν A .

Hint: Use Exercise 17.

5.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq166.gif) is self-adjoint operator and V is a closed subspace of H that is invariant under A.

(a)

Using Proposition 7.7, show that the spectrum of the restriction to V of A is contained in the spectrum of A.

(b)

Suppose now that f is a bounded measurable function on σ(A), which means that f is also a function on ![
$$\\sigma \\left \(\\left.A\\right\\vert _{V }\\right\) \\subset \\sigma \(A\)$$
](A272900_1_En_8_Chapter_IEq167.gif). Show that V is invariant under f(A) and that

![
$$\\displaystyle{\\left.f\(A\)\\right\\vert _{V } = f\\left \(\\left.A\\right\\vert _{V }\\right\),}$$
](A272900_1_En_8_Chapter_Equar.gif)

where the operator on the right-hand side is defined by the measurable functional calculus for the bounded self-adjoint operator ![
$$\\left.A\\right\\vert _{V }$$
](A272900_1_En_8_Chapter_IEq168.gif).

6.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq169.gif) is self-adjoint and ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq047.gif) is an eigenvector for A, that is, a nonzero vector with ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_8_Chapter_IEq048.gif) for some ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_8_Chapter_IEq170.gif). Show that for any bounded measurable function f on σ(A) we have

![
$$\\displaystyle{f\(A\)\\psi = f\(\\lambda \)\\psi.}$$
](A272900_1_En_8_Chapter_Equas.gif)

Hint: Use Exercise 5.

7.

Suppose ![
$$K \\subset \\mathbb{R}$$
](A272900_1_En_8_Chapter_IEq171.gif) is a compact set and μ is a finite measure on K. Let A be the bounded operator on L 2(K, μ) given by

![
$$\\displaystyle{\(A\\psi \)\(\\lambda \) =\\lambda \\psi \(\\lambda \).}$$
](A272900_1_En_8_Chapter_Equat.gif)

Now suppose that B is a bounded operator on L 2(K, μ) that commutes with A.

(a)

Let ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq049.gif) = B 1, where 1 denotes the constant function, so that ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq050.gif) ∈ L 2(K, μ). Show that for all continuous functions ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq051.gif) on K, we have ![
$$B\\psi = \\phi\\psi$$
](A272900_1_En_8_Chapter_IEq052.gif).

(b)

Using Exercise 3, show that for all bounded, Borel-measurable functions ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq053.gif) on K, we have ![
$$B\\psi = \\phi\\psi$$
](A272900_1_En_8_Chapter_IEq054.gif).

(c)

Show that ![
$$\\phi$$
](A272900_1_En_8_Chapter_IEq055.gif) is essentially bounded (i.e., bounded outside a set of μ-measure zero). Conclude that ![
$$B\\psi = \\phi\\psi$$
](A272900_1_En_8_Chapter_IEq056.gif) for all ![
$$\\psi$$
](A272900_1_En_8_Chapter_IEq057.gif) ∈ L 2(K, μ).

8.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq172.gif) is self-adjoint, define ![
$$U\(t\) \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_8_Chapter_IEq173.gif) by U(t) = exp{itA} for each ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_8_Chapter_IEq174.gif), where the exponential is defined by the functional calculus for A.

(a)

Show that U(t) is unitary for all t and that ![
$$U\(s\)U\(t\) = U\(s + t\)$$
](A272900_1_En_8_Chapter_IEq175.gif). (A family of operators with this property is called a one-parameter unitary group.)

(b)

Show that the map ![
$$t\\mapsto U\(t\)$$
](A272900_1_En_8_Chapter_IEq176.gif) is continuous in the operator norm topology.

(c)

Give an example of a one-parameter unitary group on a Hilbert space that is not continuous in the operator norm topology.

See Sect.​ 10.​2 for more on one-parameter unitary groups.

References

[12].

G.B. Folland, Real Analysis: Modern Techniques and Their Applications, 2nd edn. (Wiley, New York, 1999)

[34].

M. Reed, B. Simon, Methods of Modern Mathematical Physics. Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_9

© Springer Science+Business Media New York 2013

# 9. Unbounded Self-Adjoint Operators

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

Recall that most of the operators of quantum mechanics, including those representing position, momentum, and energy, are not defined on the entirety of the relevant Hilbert space, but only on a dense subspace thereof.

## 9.1 Introduction

Recall that most of the operators of quantum mechanics, including those representing position, momentum, and energy, are not defined on the entirety of the relevant Hilbert space, but only on a dense subspace thereof. In the case of the position operator, for example, given ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq1.gif), the function ![
$$X\\psi\(x\) = x\\psi\(x\)$$
](A272900_1_En_9_Chapter_IEq01.gif) could easily fail to be in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq2.gif). Nevertheless, the space of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq021.gif)'s in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq3.gif) for which ![
$$x\\psi\(x\)$$
](A272900_1_En_9_Chapter_IEq02.gif) is again in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq4.gif) is a dense subspace of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq5.gif). A closely related property of these operators is that they are not bounded, meaning that there is no constant C such that

![
$$\\displaystyle{\\left \\Vert A\\psi \\right\\Vert \\leq C\\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equa.gif)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq022.gif) for which A is defined. Because our operators are unbounded, we cannot use the BLT (bounded linear transformation) theorem to extend them to the whole Hilbert space.

In this chapter and the following one, we are going to study unbounded operators defined on dense subspaces of a Hilbert space H. We will introduce the "correct" notion of self-adjointness for unbounded operators, namely the one for which the spectral theorem holds. As it turns out, the obvious candidate for a definition of self-adjointness, namely that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq6.gif) for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq023.gif) and ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq024.gif) in the domain of A, is not the correct one. Rather, for any unbounded operator A, we will define another unbounded operator A ∗, the adjoint of A, with its own naturally defined domain. Then A is said to be self-adjoint if A ∗ and A are the same operators with the same domain.

In the present chapter, we give the definition of an unbounded self-adjoint operator, along with conditions for self-adjointness and several examples and counterexamples. We defer a discussion of the spectral theorem itself until Chap.​ 10. The statement of the spectral theorem (either in terms of projection-valued measures or in terms of direct integrals) is essentially the same as in the bounded case, with only a few modifications to deal with the domain of the operator.

Although this chapter is rather technical, a reader who is willing to accept some things on faith may wish simply to read the definitions of self-adjoint and essentially self-adjoint operators in Sect. 9.2, and then skip to the statements of Theorem 9.21 and Corollary 9.22 in Sect. 9.5. As in previous chapters, H will denote a separable Hilbert space over ![
$$\\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq7.gif).

## 9.2 Adjoint and Closure of an Unbounded Operator

Recall that we briefly introduced unbounded operators in Sect.​ 3.​2. According to Definition 3.1, an unbounded operator A on H is a linear map of some dense subspace Dom(A) ⊂ H (the domain of A) into H. As in Sect.​ 3.​2, "unbounded" means "not necessarily bounded," meaning that we permit the case in which Dom(A) = H and A is bounded.

Now, if A is bounded, then for any ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq03.gif), the linear functional

![
$$\\displaystyle{\\left \\langle \\phi,A\\cdot \\right\\rangle }$$
](A272900_1_En_9_Chapter_Equb.gif)

is bounded. Thus, by the Riesz theorem (Theorem A.52), there is a unique χ such that

![
$$\\displaystyle{\\left \\langle \\phi,A\\cdot \\right\\rangle = \\left \\langle \\chi,\\cdot \\right\\rangle.}$$
](A272900_1_En_9_Chapter_Equc.gif)

We then define the adjoint A ∗ of A by setting A ∗ ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq025.gif) equal to χ. (See Sect. A.4.)

If A is unbounded, then ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq8.gif) is not necessarily bounded, but may be bounded for certain vectors ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq04.gif). If ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq026.gif), ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq008.gif) does happen to be bounded, for some ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq06.gif) ∈ H, then the BLT theorem (Theorem A.36) says that this linear functional has a unique bounded extension from Dom(A) to all H. The Riesz theorem then tells us that there is a unique χ such that this linear functional is "inner product with χ." This line of reasoning leads to the following definition, which was already introduced briefly in Sect.​ 3.​2.

Definition 9.1.

Suppose A is an operator defined on a dense subspace Dom(A) ⊂ H. Let Dom(A ∗) to be the space of all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq07.gif) ∈ H for which the linear functional

![
$$\\displaystyle{\\psi \\mapsto \\left \\langle \\phi,A\\psi \\right\\rangle,\\quad \\psi \\in \\mathrm{ Dom}\(A\),}$$
](A272900_1_En_9_Chapter_Equd.gif)

is bounded. For ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq08.gif) ∈ Dom(A ∗), define ![
$$A^\\ast\\phi$$
](A272900_1_En_9_Chapter_IEq09.gif) to be the unique vector such that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\phi,\\psi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq9.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq010.gif) ∈ Dom(A).

Saying that ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq10.gif) is bounded means, explicitly, that there exists a constant C such that ![
$$\\left \\vert \\left \\langle \\phi,A\\psi \\right\\rangle \\right\\vert \\leq C\\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_9_Chapter_IEq11.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq027.gif) ∈ Dom(A). As in the bounded case, the operator A ∗ is linear on its domain, and is called the adjoint of A.

Another way to think about the definition of A ∗ is as follows. Given a vector ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq028.gif), if there exists a vector χ such that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle \\chi,\\psi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq12.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq029.gif) ∈ Dom(A), then ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq030.gif) belongs to Dom(A ∗) and A ∗ ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq031.gif) = χ. By the Riesz theorem, such a χ will exist if and only if ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq13.gif) is bounded, which means this way of thinking about A ∗ is equivalent to Definition 9.1.

Given a densely defined operator A, the adjoint A ∗ of A could fail to be densely defined. This situation, however, is a pathology that does not usually occur for operators of interest in applications.

Definition 9.2.

An unbounded operator A on H is symmetric if

![
$$\\displaystyle{ \\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_9_Chapter_Equ1.gif)

(9.1)

for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq032.gif), ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq033.gif) ∈ Dom(A).

As we will see shortly, if A is symmetric, then A ∗ is an extension of A, in the sense of the following definition.

Definition 9.3.

An unbounded operator A is an extension of an unbounded operator B if ![
$$\\mathrm{Dom}\(A\) \\supset \\mathrm{ Dom}\(B\)$$
](A272900_1_En_9_Chapter_IEq14.gif) and A = B on Dom(B).

If A is an extension of B, then very likely A is given by the same "formula" as B. If ![
$$\\mathbf{H} = {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq15.gif), for example, both operators might be given by the formula ![
$$-i\\hslash \\ d/dx$$
](A272900_1_En_9_Chapter_IEq16.gif) on their respective domains. Nevertheless, if Dom(A) ≠ Dom(B), then A is still a different operator from B.

Proposition 9.4

An unbounded operator A is symmetric if and only if A ∗ is an extension of A.

Proof.

If A is symmetric, then for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq034.gif) ∈ Dom(A), (9.1) and the Cauchy–Schwarz inequality show that

![
$$\\displaystyle{\\left \\vert \\left \\langle \\phi,A\\psi \\right\\rangle \\right\\vert \\leq \\left \\Vert A\\phi \\right\\Vert \\left \\Vert \\psi \\right\\Vert,}$$
](A272900_1_En_9_Chapter_Eque.gif)

showing that ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq035.gif) ∈ Dom(A ∗). In that case, (9.1) shows that the unique vector A ∗ ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq036.gif) for which ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\phi,\\psi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq17.gif) is nothing but A ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq037.gif), which means that A ∗ agrees with A on Dom(A).

In the other direction, if A ∗ is an extension of A, then for each ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq038.gif) ∈ Dom(A), we have

![
$$\\displaystyle{\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\phi,\\psi \\right\\rangle = \\left \\langle A\\phi,\\psi \\right\\rangle,}$$
](A272900_1_En_9_Chapter_Equf.gif)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq039.gif) ∈ Dom(A), which shows that A is symmetric.

We come now to the key definition of this section, that of self-adjointness. This notion constitutes the hypothesis of the spectral theorem for unbounded operators.

Definition 9.5.

An unbounded operator A on H is self-adjoint if

![
$$\\displaystyle{\\mathrm{Dom}\({A}^{{\\ast}}\) =\\mathrm{ Dom}\(A\)}$$
](A272900_1_En_9_Chapter_Equg.gif)

and ![
$$A^{\\ast}\\phi = A\\phi$$
](A272900_1_En_9_Chapter_IEq040.gif) for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq041.gif) ∈ Dom(A).

We may reformulate the definition of self-adjointness by saying that A is self-adjoint if A ∗ is equal to A, provided that equality of unbounded operators is understood to include equality of domains. Every self-adjoint operator is symmetric (by Proposition 9.4), but there exist many operators that are symmetric without being self-adjoint. In light of Proposition 9.4, a symmetric operator is self-adjoint if and only if Dom(A ∗) = Dom(A). In trying to show that a symmetric operator is self-adjoint, the difficulty lies in showing that Dom(A ∗) is no bigger than Dom(A).

Definition 9.6.

An unbounded operator A on H is said to be closed if the graph of A is a closed subset of H × H. An unbounded operator A on H is said to be closable if the closure in H × H of the graph of A is the graph of a function. If A is closable, then the closure A cl of A is the operator with graph equal to the closure of the graph of A.

To be more explicit, an operator A is closed if and only if the following condition holds: Suppose a sequence ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq042.gif) belongs to Dom(A) and suppose that there exist vectors ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq043.gif) and ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq044.gif) in H with ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq045.gif) → ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq046.gif) and ![
$$A\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq047.gif) → ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq048.gif). Then ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq049.gif) belongs to Dom(A) and ![
$$A\\psi = \\phi$$
](A272900_1_En_9_Chapter_IEq050.gif). Regarding closability, an operator A is not closable if there exist two elements in the closure of the graph of A of the form (![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq051.gif), ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq052.gif)) and (![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq053.gif), χ), with ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq054.gif) ≠ χ. Another way of putting it is to say that an operator A is closable if there exists some closed extension of it, in which case the closure of A is the smallest closed extension of A.

The notion of the closure of a (closable) operator is useful because it sweeps away some of the arbitrariness in the choice of a domain of an operator. If we consider, for example, the operator ![
$$A = -i\\hslash \\ d/dx$$
](A272900_1_En_9_Chapter_IEq18.gif) as an unbounded operator on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq19.gif), there are many different reasonable choices for Dom(A), including (1) the space of C ∞ functions of compact support, (2) the Schwartz space (Definition A.15), and (3) the space of continuously differentiable functions ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq055.gif) for which both ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq056.gif) and ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq057.gif) ′ belong to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq20.gif). As it turns out, each of these three choices for Dom(A) leads to the same operator A cl . Note that we are not claiming that every choice for Dom(A) leads to the same closure; nevertheless, it is often the case that many reasonable choices do lead to the same closure.

Definition 9.7.

An unbounded operator A on H is said to be essentially self-adjoint if A is symmetric and closable and A cl is self-adjoint.

Actually, as we shall see in the next section, a symmetric operator is always closable. Many symmetric operators fail to be even essentially self-adjoint. We will see examples of such operators in Sects. 9.6 and 9.10. Section 9.5 gives some reasonably simple criteria for determining when a symmetric operator is essentially self-adjoint.

## 9.3 Elementary Properties of Adjoints and Closed Operators

In this section, we spell out some of the most basic and useful properties of adjoints and closures of unbounded operators. In Sect. 9.5, we will draw on these results to prove some more substantial results. In what follows, if we say that two operators "coincide," it means that they have the same domain and that they are equal on that common domain.

Proposition 9.8

1.

If A is an unbounded operator on H , then the graph of the operator A ∗ (which may or may not be densely defined) is closed in H × H.

2.

A symmetric operator is always closable.

Proof.

Suppose ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq058.gif) is a sequence in the domain of A ∗ that converges to some ![
$$\\phi, \\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq059.gif). Suppose also that A ∗ ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq060.gif) converges to some ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq061.gif) ∈ H. Then ![
$$\\left \\langle \\psi _{n},A\\cdot \\right\\rangle = \\left \\langle {A}^{{\\ast}}\\psi _{n},\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq21.gif) and for any χ ∈ Dom(A), we have

![
$$\\displaystyle{\\left \\langle \\psi,A\\chi \\right\\rangle =\\lim _{n\\rightarrow \\infty }\\left \\langle \\psi _{n},A\\chi \\right\\rangle =\\lim _{n\\rightarrow \\infty }\\left \\langle {A}^{{\\ast}}\\psi _{ n},\\chi \\right\\rangle = \\left \\langle \\phi,\\chi \\right\\rangle.}$$
](A272900_1_En_9_Chapter_Equh.gif)

This shows that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq062.gif) belongs to the domain of A ∗ and that A ∗ ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq063.gif) = ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq064.gif), establishing that the graph of A ∗ is closed.

If A is symmetric, A ∗ is an extension of A. Since, as we have just proved, A ∗ is closed, A has a closed extension and is therefore closable.

Corollary 9.9.

If A is a symmetric operator with Dom (A) = H , then A is bounded.

Proof.

Since A is symmetric, it is closable by Proposition 9.8. But since the domain of A is already all of H, the closure of A must coincide with A itself. (The closure of A always agrees with A on Dom(A), which in this case is all of H.) Thus, A is a closed operator defined on all of H, and the closed graph theorem (Theorem A.39) implies that A is bounded.

Proposition 9.10

If A is a closable operator on H , then the adjoint of A cl coincides with the adjoint of A.

Proof.

Suppose that for some ![
$$\\phi, \\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq065.gif) there exists a ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq066.gif) such that ![
$$\\left \\langle \\psi,{A}^{cl}\\chi \\right\\rangle = \\left \\langle \\phi,\\chi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq22.gif) for all χ ∈ Dom(A cl ). Since A cl is an extension of A, it follows that ![
$$\\left \\langle \\psi,A\\chi \\right\\rangle = \\left \\langle \\phi,\\chi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq23.gif) for all χ ∈ Dom(A). This shows that ![
$$\\mathrm{Dom}\({A}^{{\\ast}}\) \\supset \\mathrm{ Dom}\({\({A}^{cl}\)}^{{\\ast}}\)$$
](A272900_1_En_9_Chapter_IEq24.gif) and that A ∗ agrees with (A cl )∗ on Dom((A cl )∗).

In the other direction, suppose for some ![
$$\\phi, \\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq067.gif) there exists a ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq068.gif) such that ![
$$\\left \\langle \\psi,A\\chi \\right\\rangle = \\left \\langle \\phi,\\chi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq25.gif) for all χ ∈ Dom(A). Suppose now ξ ∈ Dom(A cl ) with A cl ξ = η. Then there exists a sequence χ n in Dom(A) with χ n → ξ and A χ n → η, and we have

![
$$\\displaystyle{\\left \\langle \\psi,A\\chi _{n}\\right\\rangle = \\left \\langle \\phi,\\chi _{n}\\right\\rangle }$$
](A272900_1_En_9_Chapter_Equi.gif)

for all n. Letting n tend to infinity, we obtain ![
$$\\left \\langle \\psi,\\eta \\right\\rangle = \\left \\langle \\phi,\\xi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq26.gif), or ![
$$\\left \\langle \\psi,{A}^{cl}\\xi \\right\\rangle = \\left \\langle \\phi,\\xi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq27.gif). This shows that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq069.gif) ∈ Dom((A cl )∗) and A cl ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq070.gif) = ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq071.gif). Thus, ![
$$\\mathrm{Dom}\({A}^{{\\ast}}\) \\subset \\mathrm{ Dom}\({\({A}^{cl}\)}^{{\\ast}}\)$$
](A272900_1_En_9_Chapter_IEq28.gif).

Proposition 9.11

If A is essentially self-adjoint, then A cl is the unique self-adjoint extension of A.

Proof.

Suppose B is a self-adjoint extension of A. Since B = B ∗, B is closed and is, therefore, an extension of A cl . It then follows from the definition of the adjoint that Dom(B ∗) ⊂ Dom(A cl ). Thus, we have

![
$$\\displaystyle{\\mathrm{Dom}\({B}^{{\\ast}}\) \\subset \\mathrm{ Dom}\({A}^{cl}\) \\subset \\mathrm{ Dom}\(B\).}$$
](A272900_1_En_9_Chapter_Equj.gif)

Since B is self-adjoint, all three of the above sets must be equal, so actually B = A cl .

Proposition 9.12

If A is an unbounded operator on H , then

![
$$\\displaystyle{{\(\\mathrm{Range}\(A\)\)}^{\\perp } =\\ker \({A}^{{\\ast}}\).}$$
](A272900_1_En_9_Chapter_Equk.gif)

Proof.

First assume that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq072.gif) ∈ (Range(A))⊥. Then for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq073.gif) ∈ Dom(A) we have

![
$$\\displaystyle{\\left \\langle \\psi,A\\phi \\right\\rangle = 0.}$$
](A272900_1_En_9_Chapter_Equl.gif)

That is to say, the linear functional ![
$$\\left \\langle \\psi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq29.gif) is bounded—in fact, zero—on Dom(A). Thus, from the definition of the adjoint, we conclude that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq074.gif) ∈ Dom(A ∗) and A ∗ ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq075.gif) = 0.

Meanwhile, suppose that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq076.gif) is in Dom(A ∗) and that A ∗ ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq077.gif) = 0. The only way this can happen is if the linear functional ![
$$\\left \\langle \\psi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq30.gif) is zero on Dom(A), which means that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq078.gif) is orthogonal to the image of A.

Proposition 9.13

Suppose A is an unbounded operator on H and that B is a bounded operator defined on all of H . Let A + B denote the operator with ![
$$\\mathrm{Dom}\(A + B\) =\\mathrm{ Dom}\(A\)$$
](A272900_1_En_9_Chapter_IEq31.gif) and given by ![
$$\(A + B\)\\psi = A\\psi + B\\psi$$
](A272900_1_En_9_Chapter_IEq32.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq079.gif) ∈ Dom (A). Then (A + B) ∗ has the same domain as A ∗ and ![
$${\(A + B\)}^{{\\ast}}\\psi = {A}^{{\\ast}}\\psi + {B}^{{\\ast}}\\psi$$
](A272900_1_En_9_Chapter_IEq33.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq080.gif) ∈ Dom (A ∗ ).

In particular, the sum of an unbounded self-adjoint operator and a bounded self-adjoint operator (defined on all of H ) is self-adjoint on the domain of the unbounded operator.

Proof.

See Exercise 3.

The sum of two unbounded self-adjoint operators is not, in general, self-adjoint. See Sect. 9.9 for more information about this issue.

Proposition 9.14

Let A be a closed operator and λ an element of ![
$$\\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq34.gif) . Suppose that there exists ![
$$\\varepsilon > 0$$
](A272900_1_En_9_Chapter_IEq35.gif) such that

![
$$\\displaystyle{ \\left \\Vert \(A -\\lambda I\)\\psi \\right\\Vert \\geq \\varepsilon \\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equ2.gif)

(9.2)

for all A in Dom (A). Then the range of A −λI is a closed subspace of H.

Here, we take the domain of the operator A − λI to coincide with the domain of A, as in Proposition 9.13.

Proof.

Assume that ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq081.gif) n is a sequence in the range of A − λI converging to some ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq082.gif). Then ![
$$\\phi _{n} = \(A -\\lambda I\)\\psi _{n}$$
](A272900_1_En_9_Chapter_IEq36.gif), for some sequence ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq083.gif) in Dom(A). Applying (9.2) with ![
$$\\psi =\\psi _{n} -\\psi _{m}$$
](A272900_1_En_9_Chapter_IEq37.gif) shows that ![
$$\\left \\Vert \\psi _{n} -\\psi _{m}\\right\\Vert \\leq \(1/\\varepsilon \)\\left \\Vert \\phi _{n} -\\phi _{m}\\right\\Vert$$
](A272900_1_En_9_Chapter_IEq38.gif). This means that ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq084.gif) is Cauchy and thus convergent to some vector ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq085.gif). Since ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0085.gif) → ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq086.gif) and ![
$$\(A -\\lambda I\)\\psi _{n} =\\phi _{n} \\rightarrow \\phi$$
](A272900_1_En_9_Chapter_IEq39.gif), we have that

![
$$\\displaystyle{A\\psi _{n} =\\lambda \\psi _{n} +\\phi _{n} \\rightarrow \\lambda \\psi +\\phi.}$$
](A272900_1_En_9_Chapter_Equm.gif)

Thus, by the definition of a closed operator, ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq087.gif) ∈ Dom(A) and ![
$$A\\psi =\\lambda \\psi +\\phi$$
](A272900_1_En_9_Chapter_IEq40.gif). This means that ![
$$\(A -\\lambda I\)\\psi =\\phi$$
](A272900_1_En_9_Chapter_IEq41.gif) and so the range of A − λI is closed.

We conclude this section with a simple example for which we can compute the adjoint and closure explicitly.

Example 9.15

Let ![
$$\\left \\langle e_{j}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq42.gif) be an orthonormal basis for H and let ![
$$\\left \\langle \\lambda _{j}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq43.gif) be an arbitrary sequence of real numbers. Define an operator A on H with Dom(A) equal to the space of finite linear combinations of the e j 's, with A itself defined by

![
$$\\displaystyle{Ae_{j} =\\lambda _{j}e_{j}.}$$
](A272900_1_En_9_Chapter_Equn.gif)

Then A is symmetric and closable and ![
$$\\mathrm{Dom}\({A}^{{\\ast}}\) =\\mathrm{ Dom}\({A}^{cl}\) = V$$
](A272900_1_En_9_Chapter_IEq44.gif), where

![
$$\\displaystyle{ V = \\left \\{\\left.\\psi =\\sum _{j}a_{j}e_{j}\\right\\vert \\sum _{j}\(1 +\\lambda _{ j}^{2}\){\\left \\vert a_{ j}\\right\\vert }^{2} < \\infty \\right\\}. }$$
](A272900_1_En_9_Chapter_Equ3.gif)

(9.3)

For any ![
$$\\psi =\\sum _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq45.gif) in V, we have

![
$$\\displaystyle{ {A}^{{\\ast}}\\psi = {A}^{cl}\\psi =\\sum _{ j}a_{j}\\lambda _{j}e_{j}. }$$
](A272900_1_En_9_Chapter_Equ4.gif)

(9.4)

Thus, ![
$${\({A}^{cl}\)}^{{\\ast}} = {A}^{{\\ast}} = {A}^{cl}$$
](A272900_1_En_9_Chapter_IEq46.gif), showing that A is essentially self-adjoint.

Proof.

Note that for any sequence ![
$$\\left \\langle a_{j}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq47.gif) of coefficients satisfying the condition on the right-hand side of (9.3), we have ![
$$\\sum _{j}{\\left \\vert a_{j}\\right\\vert }^{2} < \\infty $$
](A272900_1_En_9_Chapter_IEq48.gif) and, thus, the sum ![
$$\\sum _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq49.gif) converges in H. Suppose first that ![
$$\\phi =\\sum _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq50.gif) belongs V. Then for any ![
$$\\psi =\\sum _{j}b_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq51.gif) (finite sum) in the domain of A we have

![
$$\\displaystyle{\\left \\langle \\phi,A\\psi \\right\\rangle =\\sum _{j}\\overline{a_{j}}\\lambda _{j}b_{j}}$$
](A272900_1_En_9_Chapter_Equo.gif)

and so by the Cauchy–Schwarz inequality,

![
$$\\displaystyle{\\left \\vert \\left \\langle \\phi,A\\psi \\right\\rangle \\right\\vert \\leq {\\left \(\\sum _{j}\\lambda _{j}^{2}{\\left \\vert a_{ j}\\right\\vert }^{2}\\right\)}^{1/2}\\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_9_Chapter_Equp.gif)

Thus, ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq52.gif) is a bounded linear functional, showing that ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq088.gif) ∈ Dom(A ∗). Furthermore, it is apparent that ![
$$\\left \\langle \\phi,A\\psi \\right\\rangle = \\left \\langle \\chi,\\psi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq53.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq089.gif) ∈ Dom(A), where ![
$$\\chi =\\sum _{j}a_{j}\\lambda _{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq54.gif).

Meanwhile, suppose ![
$$\\phi =\\sum _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq55.gif) belongs to the domain of A ∗, and consider ![
$$\\psi _{N} :=\\sum _{ j=1}^{N}\\lambda _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq56.gif) in Dom(A). Then

![
$$\\displaystyle{\\left \\vert \\left \\langle \\phi,A\\psi _{N}\\right\\rangle \\right\\vert =\\sum _{ j=1}^{N}\\lambda _{ j}^{2}{\\left \\vert a_{ j}\\right\\vert }^{2} ={ \\left \(\\sum _{ j=1}^{N}\\lambda _{ j}^{2}{\\left \\vert a_{ j}\\right\\vert }^{2}\\right\)}^{1/2}\\left \\Vert \\psi _{ N}\\right\\Vert.}$$
](A272900_1_En_9_Chapter_Equq.gif)

Since ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq090.gif) ∈ Dom(A ∗), the functional ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq57.gif) is bounded, and so ![
$$\\sum _{j=1}^{N}\\lambda _{j}^{2}{\\left \\vert a_{j}\\right\\vert }^{2}$$
](A272900_1_En_9_Chapter_IEq58.gif) must be bounded, independent of N, and so ![
$$\\sum _{j}\\lambda _{j}^{2}{\\left \\vert a_{j}\\right\\vert }^{2} < \\infty $$
](A272900_1_En_9_Chapter_IEq59.gif). Since ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq091.gif) belongs to H, we have also that ![
$$\\sum _{j}{\\left \\vert a_{j}\\right\\vert }^{2} < \\infty $$
](A272900_1_En_9_Chapter_IEq60.gif), showing that ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq092.gif) is in V.

Turning now to the closure of A, it is apparent that A is symmetric and thus closable, by Proposition 9.8. Suppose ![
$$\\psi =\\sum _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq61.gif) belongs to V and consider ![
$$\\psi _{N} :=\\sum _{ j=1}^{N}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq62.gif). Clearly, ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq093.gif) N converges to ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0094.gif). Furthermore, since ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq094.gif) ∈ V, we see that ![
$$A_{\\psi N}$$
](A272900_1_En_9_Chapter_IEq095.gif) converges to the vector ![
$$\\sum _{j}a_{j}\\lambda _{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq63.gif). This shows that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq096.gif) ∈ Dom(A cl ) and that ![
$${A}^{cl}\\psi =\\sum _{j}a_{j}\\lambda _{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq64.gif). Thus, each element of V belongs to Dom(A cl ) and A cl is given on V by (9.4).

Now, the space V forms a Hilbert space with respect to the norm given by

![
$$\\displaystyle{\\left \\Vert \\psi \\right\\Vert _{V }^{2} =\\sum _{ j}\(1 +\\lambda _{ j}^{2}\){\\left \\vert a_{ j}\\right\\vert }^{2},}$$
](A272900_1_En_9_Chapter_Equr.gif)

where ![
$$\\psi =\\sum _{j}a_{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq65.gif). [To establish completeness of V with respect to this norm, note that V can be identified isometrically with ![
$${L}^{2}\(\\mathbb{N}\)$$
](A272900_1_En_9_Chapter_IEq66.gif) with respect to the measure μ for which ![
$$\\mu \(\\{j\\}\) = 1 +\\lambda _{ j}^{2}$$
](A272900_1_En_9_Chapter_IEq67.gif).] Suppose, now, that we have a sequence ![
$$\\left \\langle {\\psi }^{m}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq68.gif) in Dom(A) for which both ![
$$\\left \\langle \\psi _{m}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq69.gif) and ![
$$\\left \\langle A\\psi _{m}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq70.gif) are convergent. Then ![
$$\\left \\langle {\\psi }^{m}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq71.gif) forms a Cauchy sequence in V which converges to some element ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq097.gif) of V. Since ![
$$\\left \\Vert \\psi \\right\\Vert _{\\mathbf{H}} \\leq \\left \\Vert \\psi \\right\\Vert _{V }$$
](A272900_1_En_9_Chapter_IEq72.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq098.gif) ∈ Dom(A), we see that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq099.gif) m also converges in H to ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0100.gif) ∈ V. This shows that each element of Dom(A cl ) belongs to V.

## 9.4 The Spectrum of an Unbounded Operator

Recall that if A is a bounded operator, then a number ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq73.gif) belongs to the resolvent set of A if the operator A − λI has a bounded inverse, and λ belongs to the spectrum of A if A − λI does not have a bounded inverse. For an unbounded operator A, we will say that a number ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq74.gif) is in the resolvent set of A if A − λI has a bounded inverse. That is, even though A is unbounded, for λ to be in the resolvent set of A, there must be a bounded inverse to A − λI; otherwise, λ is in the spectrum of A. We make this characterization more precise in the following definition.

Definition 9.16.

Suppose A is an unbounded operator on H. A number ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq75.gif) belongs to the resolvent set of A if there exists a bounded operator B with the following properties: (1) For all ![
$$\\psi \\in \\bf{H}, B\\psi$$
](A272900_1_En_9_Chapter_IEq0101.gif) belongs to Dom(A) and ![
$$\(A -\\lambda I\)B\\psi =\\psi$$
](A272900_1_En_9_Chapter_IEq76.gif), and (2) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0102.gif) ∈ Dom(A) we have ![
$$B\(A -\\lambda I\)\\psi =\\psi$$
](A272900_1_En_9_Chapter_IEq77.gif).

If no such bounded operator B exists, then λ belongs to the spectrum of A.

Note that we are implicitly taking Dom(A − λI) to equal Dom(A), as in Proposition 9.13. As in the bounded case, even if A is self-adjoint, points λ in the spectrum of A are not necessarily eigenvalues; that is, there does not necessarily exist a nonzero ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0103.gif) ∈ Dom(A) with ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_9_Chapter_IEq0104.gif). On the other hand, if ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_9_Chapter_IEq0105.gif) for some ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0106.gif) ∈ Dom(A), then A − λI is not injective and thus λ certainly does belong to the spectrum of A.

Theorem 9.17

If A is an unbounded self-adjoint operator on H , the spectrum of A is contained in the real line.

If A is symmetric but not self-adjoint, then the spectrum of A must contain points not in the real line. Indeed, Theorem 9.21 will show that at least one of (A − iI) and (A \+ iI) must fail to be surjective, and thus at least one of the numbers i and − i is in the spectrum of A. Nevertheless, a symmetric operator cannot have nonreal eigenvalues, as we showed already in Proposition 3.4.

Proof.

Consider a complex number ![
$$\\lambda = a + ib$$
](A272900_1_En_9_Chapter_IEq78.gif) with b ≠ 0. Since A is symmetric, the proof of Lemma 7.8 applies, giving

![
$$\\displaystyle{ \\left \\langle \(A -\\lambda I\)\\psi,\(A -\\lambda I\)\\psi \\right\\rangle \\geq {b}^{2}\\left \\langle \\psi,\\psi \\right\\rangle }$$
](A272900_1_En_9_Chapter_Equ5.gif)

(9.5)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0107.gif) ∈ Dom(A). This shows that (A − λI) is injective.

Meanwhile, applying Propositions 9.12 and 9.13 with ![
$$B = -\\lambda I$$
](A272900_1_En_9_Chapter_IEq79.gif) we see that

![
$$\\displaystyle{{\(\\mathrm{Range}\(A -\\lambda I\)\)}^{\\perp } =\\ker \({\(A -\\lambda I\)}^{{\\ast}}\) =\\ker \({A}^{{\\ast}}-\\bar{\\lambda } I\) =\\ker \(A -\\bar{\\lambda } I\).}$$
](A272900_1_En_9_Chapter_Equs.gif)

Since ![
$$\\bar{\\lambda }$$
](A272900_1_En_9_Chapter_IEq80.gif) again has nonzero imaginary part, ![
$$A -\\bar{\\lambda } I$$
](A272900_1_En_9_Chapter_IEq81.gif) is also injective, showing that Range(A − λI) is dense in H. Since A = A ∗ is closed, (9.5) allows us to apply Proposition 9.14 to show that Range(A − λI) is closed, hence all of H.

We have shown, then, that (A − λI) maps Dom(A) injectively onto H. It follows from (9.5) (or the closed graph theorem) that the inverse operator is bounded, so that λ is in the resolvent set of A.

Our next result shows that the spectrum of an unbounded self-adjoint operator has properties similar to that of a bounded self-adjoint operator.

Proposition 9.18

If A is an unbounded self-adjoint operator on H , then the following hold.

1.

A number ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq82.gif) belongs to the spectrum of A if and only if there exists a sequence ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0108.gif) of nonzero vectors in Dom (A) such that

![
$$\\displaystyle{ \\lim _{n\\rightarrow \\infty }\\frac{\\left \\Vert \(A -\\lambda I\)\\psi _{n}\\right\\Vert } {\\left \\Vert \\psi _{n}\\right\\Vert } = 0. }$$
](A272900_1_En_9_Chapter_Equ6.gif)

(9.6)

2.

The spectrum σ(A) of A is a closed subset of ![
$$\\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq83.gif).

Although the spectrum of a bounded self-adjoint operator is a bounded subset of ![
$$\\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq84.gif), the spectrum of an unbounded self-adjoint operator will be unbounded. Indeed, it can be shown (using the spectral theorem) that if a self-adjoint operator has bounded spectrum, then the operator must be bounded.

Proof.

For Point 1, if a sequence as in (9.6) existed, then as in the proof of Proposition 7.7, A − λI could not have a bounded inverse, so λ must be in the spectrum of A. Conversely, suppose no such sequence exists. Then there is some ![
$$\\varepsilon > 0$$
](A272900_1_En_9_Chapter_IEq85.gif) such that

![
$$\\displaystyle{ \\left \\Vert \(A -\\lambda I\)\\psi \\right\\Vert \\geq \\varepsilon \\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equ7.gif)

(9.7)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0109.gif) ∈ Dom(A). This means that A − λI is injective and that, by Proposition 9.14, the range of A − λI is closed. But

![
$$\\displaystyle{{\(A -\\lambda I\)}^{{\\ast}} = {A}^{{\\ast}}-\\lambda I = A -\\lambda I}$$
](A272900_1_En_9_Chapter_Equt.gif)

and A − λI is injective, so by Proposition 9.12, the range of A − λI is all of H. This means A − λI has an inverse, which is bounded by (9.7). Thus λ is not in the spectrum of A.

Point 2 is left as an exercise (Exercise 4).

Definition 9.19.

Let A be an unbounded operator on H. Then A is non-negative if ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle \\geq 0$$
](A272900_1_En_9_Chapter_IEq86.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0110.gif) ∈ Dom(A) and A is bounded below by ![
$$c \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq87.gif) if ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle \\geq c{\\left \\Vert \\psi \\right\\Vert }^{2}$$
](A272900_1_En_9_Chapter_IEq88.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0111.gif) ∈ Dom(A).

Proposition 9.20

Let A be an unbounded self-adjoint operator on H . If A is non-negative, then the spectrum of A is contained in [0,∞). More generally, if A is bounded below by c, then the spectrum of A is contained in [c,∞).

We will eventually see, using the spectral theorem for unbounded self-adjoint operators, that the converse to Proposition 9.20 also holds: If the spectrum of a self-adjoint operator A is contained in [0, ∞), then A is non-negative, and if the spectrum of A is contained in [c, ∞), then A is bounded below by c. These results follow easily, for example, from the form of the spectral theorem in Theorem 10.9.

Proof.

Suppose A is bounded below by c and λ is a point in the spectrum of A. If ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0112.gif) be a sequence as in Point 1 of Proposition 9.18, with the ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0113.gif)'s normalized to be unit vectors, then

![
$$\\displaystyle{\\lim _{n\\rightarrow \\infty }\\left \\vert \\left \\langle \\psi _{n},\(A -\\lambda I\)\\psi _{n}\\right\\rangle \\right\\vert \\leq \\lim _{n\\rightarrow \\infty }\\left \\Vert \(A -\\lambda I\)\\psi _{n}\\right\\Vert = 0.}$$
](A272900_1_En_9_Chapter_Equu.gif)

On the other hand, ![
$$A =\\lambda I + \(A -\\lambda I\)$$
](A272900_1_En_9_Chapter_IEq89.gif), and so

![
$$\\displaystyle{\\left \\langle \\psi _{n},A\\psi _{n}\\right\\rangle =\\lambda +\\left \\langle \\psi _{n},\(A -\\lambda I\)\\psi _{n}\\right\\rangle.}$$
](A272900_1_En_9_Chapter_Equv.gif)

Thus, ![
$$\\left \\langle \\psi _{n},A\\psi _{n}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq90.gif) converges to λ (![
$$=\\lambda \\left \\langle \\psi _{n},\\psi _{n}\\right\\rangle$$
](A272900_1_En_9_Chapter_IEq91.gif)) as n tends to infinity. Since A is bounded below by c, we must have λ ≥ c. This establishes the result for operators bounded below by c. Specializing to c = 0 gives the result for non-negative operators.

## 9.5 Conditions for Self-Adjointness and Essential Self-Adjointness

In this section, we give criteria for determining whether a symmetric operator is self-adjoint or essentially self-adjoint. See also Sect.​ 10.​2 for the connection between self-adjoint operators and one-parameter unitary groups.

Theorem 9.21

If A is a symmetric operator on H , then A is essentially self-adjoint if and only if Range (A − iI) and Range (A + iI) are dense subspaces of H.

Using Proposition 9.12, we can reformulate this result as follows.

Corollary 9.22.

If A is a symmetric operator on H , then A is essentially self-adjoint if and only if the operators A ∗ \+ iI and A ∗ − iI are injective on Dom (A ∗).

As Exercise 11 shows, it is possible to have one of the operators A ∗ \+ iI and A ∗ − iI be injective and the other fail to be injective.

Proof of Theorem 9.21.

Assume first that A is essentially self-adjoint, so that A cl is self-adjoint. Then ![
$${A}^{{\\ast}} = {\({A}^{cl}\)}^{{\\ast}} = {A}^{cl}$$
](A272900_1_En_9_Chapter_IEq92.gif), and so

![
$$\\displaystyle{{\\left \[\\mathrm{Range}\(A - iI\)\\right\]}^{\\perp } =\\ker \({A}^{{\\ast}} + iI\) =\\ker \({A}^{cl} + iI\) =\\{ 0\\},}$$
](A272900_1_En_9_Chapter_Equw.gif)

by Theorem 9.17, and similarly for the range of A \+ iI.

Conversely, assume A is symmetric and that A − iI and A \+ iI both have dense range. Since ![
$${\({A}^{cl}\)}^{{\\ast}} = {A}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq93.gif) is a closed extension of A, it is also an extension of A cl , showing that A cl is symmetric. We may then apply Lemma 7.8—the proof of which requires only symmetry—to the operator A cl with λ = i, giving

![
$$\\displaystyle{{ \\left \\Vert \({A}^{cl} - iI\)\\psi \\right\\Vert }^{2} \\geq {\\left \\Vert \\psi \\right\\Vert }^{2} }$$
](A272900_1_En_9_Chapter_Equ8.gif)

(9.8)

and showing that A cl − iI is injective. Since the range of A − iI is dense, the range of A cl − iI is certainly also dense. But since A cl is closed, (9.8) and Proposition 9.14 tell us that the range of A cl − iI is closed, hence all of H. Similar reasoning shows that the range of A cl \+ iI is also all of H.

Now, by Proposition 9.13, ![
$${\({A}^{cl} - iI\)}^{{\\ast}} = {\({A}^{cl}\)}^{{\\ast}} + iI$$
](A272900_1_En_9_Chapter_IEq94.gif), which is an extension of A cl \+ iI. Suppose (A cl )∗ \+ iI is a proper extension of A cl \+ iI, that is, that the domain of (A cl )∗ \+ iI is strictly bigger than the domain of A cl \+ iI. Then since A cl \+ iI already maps onto H, (A cl )∗ \+ iI cannot be injective. Thus, the operator

![
$$\\displaystyle{{\({A}^{cl}\)}^{{\\ast}} + iI = {A}^{{\\ast}} + iI = {\(A - iI\)}^{{\\ast}}}$$
](A272900_1_En_9_Chapter_Equx.gif)

must have a nontrivial kernel. Then by Proposition 9.12, Range(A − iI) is not dense, contradicting our assumptions.

We conclude, therefore, that (A cl )∗ \+ iI is not a proper extension of A cl \+ iI, i.e., that ![
$${\({A}^{cl}\)}^{{\\ast}} + iI = {A}^{cl} + iI$$
](A272900_1_En_9_Chapter_IEq95.gif) (with equality of domains). This, by Proposition 9.13, means that ![
$${\({A}^{cl}\)}^{{\\ast}} = {A}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq96.gif) (with equality of domains), which is what we are trying to prove.

Proposition 9.23

If A is a symmetric operator on H , then A is self-adjoint if and only if

![
$$\\displaystyle{\\mathrm{Range}\(A - iI\) =\\mathrm{ Range}\(A + iI\) = \\mathbf{H}.}$$
](A272900_1_En_9_Chapter_Equy.gif)

Proof.

Suppose first that A is self-adjoint. Then by Theorem 9.21, the ranges of A − iI and A \+ iI are dense in H. On the other hand,

![
$$\\displaystyle{{ \\left \\Vert \(A - iI\)\\psi \\right\\Vert }^{2} \\geq {\\left \\Vert \\psi \\right\\Vert }^{2}, }$$
](A272900_1_En_9_Chapter_Equ9.gif)

(9.9)

by (the proof of) Lemma 7.8, with λ = i. Since, also, A = A ∗ is closed, Proposition 9.14 tells us that the range of A − iI is closed, hence all of H. A similar argument shows that the range of A \+ iI is all of H.

Conversely, suppose that the ranges of A − iI and A \+ iI are all of H. Then A is essentially self-adjoint by Theorem 9.21, so that A ∗ is self-adjoint. Since A − iI already maps onto H, if A ∗ were a nontrivial extension of A, then A ∗ − iI could not be injective. But (9.9), with A replaced by A ∗, shows that A ∗ − iI is injective. Thus, A = A ∗ and so A is self-adjoint.

In the case that A is positive-semidefinite (i.e., ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle \\geq 0$$
](A272900_1_En_9_Chapter_IEq97.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0114.gif) ∈ Dom(A)), there is another self-adjointness condition, the proof of which is very similar to that of Theorem 9.22.

Theorem 9.24

Suppose that A is a symmetric operator on H and that ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle \\geq 0$$
](A272900_1_En_9_Chapter_IEq98.gif) for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0115.gif) ∈ Dom (A). Then A is essentially self-adjoint if and only if A + I has dense range. Equivalently, A is essentially self-adjoint if and only if A ∗ \+ I is injective.

Proof.

Assume first that A is essentially self-adjoint. Then ![
$${\(A + I\)}^{{\\ast}} = {A}^{{\\ast}} + I = {A}^{cl} + I$$
](A272900_1_En_9_Chapter_IEq99.gif). It is easily seen that A cl is also positive definite, and so

![
$$\\displaystyle{ \\left \\langle \\psi,\({A}^{cl} + I\)\\psi \\right\\rangle = \\left \\langle \\psi,\\psi \\right\\rangle + \\left \\langle \\psi,{A}^{cl}\\psi \\right\\rangle \\geq \\left \\langle \\psi,\\psi \\right\\rangle }$$
](A272900_1_En_9_Chapter_Equ10.gif)

(9.10)

Thus, ![
$${A}^{cl} + I = {\(A + I\)}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq100.gif) is injective. Thus, the range of A \+ I is dense, by Proposition 9.12.

Now assume that A \+ I has dense range. By (9.10), A cl \+ I is injective and by (9.10) and Proposition 9.14, the range of A cl \+ I is closed, hence all of H. Assume Dom(A ∗) is strictly larger than Dom(A cl ). Then because A cl \+ I is already surjective, A ∗ \+ I (which has a domain equal to the domain of A ∗) cannot be injective. Thus, ![
$${A}^{{\\ast}} + I = {\(A + I\)}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq101.gif) has a nontrivial kernel, which means that the range of A \+ I is not dense. This is a contradiction, and so the domain of A ∗ must actually be equal to the domain of A cl . Since A and so also A cl are symmetric, this means that A cl is self-adjoint.

Example 9.25

Suppose that A is a symmetric operator on H that has an orthonormal basis of eigenvectors. That is to say, suppose there is an orthonormal basis {e  j } for H such that for each j, we have e j ∈ Dom(A) and ![
$$Ae_{j} =\\lambda _{j}e_{j}$$
](A272900_1_En_9_Chapter_IEq102.gif) for some real number λ j . Then A is essentially self-adjoint.

This result is a strengthening of Example 9.15, in that we do not assume that the domain of A is equal to the space of finite linear combinations of the e j 's.

Proof.

For any j, ![
$$\(A - iI\)e_{j} = \(\\lambda _{j} - i\)e_{j}$$
](A272900_1_En_9_Chapter_IEq103.gif). Since λ j is real, we have a nonzero multiple of e j belonging to Range(A − iI), for each j. This shows that Range(A − iI) is dense, and similarly for Range(A \+ iI).

Example 9.26

Suppose H is a Hilbert space direct sum of a sequence of separable Hilbert spaces H j :

![
$$\\displaystyle{\\mathbf{H} = \\bigoplus \\limits _{j=1}^{\\infty }\\mathbf{H}_{ j}.}$$
](A272900_1_En_9_Chapter_Equz.gif)

Suppose also that A j is a bounded self-adjoint operator on H j , for each j. Define a subspace V of H by

![
$$\\displaystyle{V = \\left \\{\\psi = \(\\psi _{1},\\psi _{2},\\ldots \)\\left \\vert \\sum _{j=1}^{\\infty }\\left \(\\left \\Vert \\psi _{ j}\\right\\Vert _{j}^{2} + \\left \\Vert A_{ j}\\psi _{j}\\right\\Vert _{j}^{2}\\right\) < \\infty \\right.\\right\\}.}$$
](A272900_1_En_9_Chapter_Equaa.gif)

Suppose now that A is a symmetric operator on H whose domain contains the finite direct sum of the H j 's and such that ![
$$\\left.A\\right\\vert _{\\mathbf{H}_{j}} = A_{j}$$
](A272900_1_En_9_Chapter_IEq104.gif). Then A is essentially self-adjoint, ![
$$\\mathrm{Dom}\({A}^{cl}\) =\\mathrm{ Dom}\({A}^{{\\ast}}\) = V$$
](A272900_1_En_9_Chapter_IEq105.gif), and

![
$$\\displaystyle{ {A}^{cl}\\psi = {A}^{{\\ast}}\\psi = \(A_{ 1}\\psi _{1},A_{2}\\psi _{2},\\ldots \) }$$
](A272900_1_En_9_Chapter_Equ11.gif)

(9.11)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0116.gif) = (![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0117.gif) 1, ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0118.gif) 2,...) in V.

See Definition A.45 for the definition of the Hilbert direct sum and the finite direct sum of a sequence of Hilbert spaces. Example 9.25 is the special case of Example 9.26 in which each H j has dimension 1. This result will be useful to us in Chap.​ 10.

Proof.

Since A j is self-adjoint, the ranges of A j − iI and A j \+ iI are dense in H j . Thus, the closure of the range of A − iI contains each H j and is therefore dense in H, and similarly for A \+ iI. This shows that A is essentially self-adjoint.

It remains to show that the domain of A ∗ = A cl is V. Let W denote the finite direct sum of the H j 's. By the argument in the previous paragraph, ![
$$\\left.A\\right\\vert _{W}$$
](A272900_1_En_9_Chapter_IEq106.gif) is essentially self-adjoint. Then A ∗ is a symmetric extension of ![
$${\(\\left.A\\right\\vert _{W}\)}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq107.gif), which must coincide with ![
$${\(\\left.A\\right\\vert _{W}\)}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq108.gif). Thus, it suffices to consider the case Dom(A) = W.

If we assume that Dom(A) = W, we can compute the adjoint of A by the argument in Example 9.15. If ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0119.gif) ∈ V, then the Cauchy–Schwarz inequality shows that the linear functional ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq109.gif) is bounded and that A ∗ ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0120.gif) is as (9.11). On the other hand, if ![
$$\\left \\langle \\phi,A\\cdot \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq110.gif) is bounded, where ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0121.gif) = (![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0122.gif) 1, ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0123.gif) 2,...), take

![
$$\\displaystyle{\\psi _{N} = \(\\phi _{1},\\phi _{2},\\ldots,\\phi _{N},0,0,\\ldots \).}$$
](A272900_1_En_9_Chapter_Equab.gif)

Then, as in the proof of Example 9.15, the only way we can have ![
$$\\left \\vert \\left \\langle \\phi,A\\psi _{N}\\right\\rangle \\right\\vert \\leq C\\left \\Vert \\psi _{N}\\right\\Vert$$
](A272900_1_En_9_Chapter_IEq111.gif) is if ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0124.gif) belongs to V.

## 9.6 A Counterexample

In this section, we will examine an elementary example of an operator that is symmetric but not essentially self-adjoint. Our example will be essentially the momentum operator on a finite interval, with "wrong" boundary conditions. (A more sophisticated example is given in Sect. 9.10.) We take our Hilbert space to be L 2([0, 1]).

Proposition 9.27

Let Dom (A) ⊂ L 2 ([0,1]) be the space of continuously differentiable functions f on [0,1] satisfying

![
$$\\displaystyle{\\psi \(0\) =\\psi \(1\) = 0.}$$
](A272900_1_En_9_Chapter_Equac.gif)

For ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq00125.gif) ∈ Dom (A), define

![
$$\\displaystyle{A\\psi = -i\\hslash \\frac{d\\psi } {dx}.}$$
](A272900_1_En_9_Chapter_Equad.gif)

Then A is symmetric but not essentially self-adjoint.

We can understand the failure of essential self-adjointness of A in practical terms as a failure of the spectral theorem. The eigenvector equation ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_9_Chapter_IEq0125.gif) for ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq112.gif) is a first-order ordinary differential equation, whose general solution is ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0127.gif)(x) = ce iλx , where c is a constant. The only way such a function can satisfy the boundary conditions ![
$$\\psi \(0\) =\\psi \(1\) = 0$$
](A272900_1_En_9_Chapter_IEq113.gif) is if c = 0, in which case ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0128.gif) is the zero vector. Thus, A has no eigenvectors. Furthermore, taking the closure of A does not help, because, as the proof will show, the boundary conditions survive taking the closure.

Proof of symmetry.

Using integration by parts we see that for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0129.gif) and ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0130.gif) in Dom(A) we have

![
$$\\displaystyle{ \\int _{0}^{1}\\overline{\\phi \(x\)} \\frac{d\\psi } {dx}\\ dx = \\overline{\\phi \(1\)}\\psi \(1\) -\\overline{\\phi \(0\)}\\psi \(0\) -\\int _{0}^{1}\\overline{ \\frac{d\\phi } {dx}}\\psi \(x\)\\ dx. }$$
](A272900_1_En_9_Chapter_Equ12.gif)

(9.12)

Since we assume ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq00131.gif) and ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0131.gif) are in Dom(A), the boundary terms are zero and we get

![
$$\\displaystyle{\\left \\langle \\phi, \\frac{d\\psi } {dx}\\right\\rangle _{{L}^{2}\(\[0,1\]\)} = -\\left \\langle \\frac{d\\phi } {dx},\\psi \\right\\rangle _{{L}^{2}\(\[0,1\]\)}.}$$
](A272900_1_En_9_Chapter_Equae.gif)

Because there is a conjugate in one side of the inner product but not the other, it follows that

![
$$\\displaystyle{\\left \\langle \\phi,-i\\hslash \\frac{d\\psi } {dx}\\right\\rangle _{{L}^{2}\(\[0,1\]\)} = \\left \\langle -i\\hslash \\frac{d\\phi } {dx},\\psi \\right\\rangle _{{L}^{2}\(\[0,1\]\)},}$$
](A272900_1_En_9_Chapter_Equaf.gif)

as claimed.

We now consider A cl and ![
$${A}^{{\\ast}} = {\({A}^{cl}\)}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq114.gif). We will see that there are elements of the domain of the adjoint that are not in the domain of the closure.

Lemma 9.28.

If ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0132.gif) is a continuously differentiable function on [0,1], then ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0133.gif) ∈ Dom (A ∗ ) and ![
$${A}^{{\\ast}}\\phi = -i\\hslash \\ d\\phi /dx$$
](A272900_1_En_9_Chapter_IEq115.gif).

Proof.

If ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq00134.gif) is continuously differentiable, then for any ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0134.gif) in Dom(A), we may integrate by parts as in (9.12). Since ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0135.gif) is zero at both ends of the interval, the boundary terms vanish and we obtain

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \\phi,A\\psi \\right\\rangle & =& i\\hslash \\int _{0}^{1}\\overline{ \\frac{d\\phi } {dx}}\\psi \(x\)\\ dx \\\\ & =& \\int _{0}^{1}\\overline{\\left \(-i\\hslash \\frac{d\\phi } {dx}\\right\)}\\psi \(x\)\\ dx{}\\end{array}$$
](A272900_1_En_9_Chapter_Equ13.gif)

(9.13)

Since ![
$$d\\phi / dx$$
](A272900_1_En_9_Chapter_IEq0136.gif) is continuous and hence in L 2([0, 1]), we see that (9.13) is a continuous linear functional, as a function of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0137.gif) with fixed ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0138.gif). Thus, ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0139.gif) is in the domain of A ∗, and ![
$${A}^{{\\ast}}\\phi = -i\\ d\\phi /dx$$
](A272900_1_En_9_Chapter_IEq116.gif).

Proof of Proposition 9.27.

Suppose ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0140.gif) is in the domain of A cl . Then there exist ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0141.gif) in Dom(A) such that ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0142.gif) converges to ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0143.gif) and ![
$$A\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0144.gif) converges to some χ ∈ L 2([0, 1]). Since the derivatives of the ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0145.gif)'s are converging in L 2, the ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0146.gif)'s themselves must be converging uniformly, as can be shown by writing each ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq00147.gif) as the integral of its derivative. (See Exercise 10.) It follows that every element of Dom(A cl ) is continuous and vanishes at both ends of the interval. On the other hand, Dom(A ∗) contains all smooth functions, including many that do not vanish at the ends of the interval. Thus, A cl and ![
$${\({A}^{cl}\)}^{{\\ast}} = {A}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq117.gif) do not have the same domains.

It follows from Lemma 9.28 that every complex number λ belongs to the spectrum of A cl . See Exercise 9.

The reason that A fails to be essentially self-adjoint is that we impose too many boundary conditions on functions in the domain of A, which results in there being too few boundary conditions (in this case, no boundary conditions at all) on functions in the domain of A ∗. In this example, A ∗ is given by the same formula as A (![
$$-id/dx$$
](A272900_1_En_9_Chapter_IEq118.gif) in both cases), but the domain of A ∗ is bigger than the domain of A cl .

Suppose we define another operator B, still given by the formula ![
$$-i\\ d/dx$$
](A272900_1_En_9_Chapter_IEq119.gif), but with the domain of B to be the space of continuously differentiable functions ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0147.gif) with ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0148.gif)(0) = ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0149.gif)(1). If we integrate by parts as in (9.12), the boundary terms will cancel, showing that B is symmetric. Meanwhile, the functions ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0150.gif)(x) : = e 2πinx , ![
$$n \\in \\mathbb{Z}$$
](A272900_1_En_9_Chapter_IEq120.gif), form an orthonormal basis for L 2([0, 1]) consisting of eigenvectors for B, with real eigenvalues λ n = 2πn. Thus, by Example 9.25, B is essentially self-adjoint.

## 9.7 An Example

We now give an example of an operator that is essentially self-adjoint. Let ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq121.gif) denote the space of smooth, compactly supported functions on ![
$$\\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq122.gif).

Proposition 9.29

Let P be the densely defined operator with ![
$$\\mathrm{Dom}\(P\) = C_{c}^{\\infty }\(\\mathbb{R}\) \\subset {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq123.gif) and given by ![
$$P\\psi = -i\\hslash \\ d\\psi /dx$$
](A272900_1_En_9_Chapter_IEq124.gif) . Then P is essentially self-adjoint.

Proof.

Our strategy is to apply Corollary 9.22. Since P is symmetric, we expect that P ∗ will be given by the formula ![
$$-i\\hslash \\ d/dx$$
](A272900_1_En_9_Chapter_IEq125.gif), on some suitable domain inside ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq126.gif). Thus, if ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0151.gif) ∈ ker(P ∗ \+ iI), this should mean that ![
$$-i\\hslash \\ d\\psi /dx = -i\\psi$$
](A272900_1_En_9_Chapter_IEq127.gif), or ![
$$d\\psi /dx = \(1/\\hslash \)\\psi \(x\)$$
](A272900_1_En_9_Chapter_IEq128.gif), which ought to imply that ![
$$\\psi \(x\) = c{e}^{x/\\hslash }$$
](A272900_1_En_9_Chapter_IEq129.gif), for some constant c. Since ce x ∕ ℏ belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq130.gif) only if c = 0, we hope to conclude that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0152.gif) = 0.

To say that ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq131.gif) belongs to the kernel of P ∗ \+ iI means that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0153.gif) belongs to Dom(P ∗) and that ![
$${P}^{{\\ast}}\\psi = -i\\psi$$
](A272900_1_En_9_Chapter_IEq132.gif). This holds if and only if

![
$$\\displaystyle{-i\\hslash \\int _{\\mathbb{R}}\\overline{ \\frac{d\\chi } {dx}}\\psi \(x\)\\ dx = i\\int _{\\mathbb{R}}\\overline{\\chi \(x\)}\\psi \(x\)\\ dx}$$
](A272900_1_En_9_Chapter_Equag.gif)

for all ![
$$\\chi \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq133.gif). For any ![
$$\\xi \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq134.gif), if we take ![
$$\\chi \(x\) =\\xi \(x\){e}^{-x/\\hslash }$$
](A272900_1_En_9_Chapter_IEq135.gif) and combine the integrals into one, we get

![
$$\\displaystyle\\begin{array}{rcl} 0& =& -i\\int _{\\mathbb{R}}\\left \[\\hslash {e}^{-x/\\hslash }\\overline{ \\frac{d\\xi } {dx}} - {e}^{-x/\\hslash }\\overline{\\xi \(x\)} + {e}^{-x/\\hslash }\\overline{\\xi \(x\)}\\right\]\\psi \(x\)\\ dx \\\\ & =& -i\\hslash \\int _{\\mathbb{R}}\\overline{ \\frac{d\\xi } {dx}}{e}^{-x/\\hslash }\\psi \(x\)\\ dx. {}\\end{array}$$
](A272900_1_En_9_Chapter_Equ14.gif)

(9.14)

Now, (9.14) says that the derivative of ![
$${e}^{-x/\\hslash }\\psi \(x\)$$
](A272900_1_En_9_Chapter_IEq136.gif) in the weak or distributional sense is zero. (See Proposition A.29 in Appendix A.3.3.) Thus, by the remarks immediately following Proposition A.5, we must have ![
$${e}^{-x/\\hslash }\\psi \(x\) = c$$
](A272900_1_En_9_Chapter_IEq137.gif) for some c, meaning that ![
$$\\psi \(x\) = c{e}^{x/\\hslash }$$
](A272900_1_En_9_Chapter_IEq138.gif). Since we also assume that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq00154.gif) belongs to ![
$$\\mathrm{Dom}\({P}^{{\\ast}}\) \\subset {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq139.gif), we must have c = 0, so that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0154.gif) is the zero element of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq140.gif).

We have shown, then, that only 0 belongs to the kernel of P ∗ \+ iI. A similar argument with i replaced by − i and e x ∕ ℏ by ![
$${e}^{-x/\\hslash }$$
](A272900_1_En_9_Chapter_IEq141.gif) shows that only 0 belongs to the kernel of P ∗ − iI. Thus, by Corollary 9.22, P is essentially self-adjoint.

## 9.8 The Basic Operators of Quantum Mechanics

In this section, we consider several of the unbounded self-adjoint operators that arise in quantum mechanics. We find natural domains of self- adjointness for the position, momentum, kinetic energy, and potential energy operators. Since Schrödinger operators are more complicated to analyze, we postpone a discussion of them until the next section. We begin with the potential energy operator.

Proposition 9.30

Suppose ![
$$V : {\\mathbb{R}}^{n} \\rightarrow \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq142.gif) is a measurable function. Let V ( X ) be the unbounded operator with domain

![
$$\\displaystyle{\\mathrm{Dom}\(V \(\\mathbf{X}\)\) = \\left \\{\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\left \\vert V \(\\mathbf{x}\)\\psi \(\\mathbf{x}\) \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\right.\\right\\}}$$
](A272900_1_En_9_Chapter_Equah.gif)

and given by

![
$$\\displaystyle{\[V \(\\mathbf{X}\)\\psi \]\(\\mathbf{x}\) = V \(\\mathbf{x}\)\\psi \(\\mathbf{x}\).}$$
](A272900_1_En_9_Chapter_Equai.gif)

Then Dom (V ( X )) is dense in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq143.gif) and V ( X ) is self-adjoint on this domain.

Proof.

Define a subset E m of ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq144.gif) by

![
$$\\displaystyle{E_{m} = \\left \\{\\mathbf{x} \\in {\\mathbb{R}}^{n}\\left \\vert \\left \\vert V \(\\mathbf{x}\)\\right\\vert \\ < m\\right.\\right\\},}$$
](A272900_1_En_9_Chapter_Equaj.gif)

so that ![
$$\\cup _{m}E_{m} = {\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq145.gif). Then for any ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq146.gif), the function ![
$$\\psi 1_{E_{m}}$$
](A272900_1_En_9_Chapter_IEq147.gif) belongs to Dom(V (X)). On the other hand, using dominated convergence, we have ![
$$\\psi 1_{E_{m}} \\rightarrow \\psi$$
](A272900_1_En_9_Chapter_IEq148.gif) as m → ∞, establishing that Dom(V (X)) is dense.

Since V is real-valued, it is easy to see that V (X) is symmetric on Dom(V (X)). Thus, V (X)∗ is an extension of V (X).

Meanwhile, suppose ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0155.gif) ∈ Dom(V (X)∗), meaning that

![
$$\\displaystyle{ \\psi \\mapsto \\int _{X}\\overline{\\phi \(x\)}V \(x\)\\psi \(x\)\\ dx,\\quad \\psi \\in \\mathrm{ Dom}\(V \(\\mathbf{X}\)\) }$$
](A272900_1_En_9_Chapter_Equ15.gif)

(9.15)

is a bounded linear functional. This linear functional has a unique bounded extension to L 2 and, thus, Thus, there exists a unique ![
$$\\chi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq149.gif) such that

![
$$\\displaystyle{ \\int _{X}\\overline{\\psi \(x\)}V \(x\)\\phi \(x\)\\ dx =\\int _{X}\\overline{\\chi \(x\)}\\phi \(x\)\\ dx, }$$
](A272900_1_En_9_Chapter_Equ16.gif)

(9.16)

or

![
$$\\displaystyle{\\int _{X}\\left \[\\overline{\\psi \(x\)}V \(x\) -\\overline{\\chi \(x\)}\\right\]\\phi \(x\)\\ dx = 0}$$
](A272900_1_En_9_Chapter_Equak.gif)

for all ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0156.gif) ∈ Dom(V (X)).

Taking ![
$$\\phi = \(\\psi V -\\chi \)1_{E_{m}}$$
](A272900_1_En_9_Chapter_IEq150.gif), we see that ![
$$\\psi V -\\chi$$
](A272900_1_En_9_Chapter_IEq0157.gif) is zero almost everywhere on E m , for all m, hence zero almost everywhere on ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq151.gif). Thus, ![
$$\\psi V$$
](A272900_1_En_9_Chapter_IEq0158.gif) is equal to χ as an element of ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq152.gif). This shows that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0159.gif) ∈ Dom(V (X)). Thus, actually, Dom(V (X)∗) = Dom(V (X)). Since we have already shown that V (X)∗ is an extension of V (X), we conclude that V (X) is self-adjoint on Dom(V (X)).

If we specialize the preceding proposition to the case V (x) = x j , we obtain the following result about the position operator.

Corollary 9.31.

The position operator X j is self-adjoint on the domain

![
$$\\displaystyle{\\mathrm{Dom}\(X_{j}\) = \\left \\{\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\left \\vert x_{ j}\\psi \(\\mathbf{x}\) \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\right.\\right\\}.}$$
](A272900_1_En_9_Chapter_Equal.gif)

We now turn to consideration of the momentum operator. Since the Fourier transform converts ∂ ∕ ∂ x j into multiplication by ik j (Proposition A.17) we can use the preceding results on multiplication operators to obtain a natural domain on which the momentum operator is self-adjoint.

Proposition 9.32

For each j = 1,2,...,n, define a domain ![
$$\\mathrm{Dom}\(P_{j}\) \\subset {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq153.gif) as follows:

![
$$\\displaystyle{\\mathrm{Dom}\(P_{j}\) = \\left \\{\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\left \\vert k_{ j}\\hat{\\psi }\(\\mathbf{k}\) \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\right.\\right\\},}$$
](A272900_1_En_9_Chapter_Equam.gif)

where ![
$$\\hat{\\psi }$$
](A272900_1_En_9_Chapter_IEq154.gif) is the Fourier transform of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0160.gif). Define P j on this domain by

![
$$\\displaystyle{P_{j}\\psi = {\\mathcal{F}}^{-1}\(\\hslash k_{ j}\\hat{\\psi }\(\\mathbf{k}\)\).}$$
](A272900_1_En_9_Chapter_Equan.gif)

Then P j is self-adjoint on Dom (P j ).

The domain Dom (P j ) of P j can also be described as the set of all ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq155.gif) such that ![
$$\\partial\\psi / \\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq0161.gif), computed in the distribution sense, belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq156.gif) . For any ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0162.gif) ∈ Dom (P j ), we have ![
$$P_{j}\\psi = -i\\hslash \\partial \\psi /\\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq157.gif) , where ![
$$\\partial\\psi / \\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq0163.gif) is computed in the distribution sense.

Saying that the distributional derivative of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0164.gif) belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq158.gif) means (Proposition A.29) that there exists a (unique) ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq00165.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq159.gif) such that

![
$$\\displaystyle{-\\left \\langle \\frac{\\partial \\chi } {\\partial x_{j}},\\psi \\right\\rangle = \\left \\langle \\chi,\\phi \\right\\rangle }$$
](A272900_1_En_9_Chapter_Equao.gif)

for all ![
$$\\chi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq160.gif). If ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0165.gif) is continuously differentiable, then the distributional derivative of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0166.gif) coincides with the ordinary derivative of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0167.gif). Thus, if ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq161.gif) is continuously differentiable, then ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0168.gif) belongs to Dom(P j ) if and only if ![
$$\\partial\\psi / \\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq0169.gif), computed in the pointwise sense, belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq162.gif), in which case ![
$$P_{j}\\psi = -i\\hslash \\partial \\psi /\\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq163.gif). On the other hand, if ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0170.gif) ∈ Dom(P j ), it is not necessarily the case that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0171.gif) is continuously differentiable.

In the case n = 1, the domain of P 1 certainly contains ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq164.gif), since each element ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0172.gif) of ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq165.gif) is a Schwartz function (Definition A.15), so that ![
$$\\hat{\\psi }$$
](A272900_1_En_9_Chapter_IEq166.gif) is also a Schwartz function, in which case ![
$$k\\hat{\\psi }\(k\)$$
](A272900_1_En_9_Chapter_IEq167.gif) belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq168.gif). Now, as shown in Sect. 9.7, the operator ![
$$-i\\hslash d/dx$$
](A272900_1_En_9_Chapter_IEq169.gif) is essentially self-adjoint on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq170.gif), which means that this operator has a unique self-adjoint extension. This self-adjoint extension must, therefore, agree with the operator P 1 in the n = 1 case of Proposition 9.32.

Lemma 9.33.

Suppose ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq171.gif) has the property that ![
$$\\partial\\psi / \\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq00173.gif), computed in the distribution sense, is equal to an L 2 function ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0173.gif). Then ![
$$\\hat{\\phi }\(\\mathbf{k}\) = ik_{j}\\hat{\\psi }\(\\mathbf{k}\)$$
](A272900_1_En_9_Chapter_IEq172.gif) , showing that ![
$$k_{j}\\hat{\\psi }\(\\mathbf{k}\)$$
](A272900_1_En_9_Chapter_IEq173.gif) belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq174.gif).

Conversely, suppose ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq175.gif) has the property that ![
$$k_{j}\\hat{\\psi }\(\\mathbf{k}\)$$
](A272900_1_En_9_Chapter_IEq176.gif) belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq177.gif) . Then ![
$$\\partial\\psi / \\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq0174.gif) , computed in the distribution sense, is equal to the L 2 function ![
$${\\mathcal{F}}^{-1}\(ik_{j}\\mathcal{F}\(\\psi \)\)$$
](A272900_1_En_9_Chapter_IEq178.gif).

Proof.

Suppose ![
$$\\partial\\psi / \\partial x_{j}$$
](A272900_1_En_9_Chapter_IEq0175.gif), computed in the distribution sense, is equal to the L 2 function ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0176.gif) (see Definition A.28). Then by the unitarity of the Fourier transform (Theorem A.19) and its behavior with respect to differentiation (Proposition A.17), we have

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \\chi,\\phi \\right\\rangle & =& -\\left \\langle \\frac{\\partial \\chi } {\\partial x_{j}},\\psi \\right\\rangle {}\\\\ & =& -\\left \\langle ik_{j}\\mathcal{F}\(\\chi \),\\mathcal{F}\(\\psi \)\\right\\rangle, {}\\\\ \\end{array}$$
](A272900_1_En_9_Chapter_Equ17.gif)

for all ![
$$\\chi \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq179.gif). Thus,

![
$$\\displaystyle{\\left \\langle \\mathcal{F}\(\\chi \),\\mathcal{F}\(\\phi \)\\right\\rangle = -\\left \\langle ik_{j}\\mathcal{F}\(\\chi \),\\mathcal{F}\(\\psi \)\\right\\rangle,\\quad \\chi \\in C_{c}^{\\infty }\(\\mathbb{R}\).}$$
](A272900_1_En_9_Chapter_Equap.gif)

Writing this equality out as an integral, we have

![
$$\\displaystyle\\begin{array}{rcl} \\int _{{\\mathbb{R}}^{n}}\\overline{\\hat{\\chi }\(\\mathbf{k}\)}\\hat{\\phi }\(\\mathbf{k}\)\\ d\\mathbf{k}& =& -\\int _{{\\mathbb{R}}^{n}}\\overline{ik_{j}\\hat{\\chi }\(\\mathbf{k}\)}\\hat{\\psi }\(\\mathbf{k}\)\\ d\\mathbf{k} \\\\ & =& \\int _{{\\mathbb{R}}^{n}}\\overline{\\hat{\\chi }\(\\mathbf{k}\)}ik_{j}\\hat{\\psi }\(\\mathbf{k}\)\\ d\\mathbf{k}{}\\end{array}$$
](A272900_1_En_9_Chapter_Equ18.gif)

(9.17)

for all ![
$$\\chi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq181.gif).

We now claim that because (9.17) holds for all ![
$$\\chi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq182.gif), we must have ![
$$\\hat{\\phi }\(\\mathbf{k}\) = ik_{j}\\hat{\\psi }\(\\mathbf{k}\)$$
](A272900_1_En_9_Chapter_IEq183.gif) for almost every k. Using the Stone–Weierstrass theorem and Theorem A.10, it is not hard to show that the space of smooth functions with support in [a, b] is dense in L 2([a, b]), for all ![
$$a < b \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq184.gif). Since both ![
$$\\hat{\\phi }$$
](A272900_1_En_9_Chapter_IEq185.gif) and ![
$$k_{j}\\hat{\\psi }\(\\mathbf{k}\)$$
](A272900_1_En_9_Chapter_IEq186.gif) are locally square-integrable, we see that these two functions are equal almost everywhere on [a, b], for all ![
$$a < b \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq187.gif), and hence equal almost everywhere on ![
$$\\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq188.gif).

Since ![
$$\\hat{\\phi }$$
](A272900_1_En_9_Chapter_IEq189.gif) is globally square-integrable, so is ![
$$k_{j}\\hat{\\psi }\(\\mathbf{k}\)$$
](A272900_1_En_9_Chapter_IEq190.gif). Furthermore, by the injectivity of the L 2 Fourier transform, we have

![
$$\\displaystyle{ \\frac{\\partial \\psi } {\\partial x_{j}} =\\phi = {\\mathcal{F}}^{-1}\(ik_{ j}\\mathcal{F}\(\\psi \)\)}$$
](A272900_1_En_9_Chapter_Equaq.gif)

as claimed.

The argument for the second part of the lemma is similar and left as an exercise (Exercise 12).

Proof of Proposition 9.32.

By Proposition 9.30, the operator of multiplication by k j is an unbounded self-adjoint operator on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq191.gif), with domain equal to the set of ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0177.gif) for which k j ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0178.gif)(k) belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq192.gif). It then follows from the unitarity of the Fourier transform that ![
$$P_{j} = \\hslash {\\mathcal{F}}^{-1}M_{k_{j}}\\mathcal{F}$$
](A272900_1_En_9_Chapter_IEq193.gif) is self-adjoint on ![
$${\\mathcal{F}}^{-1}\(\\mathrm{Dom}\(M_{k_{j}}\)\)$$
](A272900_1_En_9_Chapter_IEq194.gif), where ![
$$M_{k_{j}}$$
](A272900_1_En_9_Chapter_IEq195.gif) denotes multiplication by k j .

The second characterization of Dom(P j ) follows from Lemma 9.33.

Proposition 9.34

Define a domain Dom (Δ) as follows:

![
$$\\displaystyle{\\mathrm{Dom}\(\\Delta \) = \\left \\{\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\left \\vert {\\left \\vert \\mathbf{k}\\right\\vert }^{2}\\hat{\\psi }\(\\mathbf{k}\) \\in {L}^{2}\({\\mathbb{R}}^{n}\)\\right.\\right\\}.}$$
](A272900_1_En_9_Chapter_Equar.gif)

Define Δ on this domain by the expression

![
$$\\displaystyle{ \\Delta \\psi = -{\\mathcal{F}}^{-1}\({\\left \\vert \\mathbf{k}\\right\\vert }^{2}\\hat{\\psi }\(\\mathbf{k}\)\), }$$
](A272900_1_En_9_Chapter_Equ19.gif)

(9.18)

where ![
$$\\hat{\\psi }$$
](A272900_1_En_9_Chapter_IEq196.gif) is the Fourier transform of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq019.gif) and ![
$${\\mathcal{F}}^{-1}$$
](A272900_1_En_9_Chapter_IEq197.gif) is the inverse Fourier. Then Δ is self-adjoint on Dom (Δ).

The domain Dom (Δ) may also be described as the set of all ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq198.gif) such that ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0180.gif), computed in the distribution sense, belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq199.gif) . If ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0181.gif) ∈ Dom (Δ), then ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0182.gif) as defined by ( 9.18 ) agrees with ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0183.gif) computed in the distribution sense.

The proof of Proposition 9.34 is extremely similar to that of Proposition 9.32 and is omitted. Of course, the kinetic energy operator ![
$$-{\\hslash }^{2}\\Delta /\(2m\)$$
](A272900_1_En_9_Chapter_IEq200.gif) is also self-adjoint on the same domain as Δ. It is easy to see from (9.18) and the unitarity of the Fourier transform that ![
$$-{\\hslash }^{2}\\Delta /\(2m\)$$
](A272900_1_En_9_Chapter_IEq201.gif) is non-negative, that is, that

![
$$\\displaystyle{\\left \\langle \\psi,-\\frac{{\\hslash }^{2}} {2m}\\Delta \\psi \\right\\rangle \\geq 0}$$
](A272900_1_En_9_Chapter_Equas.gif)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0184.gif) ∈ Dom(Δ).

Using the same reasoning as in Sects. 9.6 and 9.7, it is not hard to show that the operators P j and Δ are essentially self-adjoint on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq202.gif). See Exercise 16.

Care must be exercised in applying Proposition 9.34. Although the function

![
$$\\displaystyle{\\psi \(\\mathbf{x}\) := \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }}$$
](A272900_1_En_9_Chapter_Equat.gif)

is harmonic on ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_9_Chapter_IEq203.gif), the Laplacian over R 3 of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0185.gif) in the distribution sense is not zero (Exercise 13). (It can be shown, by carefully analyzing the calculation in the proof of Proposition 9.35, that ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0186.gif) is a nonzero multiple of a δ-function.) This example shows that if a function ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0187.gif) has a singularity, calculating the Laplacian of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0188.gif) away from the singularity may not give the correct distributional Laplacian of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0189.gif). For example, the function ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0190.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_9_Chapter_IEq204.gif) given by

![
$$\\displaystyle{ \\phi \(\\mathbf{x}\) := \\frac{{e}^{-{\\left \\vert \\mathbf{x}\\right\\vert }^{2} }} {\\left \\vert \\mathbf{x}\\right\\vert } }$$
](A272900_1_En_9_Chapter_Equ20.gif)

(9.19)

is not in Dom(Δ), even though both ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0200.gif) and ![
$$\\Delta\\phi$$
](A272900_1_En_9_Chapter_IEq0201.gif) are (by direct computation) square-integrable over ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_9_Chapter_IEq205.gif). Indeed, when n ≤ 3, every element of Dom(Δ)n is continuous (Exercise 14).

Proposition 9.35

Suppose ![
$$\\psi \(\\mathbf{x}\) = g\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \)$$
](A272900_1_En_9_Chapter_IEq206.gif) , where g is a smooth function on ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq207.gif) and f is a smooth function on (0,∞). Suppose also that f satisfies

![
$$\\displaystyle\\begin{array}{rcl} \\lim _{r\\rightarrow {0}^{+}}{r}^{n-1}f\(r\)& =& 0 {}\\\\ \\lim _{r\\rightarrow {0}^{+}}{r}^{n-1}{f}^{{\\prime}}\(r\)& =& 0. {}\\\\ \\end{array}$$
](A272900_1_En_9_Chapter_Equ21.gif)

If both ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0202.gif) and ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0203.gif) are square-integrable over ![
$${\\mathbb{R}}^{n}\\setminus \\{0\\}$$
](A272900_1_En_9_Chapter_IEq208.gif), then ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0204.gif) belongs to Dom (Δ).

Note that the second condition in the proposition fails if n = 3 and ![
$$f\(r\) = 1/r$$
](A272900_1_En_9_Chapter_IEq209.gif). We will make use of this result in Chap.​ 18.

Proof.

To apply Proposition 9.34, we need to compute ![
$$\\left \\langle \\psi,\\Delta \\chi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq210.gif), for each ![
$$\\chi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq211.gif). We choose a large cube C, centered at the origin and such that the support of χ is contained in the interior of C. Then we consider the integral of ![
$$\\bar{\\psi }\({\\partial }^{2}\\chi /\\partial x_{j}^{2}\)$$
](A272900_1_En_9_Chapter_IEq212.gif) over ![
$$C\\setminus C_{\\varepsilon }$$
](A272900_1_En_9_Chapter_IEq213.gif), where ![
$$C_{\\varepsilon }$$
](A272900_1_En_9_Chapter_IEq214.gif) is a cube centered at the origin and having side-length ![
$$\\varepsilon$$
](A272900_1_En_9_Chapter_IEq215.gif). We evaluate the x j -integral first and we integrate by parts twice. For "good" values of the remaining variables, x j ranges over all of C, in which case there are no boundary terms to worry about. For "bad" values of the remaining variables, we get two kinds of boundary terms, one involving ![
$$\\bar{\\psi }\(\\partial \\chi /\\partial x_{j}\)$$
](A272900_1_En_9_Chapter_IEq216.gif) and one involving ![
$$\(\\partial \\bar{\\psi }/\\partial x_{j}\)\\chi$$
](A272900_1_En_9_Chapter_IEq217.gif), in both cases integrated over two opposite faces of ![
$$C_{\\varepsilon }$$
](A272900_1_En_9_Chapter_IEq218.gif).

Now,

![
$$\\displaystyle{ \\frac{\\partial \\psi } {\\partial x_{j}} = \\frac{\\partial g} {\\partial x_{j}}f\(\\left \\vert \\mathbf{x}\\right\\vert \) + g\(\\mathbf{x}\)\\frac{df} {dr} \\frac{x_{j}} {r}.}$$
](A272900_1_En_9_Chapter_Equau.gif)

Since the area of the faces of the cube is ![
$${\\varepsilon }^{n-1}$$
](A272900_1_En_9_Chapter_IEq219.gif), the assumption on f will cause the boundary terms to disappear in the limit as ![
$$\\varepsilon$$
](A272900_1_En_9_Chapter_IEq220.gif) tends to zero. Furthermore, both ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0205.gif) and ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0206.gif) are in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq221.gif) and thus in L 1(C), where in the case of ![
$$\\Delta\\psi$$
](A272900_1_En_9_Chapter_IEq0207.gif), we simply leave the value at the origin (which is a set of measure zero) undefined. Thus, integrals of ![
$$\\bar{\\psi }\\Delta \\chi$$
](A272900_1_En_9_Chapter_IEq222.gif) and ![
$$\(\\Delta \\bar{\\psi }\)\\chi$$
](A272900_1_En_9_Chapter_IEq223.gif) over ![
$$C\\setminus C_{\\varepsilon }$$
](A272900_1_En_9_Chapter_IEq224.gif) will converge to integrals over C. Since the boundary terms vanish in the limit, we are left with

![
$$\\displaystyle{\\left \\langle \\psi,\\Delta \\chi \\right\\rangle = \\left \\langle \\Delta \\psi,\\chi \\right\\rangle.}$$
](A272900_1_En_9_Chapter_Equav.gif)

Thus, the distributional Laplacian of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0208.gif) is simply integration against the "pointwise" Laplacian, ignoring the origin. Proposition 9.34 then tells us that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0209.gif) ∈ Dom(Δ).

## 9.9 Sums of Self-Adjoint Operators

In the previous section, we have succeeded in defining the Laplacian Δ, and hence also the kinetic energy operator ![
$$-{\\hslash }^{2}\\Delta /\(2m\)$$
](A272900_1_En_9_Chapter_IEq225.gif), as a self-adjoint operator on a natural dense domain in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq226.gif). We have also defined the potential energy operator V (X) as a self-adjoint operator on a different dense domain, for any measurable function ![
$$V : {\\mathbb{R}}^{n} \\rightarrow \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq227.gif). To obtain the Schrödinger operator ![
$$-{\\hslash }^{2}\\Delta /\(2m\) + V \(\\mathbf{X}\)$$
](A272900_1_En_9_Chapter_IEq228.gif), we "merely" have to make sense of the sum of two unbounded self-adjoint operators. This task, however, turns out to be more difficult than might be expected. In particular, if V is a highly singular function, then ![
$$-{\\hslash }^{2}\\Delta /\(2m\) + V \(\\mathbf{X}\)$$
](A272900_1_En_9_Chapter_IEq229.gif) may fail to be self-adjoint or essentially self-adjoint on any natural domain.

Definition 9.36.

If A and B are unbounded operators on H, then A \+ B is the operator with domain

![
$$\\displaystyle{\\mathrm{Dom}\(A + B\) :=\\mathrm{ Dom}\(A\) \\cap \\mathrm{ Dom}\(B\)}$$
](A272900_1_En_9_Chapter_Equaw.gif)

and given by ![
$$\(A + B\)\\psi = A\\psi + B\\psi$$
](A272900_1_En_9_Chapter_IEq230.gif).

The sum of two unbounded self-adjoint operators A and B may fail to be self-adjoint or even essentially self-adjoint. [If, however, B is bounded with Dom(B) = H, then Proposition 9.13 shows that A \+ B is self-adjoint on ![
$$\\mathrm{Dom}\(A\) \\cap \\mathrm{ Dom}\(B\) =\\mathrm{ Dom}\(A\)$$
](A272900_1_En_9_Chapter_IEq231.gif).] For one thing, if A and B are unbounded, then ![
$$\\mathrm{Dom}\(A\) \\cap \\mathrm{ Dom}\(B\)$$
](A272900_1_En_9_Chapter_IEq232.gif) may fail to be dense in H. But even if ![
$$\\mathrm{Dom}\(A\) \\cap \\mathrm{ Dom}\(B\)$$
](A272900_1_En_9_Chapter_IEq233.gif) is dense in H, it can easily happen that A \+ B is not essentially self-adjoint on this domain. (See, for example, Sect. 9.10.) Many things that are simple for bounded self-adjoint operators becomes complicated when dealing with unbounded self-adjoint operators!

In this section, we examine criteria on a function V under which the Schrödinger operator

![
$$\\displaystyle{\\hat{H} = -\\frac{{\\hslash }^{2}} {2m}\\Delta + V }$$
](A272900_1_En_9_Chapter_Equax.gif)

is self-adjoint or essentially self-adjoint on some natural domain inside ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq234.gif).

Theorem 9.37 (Kato–Rellich Theorem)

Suppose that A and B are unbounded self-adjoint operators on H . Suppose that Dom (A) ⊂ Dom (B) and that there exist positive constants a and b with a < 1 such that

![
$$\\displaystyle{ \\left \\Vert B\\psi \\right\\Vert \\leq a\\left \\Vert A\\psi \\right\\Vert + b\\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equ22.gif)

(9.20)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0210.gif) ∈ Dom (A). Then A + B is self-adjoint on Dom (A) and essentially self-adjoint on any subspace of Dom (A) on which A is essentially self-adjoint. Furthermore, if A is non-negative, then the spectrum of A + B is bounded below by ![
$$-b/\(1 - a\)$$
](A272900_1_En_9_Chapter_IEq235.gif).

Note that since we assume ![
$$\\mathrm{Dom}\(B\) \\supset \\mathrm{ Dom}\(A\)$$
](A272900_1_En_9_Chapter_IEq236.gif), the natural domain for A \+ B is ![
$$\\mathrm{Dom}\(A\) \\cap \\mathrm{ Dom}\(B\) =\\mathrm{ Dom}\(A\)$$
](A272900_1_En_9_Chapter_IEq237.gif). An operator B satisfying (9.20) is said to be relatively bounded with respect to A, with relative bound a.

Proof.

We use the trivial variant of Theorem 9.21 given in Exercise 8. Choose a positive real number μ large enough that ![
$$a + b/\\mu < 1$$
](A272900_1_En_9_Chapter_IEq238.gif), which is possible because we assume a < 1. Then for any ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0211.gif) ∈ Dom(A), we have

![
$$\\displaystyle{ \(A + B + i\\mu I\)\\psi = \\left \(B{\(A + i\\mu I\)}^{-1} + I\\right\)\(A + i\\mu I\)\\psi. }$$
](A272900_1_En_9_Chapter_Equ23.gif)

(9.21)

For any ![
$$\\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq02012.gif), we compute that

![
$$\\displaystyle\\begin{array}{rcl} \\left \\Vert B{\(A + i\\mu I\)}^{-1}\\psi \\right\\Vert & \\leq & a\\left \\Vert A{\(A + i\\mu I\)}^{-1}\\psi \\right\\Vert + b\\left \\Vert {\(A + i\\mu I\)}^{-1}\\psi \\right\\Vert \\\\ & \\leq & \\left \(a + \\frac{b} {\\mu } \\right\)\\left \\Vert \\psi \\right\\Vert. {}\\end{array}$$
](A272900_1_En_9_Chapter_Equ24.gif)

(9.22)

Here we have made use of the estimates

![
$$\\displaystyle{\\left \\Vert A{\(A + i\\mu I\)}^{-1}\\right\\Vert < 1,\\quad \\left \\Vert {\(A + i\\mu I\)}^{-1}\\right\\Vert < \\frac{1} {\\mu },}$$
](A272900_1_En_9_Chapter_Equay.gif)

both of which are elementary (Exercise 17).

If C denotes the operator ![
$$B{\(A + i\\mu I\)}^{-1}$$
](A272900_1_En_9_Chapter_IEq239.gif), (9.22) tells us that ![
$$\\left \\Vert C\\right\\Vert < \(a + b/\\mu \) < 1$$
](A272900_1_En_9_Chapter_IEq240.gif). Thus, by Lemma 7.6, C \+ I is invertible. Furthermore, since A is self-adjoint, A \+ iμI maps Dom(A) onto H. Thus, (9.21) tells us that ![
$$A + B + i\\mu I$$
](A272900_1_En_9_Chapter_IEq241.gif) also maps Dom(A) onto H. The same argument shows that ![
$$A + B - i\\mu I$$
](A272900_1_En_9_Chapter_IEq242.gif) maps Dom(A) onto H and we conclude, by Exercise 8, that A \+ B is self-adjoint on Dom(A).

Suppose, in addition, that A is non-negative. Let us replace iμ by λ > 0, in (9.21). Calculating as in (9.22), using the estimates in Exercise 18, we obtain that

![
$$\\displaystyle{\\left \\Vert B{\(A +\\lambda I\)}^{-1}\\psi \\right\\Vert \\leq \\left \(a + \\frac{b} {\\lambda } \\right\)\\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equaz.gif)

for all ![
$$\\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq0212.gif). If ![
$$\\lambda > b/\(1 - a\)$$
](A272900_1_En_9_Chapter_IEq243.gif), then ![
$$a + b/\\lambda < 1$$
](A272900_1_En_9_Chapter_IEq244.gif), and by the above argument, ![
$$\\mathrm{Range}\(A + B +\\lambda I\) = \\mathbf{H}$$
](A272900_1_En_9_Chapter_IEq245.gif). Furthermore, since ![
$$A + B +\\lambda I$$
](A272900_1_En_9_Chapter_IEq246.gif) is self-adjoint, Proposition 9.12 tells us that ![
$$\\ker \(A + B +\\lambda I\) =\\{ 0\\}$$
](A272900_1_En_9_Chapter_IEq247.gif). This shows that ![
$$A + B +\\lambda I$$
](A272900_1_En_9_Chapter_IEq248.gif) is invertible and − λ is in the resolvent set of A \+ B. We conclude, then, that the spectrum of A \+ B is contained in ![
$$\[-b/\(1 - a\),+\\infty \)$$
](A272900_1_En_9_Chapter_IEq249.gif).

The last part of the theorem, concerning essential self-adjointness, is left as an exercise (Exercise 19).

Theorem 9.38

Suppose n is at most 3 and ![
$$V : {\\mathbb{R}}^{n} \\rightarrow \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq250.gif) is a measurable function that can be decomposed as a sum of two real-valued, measurable functions V 1 and V 2 , with V 1 belonging to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq251.gif) and V 2 being bounded. Then the Schrödinger operator ![
$$-{\\hslash }^{2}\\Delta /\(2m\) + V \(\\mathbf{X}\)$$
](A272900_1_En_9_Chapter_IEq252.gif) is self-adjoint on Dom (Δ). Furthermore, ![
$$-{\\hslash }^{2}\\Delta /\(2m\) + V \(\\mathbf{X}\)$$
](A272900_1_En_9_Chapter_IEq253.gif) is bounded below.

Implicit in the statement of the theorem is that Dom(V (X)), as given in Proposition 9.30, contains Dom(Δ). A result similar to Theorem 9.38 in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq254.gif), n ≥ 4, but the condition that V 1 belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq255.gif) is replaced by the condition that V 1 belongs to ![
$${L}^{p}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq256.gif) for some p > n ∕ 2. See Theorem X.20 in Volume II of [34].

Proof.

We apply the Kato–Rellich theorem with ![
$$A = -{\\hslash }^{2}\\Delta /2m$$
](A272900_1_En_9_Chapter_IEq257.gif) and B = V (X). Assume ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0213.gif) ∈ Dom(Δ) and fix some ![
$$\\varepsilon > 0$$
](A272900_1_En_9_Chapter_IEq258.gif). By Exercise 14, there exists a constant ![
$$c_{\\varepsilon }$$
](A272900_1_En_9_Chapter_IEq259.gif) such that

![
$$\\displaystyle{\\left \\vert \\psi \(\\mathbf{x}\)\\right\\vert \\leq \\varepsilon \\left \\Vert \\Delta \\psi \\right\\Vert + c_{\\varepsilon }\\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equba.gif)

for all ![
$$\\mathbf{x} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq260.gif). Thus, if V is as in the theorem and ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0214.gif) ∈ Dom(Δ),

![
$$\\displaystyle\\begin{array}{rcl} \\left \\Vert V \\psi \\right\\Vert & \\leq & \\sup \\left \\vert \\psi \(\\mathbf{x}\)\\right\\vert \\left \\Vert V _{1}\\right\\Vert +\\sup \\left \\vert V _{2}\(\\mathbf{x}\)\\right\\vert \\left \\Vert \\psi \\right\\Vert {}\\\\ & \\leq & \\varepsilon \\left \\Vert V _{1}\\right\\Vert \\left \\Vert \\Delta \\psi \\right\\Vert + \(c_{\\varepsilon }\\left \\Vert V _{1}\\right\\Vert +\\sup \\left \\vert V _{2}\(\\mathbf{x}\)\\right\\vert \)\\left \\Vert \\psi \\right\\Vert. {}\\\\ \\end{array}$$
](A272900_1_En_9_Chapter_Equ25.gif)

This shows that ![
$$\\mathrm{Dom}\(V \(\\mathbf{X}\)\) \\supset \\mathrm{ Dom}\(\\Delta \)$$
](A272900_1_En_9_Chapter_IEq261.gif). Since ![
$$\\varepsilon$$
](A272900_1_En_9_Chapter_IEq262.gif) is arbitrary, we can arrange for the constant in front of ![
$$\\left \\Vert \\Delta \\psi \\right\\Vert$$
](A272900_1_En_9_Chapter_IEq263.gif) to be less than one and the Kato–Rellich theorem applies.

Theorem 9.39

Suppose n is at most 3 and ![
$$V : {\\mathbb{R}}^{n} \\rightarrow \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq264.gif) is a measurable function that can be decomposed as a sum of three real-valued, measurable functions V 1 , V 2 , and V 3 , with V 1 belonging to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq265.gif) , V 2 being bounded, and V 3 being non-negative and locally square-integrable. Then the Schrödinger operator ![
$$-{\\hslash }^{2}\\Delta /\(2m\) + V \(\\mathbf{X}\)$$
](A272900_1_En_9_Chapter_IEq266.gif) is essentially self-adjoint on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq267.gif).

The proof of this result would take us too far afield and is omitted. See Theorem X.29 in Volume II of [34]. Note that we assume only that V 3 is non-negative and locally square-integrable; V 3 can tend to + ∞ arbitrarily fast at infinity. Again, the same result applies in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq268.gif), n ≥ 4, if the condition on V 1 is replaced by the assumption that ![
$$V _{1} \\in {L}^{p}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq269.gif) for some p > n ∕ 2.

Proposition 9.40

Fix a and b in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq270.gif) and let a ⋅ X + b ⋅ P denote the operator given by

![
$$\\displaystyle{\(\\mathbf{a} \\cdot \\mathbf{X} + \\mathbf{b} \\cdot \\mathbf{P}\)\\psi \(\\mathbf{x}\) = \(\\mathbf{a} \\cdot \\mathbf{x}\)\\psi \(\\mathbf{x}\) - i\\hslash \\sum _{j=1}^{n}b_{ j} \\frac{\\partial \\psi } {\\partial x_{j}}.}$$
](A272900_1_En_9_Chapter_Equbb.gif)

Then a ⋅ X + b ⋅ P is essentially self-adjoint on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq271.gif).

Proof.

We use the same strategy as in Sect. 9.7, namely we explicitly solve the equation ![
$$A^{\\ast}\\psi = {\\pm}{i}{\\psi}$$
](A272900_1_En_9_Chapter_IEq0215.gif) and find that there are no nonzero, square-integrable solutions.

The case b = 0 is not hard to analyze and is left as an exercise (Exercise 20). Assume, then, that b ≠ 0. By making a rotational change of variables, we can assume that b = α e 1 and ![
$$\\mathbf{a} =\\beta \\mathbf{e}_{1} +\\gamma \\mathbf{e}_{2}$$
](A272900_1_En_9_Chapter_IEq272.gif), so that

![
$$\\displaystyle{ \(A\\psi \)\(\\mathbf{x}\) = \(\\beta x_{1} +\\gamma x_{2}\)\\psi \(\\mathbf{x}\) - i\\hslash \\alpha \\frac{\\partial \\psi } {\\partial x_{1}}. }$$
](A272900_1_En_9_Chapter_Equ26.gif)

(9.23)

(If n = 1, the γx 2 term is not present.) As in the proof of Proposition 9.29, the adjoint A ∗ of A will be given by the same formula as A, with Dom(A ∗) consisting of those elements ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0216.gif) of ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq273.gif) for which the right-hand side of (9.23), computed in the distributional sense, belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq274.gif).

We now apply the criterion for essential self-adjointness in Corollary 9.22. We need to show that the equations ![
$$A^{\\ast}\\psi = i\\psi$$
](A272900_1_En_9_Chapter_IEq0217.gif) and ![
$${A}^{{\\ast}}\\psi = -i\\psi$$
](A272900_1_En_9_Chapter_IEq275.gif) have no nonzero solutions in Dom(A ∗). After rewriting the equation ![
$$A^{\\ast}\\psi = i\\psi$$
](A272900_1_En_9_Chapter_IEq0218.gif) as

![
$$\\displaystyle{ \\frac{\\partial \\psi } {\\partial x_{1}} = -\\frac{i} {\\hslash \\alpha }\(\\beta x_{1} +\\gamma x_{2}\)\\psi \(\\mathbf{x}\) -\\frac{1} {\\hslash \\alpha }\\psi \(\\mathbf{x}\), }$$
](A272900_1_En_9_Chapter_Equ27.gif)

(9.24)

we can easily find the general distributional solution as

![
$$\\displaystyle{ \\psi \(\\mathbf{x}\) = c\(x_{2},\\ldots,x_{n}\)\\exp \\left \\{- \\frac{i\\beta } {2\\alpha \\hslash }x_{1}^{2} - \\frac{i\\gamma } {\\alpha \\hslash }x_{1}x_{2} -\\frac{1} {\\alpha \\hslash }x_{1}\\right\\}. }$$
](A272900_1_En_9_Chapter_Equ28.gif)

(9.25)

[It is easily verified that if we let ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0219.gif) equal ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0220.gif) divided by the exponential on the right-hand side of (9.25), then ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0221.gif) satisfies ![
$$\\partial \\phi /\\partial x_{1} = 0$$
](A272900_1_En_9_Chapter_IEq276.gif) in the distributional sense. Exercise 21 then tells us that ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0223.gif) must be a function of x 2,..., x n .] Since the exponential factor is never square integrable as a function of x 1 with x 2 fixed, the only way that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0224.gif) can be square integrable is if c is zero for almost every value of (x 2,..., x n ), in which case ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0225.gif) is the zero element of ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq277.gif). A similar argument shows that the equation ![
$${A}^{{\\ast}}\\psi = -i\\psi$$
](A272900_1_En_9_Chapter_IEq278.gif) has no nonzero solutions.

## 9.10 Another Counterexample

In this section, we will show that the Schrödinger operator ![
$$\\hat{H} = {P}^{2}/\(2m\) - {X}^{4}$$
](A272900_1_En_9_Chapter_IEq279.gif) is not essentially self-adjoint on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq280.gif), even though ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq281.gif) is certainly symmetric. By contrast, ![
$${P}^{2}/\(2m\) + {X}^{4}$$
](A272900_1_En_9_Chapter_IEq282.gif) is essentially self-adjoint, by Theorem 9.39. The operator ![
$${P}^{2}/\(2m\) - {X}^{4}$$
](A272900_1_En_9_Chapter_IEq283.gif) is a more serious counterexample than the one in Sect.​ 12.​2, in that it does not involve any obviously incorrect choice of boundary conditions. On the other hand, it should not be surprising that something goes "wrong" in a quantum system with a potential equal to − x 4. After all, a classical system with this potential has trajectories that go to infinity in finite time (see Exercise 4 in Chap.​ 2).

To show that ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq284.gif) is not essentially self-adjoint, we will show that the adjoint ![
$$\\hat{{H}}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq285.gif) is not symmetric. Suppose ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0226.gif) is a C ∞ function such that both ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq02207.gif) and the function

![
$$\\displaystyle{ -{\\frac{{\\hslash }^{2}} {2m}}\\psi^{{\\prime\\prime}}\(x\) - {x}^{4}\\psi \(x\) }$$
](A272900_1_En_9_Chapter_Equ29.gif)

(9.26)

belong to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq286.gif). Using integration by parts, as in the proof of Lemma 9.28, we can see that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0227.gif) is in the domain of ![
$$\\hat{{H}}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq287.gif) and ![
$$\\hat{{H}}^{{\\ast}}\\psi$$
](A272900_1_En_9_Chapter_IEq288.gif) is the function in (9.26). We will construct an approximate eigenvector ![
$$\\psi \\in \\mathrm{ Dom}\(\\hat{{H}}^{{\\ast}}\)$$
](A272900_1_En_9_Chapter_IEq289.gif) for ![
$$\\hat{{H}}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq290.gif) with an imaginary eigenvalue i α, which will show that ![
$$\\hat{{H}}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq291.gif) is not symmetric and thus ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq292.gif) is not essentially self-adjoint.

Theorem 9.41

Define an operator ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq293.gif) with ![
$$\\mathrm{Dom}\(\\hat{H}\) = C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq294.gif) by the formula

![
$$\\displaystyle{\\hat{H} = -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}} {d{x}^{2}} - {x}^{4}.}$$
](A272900_1_En_9_Chapter_Equbc.gif)

Then ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq295.gif) is not essentially self-adjoint.

In preparation for the proof, let us define a function p(x) on ![
$$\\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq296.gif) such that

![
$$\\displaystyle{\\frac{p{\(x\)}^{2}} {2m} - {x}^{4} = i\\alpha,}$$
](A272900_1_En_9_Chapter_Equbd.gif)

that is,

![
$$\\displaystyle{ p\(x\) = \\sqrt{2m}\\sqrt{{x}^{4 } + i\\alpha }. }$$
](A272900_1_En_9_Chapter_Equ30.gif)

(9.27)

Here we take the square root that is in the first quadrant. The function p(x) represents "the momentum of a classical particle with energy i α."

Lemma 9.42.

If ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq0229.gif) is given by

![
$$\\displaystyle{ \\psi _{\\alpha }\(x\) = \\frac{1} {\\sqrt{p\(x\)}}\\exp \\left \\{ \\frac{i} {\\hslash }\\int _{0}^{x}p\(y\)\\ dy\\right\\}, }$$
](A272900_1_En_9_Chapter_Equ31.gif)

(9.28)

then ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq0230.gif) belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq297.gif) and the function

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi _{\\alpha }} {d{x}^{2}} - {x}^{4}\\psi _{ \\alpha } }$$
](A272900_1_En_9_Chapter_Equ32.gif)

(9.29)

also belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq298.gif) . Furthermore, we have

![
$$\\displaystyle{\\left \[-\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}} {d{x}^{2}} - {x}^{4} - i\\alpha \\right\]\\psi _{\\alpha }\(x\) = -\\frac{{\\hslash }^{2}} {2m}\\psi _{\\alpha }\(x\)m_{\\alpha }\(x\),}$$
](A272900_1_En_9_Chapter_Eqube.gif)

where

![
$$\\displaystyle{m_{\\alpha }\(x\) = \\frac{5} {4} \\frac{{x}^{6}} {{\({x}^{4} + i\\alpha \)}^{2}} - 3 \\frac{{x}^{2}} {\({x}^{4} + i\\alpha \)}.}$$
](A272900_1_En_9_Chapter_Equbf.gif)

It will be apparent from the proof that the two terms in (9.29) are not separately in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq299.gif). The motivation for the definition of ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq02031.gif) comes from the WKB approximation (Chap.​ 15) with a complex value for the energy.

Proof.

Let us consider the integral of p,

![
$$\\displaystyle{\\int _{0}^{x}p\(y\)\\ dy = \\sqrt{2m}\\int _{ 0}^{x}\\sqrt{{y}^{4 } + i\\alpha }\\ dy.}$$
](A272900_1_En_9_Chapter_Equbg.gif)

Using the power series for (1 + x) a we see that for large y,

![
$$\\displaystyle{\\sqrt{{y}^{4 } + i\\alpha } = {y}^{2}\\sqrt{1 + i\\alpha /{y}^{4}} = {y}^{2}\\left \(1 + \\frac{i\\alpha } {2{y}^{4}} + O\\left \( \\frac{1} {{y}^{8}}\\right\)\\right\).}$$
](A272900_1_En_9_Chapter_Equbh.gif)

From this estimate, it is easy to see that the imaginary part of ![
$$\\int\\nolimits_{0}^{x} p\(y\)\\ dy$$
](A272900_1_En_9_Chapter_IEq02033.gif) remains bounded as x tends to ±∞. It follows that the exponential in the definition of ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0232.gif) is bounded, from which it is easy to see that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0233.gif) is square integrable.

Now, using the formula for the second derivative of a product, we obtain

![
$$\\displaystyle\\begin{array}{lll} &- {\\hslash }^{2}\\frac{{d}^{2}} {d{x}^{2}}\\psi _{\\alpha } = \\left \[ \\frac{p{\(x\)}^{2}}{\\sqrt{p\(x\)}} - i\\hslash \\frac{{p}^{{\\prime}}\(x\)} {\\sqrt{p\(x\)}} -2{\\hslash }^{2}\\left \(-\\frac{1} {2} \\frac{{p}^{{\\prime}}\(x\)}{p{\(x\)}^{3/2}}\\right\)\\frac{ip\(x\)} {\\hslash } \\right. \\\\ &\\left.-{\\hslash }^{2} \\frac{{d}^{2}} {d{x}^{2}} \\frac{1}{\\sqrt{p\(x\)}}\\right\]\\exp \\left \\{ \\frac{i} {\\hslash }\\int_{0}^{x}p\(y\)\\ dy\\right\\}. {}\\end{array}$$
](A272900_1_En_9_Chapter_Equ33.gif)

(9.30)

The factor of ![
$$1/\\sqrt{p\(x\)}$$
](A272900_1_En_9_Chapter_IEq300.gif) in the definition of ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq0235.gif) was chosen precisely so that the second and third terms in square brackets will cancel. If we replace p 2(x) in the numerator of the first term by 2m(x 4 \+ i α), we obtain

![
$$\\displaystyle{-\\frac{{\\hslash }^{2}} {2m}\\psi _{\\alpha }^{{\\prime\\prime}}\(x\) - {x}^{4}\\psi _{ \\alpha } - i\\alpha \\psi _{\\alpha } = -\\frac{{\\hslash }^{2}} {2m}\\left \( \\frac{{d}^{2}} {d{x}^{2}}p{\(x\)}^{-1/2}\\right\)\\exp \\left \\{ \\frac{i} {\\hslash }\\int _{0}^{x}p\(y\)\\ dy\\right\\}.}$$
](A272900_1_En_9_Chapter_Equbi.gif)

It is then an elementary calculation to show that

![
$$\\displaystyle{ \\frac{{d}^{2}} {d{x}^{2}}p{\(x\)}^{-1/2} = p{\(x\)}^{-1/2}\\left \[\\frac{5} {4}{\({x}^{4} + i\\alpha \)}^{-2}{x}^{6} - 3{\({x}^{4} + i\\alpha \)}^{-1}{x}^{2}\\right\],}$$
](A272900_1_En_9_Chapter_Equbj.gif)

from which the lemma follows.

Proof of Theorem 9.41.

If ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq301.gif) were essentially self-adjoint, ![
$$\\hat{{H}}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq302.gif) (which would coincide with ![
$$\\hat{{H}}^{cl}$$
](A272900_1_En_9_Chapter_IEq303.gif)) would be self-adjoint and, in particular, symmetric. If this were the case, we would have, by the proof of Lemma 7.8,

![
$$\\displaystyle{ \\left \\langle \(\\hat{{H}}^{{\\ast}}- i\\alpha I\)\\psi,\(\\hat{{H}}^{{\\ast}}- i\\alpha I\)\\psi \\right\\rangle {\\geq \\alpha }^{2}\\left \\langle \\psi,\\psi \\right\\rangle }$$
](A272900_1_En_9_Chapter_Equ34.gif)

(9.31)

for all ![
$$\\psi \\in \\mathrm{ Dom}\(\\hat{{H}}^{{\\ast}}\)$$
](A272900_1_En_9_Chapter_IEq304.gif) and ![
$$\\alpha \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq305.gif). But if ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq0236.gif) is the function in Lemma 9.42, the discussion preceding Theorem 9.41 shows that ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq0237.gif) belongs to ![
$$\\mathrm{Dom}\(\\hat{{H}}^{{\\ast}}\)$$
](A272900_1_En_9_Chapter_IEq306.gif). Furthermore, it is easily verified that there is a constant C such that ![
$$\\left \\vert m_{\\alpha }\(x\)\\right\\vert \\leq C$$
](A272900_1_En_9_Chapter_IEq307.gif) for all α ≥ 1 and ![
$$x \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq308.gif). Thus, for all sufficiently large α, we have

![
$$\\displaystyle{{\\left \\Vert \(\\hat{{H}}^{{\\ast}}- i\\alpha I\)\\psi _{\\alpha }\\right\\Vert }^{2} \\leq \\frac{{\\hslash }^{4}} {4{m}^{2}}{C}^{2}{\\left \\Vert \\psi _{ \\alpha }\\right\\Vert }^{2} {<\\alpha }^{2}{\\left \\Vert \\psi _{ \\alpha }\\right\\Vert }^{2},}$$
](A272900_1_En_9_Chapter_Equbk.gif)

contradicting (9.31).

See Exercise 22 for a more explicit approach to showing that ![
$$\\hat{{H}}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq309.gif) is not symmetric.

## 9.11 Exercises

1.

Show that an unbounded operator A fails to be closable if and only if the closure of the graph of A contains an element of the form (![
$$0, \\psi$$
](A272900_1_En_9_Chapter_IEq0238.gif)) with ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0239.gif) ≠ 0.

2.

Define an unbounded operator A on L 2([0, 1]) with domain Dom(A) = C([0, 1]) by

![
$$\\displaystyle{Af = f\(0\)\\mathbf{1},}$$
](A272900_1_En_9_Chapter_Equbl.gif)

where 1 is the constant function. Show that A is not closable.

3.

Prove Proposition 9.13.

4.

Suppose that A is an unbounded self-adjoint operator on H and that numbers λ n in σ(A) converge to some ![
$$\\lambda \\in \\mathbb{R}$$
](A272900_1_En_9_Chapter_IEq310.gif). Using Point 1 of Proposition 9.18, show that λ ∈ σ(A).

5.

Suppose A is a closed operator on H. Show that the kernel of A is a closed subspace of H.

6.

Suppose A is a closed operator on H. Define a norm ![
$$\\left \\Vert \\cdot \\right\\Vert _{1}$$
](A272900_1_En_9_Chapter_IEq311.gif) on Dom(A) by

![
$$\\displaystyle{\\left \\Vert \\psi \\right\\Vert _{1} = \\left \\Vert \\psi \\right\\Vert + \\left \\Vert A\\psi \\right\\Vert.}$$
](A272900_1_En_9_Chapter_Equbm.gif)

Show that Dom(A) is a Banach space with respect to ![
$$\\left \\Vert \\cdot \\right\\Vert _{1}$$
](A272900_1_En_9_Chapter_IEq312.gif).

7.

Let A be an unbounded operator on H.

(a)

Show that if A is symmetric, then A cl is also symmetric.

(b)

Show that if B is an extension of A, then A ∗ is an extension of B ∗.

(c)

Suppose A is self-adjoint and B is an extension of A. Show that if B is symmetric, then Dom(A) = Dom(B). (That is to say, a self-adjoint operator has no proper symmetric extensions.)

8.

Fix a positive real number μ.

(a)

Show that a symmetric operator A is self-adjoint if and only if Range(A \+ iμI) and Range(A − iμI) are equal to H.

(b)

Show that a symmetric operator A is essentially self-adjoint if and only if Range(A \+ iμI) and Range(A − iμI) are dense in H.

9.

Let A be the operator considered in Sect. 9.6. Using Lemma 9.28, show that for each ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq313.gif), there exists ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0240.gif) ∈ Dom(A ∗) with ![
$$A^{\\ast}\\psi = \\lambda\\psi$$
](A272900_1_En_9_Chapter_IEq02401.gif). Conclude that each ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_9_Chapter_IEq314.gif) belongs to the spectrum of A cl .

Hint: Recall that ![
$${\({A}^{cl}\)}^{{\\ast}} = {A}^{{\\ast}}$$
](A272900_1_En_9_Chapter_IEq315.gif).

10.

Let A be the operator considered in Sect. 9.6 and suppose ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0241.gif) is in the domain of A cl . Then there exists a sequence ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0242.gif) in Dom(A) such that ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0243.gif) converges to ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0244.gif) in L 2([0, 1]) and such that ![
$$A\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0245.gif) converges to some χ in L 2([0, 1]).

(a)

Show that

![
$$\\displaystyle{\\psi _{n}\(x\) = \\left \\langle 1_{\[0,x\]}, \\frac{d\\psi _{n}} {dx}\\right\\rangle = i\\left \\langle 1_{\[0,x\]},A\\psi _{n}\\right\\rangle }$$
](A272900_1_En_9_Chapter_Equbn.gif)

for all ![
$$x \\in \[0,1\]$$
](A272900_1_En_9_Chapter_IEq316.gif).

(b)

Show that ![
$$\\psi_{n}$$
](A272900_1_En_9_Chapter_IEq0246.gif) converges uniformly to the function

![
$$\\displaystyle{\\psi \(x\) = i\\left \\langle 1_{\[0,x\]},\\chi \\right\\rangle.}$$
](A272900_1_En_9_Chapter_Equbo.gif)

(c)

Conclude that ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0247.gif) is continuous and satisfies ![
$$\\psi \(0\) =\\psi \(1\) = 0$$
](A272900_1_En_9_Chapter_IEq317.gif).

11.

Take H = L 2((0, ∞)) and let A be the operator ![
$$-i\\ d/dx$$
](A272900_1_En_9_Chapter_IEq318.gif), with Dom(A) consisting of those smooth functions that are supported on a compact subset of (0, ∞). (Such a function is, in particular, zero on ![
$$\(0,\\varepsilon \)$$
](A272900_1_En_9_Chapter_IEq319.gif) for some ![
$$\\varepsilon > 0$$
](A272900_1_En_9_Chapter_IEq320.gif).) Show that A is symmetric and that A ∗ \+ iI is injective but that A ∗ − iI is not injective.

Hint: Imitate the arguments in the proof of Propositions 9.27 and 9.29.

12.

Prove the second part of Lemma 9.33.

13.

Let χ be a smooth, radial function on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_9_Chapter_IEq321.gif) such that for ![
$$\\left \\vert \\mathbf{x}\\right\\vert < 1$$
](A272900_1_En_9_Chapter_IEq322.gif) we have χ(x) = 1, for ![
$$\\left \\vert \\mathbf{x}\\right\\vert > 2$$
](A272900_1_En_9_Chapter_IEq323.gif) we have χ(x) = 0, and for ![
$$1 < \\left \\vert \\mathbf{x}\\right\\vert < 2$$
](A272900_1_En_9_Chapter_IEq324.gif), we have ∂ χ ∕ ∂ r < 0. Show that

![
$$\\displaystyle{\\int _{{\\mathbb{R}}^{3}} \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }\\Delta \\chi \(\\mathbf{x}\)\\ d\\mathbf{x} < 0,}$$
](A272900_1_En_9_Chapter_Equbp.gif)

which shows that the Laplacian of ![
$$1/\\left \\vert \\mathbf{x}\\right\\vert$$
](A272900_1_En_9_Chapter_IEq325.gif), in the distribution sense, is not zero.

Hint: Let ![
$$E = C_{1}\\setminus C_{2}$$
](A272900_1_En_9_Chapter_IEq326.gif), where C 1 is a cube centered at the origin with side length 3 and where C 2 is a cube centered at the origin with side length 1 ∕ 2. Then E contains the support of Δ χ. Using integration by parts on E, show that

![
$$\\displaystyle{\\int _{{\\mathbb{R}}^{3}} \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }\\Delta \\chi \(\\mathbf{x}\)\\ d\\mathbf{x} = -\\int _{{\\mathbb{R}}^{3}}\\nabla \\left \( \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\) \\cdot \\nabla \\chi \(\\mathbf{x}\)\\ d\\mathbf{x}.}$$
](A272900_1_En_9_Chapter_Equbq.gif)

14.

Let ![
$$\\mathrm{Dom}\(\\Delta \) \\subset {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq327.gif) denote the domain of the Laplacian, as given in Proposition 9.34, and assume n ≤ 3.

(a)

Show that each ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0248.gif) ∈ Dom(Δ) is continuous and that there exists constants c 1 and c 2 such that

![
$$\\displaystyle{\\left \\vert \\psi \(\\mathbf{x}\)\\right\\vert \\leq c_{1}\\left \\Vert \\psi \\right\\Vert + c_{2}\\left \\Vert {\\left \\vert \\mathbf{k}\\right\\vert }^{9/5}\\left \\vert \\hat{\\psi }\(\\mathbf{k}\)\\right\\vert \\right\\Vert,}$$
](A272900_1_En_9_Chapter_Equbr.gif)

for all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0249.gif) ∈ Dom(Δ).

Hint: Show that ![
$$\\hat{\\psi }$$
](A272900_1_En_9_Chapter_IEq328.gif) is in L 1 by expressing ![
$$\\hat{\\psi }$$
](A272900_1_En_9_Chapter_IEq329.gif) as the product of two L 2 functions.

(b)

Show that for any ![
$$\\varepsilon > 0$$
](A272900_1_En_9_Chapter_IEq330.gif), there exists a constant ![
$$c_{\\varepsilon }$$
](A272900_1_En_9_Chapter_IEq331.gif) such that

![
$$\\displaystyle{\\left \\vert \\psi \(\\mathbf{x}\)\\right\\vert \\leq c_{\\varepsilon }\\left \\Vert \\psi \\right\\Vert +\\varepsilon \\left \\Vert \\Delta \\psi \\right\\Vert }$$
](A272900_1_En_9_Chapter_Equbs.gif)

for all ![
$$\\psi \\in \\mathrm{ Dom}\(\\Delta \)$$
](A272900_1_En_9_Chapter_IEq332.gif).

15.

Recall the definitions of Dom(P j ) and Dom(Δ) in Sect. 9.8. Let Dom(P j 2) be the set of all ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0250.gif) belonging to Dom(P j ) such that ![
$$p_{j}\\psi$$
](A272900_1_En_9_Chapter_IEq0251.gif) again belongs to Dom(P j ). Show that

![
$$\\displaystyle{\\bigcap \\limits _{j=1}^{n}\\mathrm{Dom}\(P_{ j}^{2}\) =\\mathrm{ Dom}\(\\Delta \).}$$
](A272900_1_En_9_Chapter_Equbt.gif)

16.

Let Q j denote the restriction to ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq333.gif) of the momentum operator P j . Show that ![
$$\\mathrm{Dom}\(Q_{j}^{{\\ast}}\) =\\mathrm{ Dom}\(P_{j}\)$$
](A272900_1_En_9_Chapter_IEq334.gif). Conclude that Q j is essentially self-adjoint.

17.

Let A be an unbounded self-adjoint operator on H and let μ be a nonzero real number.

(a)

Show that ![
$$\\left \\Vert {\(A + i\\mu I\)}^{-1}\\right\\Vert \\leq 1/\\left \\vert \\mu \\right\\vert$$
](A272900_1_En_9_Chapter_IEq335.gif). Note that ![
$${\(A + i\\mu I\)}^{-1}$$
](A272900_1_En_9_Chapter_IEq336.gif) exists, by Theorem 9.17.

(b)

Show that for all ![
$$\\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq0252.gif),

![
$$\\displaystyle{{\\left \\Vert \\psi \\right\\Vert }^{2} ={ \\left \\Vert A{\(A + i\\mu I\)}^{-1}\\psi \\right\\Vert }^{2} {+\\mu }^{2}{\\left \\Vert {\(A + i\\mu I\)}^{-1}\\psi \\right\\Vert }^{2}.}$$
](A272900_1_En_9_Chapter_Equbu.gif)

Conclude that ![
$$\\left \\Vert A{\(A + i\\mu I\)}^{-1}\\right\\Vert \\leq 1$$
](A272900_1_En_9_Chapter_IEq337.gif).

18.

Let A be an unbounded self-adjoint operator on H. Suppose A is non-negative (Definition 9.19) and let λ be a positive real number.

(a)

Show that ![
$$\\left \\Vert {\(A +\\lambda I\)}^{-1}\\right\\Vert \\leq 1/\\lambda$$
](A272900_1_En_9_Chapter_IEq338.gif).

(b)

Show that for all ![
$$\\phi, \\psi \\in \\bf{H}$$
](A272900_1_En_9_Chapter_IEq02503.gif),

![
$$\\displaystyle{{\\left \\Vert \\psi \\right\\Vert }^{2} \\geq {\\left \\Vert A{\(A +\\lambda I\)}^{-1}\\psi \\right\\Vert }^{2} {+\\lambda }^{2}{\\left \\Vert {\(A +\\lambda I\)}^{-1}\\psi \\right\\Vert }^{2}.}$$
](A272900_1_En_9_Chapter_Equbv.gif)

Conclude that ![
$$\\left \\Vert A{\(A +\\lambda I\)}^{-1}\\right\\Vert < 1$$
](A272900_1_En_9_Chapter_IEq339.gif).

19.

Prove the last part of Theorem 9.37, concerning domains of essential self-adjointness.

Hint: If A is self-adjoint on Dom(A) and V ⊂ Dom(A) is a dense subspace of H, then A is essentially self-adjoint on V if and only if the closure of ![
$$\\left.A\\right\\vert _{V }$$
](A272900_1_En_9_Chapter_IEq340.gif) is equal to A.

20.

Let A be the operator b ⋅X on the domain ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq341.gif), for some ![
$$\\mathbf{b} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq342.gif).

(a)

Using the definition of the adjoint of an unbounded operator, show that Dom(A ∗) consists of all those ![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0253.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq343.gif) for which the function (b ⋅x)![
$$\\psi$$
](A272900_1_En_9_Chapter_IEq0300.gif)(x) again belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq344.gif).

(b)

Using Proposition 9.30, show that A is essentially self-adjoint.

21.

(a)

Show that a function ![
$$\\phi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq345.gif) can be expressed as ![
$$\\phi = \\partial \\chi /\\partial x_{1}$$
](A272900_1_En_9_Chapter_IEq346.gif) for some ![
$$\\chi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq347.gif) if and only if ![
$$\\phi$$
](A272900_1_En_9_Chapter_IEq0301.gif) satisfies

![
$$\\displaystyle{\\int _{-\\infty }^{\\infty }\\phi \(x_{ 1},x_{2},\\ldots,x_{n}\)\\ dx_{1} = 0}$$
](A272900_1_En_9_Chapter_Equbw.gif)

for all (x 2,..., x n ).

(b)

Fix a function ![
$$\\gamma \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_9_Chapter_IEq348.gif) such that ![
$$\\int _{-\\infty }^{\\infty }\\gamma \(x\)\\ dx = 1$$
](A272900_1_En_9_Chapter_IEq349.gif). Show that any ![
$$\\phi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq350.gif) can be expressed as

![
$$\\displaystyle{\\phi \(\\mathbf{x}\) = f\(x_{2},\\ldots,x_{n}\)\\gamma \(x_{1}\) + \\frac{\\partial \\chi } {\\partial x_{1}}}$$
](A272900_1_En_9_Chapter_Equbx.gif)

for some ![
$$\\chi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq351.gif), where f is the element of ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n-1}\)$$
](A272900_1_En_9_Chapter_IEq352.gif) given by

![
$$\\displaystyle{f\(x_{2},\\ldots,x_{n}\) =\\int _{ -\\infty }^{\\infty }\\phi \(x_{ 1},x_{2},\\ldots,x_{n}\)\\ dx_{1}.}$$
](A272900_1_En_9_Chapter_Equby.gif)

(c)

Suppose T is a distribution on ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_9_Chapter_IEq353.gif) with the property that

![
$$\\displaystyle{ \\frac{\\partial T} {\\partial x_{1}} = 0.}$$
](A272900_1_En_9_Chapter_Equbz.gif)

Define a distribution c on ![
$${\\mathbb{R}}^{n-1}$$
](A272900_1_En_9_Chapter_IEq354.gif) by the formula

![
$$\\displaystyle{c\(f\) = T\(f\(x_{2},\\ldots,x_{n}\)\\gamma \(x_{1}\)\).}$$
](A272900_1_En_9_Chapter_Equca.gif)

Show that for all ![
$$\\phi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_9_Chapter_IEq355.gif) we have

![
$$\\displaystyle{T\(\\phi \) = c\(\\tilde{\\phi }\),}$$
](A272900_1_En_9_Chapter_Equcb.gif)

where ![
$$\\tilde{\\phi }\\in C_{c}^{\\infty }\({\\mathbb{R}}^{n-1}\)$$
](A272900_1_En_9_Chapter_IEq356.gif) is given by

![
$$\\displaystyle{\\tilde{\\phi }\(x_{2},\\ldots,x_{n}\) =\\int _{\\mathbb{R}}\\phi \(x_{1},x_{2},\\ldots,x_{n}\)\\ dx_{1}.}$$
](A272900_1_En_9_Chapter_Equcc.gif)

22.

Let ![
$$\\hat{H}$$
](A272900_1_En_9_Chapter_IEq357.gif) denote the Schrödinger operator in Theorem 9.41 and let ![
$$\\psi_{\\alpha}$$
](A272900_1_En_9_Chapter_IEq0302.gif) be the function defined in Lemma 9.42.

(a)

Show that

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \\langle \\psi _{\\alpha },\\hat{{H}}^{{\\ast}}\\psi _{ \\alpha }\\right\\rangle -\\left \\langle \\hat{{H}}^{{\\ast}}\\psi _{ \\alpha },\\psi _{\\alpha }\\right\\rangle {}\\\\ & =& -\\frac{{\\hslash }^{2}} {2m}\\lim _{A\\rightarrow \\infty }\\left \[\\left.\\overline{\\psi _{\\alpha }\(x\)}\\psi _{\\alpha }^{{\\prime}}\(x\)\\right\\vert _{ -A}^{A} -\\left.\\overline{\\psi _{\\alpha }^{{\\prime}}\(x\)}\\psi _{\\alpha }\(x\)\\right\\vert _{ -A}^{A}\\right\]. {}\\\\ \\end{array}$$
](A272900_1_En_9_Chapter_Equ35.gif)

(b)

Now show by direct calculation that ![
$$\\left \\langle \\psi,\\hat{{H}}^{{\\ast}}\\psi \\right\\rangle \\neq \\left \\langle \\hat{{H}}^{{\\ast}}\\psi,\\psi \\right\\rangle$$
](A272900_1_En_9_Chapter_IEq358.gif).

References

[34].

M. Reed, B. Simon, Methods of Modern Mathematical Physics. Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_10

© Springer Science+Business Media New York 2013

# 10. The Spectral Theorem for Unbounded Self-Adjoint Operators

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

This chapter gives statements and proofs of the spectral theorem for unbounded self-adjoint operators, in the same forms as in the bounded case, in terms of projection-valued measures, in terms of direct integrals, and in terms of multiplication operators.

This chapter gives statements and proofs of the spectral theorem for unbounded self-adjoint operators, in the same forms as in the bounded case, in terms of projection-valued measures, in terms of direct integrals, and in terms of multiplication operators. The proof reduces the spectral theorem for an unbounded self-adjoint operator A to spectral theorem for the bounded operator ![
$$U := \(A + iI\){\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq1.gif) (Sect. 10.4). This bounded operator is, however, not self-adjoint but rather unitary. Thus, before coming to the proof of the spectral theorem for unbounded self-adjoint operators, we prove (Sect. 10.3) the spectral theorem for bounded normal operators, those that commute with their adjoints. (A unitary operator U certainly commutes with its adjoint ![
$${U}^{{\\ast}} = {U}^{-1}$$
](A272900_1_En_10_Chapter_IEq2.gif).) The proof for a bounded normal operator B is the same as for bounded self-adjoint operators, except for the step in which we approximate continuous functions on σ(B) by polynomials. Since σ(B) is not necessarily contained in ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq3.gif), we need to use the complex version of the Stone–Weierstrass theorem, which requires us to consider polynomials in λ and ![
$$\\bar{\\lambda }$$
](A272900_1_En_10_Chapter_IEq4.gif). We must then prove a strengthened version of the spectral mapping theorem before proceeding along the lines of the proof for bounded self-adjoint operators.

In Sect. 10.2, we discuss Stone's theorem, which gives a one-to-one correspondence between strongly continuous one-parameter unitary groups and self-adjoint operators. One direction of Stone's theorem follows from the spectral theorem, that is, from the functional calculus that results from the spectral theorem.

## 10.1 Statements of the Spectral Theorem

The statement of the spectral theorem—in any of the forms that we have considered—is almost the same for unbounded self-adjoint operators as for bounded ones. The only difference is that the statement of the theorem in the unbounded case has to contain some description of the domain of the operator.

Recall that if μ is a projection-valued measure on (X, Ω) with values in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq5.gif) and ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq01.gif) is an element of H, then we can construct a non-negative, real-valued measure ![
$$\\mu_\\psi$$
](A272900_1_En_10_Chapter_IEq02.gif) from μ by setting ![
$$\\mu _{\\psi }\(E\) = \\left \\langle \\psi,\\mu \(E\)\\psi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq6.gif), for each measurable set E. To motivate the following definition, consider integration of a bounded measurable function f against a projection-valued measure μ. Since the integral is multiplicative and complex-conjugation of a function corresponds to adjoint of the operator, we have

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \\left \(\\int _{X}f\\ d\\mu \\right\)\\psi,\\left \(\\int _{X}f\\ d\\mu \\right\)\\psi \\right\\rangle & =& \\left \\langle \\psi,\\left \(\\int _{X}\\bar{f}f\\ d\\mu \\right\)\\psi \\right\\rangle \\\\ & =& \\int _{X}{\\left \\vert f\\right\\vert }^{2}\\ d\\mu _{\\psi }.{}\\end{array}$$
](A272900_1_En_10_Chapter_Equ1.gif)

(10.1)

Suppose, now, that f is an unbounded measurable function on X and we wish to define ∫ X f dμ, which will presumably be an unbounded operator. It seems reasonable to define the domain of f to be the set of ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq03.gif) for which the right-hand side of (10.1) is finite.

Proposition 10.1.

Suppose μ is a projection-valued measure on (X,Ω) with values in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq7.gif) and ![
$$f : X \\rightarrow \\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq8.gif) is a measurable function (not necessarily bounded). Define a subspace W f of H by

![
$$\\displaystyle{ W_{f} = \\left \\{\\psi \\in \\mathbf{H}\\left \\vert \\int _{X}{\\left \\vert f\(\\lambda \)\\right\\vert }^{2}d\\mu _{\\psi }\(\\lambda \) < \\infty \\right.\\right\\}. }$$
](A272900_1_En_10_Chapter_Equ2.gif)

(10.2)

Then there exists a unique unbounded operator on H with domain W f —which is denoted by ∫ X f dμ—with the property that

![
$$\\displaystyle{\\left \\langle \\psi,\\left \(\\int _{X}f\\ d\\mu \\right\)\\psi \\right\\rangle =\\int _{X}f\(\\lambda \)\\ d\\mu _{\\psi }\(\\lambda \)}$$
](A272900_1_En_10_Chapter_Equa.gif)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq04.gif) in W f . This operator satisfies (10.1) for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq05.gif) ∈ W f .

Note that since ![
$$\\mu_\\psi$$
](A272900_1_En_10_Chapter_IEq06.gif) is a finite measure for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq07.gif), if f is bounded then the domain of ∫ X f dμ is all of H. Thus, in the bounded case, the definition of ∫ X f dμ in Proposition 10.1 agrees with our earlier definition (in Chap.​ 7) of the integral. This means, in particular, that if f is a bounded function, ∫ X f dμ is a bounded operator. Proposition 10.1 follows immediately from the following result.

Proposition 10.2.

Let f be a measurable function on X and let W f be as in ( 10.2 ). Then the following results hold.

1.

The space W f is a dense subspace of H and the map ![
$$Q_{f} : W_{f} \\rightarrow \\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq9.gif) given by

![
$$\\displaystyle{Q_{f}\(\\psi \) =\\int _{X}f\(\\lambda \)\\ d\\mu _{\\psi }\(\\lambda \)}$$
](A272900_1_En_10_Chapter_Equb.gif)

is a quadratic form on W f .

2.

If L f is the associated sesquilinear form on W f , we have

![
$$\\displaystyle{ \\left \\vert L_{f}\(\\phi,\\psi \)\\right\\vert \\leq \\left \\Vert \\phi \\right\\Vert \\left \\Vert f\\right\\Vert _{{L}^{2}\(X,\\mu _{\\psi }\)} }$$
](A272900_1_En_10_Chapter_Equ3.gif)

(10.3)

for all ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq08.gif), ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq09.gif) ∈ W f .

3.

For each ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq010.gif) ∈ W f , there is a unique χ ∈ H such that ![
$$L_{f}\(\\phi,\\psi \) = \\left \\langle \\phi,\\chi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq10.gif) for all ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq011.gif) ∈ W f . Furthermore, the map ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq012.gif) ↦ χ is linear and for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq013.gif) ∈ W f , we have

![
$$\\displaystyle{{ \\left \\Vert \\chi \\right\\Vert }^{2} =\\int _{ X}{\\left \\vert f\\right\\vert }^{2}\\ d\\mu _{\\psi } }$$
](A272900_1_En_10_Chapter_Equ4.gif)

(10.4)

Proof.

It is easy to see that W f is closed under scalar multiplication. To show that it is closed under addition, note that since μ(E) is self-adjoint and satisfies μ(E)2 = μ(E), we have

![
$$\\displaystyle\\begin{array}{rcl} \\mu _{\\phi +\\psi }\(E\)& =&{ \\left \\Vert \\mu \(E\)\(\\phi +\\psi \)\\right\\Vert }^{2} {}\\\\ & \\leq &{ \\left \(\\left \\Vert \\mu \(E\)\\phi \\right\\Vert + \\left \\Vert \\mu \(E\)\\psi \\right\\Vert \\right\)}^{2} {}\\\\ & \\leq & 2{\\left \\Vert \\mu \(E\)\\phi \\right\\Vert }^{2} + 2{\\left \\Vert \\mu \(E\)\\psi \\right\\Vert }^{2} {}\\\\ & =& 2\\mu _{\\phi }\(E\) + 2\\mu _{\\psi }\(E\), {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ5.gif)

where in the third line we have use the elementary inequality ![
$${\(x + y\)}^{2} \\leq 2{x}^{2} + 2{y}^{2}$$
](A272900_1_En_10_Chapter_IEq11.gif).

To show that W f is dense in H, let ![
$$E_{n} = \\left \\{x \\in X\\left \\vert \\ \\left \\vert f\(x\)\\right\\vert < n\\right.\\right\\}$$
](A272900_1_En_10_Chapter_IEq12.gif). If ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq014.gif) ∈ Range(μ(E n )), then ![
$$\\mu _{\\psi }\(E_{n}^{c}\) = 0$$
](A272900_1_En_10_Chapter_IEq13.gif), and, thus,

![
$$\\displaystyle{ \\int _{X}{\\left \\vert f\\right\\vert }^{2}d\\mu _{\\psi } =\\int _{ E_{n}}{\\left \\vert f\\right\\vert }^{2}d\\mu _{\\psi } \\leq {n}^{2}\\mu _{ \\psi }\(E_{n}\) < \\infty, }$$
](A272900_1_En_10_Chapter_Equ6.gif)

(10.5)

showing that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq015.gif) belongs to W f . Since also ![
$$\\cup _{n}E_{n} = X$$
](A272900_1_En_10_Chapter_IEq14.gif), the union of the ranges of the μ(E n )'s is dense and contained in W f .

If f is bounded, Q f may be computed as

![
$$\\displaystyle{Q_{f}\(\\psi \) = \\left \\langle \\psi,\\left \(\\int _{X}f\\ d\\mu \\right\)\\psi \\right\\rangle,\\quad \\psi \\in \\mathbf{H},}$$
](A272900_1_En_10_Chapter_Equc.gif)

where ∫ X f dμ is as in Chap.​ 7. Thus, Q f is a quadratic form for which the associated sesquilinear form is

![
$$\\displaystyle{L_{f}\(\\phi,\\psi \) = \\left \\langle \\phi,\\left \(\\int _{X}f\\ d\\mu \\right\)\\psi \\right\\rangle,\\quad \\phi,\\psi \\in \\mathbf{H}.}$$
](A272900_1_En_10_Chapter_Equd.gif)

This form satisfies

![
$$\\displaystyle\\begin{array}{rcl} \\left \\vert L_{f}\(\\phi,\\psi \)\\right\\vert & \\leq & \\left \\Vert \\phi \\right\\Vert \\left \\Vert \\left \(\\int _{X}f\\ d\\mu \\right\)\\psi \\right\\Vert \\\\ & =& \\left \\Vert \\phi \\right\\Vert \\left \\Vert f\\right\\Vert _{{L}^{2}\(X,\\mu _{\\psi }\)},{}\\end{array}$$
](A272900_1_En_10_Chapter_Equ7.gif)

(10.6)

for all ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq016.gif), ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq017.gif) ∈ H, where in the second line we have used (10.1).

If f is unbounded and ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq018.gif) belongs to W f , let ![
$$f_{n} = f1_{E_{n}}$$
](A272900_1_En_10_Chapter_IEq15.gif). Then ![
$$Q_{f}\(\\psi \) =\\lim _{n\\rightarrow \\infty }Q_{f_{n}}\(\\psi \)$$
](A272900_1_En_10_Chapter_IEq16.gif), by monotone convergence, in which case, it is easy to see that Q f is still a quadratic form and that (10.6) still holds for all ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq019.gif) ∈ H. From (10.6), we see that for each ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq020.gif) ∈ W f , the conjugate-linear functional ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq021.gif) ↦ L f (![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq022.gif), ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq023.gif)) is bounded. Thus, by (the complex-conjugate of) the Riesz theorem, there is a unique vector χ such that ![
$$L_{f}\(\\phi,\\psi \) = \\left \\langle \\phi,\\chi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq17.gif). Furthermore, (10.6) tells us that ![
$$\\left \\Vert \\chi \\right\\Vert \\leq \\left \\Vert f\\right\\Vert _{{L}^{2}\(X,\\mu _{\\psi }\)}$$
](A272900_1_En_10_Chapter_IEq18.gif). Conversely, since ![
$$L_{f}\(\\phi,\\psi \) = \\left \\langle \\phi,\\chi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq19.gif), (10.6) is an equality when ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq024.gif) = χ, showing that ![
$$\\left \\Vert \\chi \\right\\Vert \\geq \\left \\Vert f\\right\\Vert _{{L}^{2}\(X,\\mu _{\\psi }\)}$$
](A272900_1_En_10_Chapter_IEq20.gif). Finally, the map ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq025.gif) ↦ χ is linear because L f (![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq026.gif), ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq027.gif)) is linear in ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq028.gif).

Proposition 10.3.

If f is a real-valued, measurable function on X, then ∫ X f dμ is self-adjoint on W f .

Proof.

Let A f = ∫ X f dμ. Define subsets F n of X by

![
$$\\displaystyle{F_{n} = \\left \\{x \\in X\\left \\vert \\ n - 1 \\leq \\left \\vert f\(x\)\\right\\vert < n\\right.\\right\\},}$$
](A272900_1_En_10_Chapter_Eque.gif)

so that X is the disjoint union of the F n 's, and let W n = Range(μ(F n )). As in the proof of Proposition 10.2, any ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq029.gif) ∈ W n is in W f , and the quadratic form Q f is bounded on W n [compare (10.5)]. Furthermore, if ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq030.gif) ∈ (W n )⊥ and ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq031.gif) ∈ W n , it is straightforward to check that ![
$$\\mu _{\\phi +\\psi } =\\mu _{\\phi } +\\mu _{\\psi }$$
](A272900_1_En_10_Chapter_IEq21.gif) and so

![
$$\\displaystyle{ Q_{f}\(\\phi +\\psi \) = Q_{f}\(\\phi \) + Q_{f}\(\\psi \). }$$
](A272900_1_En_10_Chapter_Equ8.gif)

(10.7)

From (10.7), we obtain, by the polarization identity,

![
$$\\displaystyle{\\left \\langle \\phi,A_{f}\\psi \\right\\rangle = L_{f}\(\\phi,\\psi \) = 0.}$$
](A272900_1_En_10_Chapter_Equf.gif)

This shows that A f ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq032.gif) belongs to ![
$${\({W}^{n}\)}^{\\perp \\perp } = {W}^{n}$$
](A272900_1_En_10_Chapter_IEq22.gif).

We conclude that A f maps W n boundedly to itself. Indeed, the restriction to W n of A f coincides with the restriction to W n of the bounded operator obtained by integrating ![
$$f1_{F_{n}}$$
](A272900_1_En_10_Chapter_IEq23.gif) with respect to μ (compare the quadratic forms). Furthermore, since Q f is real-valued, the restriction of A f to W n is self-adjoint (Proposition A.63).

Now, H is the orthogonal direct sum of the W n 's, meaning that H may be identified with the set of infinite sequences ![
$$\(\\psi _{1},\\psi _{2},\\psi _{3},\\ldots \)$$
](A272900_1_En_10_Chapter_IEq24.gif) with ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq033.gif) n ∈ W n and such that

![
$$\\displaystyle{\\sum _{n=1}^{\\infty }{\\left \\Vert \\psi _{ n}\\right\\Vert }^{2} < \\infty.}$$
](A272900_1_En_10_Chapter_Equg.gif)

If A n denotes the restriction of A f to W n , then under this decomposition of H, we have

![
$$\\displaystyle\\begin{array}{rcl} W_{f}& =& \\left \\{\\psi \\in \\mathbf{H}\\left \\vert \\sum _{n=1}^{\\infty }{\\left \\Vert A_{ n}\\psi _{n}\\right\\Vert }^{2} < \\infty \\right.\\right\\} \\\\ & =& \\left \\{\\psi = \(\\psi _{1},\\psi _{2},\\ldots \)\\left \\vert \\sum _{n=1}^{\\infty }\\left \({\\left \\Vert \\psi _{ n}\\right\\Vert }^{2} +{ \\left \\Vert A_{ n}\\psi _{n}\\right\\Vert }^{2}\\right\) < \\infty \\right.\\right\\}.{}\\end{array}$$
](A272900_1_En_10_Chapter_Equ9.gif)

(10.8)

To verify (10.8), we note that

![
$$\\displaystyle{ \\int _{X}{\\left \\vert f\\right\\vert }^{2}\\ d\\mu _{\\psi } =\\sum _{ n=1}^{\\infty }\\int _{ W_{n}}{\\left \\vert f\\right\\vert }^{2}\\ d\\mu _{\\psi } =\\sum _{ n=1}^{\\infty }{\\left \\Vert A_{ n}\\psi _{n}\\right\\Vert }^{2}. }$$
](A272900_1_En_10_Chapter_Equ10.gif)

(10.9)

The first equality is by monotone convergence and the second holds because ![
$$\\mu _{\\psi } =\\mu _{\\psi _{n}}$$
](A272900_1_En_10_Chapter_IEq25.gif) on W n . In particular, the first quantity in (10.9) is finite if and only if the last quantity if finite.

By a similar argument, for ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq034.gif) ∈ W f , we have

![
$$\\displaystyle{Q_{f}\(\\psi \) =\\int _{X}f\(\\lambda \)\\ d\\mu _{\\psi }\(\\lambda \) =\\sum _{ n=1}^{\\infty }\\left \\langle \\psi _{ n},A_{n}\\psi _{n}\\right\\rangle,}$$
](A272900_1_En_10_Chapter_Equh.gif)

from which it follows that

![
$$\\displaystyle{L_{f}\(\\phi,\\psi \) =\\sum _{ n=1}^{\\infty }\\left \\langle \\phi _{ n},A_{n}\\psi _{n}\\right\\rangle }$$
](A272900_1_En_10_Chapter_Equi.gif)

for all ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq035.gif), ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq036.gif) ∈ W f . From this we see that A f ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq037.gif) is the vector represented by the sequence ![
$$\(A_{1}\\psi _{1},A_{2}\\psi _{2},\\ldots \)$$
](A272900_1_En_10_Chapter_IEq26.gif). It then follows from Example 9.26 that A f is self-adjoint.

Theorem 10.4 (Spectral Theorem, First Form).

Suppose A is a self-adjoint operator on H . Then there is a unique projection-valued measure μ A on σ(A) with values in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq27.gif) such that

![
$$\\displaystyle{ \\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A. }$$
](A272900_1_En_10_Chapter_Equ11.gif)

(10.10)

Since the spectrum of A is typically an unbounded set, the function f(λ) = λ is an unbounded function on σ(A). Note also that the equality in (10.10) includes, as always, equality of domains. That is, the domain of the integral on the left-hand side, namely the space W f in Proposition 10.1, coincides with Dom(A). The proof of this theorem is given in Sect. 10.4.

Definition 10.5 (Functional Calculus).

For any measurable function f on σ(A), define a (possibly unbounded) operator, denoted f(A), by

![
$$\\displaystyle{f\(A\) =\\int _{\\sigma \(A\)}f\(\\lambda \)\\ {d\\mu }^{A}\(\\lambda \).}$$
](A272900_1_En_10_Chapter_Equj.gif)

As usual, we can extend the projection-valued measure μ A from σ(A) to ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq28.gif) by setting μ A equal to zero on the complement of σ(A).

Definition 10.6 (Spectral Subspaces).

If A is a self-adjoint operator on H, then for any Borel set ![
$$E \\subset \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq29.gif), define the spectral subspace V E of H by

![
$$\\displaystyle{V _{E} =\\mathrm{ Range}{\(\\mu }^{A}\(E\)\).}$$
](A272900_1_En_10_Chapter_Equk.gif)

Definition 10.7 (Measurement Probabilities).

If A is a self-adjoint operator on H, then for any unit vector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq038.gif) ∈ H, define a probability measure ![
$$\\mu_\\psi^A$$
](A272900_1_En_10_Chapter_IEq039.gif) on ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq30.gif) by the formula

![
$$\\displaystyle{\\mu _{\\psi }^{A}\(E\) = \\left \\langle \\psi {,\\mu }^{A}\(E\)\\psi \\right\\rangle.}$$
](A272900_1_En_10_Chapter_Equl.gif)

If the operator A represents some observable in quantum mechanics, then we interpret ![
$$\\mu_\\psi^A$$
](A272900_1_En_10_Chapter_IEq040.gif) to be the probability distribution for the result of measuring A in the state ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq041.gif).

Proposition 10.8.

Let A be a self-adjoint operator on H . Then the spectral subspaces V E associated to A have the following properties.

1.

If E is a bounded subset of ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq31.gif), then V E ⊂ Dom(A), V E is invariant under A, and the restriction of A to V E is bounded.

2.

If E is contained in ![
$$\(\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \)$$
](A272900_1_En_10_Chapter_IEq32.gif), then for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq042.gif) ∈ V E, we have

![
$$\\displaystyle{\\left \\Vert \(A -\\lambda _{0}I\)\\psi \\right\\Vert \\leq \\varepsilon \\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_10_Chapter_Equm.gif)

Proof.

Point 1 holds because the function f(λ) = λ is bounded on E. (See the proof of Proposition 10.3.) Point 2 then holds because, as in the proof of Proposition 10.3, the restriction of A to V E coincides with the restriction to V E of the operator f(A), where f(λ) = λ1 E (λ).

Theorem 10.9 (Spectral Theorem, Second Form).

Suppose A is a self-adjoint operator on H . Then there is a σ-finite measure μ on σ(A), a direct integral

![
$$\\displaystyle{\\int _{\\sigma \(A\)}^{\\oplus }\\mathbf{H}_{\\lambda }\\ d\\mu \(\\lambda \),}$$
](A272900_1_En_10_Chapter_Equn.gif)

and a unitary map U from H to the direct integral such that:

![
$$\\displaystyle{U\(\\mathrm{Dom}\(A\)\) = \\left \\{\\left.s \\in \\int _{\\sigma \(A\)}^{\\oplus }\\mathbf{H}_{\\lambda }\\ d\\mu \(\\lambda \)\\right\\vert \\int _{\\sigma \(A\)}\\left \\Vert \\lambda s\(\\lambda \)\\right\\Vert _{\\lambda }^{2}\\ d\\mu \(\\lambda \) < \\infty \\right\\}}$$
](A272900_1_En_10_Chapter_Equo.gif)

and such that

![
$$\\displaystyle{\\left \(UA{U}^{-1}\(s\)\\right\)\(\\lambda \) =\\lambda s\(\\lambda \)}$$
](A272900_1_En_10_Chapter_Equp.gif)

for all s ∈ U(Dom(A)).

Theorem 10.10 (​Spectral Theorem,Multiplication Operator Form).

Suppose A is a self-adjoint operator on H . Then there is a σ-finite measure space (X,μ), a measurable, real-valued function h on X, and a unitary map U : H → L 2 (X,μ) such that

![
$$\\displaystyle{U\(\\mathrm{Dom}\(A\)\) = \\left \\{\\psi \\in {L}^{2}\(X,\\mu \)\\left \\vert h\\psi \\in {L}^{2}\(X,\\mu \)\\right.\\right\\}}$$
](A272900_1_En_10_Chapter_Equq.gif)

and such that

![
$$\\displaystyle{\(UA{U}^{-1}\(\\psi \)\)\(x\) = h\(x\)\\psi \(x\)}$$
](A272900_1_En_10_Chapter_Equr.gif)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq043.gif) ∈ U(Dom(A)).

These theorems are also proved in Sect. 10.4.

## 10.2 Stone's Theorem and One-Parameter Unitary Groups

In this section we explore the notion of one-parameter unitary groups and their connection to self-adjoint operators. We assume here the spectral theorem, the proof of which (in Sect. 10.4) does not use any results from this section.

Definition 10.11.

A one-parameter unitary group on H is a family U(t), ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq33.gif), of unitary operators with the property that U(0) = I and that ![
$$U\(s+t\) = U\(s\)U\(t\)$$
](A272900_1_En_10_Chapter_IEq34.gif) for all ![
$$s,t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq35.gif). A one-parameter unitary group is said to be strongly continuous if

![
$$\\displaystyle{ \\lim _{s\\rightarrow t}\\left \\Vert U\(t\)\\psi - U\(s\)\\psi \\right\\Vert = 0 }$$
](A272900_1_En_10_Chapter_Equ12.gif)

(10.11)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq044.gif) ∈ H and all ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq36.gif).

Almost all one-parameter unitary groups arising in applications are strongly continuous.

Example 10.12.

Let ![
$$\\mathbf{H} = {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq37.gif) and let U a (t) be the translation operator given by

![
$$\\displaystyle{ \\left \(U_{\\mathbf{a}}\(t\)\\psi \\right\)\(\\mathbf{x}\) =\\psi \(\\mathbf{x} + t\\mathbf{a}\). }$$
](A272900_1_En_10_Chapter_Equ13.gif)

(10.12)

Then U(⋅) is a strongly continuous one-parameter unitary group.

Proof.

It is easy to see that U a (⋅) is a one-parameter unitary group. To see that U a (⋅) is strongly continuous, consider first the case in which ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq045.gif) is continuous and compactly supported. Since a continuous function on a compact metric space is automatically uniformly continuous, it follows that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq046.gif)(x \+ t a) tends uniformly to ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq047.gif)(x) as t tends to zero. Since also the support of ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq048.gif) is compact and thus of finite measure, it follows that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq049.gif)(x \+ t a) tends to ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq050.gif)(x) in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq38.gif) as t tends to zero.

Now, the space ![
$$C_{c}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq39.gif) of continuous functions of compact support is dense in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq40.gif) (Theorem A.10). Thus, given ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq41.gif) and ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq42.gif), we can find ![
$$\\phi \\in C_{c}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq43.gif) such that ![
$$\\left \\Vert \\psi -\\phi \\right\\Vert _{{L}^{2}\(\\mathbb{R}\)} <\\varepsilon /3$$
](A272900_1_En_10_Chapter_IEq44.gif). Then choose δ so that ![
$$\\left \\Vert U_{\\mathbf{a}}\(a\)\\phi -\\phi \\right\\Vert <\\varepsilon /3$$
](A272900_1_En_10_Chapter_IEq45.gif) whenever ![
$$\\left \\vert a\\right\\vert <\\delta$$
](A272900_1_En_10_Chapter_IEq46.gif). Then given ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq47.gif), if ![
$$\\left \\vert t - s\\right\\vert <\\delta$$
](A272900_1_En_10_Chapter_IEq48.gif), we have

![
$$\\displaystyle\\begin{array}{lll} \\left \\Vert U_{\\mathbf{a}}\(t\)\\psi - U_{\\mathbf{a}}\(s\)\\psi \\right\\Vert \\\\ \\leq  \\left \\Vert U_{\\mathbf{a}}\(t\)\\psi - U_{\\mathbf{a}}\(t\)\\phi \\right\\Vert + \\left \\Vert U_{\\mathbf{a}}\(t\)\\phi - U_{\\mathbf{a}}\(s\)\\phi \\right\\Vert + \\left \\Vert U_{\\mathbf{a}}\(s\)\\phi - U_{\\mathbf{a}}\(s\)\\psi \\right\\Vert \\\\ = \\left \\Vert U_{\\mathbf{a}}\(t\)\(\\psi -\\phi \)\\right\\Vert + \\left \\Vert U_{\\mathbf{a}}\(s\)\\left \(U_{\\mathbf{a}}\(t - s\)\\phi -\\phi \\right\)\\right\\Vert + \\left \\Vert U_{\\mathbf{a}}\(s\)\(\\phi -\\psi \)\\right\\Vert.{}\\end{array}$$
](A272900_1_En_10_Chapter_Equ14.gif)

(10.13)

Since U a (t) and U a (s) are unitary, we can see that each of the terms on the last line of (10.13) is less than ![
$$\\varepsilon /3$$
](A272900_1_En_10_Chapter_IEq49.gif).

Note that for a≠0 the unitary group U a (⋅) in Example 10.12 is not continuous in the operator norm topology. After all, given any ![
$$\\varepsilon \\neq 0$$
](A272900_1_En_10_Chapter_IEq50.gif), we can take a nonzero element ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq051.gif) of ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq51.gif) that is supported in a very small ball around the origin. Then ![
$$U_{\\mathbf{a}}\(\\varepsilon \)\\psi$$
](A272900_1_En_10_Chapter_IEq52.gif) is orthogonal to ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq052.gif) and has the same norm as ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq053.gif), so that

![
$$\\displaystyle{\\left \\Vert U_{\\mathbf{a}}\(\\varepsilon \)\\psi - U_{\\mathbf{a}}\(0\)\\psi \\right\\Vert = \\left \\Vert U_{\\mathbf{a}}\(\\varepsilon \)\\psi -\\psi \\right\\Vert = \\sqrt{2}\\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_10_Chapter_Equs.gif)

Thus, ![
$$\\left \\Vert U_{\\mathbf{a}}\(\\varepsilon \) - U_{\\mathbf{a}}\(0\)\\right\\Vert \\geq \\sqrt{2}$$
](A272900_1_En_10_Chapter_IEq53.gif) for all ![
$$\\varepsilon \\neq 0$$
](A272900_1_En_10_Chapter_IEq54.gif).

Definition 10.13.

If U(⋅) is a strongly continuous one-parameter unitary group, the infinitesimal generator of U(⋅) is the operator A given by

![
$$\\displaystyle{ A\\psi =\\lim _{t\\rightarrow 0}\\frac{1} {i} \\frac{U\(t\)\\psi -\\psi } {t}, }$$
](A272900_1_En_10_Chapter_Equ15.gif)

(10.14)

with Dom(A) consisting of the set of ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq054.gif) ∈ H for which the limit in ( 10.14 ) exists in the norm topology on H.

The following result shows that we can construct a strongly continuous one-parameter unitary group from any self-adjoint operator A by setting U(t) = e i A t . Furthermore, the original operator A is precisely the infinitesimal generator of U(t).

Proposition 10.14.

Suppose A is a self-adjoint operator on H and let U(⋅) be defined by

![
$$\\displaystyle{U\(t\) = {e}^{itA},}$$
](A272900_1_En_10_Chapter_Equt.gif)

where the operator e itA is defined by the functional calculus for A. Then the following hold.

1.

U(⋅) is a strongly continuous one-parameter unitary group.

2.

For all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq055.gif) ∈ Dom(A), we have

![
$$\\displaystyle{A\\psi =\\lim _{t\\rightarrow 0}\\frac{1} {i} \\frac{U\(t\)\\psi -\\psi } {t},}$$
](A272900_1_En_10_Chapter_Equu.gif)

where the limit is in the norm topology on H.

3.

For all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq056.gif) ∈ H , if the limit

![
$$\\displaystyle{\\lim _{t\\rightarrow 0}\\frac{1} {i} \\frac{U\(t\)\\psi -\\psi } {t} }$$
](A272900_1_En_10_Chapter_Equv.gif)

exists in the norm topology on H, then ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq058.gif) ∈ Dom(A) and the limit is equal to A ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq059.gif).

Proof.

Since ![
$$\\sigma \(A\) \\subset \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq55.gif), the function f(λ) : = e i t λ is bounded on σ(A) and satisfies ![
$$f\(\\lambda \)\\overline{f\(\\lambda \)} = 1$$
](A272900_1_En_10_Chapter_IEq56.gif) for all λ ∈ σ(A). Thus, the operator f(A) is bounded and satisfies

![
$$\\displaystyle{f\(A\)f{\(A\)}^{{\\ast}} = f{\(A\)}^{{\\ast}}f\(A\) = I,}$$
](A272900_1_En_10_Chapter_Equw.gif)

which shows that f(A) = e i t A is unitary. The multiplicativity of the functional calculus then tells us that U(⋅) is a one-parameter unitary group. To see that U(t) is strongly continuous, note that

![
$$\\displaystyle\\begin{array}{rcl}{ \\left \\Vert U\(t\)\\psi - U\(s\)\\psi \\right\\Vert }^{2}& =& \\left \\langle \\psi,\(U{\(t\)}^{{\\ast}}- U{\(s\)}^{{\\ast}}\)\(U\(t\) - U\(s\)\)\\psi \\right\\rangle \\\\ & =& \\int _{-\\infty }^{\\infty }{\\left \\vert {e}^{it\\lambda } - {e}^{is\\lambda }\\right\\vert }^{2}\\ d\\mu _{\\psi }^{A}\(\\lambda \). {}\\end{array}$$
](A272900_1_En_10_Chapter_Equ16.gif)

(10.15)

The integral on the right-hand side of (10.15) tends to zero as s approaches t, by dominated convergence.

For Point 2, from recall from Theorem 10.4 that ![
$$A =\\int _{ -\\infty }^{\\infty }\\lambda \\ {d\\mu }^{A}\(\\lambda \)$$
](A272900_1_En_10_Chapter_IEq57.gif), and take ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq060.gif) ∈ Dom(A). Then, by (10.4), we have

![
$$\\displaystyle{{ \\left \\Vert \\frac{1} {i} \\frac{U\(t\)\\psi -\\psi } {t} - A\\psi \\right\\Vert }^{2} =\\int _{ -\\infty }^{\\infty }{\\left \\vert \\frac{1} {i} \\frac{{e}^{it\\lambda } - 1} {t} -\\lambda \\right\\vert }^{2}\\ d\\mu _{\\psi }^{A}\(\\lambda \). }$$
](A272900_1_En_10_Chapter_Equ17.gif)

(10.16)

If we write the function e i t λ − 1 as the integral of its derivative with respect to λ, starting at λ = 0, we can see that ![
$$\\left \\vert \({e}^{it\\lambda } - 1\)/t\\right\\vert \\leq \\lambda$$
](A272900_1_En_10_Chapter_IEq58.gif). Meanwhile, since ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq061.gif) is in the domain of the operator ![
$$A =\\int _{ -\\infty }^{\\infty }\\lambda \\ {d\\mu }^{A}\(\\lambda \)$$
](A272900_1_En_10_Chapter_IEq59.gif), we have ![
$$\\int _{-\\infty }^{\\infty }{\\lambda }^{2}\\ d\\mu _{\\psi }^{A}\(\\lambda \) < \\infty $$
](A272900_1_En_10_Chapter_IEq60.gif). Thus, we may apply dominated convergence, with 4λ 2 as our dominating function, to show that the right-hand side of (10.16) tends to zero as t tends to zero.

For Point 3, let B be the infinitesimal generator of U(⋅). If ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq062.gif) and ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq063.gif) belong to Dom(B), then

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \\phi,B\\psi \\right\\rangle & =& \\lim _{t\\rightarrow 0}\\left \\langle \\phi, \\frac{1} {i} \\frac{U\(t\)\\psi -\\psi } {t} \\right\\rangle {}\\\\ & =& \\lim _{t\\rightarrow 0}\\left \\langle -\\frac{1} {i} \\frac{U{\(t\)}^{{\\ast}}\\phi -\\phi } {t},\\psi \\right\\rangle {}\\\\ & =& \\lim _{t\\rightarrow 0}\\left \\langle \\frac{1} {i} \\frac{U\(-t\)\\phi -\\phi } {\(-t\)},\\psi \\right\\rangle {}\\\\ & =& \\left \\langle B\\phi,\\psi \\right\\rangle. {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ18.gif)

Thus, B is symmetric. On the other hand, Point 2 shows that B is an extension of A, so by Exercise 7 in Chap.​ 9, B = A (with equality of domain).

Theorem 10.15 (Stone's Theorem).

Suppose U(⋅) is a strongly continuous one-parameter unitary group on H. Then the infinitesimal generator A of U(⋅) is densely defined and self-adjoint, and U(t) = e itA for all ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq61.gif).

If U(⋅) is a strongly continuous one-parameter unitary group, then U(⋅) is continuous in the operator norm topology if and only if the infinitesimal generator of U(⋅) is a bounded operator (Exercise 1). As Example 10.12 suggests, most one-parameter unitary groups that arise in applications are not continuous in the operator norm topology.

Before giving the proof of Stone's theorem, let us work out the generator of the group in Example 10.12.

Example 10.16.

If U a (⋅), ![
$$\\mathbf{a} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_10_Chapter_IEq62.gif), is the strongly continuous one- parameter unitary group in Example 10.12, then each ![
$$\\psi \\in C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq63.gif) is in the domain of the infinitesimal generator A of U a (⋅) and for all such ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq064.gif), we have

![
$$\\displaystyle{ A\\psi = -i\\sum _{j}a_{j} \\frac{\\partial \\psi } {\\partial x_{j}}. }$$
](A272900_1_En_10_Chapter_Equ19.gif)

(10.17)

Furthermore, A is essentially self-adjoint on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq64.gif).

Proof.

The formula for the infinitesimal generator is easy to establish for ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq065.gif) in ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq65.gif). The essential self-adjointness of A is a special case of Proposition 13.5 (the proof of which is similar to the proof of Proposition 9.29).

We now establish two intermediate results before coming to the proof of Stone's theorem.

Lemma 10.17.

Let U(⋅) be a strongly continuous one-parameter unitary group and let A be its infinitesimal generator. If ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq066.gif) ∈ Dom(A), then for all ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq66.gif), the vector U(t)![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq067.gif) belongs to Dom(A) and

![
$$\\displaystyle{ \\lim _{h\\rightarrow 0}\\frac{U\(t + h\)\\psi - U\(t\)\\psi } {h} = iU\(t\)A\\psi = iAU\(t\)\\psi. }$$
](A272900_1_En_10_Chapter_Equ20.gif)

(10.18)

Note that Lemma 10.17 tells us that the curve ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq068.gif)(t) : = U(t)![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq069.gif) 0 in H satisfies the differential equation

![
$$\\displaystyle{ \\frac{d\\psi } {dt} = iA\\psi \(t\)}$$
](A272900_1_En_10_Chapter_Equx.gif)

in the natural Hilbert space sense, provided that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq070.gif) 0 belongs to Dom(A). This result, together with Proposition 10.14, tells us that if ![
$$\\psi _{0} \\in \\mathrm{ Dom}\(\\hat{H}\)$$
](A272900_1_En_10_Chapter_IEq67.gif), then the curve ![
$$\\psi \(t\) := {e}^{-it\\hat{H}/\\hslash }\\psi _{0}$$
](A272900_1_En_10_Chapter_IEq68.gif) indeed solves the Schrödinger equation in the Hilbert space sense.

Proof.

We compute that

![
$$\\displaystyle{ \\frac{U\(t + h\)\\psi - U\(t\)\\psi } {h} = U\(t\)\\frac{\\left \[U\(h\)\\psi -\\psi \\right\]} {h}. }$$
](A272900_1_En_10_Chapter_Equ21.gif)

(10.19)

Since ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq071.gif) ∈ Dom(A), the limit as h tends to zero of (10.19) exists and is equal to iU(t)A ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq072.gif). On the other hand,

![
$$\\displaystyle{\\frac{U\(t + h\)\\psi - U\(t\)\\psi } {h} = \\frac{U\(h\)\(U\(t\)\\psi \) - \(U\(t\)\\psi \)} {h}.}$$
](A272900_1_En_10_Chapter_Equy.gif)

Thus, the limit as h tends to zero of (10.19) is, by the definition of A, equal to iA(U(t)![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq073.gif)). This shows that U(t)![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq074.gif) is in the domain of A and establishes the second equality in (10.18).

Lemma 10.18.

For any strongly continuous one-parameter unitary group U(⋅), the infinitesimal generator A is densely defined.

Proof.

Given any continuous function f of compact support, define an operator B f by setting

![
$$\\displaystyle{B_{f} =\\int _{ -\\infty }^{\\infty }f\(\\tau \)U\(\\tau \)\\ d\\tau.}$$
](A272900_1_En_10_Chapter_Equz.gif)

Here, the operator-valued integral is the unique bounded operator such that

![
$$\\displaystyle{ \\left \\langle \\phi,B_{f}\\psi \\right\\rangle =\\int _{ -\\infty }^{\\infty }f\(\\tau \)\\left \\langle \\phi,U\(\\tau \)\\psi \\right\\rangle \\ d\\tau. }$$
](A272900_1_En_10_Chapter_Equ22.gif)

(10.20)

[It is easy to see that right-hand side of (10.20) defines a bounded sesquilinear form, for each fixed ![
$$f \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_10_Chapter_IEq69.gif).]

Using the group property of U(⋅), we see that

![
$$\\displaystyle\\begin{array}{rcl} U\(t\)B_{f}\\psi - B_{f}\\psi & =& \\int _{-\\infty }^{\\infty }\[f\(\\tau \)U\(\\tau +t\)\\psi - f\(\\tau \)U\(\\tau \)\\psi \]\\ d\\tau {}\\\\ & =& \\int _{-\\infty }^{\\infty }\[f\(\\tau -t\) - f\(\\tau \)\]U\(\\tau \)\\psi \\ d\\tau, {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ23.gif)

where in the second line, we have made a change of variable in the first term in the integral. From this, we easily obtain that

![
$$\\displaystyle{\\lim _{t\\rightarrow 0}\\frac{U\(t\)B_{f}\\psi - B_{f}\\psi } {t} = -\\int _{-\\infty }^{\\infty }{f}^{{\\prime}}\(\\tau \)U\(\\tau \)\\psi \\ d\\tau.}$$
](A272900_1_En_10_Chapter_Equaa.gif)

This shows that B f ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq075.gif) is in the domain of A for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq076.gif) ∈ H and ![
$$f \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_10_Chapter_IEq70.gif).

Now choose a sequence ![
$$f_{n} \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_10_Chapter_IEq71.gif) such that f n is non-negative and supported in the interval ![
$$\[-1/n,1/n\]$$
](A272900_1_En_10_Chapter_IEq72.gif) and such that ![
$$\\int _{-\\infty }^{\\infty }f_{n}\(\\tau \)\\ d\\tau = 1$$
](A272900_1_En_10_Chapter_IEq73.gif). Then for any ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq077.gif) ∈ H, we have

![
$$\\displaystyle{B_{f_{n}}\\psi -\\psi =\\int _{ -\\infty }^{\\infty }f_{ n}\(\\tau \)\[U_{n}\(\\tau \)\\psi -\\psi \]\\ d\\tau,}$$
](A272900_1_En_10_Chapter_Equab.gif)

so that

![
$$\\displaystyle\\begin{array}{rcl} \\left \\Vert B_{f_{n}}\\psi -\\psi \\right\\Vert & \\leq & \\int _{-\\infty }^{\\infty }f_{ n}\(\\tau \)\\left \\Vert U\(\\tau \)\\psi -\\psi \\right\\Vert \\ d\\tau {}\\\\ & \\leq & \\sup _{-1/n\\leq \\tau \\leq 1/n}\\left \\Vert U\(\\tau \)\\psi -\\psi \\right\\Vert. {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ24.gif)

Since U(⋅) is strongly continuous, we see that ![
$$B_{f_{n}}\\psi$$
](A272900_1_En_10_Chapter_IEq74.gif) converges to ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq078.gif) as n → ∞. Thus, every element of H can be approximated by vectors in the domain of A.

Proof of Theorem 10.15.

Suppose U(⋅) is a strongly continuous one-parameter unitary group and A is its infinitesimal generator. By Lemma 10.18, A is densely defined. As shown in the proof of Proposition 10.14, A (denoted by B in that proof) is symmetric.

Next, we show that A is essentially self-adjoint. Suppose now that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq079.gif) belongs to the kernel of A ∗ − iI, i.e., A ∗ ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq080.gif) = i ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq081.gif). Given ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq082.gif) ∈ Dom(A), set ![
$$y\(t\) = \\left \\langle U\(t\)\\phi,\\psi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq75.gif), so that ![
$$\\left \\vert y\(t\)\\right\\vert \\leq \\left \\Vert \\phi \\right\\Vert \\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_10_Chapter_IEq76.gif). On the other hand, we expect that U(t) = e i A t , so that U(t)∗ should be ![
$${e}^{-i{A}^{{\\ast}}t }$$
](A272900_1_En_10_Chapter_IEq77.gif). Thus, y(t) should (formally) be equal to ![
$$\\left \\langle \\phi,{e}^{t}\\psi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq78.gif). If this is correct, then since y(t) is a bounded function of t, we must have ![
$$\\left \\langle \\phi,\\psi \\right\\rangle = 0$$
](A272900_1_En_10_Chapter_IEq79.gif). Thus, ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq083.gif) would be orthogonal to every element of a dense subspace of H, showing that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq084.gif) = 0. We could then similarly argue that ![
$$\\ker \({A}^{{\\ast}} + iI\) =\\{ 0\\}$$
](A272900_1_En_10_Chapter_IEq80.gif), which would show that A is essentially self-adjoint.

To make the argument rigorous, we apply Lemma 10.17, giving

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}\\left \\langle U\(t\)\\phi,\\psi \\right\\rangle & =& \\left \\langle iAU\(t\)\\phi,\\psi \\right\\rangle = \\left \\langle iU\(t\)\\phi,{A}^{{\\ast}}\\psi \\right\\rangle {}\\\\ & =& \\left \\langle iU\(t\)\\phi,i\\psi \\right\\rangle = \\left \\langle U\(t\)\\phi,\\psi \\right\\rangle. {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ25.gif)

Thus, the function ![
$$y\(t\) := \\left \\langle U\(t\)\\phi,\\psi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq81.gif) satisfies the ordinary differential equation ![
$$dy/dt = y$$
](A272900_1_En_10_Chapter_IEq82.gif). The unique solution to this equation is y(t) = y(0)e t . Since y is bounded, we must have ![
$$0 = y\(0\) = \\left \\langle \\phi,\\psi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq83.gif) for all ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq085.gif) ∈ Dom(A), which implies that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq086.gif) = 0. Thus, ![
$$\\ker \({A}^{{\\ast}}- iI\) =\\{ 0\\}$$
](A272900_1_En_10_Chapter_IEq84.gif), and by a similar argument ![
$$\\ker \({A}^{{\\ast}} + iI\) =\\{ 0\\}$$
](A272900_1_En_10_Chapter_IEq85.gif). This shows (Corollary 9.22) that A is essentially self-adjoint.

We can now construct a strongly continuous unitary group V (⋅) by setting ![
$$V \(t\) = {e}^{i{A}^{cl}t }$$
](A272900_1_En_10_Chapter_IEq86.gif). To show that V (⋅) = U(⋅), take ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq087.gif) ∈ Dom(A) ⊂ Dom(A cl ) and set ![
$$w\(t\) = U\(t\)\\psi - V \(t\)\\psi$$
](A272900_1_En_10_Chapter_IEq87.gif). By Proposition 10.14, the infinitesimal generator of V (⋅) is A cl . Thus, applying Lemma 10.17 to both U(⋅) and V (⋅), we have

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}w\(t\)& =& iAU\(t\)\\psi - iAV \(t\)\\psi {}\\\\ & =& iAw\(t\), {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ26.gif)

where the limit defining dw ∕ dt is taken in the norm topology on H. Thus,

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d} {dt}{\\left \\Vert w\(t\)\\right\\Vert }^{2}& =& \\left \\langle iAw\(t\),w\(t\)\\right\\rangle + \\left \\langle w\(t\),iAw\(t\)\\right\\rangle {}\\\\ & =& -i\\left \\langle Aw\(t\),w\(t\)\\right\\rangle + i\\left \\langle w\(t\),Aw\(t\)\\right\\rangle {}\\\\ & =& 0, {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ27.gif)

because A is symmetric. Since also w(0) = 0, we conclude that w(t) = 0 for all t. Thus, U(⋅) and V (⋅) agree on a dense subspace and hence on all of H.

We now know that ![
$$U\(t\) = {e}^{i{A}^{cl}t }$$
](A272900_1_En_10_Chapter_IEq88.gif). It then follows from Points 2 and 3 of Proposition 10.14 that the infinitesimal generator of U(⋅) (namely A) is precisely A cl . That is, A = A cl and U(t) = e i A t . Furthermore, we have already shown that A is essentially self-adjoint and we now know that A = A cl , so A is actually self-adjoint. Finally, if B is any self-adjoint operator for which U(t) = e i B t , then by Proposition 10.14, B must be the infinitesimal generator of U(⋅), i.e., B = A.

## 10.3 The Spectral Theorem for Bounded Normal Operators

We are going to prove the spectral theorem for an unbounded self-adjoint operator by reducing it to the spectral theorem for a bounded operator. The reduction, however, will not be to a bounded self-adjoint operator, but rather to a unitary operator. Although we proved the spectral theorem only for bounded self-adjoint operators, the theorem applies more generally to bounded normal operators. (See Exercise 4 in Chap.​ 7 for the matrix case.)

Definition 10.19.

A bounded operator A on H is normal if A commutes with its adjoint: AA ∗ = A ∗ A.

Every bounded self-adjoint operator is obviously normal. Other examples of normal operators are skew-self-adjoint operators (![
$${A}^{{\\ast}} = -A$$
](A272900_1_En_10_Chapter_IEq89.gif)) and unitary operators (![
$$U{U}^{{\\ast}} = {U}^{{\\ast}}U = I$$
](A272900_1_En_10_Chapter_IEq90.gif)). The spectrum of a bounded normal operator need not be contained in ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq91.gif), but can be an arbitrary closed, bounded, nonempty subset of ![
$$\\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq92.gif). On the other hand, if U is unitary, then the spectrum of U is contained in the unit circle (Exercise 6 in Chap.​ 7).

In this section, we consider the spectral theorem for a bounded normal operator A. The statements of the two versions of the theorem are precisely the same as in the self-adjoint case, except that σ(A) is no longer necessarily contained in the real line. Almost all of the proofs of these results are the same as in the self-adjoint case; we will, therefore, consider only those steps where some modification in the argument is required.

Theorem 10.20.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq93.gif) is normal. Then there exists a unique projection-valued measure μ A on the Borel σ-algebra in σ(A), with values in ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq94.gif) , such that

![
$$\\displaystyle{\\int _{\\sigma \(A\)}\\lambda \\ {d\\mu }^{A}\(\\lambda \) = A.}$$
](A272900_1_En_10_Chapter_Equac.gif)

Furthermore, for any measurable set E ⊂σ(A), Range (μ A (E)) is invariant under A and A ∗.

Once we have the projection-valued measure μ A , we can define a functional calculus for A, as in the self-adjoint case, by setting

![
$$\\displaystyle{f\(A\) =\\int _{\\sigma \(A\)}f\(\\lambda \)\\ {d\\mu }^{A}\(\\lambda \)}$$
](A272900_1_En_10_Chapter_Equad.gif)

for any bounded measurable function f on σ(A).

We can also define spectral subspaces, as in the self-adjoint case, by setting

![
$$\\displaystyle{V _{E} :=\\mathrm{ Range}{\(\\mu }^{A}\(E\)\)}$$
](A272900_1_En_10_Chapter_Equae.gif)

for each Borel set E ⊂ σ(A). These spectral subspaces have precisely the same properties (with the same proofs) as in Proposition 7.15, with the following two exceptions. First, the assertion that V E is invariant under A should be replaced by the assertion that V E is invariant under A and A ∗. Second, in Point 2 of the proposition, the condition ![
$$E \\subset \[\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \]$$
](A272900_1_En_10_Chapter_IEq95.gif) should be replaced by ![
$$E \\subset \\overline{D\(\\lambda _{0},\\varepsilon \)}$$
](A272900_1_En_10_Chapter_IEq96.gif), where D(z, r) denotes the disk of radius r in ![
$$\\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq97.gif) centered at z.

Meanwhile, the spectral theorem in its direct integral and multiplication operator versions also holds for a bounded normal operator A. The statements are identical to the self-adjoint case, except that we no longer assume ![
$$\\sigma \(A\) \\subset \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq98.gif) and we no longer assume that the function h in the multiplication operator version is real valued.

Let us recall the two stages in the proof of the spectral theorem (first version) for bounded self-adjoint operators. The first stage is the construction of the continuous functional calculus. The steps in this construction are (1) the equality of the norm and spectral radius for self-adjoint operators, (2) the spectral mapping theorem, and (3) the Stone–Weierstrass theorem. The second stage is a sort of operator-valued Riesz representation theorem, which we prove by reducing it to the ordinary Riesz representation theorem using quadratic forms. In generalizing from bounded self-adjoint to bounded normal operators, the second stage of the proof is precisely the same as in the self-adjoint case. In the first stage, however, there are some additional ideas needed in each step of the argument.

There is a relatively simple argument that reduces the equality of norm and spectral radius for normal operators to the self-adjoint case. Meanwhile, since the spectral mapping theorem, as stated in Chap.​ 8, already holds for arbitrary bounded operators, it appears that no change is needed in this step. We must think, however, about the proper notion of "polynomial." For a general normal operator A, the spectrum of A is not contained in ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq99.gif), and, thus, powers of λ are complex-valued functions on σ(A). We must, therefore, use the complex-valued version of the Stone–Weierstrass theorem (Appendix A.3.1), which requires that our algebra of functions be closed under complex-conjugation. This means that we need to consider polynomials in λ and ![
$$\\bar{\\lambda }$$
](A272900_1_En_10_Chapter_IEq100.gif), that is, linear combinations of functions of the form ![
$$\\lambda {}^{m}\\bar{{\\lambda }}^{n}$$
](A272900_1_En_10_Chapter_IEq101.gif).

What we need, then, is a form of the spectral mapping theorem that applies to this sort of polynomial. On the operator side, the natural counterpart to the complex conjugate of a function is the adjoint of an operator. Thus, applying the function ![
$$\\lambda {}^{m}\\bar{{\\lambda }}^{n}$$
](A272900_1_En_10_Chapter_IEq102.gif) to a normal operator A should give ![
$${A}^{m}{\({A}^{{\\ast}}\)}^{n}$$
](A272900_1_En_10_Chapter_IEq103.gif). The desired "spectral mapping theorem" is then the following: If p is a polynomial in two variables, and A is a bounded normal operator, then

![
$$\\displaystyle{ \\sigma \(p\(A,{A}^{{\\ast}}\)\) = \\left \\{\\left.p\(\\lambda,\\bar{\\lambda }\)\\right\\vert \\lambda \\in \\sigma \(A\)\\right\\}. }$$
](A272900_1_En_10_Chapter_Equ28.gif)

(10.21)

This statement is true (Theorem 10.23), but its proof is not nearly as simple as the proof of the ordinary spectral mapping theorem. One way to prove (10.21) is to use the theory of commutative C ∗-algebras, as in [33]. (See Theorem 11.19 in [33] along with the assertion on p. 321 that the spectrum of an element is independent of the algebra containing that element.) Another approach is the direct argument found in Bernau [3], which uses no fancy machinery but which is long and not easily motivated. A third approach is to use the spectral theorem for bounded self-adjoint operators to help us prove (10.21); this is the approach we will follow.

We begin with the equality of norm and spectral radius and then turn to (10.21).

Proposition 10.21.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq104.gif) is normal, then

![
$$\\displaystyle{\\left \\Vert A\\right\\Vert = R\(A\).}$$
](A272900_1_En_10_Chapter_Equaf.gif)

Lemma 10.22.

If A and B are commuting elements of ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq105.gif) , then

![
$$\\displaystyle{R\(AB\) \\leq R\(A\)R\(B\).}$$
](A272900_1_En_10_Chapter_Equag.gif)

Proof.

If A is any bounded operator, the proof of Lemma 8.1 shows that for any real number T with T > R(A), we have

![
$$\\displaystyle{\\lim _{m\\rightarrow \\infty }\\frac{\\left \\Vert {A}^{m}\\right\\Vert } {{T}^{m}} = 0.}$$
](A272900_1_En_10_Chapter_Equah.gif)

If A and B are two commuting bounded operators and S and T are two real numbers, with S > R(A) and T > R(B), then

![
$$\\displaystyle{\\frac{\\left \\Vert {\(AB\)}^{m}\\right\\Vert } {{S}^{m}{T}^{m}} = \\frac{\\left \\Vert {A}^{m}{B}^{m}\\right\\Vert } {{S}^{m}{T}^{m}} \\leq \\frac{\\left \\Vert {A}^{m}\\right\\Vert \\left \\Vert {B}^{m}\\right\\Vert } {{S}^{m}{T}^{m}}.}$$
](A272900_1_En_10_Chapter_Equai.gif)

Thus,

![
$$\\displaystyle{ \\lim _{m\\rightarrow \\infty }\\frac{\\left \\Vert {\(AB\)}^{m}\\right\\Vert } {{S}^{m}{T}^{m}} = 0. }$$
](A272900_1_En_10_Chapter_Equ29.gif)

(10.22)

Meanwhile, if we apply the expression for the resolvent in the proof of Lemma 8.1 to AB, we obtain

![
$$\\displaystyle{ {\(AB-\\lambda \)}^{-1} = -\\sum _{ m=0}^{\\infty }{\\frac{{A}^{m}{B}^{m}} {\\lambda }^{m+1}}, }$$
](A272900_1_En_10_Chapter_Equ30.gif)

(10.23)

since A and B commute. For any λ 1 with ![
$$\\left \\vert \\lambda _{1}\\right\\vert > R\(A\)R\(B\)$$
](A272900_1_En_10_Chapter_IEq106.gif), take λ 2 with ![
$$\\left \\vert \\lambda _{1}\\right\\vert > \\left \\vert \\lambda _{2}\\right\\vert > R\(A\)R\(B\)$$
](A272900_1_En_10_Chapter_IEq107.gif). The terms in (10.23) with λ = λ 2 tend to zero by (10.22), which means that (10.23) converges with λ = λ 1. Thus, λ 1 is in the resolvent set of AB.

Proof of Proposition 10.21.

For any bounded operator, ![
$$\\left \\Vert A\\right\\Vert \\geq R\(A\)$$
](A272900_1_En_10_Chapter_IEq108.gif) (Proposition 7.5). To get the inequality in the other direction, recall (Proposition 7.2) that ![
$${\\left \\Vert A\\right\\Vert }^{2} = \\left \\Vert {A}^{{\\ast}}A\\right\\Vert$$
](A272900_1_En_10_Chapter_IEq109.gif). Note also that A ∗ A is self-adjoint, since its adjoint is ![
$${A}^{{\\ast}}{A}^{{\\ast}{\\ast}} = {A}^{{\\ast}}A$$
](A272900_1_En_10_Chapter_IEq110.gif). Thus, if A and A ∗ commute, we have

![
$$\\displaystyle\\begin{array}{rcl}{ \\left \\Vert A\\right\\Vert }^{2}& =& \\left \\Vert {A}^{{\\ast}}A\\right\\Vert = R\({A}^{{\\ast}}A\) \\leq R\({A}^{{\\ast}}\)R\(A\) {}\\\\ & \\leq & \\left \\Vert {A}^{{\\ast}}\\right\\Vert R\(A\) = \\left \\Vert A\\right\\Vert R\(A\). {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ31.gif)

Here we have used Lemmas 8.1 and 10.22 and the general inequality between norm and spectral radius. Dividing by ![
$$\\left \\Vert A\\right\\Vert$$
](A272900_1_En_10_Chapter_IEq111.gif) gives ![
$$\\left \\Vert A\\right\\Vert \\leq R\(A\)$$
](A272900_1_En_10_Chapter_IEq112.gif), unless ![
$$\\left \\Vert A\\right\\Vert = 0$$
](A272900_1_En_10_Chapter_IEq113.gif), in which case the desired inequality is trivially satisfied.

Theorem 10.23.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq114.gif) is normal, then for any polynomial p in two variables, we have

![
$$\\displaystyle{\\sigma \\left \(p\(A,{A}^{{\\ast}}\)\\right\) = \\left \\{\\left.p\(\\lambda,\\bar{\\lambda }\)\\right\\vert \\lambda \\in \\sigma \(A\)\\right\\}.}$$
](A272900_1_En_10_Chapter_Equaj.gif)

If, for example, ![
$$p\(\\lambda,\\bar{\\lambda }\) {=\\lambda { }^{2}\\bar{\\lambda }}^{3}$$
](A272900_1_En_10_Chapter_IEq115.gif), then ![
$$p\(A,{A}^{{\\ast}}\) = {A}^{2}{\({A}^{{\\ast}}\)}^{3}$$
](A272900_1_En_10_Chapter_IEq116.gif). Note that since A and A ∗ are assumed to commute, the map sending the polynomial ![
$$p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq117.gif) to p(A, A ∗) is an algebra homomorphism. That is to say, ![
$$\(pq\)\(A,{A}^{{\\ast}}\) = p\(A,{A}^{{\\ast}}\)q\(A,{A}^{{\\ast}}\)$$
](A272900_1_En_10_Chapter_IEq118.gif). This would not be the case if A did not commute with A ∗.

We begin by proving Theorem 10.23 in the case that A is a normal matrix. Although the matrix case is quite simple, it provides an outline for our assault on the general result.

Proof of Theorem 10.23 in the Matrix Case. For matrices, the spectrum is nothing but the set of eigenvalues. If A commutes with A ∗, then for any ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq119.gif),

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \({A}^{{\\ast}}-\\bar{\\lambda } I\)\\psi,\({A}^{{\\ast}}-\\bar{\\lambda } I\)\\psi \\right\\rangle & =& \\left \\langle \\psi,\(A -\\lambda I\)\({A}^{{\\ast}}-\\bar{\\lambda } I\)\\psi \\right\\rangle \\\\ & =& \\left \\langle \\psi,\({A}^{{\\ast}}-\\bar{\\lambda } I\)\(A -\\lambda I\)\\psi \\right\\rangle \\\\ & =& \\left \\langle \(A -\\lambda I\)\\psi,\(A -\\lambda I\)\\psi \\right\\rangle {}\\end{array}$$
](A272900_1_En_10_Chapter_Equ32.gif)

(10.24)

Thus, if ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq088.gif) is an eigenvalue for A with eigenvalue λ, ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq089.gif) is automatically an eigenvalue for A ∗ with eigenvalue ![
$$\\bar{\\lambda }$$
](A272900_1_En_10_Chapter_IEq120.gif). It then easily follows that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq090.gif) is an eigenvector for p(A, A ∗) with eigenvalue ![
$$p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq121.gif).

In the other direction, suppose μ is an eigenvalue for p(A, A ∗) and let W denote the μ-eigenspace for p(A, A ∗). Since A and A ∗ commute with each other, they also commute with p(A, A ∗). Thus, A and A ∗ preserve W, as is easily verified, and the operator ![
$$\\left.A\\right\\vert _{W}$$
](A272900_1_En_10_Chapter_IEq122.gif) will have some eigenvector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq091.gif) with eigenvalue λ. Since A ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq092.gif) = λ ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq093.gif), then, as in (10.24), ![
$${A}^{{\\ast}}\\psi =\\bar{\\lambda }\\psi$$
](A272900_1_En_10_Chapter_IEq123.gif) and so

![
$$\\displaystyle{p\(A,{A}^{{\\ast}}\)\\psi = p\(\\lambda,\\bar{\\lambda }\)\\psi.}$$
](A272900_1_En_10_Chapter_Equak.gif)

Since also p(A, A ∗)![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq094.gif) = μ ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq095.gif), by assumption, we have ![
$$\\mu = p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq124.gif), where λ is an eigenvalue for A.

We now attempt to run the same argument for a bounded normal operator on H, replacing "eigenvector" with "almost eigenvector," where ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq096.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq125.gif)-almost eigenvector for ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq097.gif) if ![
$$\\left \\Vert \(A -\\lambda I\)\\psi \\right\\Vert$$
](A272900_1_En_10_Chapter_IEq126.gif) is less than ![
$$\\varepsilon \\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_10_Chapter_IEq127.gif). The main difficulty with this approach is that for a given eigenvalue λ, the set of ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq128.gif)-almost eigenvectors is not a vector space. To surmount this difficulty, we will use the spectral theorem for the self-adjoint operator B ∗ B, where ![
$$B = p\(A,{A}^{{\\ast}}\) -\\mu I$$
](A272900_1_En_10_Chapter_IEq129.gif), with μ ∈ σ(p(A, A ∗)). We will construct a spectral subspace W for B ∗ B such that W is invariant under A and A ∗ and such that each element of W is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq130.gif)-almost eigenvector for p(A, A ∗) with eigenvalue μ. (Note, however, that we are not claiming that W contains all the ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq131.gif)-almost eigenvectors for p(A, A ∗).)

Definition 10.24.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq132.gif), then an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq133.gif) -almost eigenvector for A with eigenvalue ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq134.gif) is a nonzero vector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq098.gif) ∈ H such that

![
$$\\displaystyle{\\left \\Vert \(A -\\lambda I\)\\psi \\right\\Vert <\\varepsilon \\left \\Vert \\psi \\right\\Vert.}$$
](A272900_1_En_10_Chapter_Equal.gif)

We now establish three lemmas about almost eigenvectors, the last of which makes use of the spectral theorem for bounded self-adjoint operators. With these lemmas in hand, we will have a clear path to imitate the proof of the matrix case of Theorem 10.23.

Lemma 10.25.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq135.gif) is normal.

1.

If ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq099.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq136.gif) -almost eigenvector for A with eigenvalue λ, then ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0100.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq137.gif) -almost eigenvector for A ∗ with eigenvalue ![
$$\\bar{\\lambda }$$
](A272900_1_En_10_Chapter_IEq138.gif).

2.

A number ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq139.gif) belongs to σ(A) if and only if for all ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq140.gif) , there exists an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq141.gif) -almost eigenvector with eigenvalue λ.

Proof.

Point 1 follows immediately from (10.24), which holds for bounded normal operators, not just matrices. For Point 2, suppose that an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq142.gif)-almost eigenvector with eigenvalue λ exists for all ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq143.gif). Then A − λ I cannot have a bounded inverse, and so λ ∈ σ(A). In the other direction, if there is some ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq144.gif) for which no ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq145.gif)-almost eigenvector exists, then

![
$$\\displaystyle{ \\left \\Vert \(A -\\lambda I\)\\psi \\right\\Vert \\geq \\varepsilon \\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_10_Chapter_Equ33.gif)

(10.25)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0101.gif) ∈ H, showing that A − λ I is injective. By (10.24), the same inequality hods with A − λ I replaced by ![
$${A}^{{\\ast}}-\\bar{\\lambda } I$$
](A272900_1_En_10_Chapter_IEq146.gif). Thus, ![
$${A}^{{\\ast}}-\\bar{\\lambda } I$$
](A272900_1_En_10_Chapter_IEq147.gif) is injective, so by Proposition 7.3, the range of A − λ I is dense in H. Using (10.25) as in the proof of Proposition 7.7, it is easily seen that the range of A − λ I is also closed, hence all of H. Thus, (A − λ I) is invertible and the inverse is bounded, by (10.25).

Lemma 10.26.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq148.gif) is normal. Then for each polynomial p in two variables and each number ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_10_Chapter_IEq149.gif), there is a constant C such that if ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0102.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq150.gif) -almost eigenvector for A with eigenvalue λ, then ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq151.gif) is a ![
$$\(C\\varepsilon \)$$
](A272900_1_En_10_Chapter_IEq152.gif) -almost eigenvector for p(A,A ∗ ) with eigenvalue ![
$$p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq153.gif).

Proof.

We decompose ![
$$p\(A,{A}^{{\\ast}}\) - p\(\\lambda,\\bar{\\lambda }\)I$$
](A272900_1_En_10_Chapter_IEq154.gif) into a linear combination of terms of the form ![
$${A}^{k}{\({A}^{{\\ast}}\)}^{l} {-\\lambda {}^{k}\\bar{\\lambda }}^{l}$$
](A272900_1_En_10_Chapter_IEq155.gif) and we estimate such terms by induction on k \+ l. If k = 1 and l = 0, there is nothing to prove, and if k = 0 and l = 1, we use (10.24). Assume now that we have established the desired result for ![
$$k + l = N$$
](A272900_1_En_10_Chapter_IEq156.gif) and consider a case with ![
$$k + l = N + 1$$
](A272900_1_En_10_Chapter_IEq157.gif). If k > 0, we write

![
$$\\displaystyle\\begin{array}{rcl} \\left \({A}^{k}{\({A}^{{\\ast}}\)}^{l} {-\\lambda {}^{k}\\bar{\\lambda }}^{l}\\right\)\\psi & =& {A}^{k-1}{\({A}^{{\\ast}}\)}^{l}\\left \(A -\\lambda I\\right\)\\psi \\\\ & +& \\lambda \\left \({A}^{k-1}{\({A}^{{\\ast}}\)}^{l} {-\\lambda {}^{k-1}\\bar{\\lambda }}^{l}I\\right\)\\psi.{}\\end{array}$$
](A272900_1_En_10_Chapter_Equ34.gif)

(10.26)

Since ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0103.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq158.gif)-almost eigenvector and A and A ∗ are bounded, the norm of the first term on the right-hand side of (10.26) is at most ![
$$c_{1}\\varepsilon$$
](A272900_1_En_10_Chapter_IEq159.gif). By induction, the norm of the second term on the right-hand side of (10.26) is at most ![
$$\\left \\vert \\lambda \\right\\vert c_{2}\\varepsilon$$
](A272900_1_En_10_Chapter_IEq160.gif). Thus, the norm of the left-hand side of (10.26) is at most ![
$$\(c_{1} + \\left \\vert \\lambda \\right\\vert c_{2}\)\\varepsilon$$
](A272900_1_En_10_Chapter_IEq161.gif). A similar analysis holds if k = 0, in which case l > 0.

Lemma 10.27.

Let ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq162.gif) be normal, let p be a polynomial in two variables, and let μ be an element of the spectrum of p(A,A ∗ ). Then for all ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq163.gif) , there exists a nonzero closed subspace ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq164.gif) of H such that ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq165.gif) is invariant under A and A ∗ and such that every nonzero element of ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq166.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq167.gif) -almost eigenvector for p(A,A ∗ ) with eigenvalue μ.

Proof.

Fix some μ in the spectrum of p(A, A ∗) and let ![
$$B = p\(A,{A}^{{\\ast}}\) -\\mu I$$
](A272900_1_En_10_Chapter_IEq168.gif). Then B is normal and 0 belongs to the spectrum of B. Using Point 2 of Lemma 10.25 and Lemma 10.26, we see that 0 belongs to the spectrum of the self-adjoint operator B ∗ B. We apply the spectral theorem to B ∗ B and we let ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq169.gif) be the spectral subspace for B ∗ B corresponding to the interval ![
$$\({-\\varepsilon }^{2}{,\\varepsilon }^{2}\)$$
](A272900_1_En_10_Chapter_IEq170.gif). By Proposition 7.15, ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq171.gif) is nonzero and invariant under B ∗ B, and the restriction of B ∗ B to ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq172.gif) has norm at most ![
$${\\varepsilon }^{2}$$
](A272900_1_En_10_Chapter_IEq173.gif). Thus, for all ![
$$\\psi \\in {W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq174.gif) we have

![
$$\\displaystyle{\\left \\langle B\\psi,B\\psi \\right\\rangle = \\left \\langle \\psi,{B}^{{\\ast}}B\\psi \\right\\rangle \\leq \\left \\Vert \\psi \\right\\Vert \\left \\Vert {B}^{{\\ast}}B\\psi \\right\\Vert {\\leq \\varepsilon }^{2}{\\left \\Vert \\psi \\right\\Vert }^{2}.}$$
](A272900_1_En_10_Chapter_Equam.gif)

Since ![
$$B = p\(A,{A}^{{\\ast}}\) -\\mu I$$
](A272900_1_En_10_Chapter_IEq175.gif), this shows that every nonzero element of ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq176.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq177.gif)-almost eigenvector for p(A, A ∗) with eigenvalue μ. Furthermore, A and A ∗ commute with B ∗ B and thus they preserve each spectral subspace of B ∗ B (Proposition 7.16) including ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq178.gif).

Proof of Theorem 10.23.

Suppose first that λ belongs to the spectrum of A. By Point 2 of Lemma 10.25, A has ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq179.gif)-almost eigenvalues with eigenvalue λ for every ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq180.gif). Lemma 10.26 then shows that p(A, A ∗) has ![
$$\(C\\varepsilon \)$$
](A272900_1_En_10_Chapter_IEq181.gif)-almost eigenvectors with eigenvalue ![
$$p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq182.gif) for every ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq183.gif), which shows that ![
$$p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq184.gif) is in the spectrum of p(A, A ∗).

In the other direction, suppose that μ is in the spectrum of p(A, A ∗). For any ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq185.gif), we consider the nonzero subspace ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq186.gif) in Lemma 10.27, which is invariant under A and A ∗. The restriction of A to ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq187.gif) is again a normal operator (Exercise 8), and ![
$$\\left.A\\right\\vert _{{W}^{\\varepsilon }}$$
](A272900_1_En_10_Chapter_IEq188.gif) has nonempty spectrum (Proposition 7.5). If we fix some ![
$$\\lambda \\in \\sigma \(\\left.A\\right\\vert _{{W}^{\\varepsilon }}\)$$
](A272900_1_En_10_Chapter_IEq189.gif), Lemma 10.25 tells us that there exists an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq190.gif)-almost eigenvector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0104.gif) for A in ![
$${W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq191.gif). By Lemma 10.26, ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0105.gif) is a ![
$$\(C\\varepsilon \)$$
](A272900_1_En_10_Chapter_IEq192.gif)-almost eigenvector for p(A, A ∗) with eigenvalue ![
$$p\(\\lambda,\\bar{\\lambda }\)$$
](A272900_1_En_10_Chapter_IEq193.gif). Meanwhile, since ![
$$\\psi \\in {W}^{\\varepsilon }$$
](A272900_1_En_10_Chapter_IEq194.gif), the same vector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0106.gif) is also an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq195.gif)-almost eigenvector for p(A, A ∗) with eigenvalue μ. It then is easy to see (Exercise 10) that

![
$$\\displaystyle{ \\left \\vert \\mu -p\(\\lambda,\\bar{\\lambda }\)\\right\\vert < C\\varepsilon +\\varepsilon. }$$
](A272900_1_En_10_Chapter_Equ35.gif)

(10.27)

Since (10.27) holds for all ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq196.gif), we can find a sequence λ n of points in σ(A) such that ![
$$p\(\\lambda _{n},\\bar{\\lambda }_{n}\) \\rightarrow \\mu$$
](A272900_1_En_10_Chapter_IEq197.gif). Since σ(A) is compact, we can pass to a subsequence of the λ n 's that is convergent to some λ ∈ σ(A), and this λ will satisfy ![
$$p\(\\lambda,\\bar{\\lambda }\) =\\mu$$
](A272900_1_En_10_Chapter_IEq198.gif).

Combining Theorem 10.23 with the equality of the norm and spectral radius for normal operators (Proposition 10.21), we have the following result. If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq199.gif) is normal and p is a polynomial in two variables, then

![
$$\\displaystyle{\\left \\Vert p\(A,{A}^{{\\ast}}\)\\right\\Vert =\\sup _{\\lambda \\in \\sigma \(A\)}\\left \\vert p\(\\lambda,\\bar{\\lambda }\)\\right\\vert.}$$
](A272900_1_En_10_Chapter_Equan.gif)

The map p ↦ p(A, A ∗) has the property that ![
$$\\bar{p}\(A,{A}^{{\\ast}}\) = {\(p\(A,{A}^{{\\ast}}\)\)}^{{\\ast}}$$
](A272900_1_En_10_Chapter_IEq200.gif), where the polynomial ![
$$\\bar{p}$$
](A272900_1_En_10_Chapter_IEq201.gif) is the complex-conjugate of p. In particular, if p takes only real values on σ(A), then p(A, A ∗) is self-adjoint.

By the complex-valued version of the Stone–Weierstrass theorem (A.12), polynomials in λ and ![
$$\\bar{\\lambda }$$
](A272900_1_En_10_Chapter_IEq202.gif) are dense in ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{C}\)$$
](A272900_1_En_10_Chapter_IEq203.gif), the space of continuous complex-valued functions on σ(A). Thus, the BLT theorem (Theorem A.36) tells that we can extend the map p ↦ p(A, A ∗) to an isometric map of ![
$$\\mathcal{C}\(\\sigma \(A\); \\mathbb{C}\)$$
](A272900_1_En_10_Chapter_IEq204.gif) into ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq205.gif). This extension, which we call the continuous functional calculus for A, has all the same properties as in the self-adjoint case.

Now that the continuous functional calculus for normal operators has been established, the proof of the spectral theorem—in any of its various versions—proceeds exactly as in the self-adjoint case. There is no need, then, to repeat the arguments given in Chap.​ 8.

## 10.4 Proof of the Spectral Theorem for Unbounded Self-Adjoint Operators

To prove the spectral theorem for an unbounded self-adjoint operator A, we will construct from A a certain unitary (and thus normal) operator U. We then apply the spectral theorem for bounded normal operators to U and translate this result into the desired result for A. To motivate the construction of U, consider the function

![
$$\\displaystyle{ C\(x\) := \\frac{x + i} {x - i},\\quad x \\in \\mathbb{R}. }$$
](A272900_1_En_10_Chapter_Equ36.gif)

(10.28)

It is a simple matter to check that C maps ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq206.gif) injectively onto ![
$${S}^{1}\\setminus \\{1\\}$$
](A272900_1_En_10_Chapter_IEq207.gif), with inverse given by

![
$$\\displaystyle{ D\(u\) := i\\frac{u + 1} {u - 1},\\quad u \\in {S}^{1}\\setminus \\{1\\}. }$$
](A272900_1_En_10_Chapter_Equ37.gif)

(10.29)

Furthermore, we have lim x → ± ∞ C(x) = 1. The function C(x) in (10.28) is the simplest bounded, injective function one can define on ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq208.gif).

We wish to apply the map C to a self-adjoint operator A. If A is bounded and self-adjoint, it is straightforward to check that the operator ![
$$\(A + iI\){\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq209.gif) is unitary (Exercise 5). Even in the unbounded case, it is possible to make sense of the operator U : = C(A), and we can recover A from U, by (essentially) applying D. The operator U is unitary and is known as the Cayley transform of A.

Recall that if A is self-adjoint, then i is in the resolvent set of A and the operator ![
$${\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq210.gif) maps H into Dom(A).

Theorem 10.28 (Cayley Transform).

If A is a self-adjoint operator on H , let U be the operator defined by

![
$$\\displaystyle{U\\psi = \(A + iI\){\(A - iI\)}^{-1}\\psi.}$$
](A272900_1_En_10_Chapter_Equao.gif)

Then the following results hold.

1.

The operator U is a unitary operator on H.

2.

The operator U − I is injective.

3.

The range of the operator U − I is equal to Dom (A) and for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0107.gif) ∈ Range (U − I) we have

![
$$\\displaystyle{ A\\psi = i\(U + I\){\(U - I\)}^{-1}\\psi. }$$
](A272900_1_En_10_Chapter_Equ38.gif)

(10.30)

According to Point 2, U − I is injective, while according to Point 3, the range of U − I is Dom(A). Thus, in (10.30), the expression ![
$${\(U - I\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq211.gif) refers to the inverse of the one-to-one and onto map U − I : H → Dom(A). We are not claiming that 1 is in the resolvent set of U. That is to say, ![
$${\(U - I\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq212.gif) is not a bounded operator, unless Dom(A) = H, which occurs only if A is bounded.

Proof.

The resolvent operator ![
$${\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq213.gif) must be injective, because

![
$$\\displaystyle{\(A - iI\){\(A - iI\)}^{-1}\\psi =\\psi }$$
](A272900_1_En_10_Chapter_Equap.gif)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0108.gif) ∈ H. Furthermore, ![
$${\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq214.gif) maps H onto Dom(A), because

![
$$\\displaystyle{\\psi = {\(A - iI\)}^{-1}\(A - iI\)\\psi }$$
](A272900_1_En_10_Chapter_Equaq.gif)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0109.gif) ∈ Dom(A). Since − i is also in the resolvent set of A, similar reasoning shows that A \+ iI maps Dom(A) injectively onto H. Thus, U is the composition of one operator that maps H injectively onto Dom(A) and another operator that maps Dom(A) injectively onto H, so that U maps H injectively onto H.

Now, for any ![
$$\\phi$$
](A272900_1_En_10_Chapter_IEq0110.gif) ∈ Dom(A) we have

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \(A + iI\)\\phi,\(A + iI\)\\phi \\right\\rangle & =& \\left \\langle A\\phi,A\\phi \\right\\rangle + \\left \\langle \\phi,\\phi \\right\\rangle {}\\\\ & =& \\left \\langle \(A - iI\)\\phi,\(A - iI\)\\phi \\right\\rangle, {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ39.gif)

because of a familiar cancellation of cross terms. Thus, applying this with ![
$$\\phi = {\(A - iI\)}^{-1}\\psi$$
](A272900_1_En_10_Chapter_IEq215.gif) shows that for any ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0111.gif) ∈ H, we have

![
$$\\begin{array}{lll} \\left \\langle \(A + iI\){\(A -iI\)}^{-1}\\psi,\(A + iI\){\(A - iI\)}^{-1}\\psi \\right\\rangle {}\\\\ =\\left \\langle \(A - iI\){\(A - iI\)}^{-1}\\psi,\(A - iI\){\(A -iI\)}^{-1}\\psi \\right\\rangle {}\\\\ =\\left \\langle \\psi,\\psi \\right\\rangle. {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ40.gif)

Thus, U is one-to-one and onto and preserves norms and is therefore unitary.

For Point 2, observe that for any ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0112.gif) ∈ H, we have

![
$$\\displaystyle\\begin{array}{rcl} \(A + iI\){\(A - iI\)}^{-1}\\psi & =& \(\(A - iI\) + 2iI\){\(A - iI\)}^{-1}\\psi \\\\ & =& \\psi +2i{\(A - iI\)}^{-1}\\psi. {}\\end{array}$$
](A272900_1_En_10_Chapter_Equ41.gif)

(10.31)

Thus, since ![
$${\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq216.gif) is injective, we cannot have U ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0113.gif) = ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0114.gif) unless ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0115.gif) = 0.

Finally, for Point 3, (10.31) says that

![
$$\\displaystyle{ U - I = 2i{\(A - iI\)}^{-1}, }$$
](A272900_1_En_10_Chapter_Equ42.gif)

(10.32)

which means (by the reasoning at the start of the proof) that the range of U − I is Dom(A). For ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0116.gif) ∈ Dom(A), we then have

![
$$\\displaystyle\\begin{array}{rcl} \(U + I\){\(U - I\)}^{-1}\\psi & =& \\frac{1} {2i}\(U + I\)\(A - iI\)\\psi {}\\\\ & =& \\frac{1} {2i}\\left \[\(A + iI\) + \(A - iI\)\\right\]\\psi {}\\\\ & =& \\frac{1} {i} A\\psi, {}\\\\ \\end{array}$$
](A272900_1_En_10_Chapter_Equ43.gif)

which establishes Point 3.

We may apply the spectral theorem for bounded normal operators to associate a projection-valued measure μ U to U. We will then transfer this measure from ![
$${S}^{1}\\setminus \\{0\\}$$
](A272900_1_En_10_Chapter_IEq217.gif) to ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq218.gif) by means of the map D in (10.29) to obtain the desired projection-valued measure μ A for A.

Proposition 10.29.

Let A be a self-adjoint operator on H , let U be the unitary operator in Theorem 10.28 , and let ![
$$D : {S}^{1}\\setminus \\{0\\} \\rightarrow \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq219.gif) be as in ( 10.29 ). Then

![
$$\\displaystyle{ A = D\(U\), }$$
](A272900_1_En_10_Chapter_Equ44.gif)

(10.33)

where D(U) is defined by the functional calculus for U.

More precisely, ![
$$D\(U\) =\\int _{\\sigma \(U\)}D\(\\lambda \)\\ {d\\mu }^{U}\(\\lambda \)$$
](A272900_1_En_10_Chapter_IEq220.gif), where μ U is the projection-valued measure associated to U by the spectral theorem for bounded normal operators. Note that by Point 2 of Theorem 10.28, 1 is not an eigenvalue for U and thus μ U ({1}) = 0. Thus, D is an almost-everywhere-defined function on σ(U), even if 1 ∈ σ(A). As always, the equality in (10.33) includes equality of domains, where the domain of ∫ σ(U) D dμ U is the space W D in Proposition 10.1.

Proposition 10.29 should certainly be plausible in light of the previously established formula (10.30) for A in terms of U.

Proof.

Suppose E is a Borel subset of ![
$${S}^{1}\\setminus \\{0\\}$$
](A272900_1_En_10_Chapter_IEq221.gif) such that the closure of E does not contain 1, and let V E = Range(μ U (E)) be the associated spectral subspace. Then the spectrum of ![
$$\\left.U\\right\\vert _{E}$$
](A272900_1_En_10_Chapter_IEq222.gif) is contained in ![
$$\\bar{E}$$
](A272900_1_En_10_Chapter_IEq223.gif), which means that the functions u ↦ D(u) and ![
$$u\\mapsto 1/\(u - 1\)$$
](A272900_1_En_10_Chapter_IEq224.gif) are bounded on ![
$$\\sigma \(\\left.U\\right\\vert _{V _{E}}\)$$
](A272900_1_En_10_Chapter_IEq225.gif). Now, by comparing the quadratic forms, we can see that ![
$$\\left.D\(U\)\\right\\vert _{V _{E}} = D\(\\left.U\\right\\vert _{V _{E}}\)$$
](A272900_1_En_10_Chapter_IEq226.gif). Then by the multiplicativity of the functional calculus for U on bounded functions, we have

![
$$\\displaystyle{D\(U\)\\psi = i\(U + I\){\(U - I\)}^{-1}\\psi }$$
](A272900_1_En_10_Chapter_Equar.gif)

for all ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0117.gif) ∈ V E . Thus, by Point 3 of Theorem 10.28, D(U) agrees with A on V E .

Meanwhile, if we decompose ![
$${S}^{1}\\setminus \\{0\\}$$
](A272900_1_En_10_Chapter_IEq227.gif) as the disjoint union of sets E n for which ![
$$\\bar{E}_{n}$$
](A272900_1_En_10_Chapter_IEq228.gif) does not contain 1, then H is the Hilbert space direct sum of the subspaces ![
$$V _{E_{n}}$$
](A272900_1_En_10_Chapter_IEq229.gif). Now, A and (by Proposition 10.3) D(U) are both self-adjoint. Furthermore, these operators agree on the finite direct sum of the ![
$$V _{E_{n}}$$
](A272900_1_En_10_Chapter_IEq230.gif)'s and they are essentially self-adjoint on this finite sum, by Example 9.26. Thus, A and D(U) must be equal (with equality of domain).

Theorem 10.30.

Define a projection-valued measure μ A on ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq231.gif) by

![
$$\\displaystyle{{ \\mu }^{A}\(E\) {=\\mu }^{U}\(C\(E\)\). }$$
](A272900_1_En_10_Chapter_Equ45.gif)

(10.34)

Then

![
$$\\displaystyle{ A =\\int _{\\mathbb{R}}\\lambda \\ {d\\mu }^{A}\(\\lambda \), }$$
](A272900_1_En_10_Chapter_Equ46.gif)

(10.35)

where μ U is the projection-valued measure coming from the spectral theorem for the bounded normal operator U and C is the map defined in ( 10.28 ).

Proof.

If for any ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0118.gif) ∈ H, we define ![
$$\\mu _{\\psi }^{U}\(E\) = \\left \\langle \\psi {,\\mu }^{U}\\psi \\right\\rangle$$
](A272900_1_En_10_Chapter_IEq232.gif) and similarly define ![
$$\\mu_\\psi^A$$
](A272900_1_En_10_Chapter_IEq0119.gif), then we have

![
$$\\displaystyle{\\mu _{\\psi }^{A}\(E\) =\\mu _{ \\psi }^{U}\(C\(E\)\).}$$
](A272900_1_En_10_Chapter_Equas.gif)

By the abstract change of variables theorem from measure theory, we have

![
$$\\displaystyle{ \\int {_{\\mathbb{R}}\\lambda }^{2}\\ d\\mu _{\\psi }^{A}\(\\lambda \) =\\int _{{ S}^{1}\\setminus \\{0\\}}D{\(u\)}^{2}\\ d\\mu _{\\psi }^{U}\(u\), }$$
](A272900_1_En_10_Chapter_Equ47.gif)

(10.36)

since D is the inverse map to C. Thus, the two operators in (10.35) have the same domain. Furthermore, if we replace λ 2 by λ and D(u)2 by D(u) in (10.36), we see that the operators in (10.35) are also equal.

Proof of Theorem 10.4.

The existence of the desired projection-valued measure μ A is the content of Theorem 10.30. To establish uniqueness, suppose ν A is a projection-valued measure on σ(A) such that ∫ λ d ν A (λ) = A. Consider then the operator C(A) as defined by integration of the function c(λ) against ν A . Arguing as in the proof of Proposition 10.29, we can see that C(A), computed in this fashion, coincides with the operator U = C(A) defined as the product of (A \+ iI) and ![
$${\(A - iI\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq233.gif).

Now define a projection-valued measure ν U on S 1 by setting ![
$${\\nu }^{U}\(E\) {=\\nu }^{A}\({C}^{-1}\(E\)\)$$
](A272900_1_En_10_Chapter_IEq234.gif). Then as in the proof of Theorem 10.30, we have ![
$$\\int _{{S}^{1}}u\\ {d\\nu }^{U}\(u\) = U$$
](A272900_1_En_10_Chapter_IEq235.gif). The uniqueness part of the spectral theorem for U (Theorem 10.20) then tells us that ν U = μ U , from which it follows that ν A = μ A .

Proof of Theorem 10.9.

By the direct-integral form of the spectral theorem for U = C(A), there is a family of Hilbert spaces H λ , ![
$$\\lambda \\in \\sigma \(U\) \\subset {S}^{1}$$
](A272900_1_En_10_Chapter_IEq236.gif), and a positive, real-valued measure μ on σ(U) such that H is unitarily equivalent to ∫ σ(U) H λ dμ, in such a way that the operator U corresponds to the map s(λ) ↦ λ s(λ). Since 1 is not an eigenvalue for U, either H 1 = { 0} or μ({1}) = 0. Either way, H 1 is "negligible" in the direct integral. We can then define a family of Hilbert spaces K λ : = H C(λ), for ![
$$\\lambda \\in \\sigma \(A\) \\subset \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq237.gif), and a measure ν on σ(A) given by ν(E) = μ(C(E)). We may then form the direct integral ∫ σ(A) K λ d ν. This direct integral is unitarily equivalent in an obvious way to ∫ σ(U) H λ dμ. We wish to show, then, that ∫ σ(A) K λ d ν is unitarily equivalent to H in such a way that the operator A corresponds to the (unbounded) operator mapping s(λ) to λ s(λ). Since the argument is similar to that in the proof of Theorem 10.4, we omit the details.

As in the proof of Theorem 10.4, the uniqueness in Theorem 10.9 can be reduced to the uniqueness for the direct-integral form of the spectral theorem for U.

The proof of the multiplication operator form of the spectral theorem for unbounded operators is similar to the preceding proofs and is omitted.

## 10.5 Exercises

1.

(a)

If A is a bounded self-adjoint operator, show that U(t) : = e iAt is continuous in the operator norm topology.

(b)

Using the spectral theorem, show that if A is a self-adjoint operator and σ(A) is a bounded subset of ![
$$\\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq238.gif), then A is bounded.

(c)

Suppose A is a self-adjoint operator that is not bounded. Show that U(t) : = e iAt is not continuous in the operator norm topology.

Hint: Consider ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0120.gif) in a spectral subspace of the form ![
$$V _{\(\\lambda _{0}-\\varepsilon,\\lambda _{0}+\\varepsilon \)}$$
](A272900_1_En_10_Chapter_IEq239.gif), where λ 0 is a point in σ(A) with ![
$$\\left \\vert \\lambda _{0}\\right\\vert$$
](A272900_1_En_10_Chapter_IEq240.gif) large.

2.

Let P j be the unbounded self-adjoint operator defined in Sect.​ 9.​8. Show that the one-parameter unitary group ![
$${e}^{itP_{j}}$$
](A272900_1_En_10_Chapter_IEq241.gif) generated by P j is given by

![
$$\\displaystyle{\({e}^{itP_{j} }\\psi \)\(\\mathbf{x}\) =\\psi \(\\mathbf{x} + t\\hslash \\mathbf{e}_{j}\)}$$
](A272900_1_En_10_Chapter_Equat.gif)

for all ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_10_Chapter_IEq242.gif), where e j is the jth element of the standard basis for ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_10_Chapter_IEq243.gif).

Hint: First determine the Fourier transform of ![
$${e}^{itP_{j}}\\psi$$
](A272900_1_En_10_Chapter_IEq244.gif), using Proposition 9.32.

3.

If A is an unbounded self-adjoint operator on H, let us say that a family ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0121.gif)(t) of elements of H satisfies the equation

![
$$\\displaystyle{ \\frac{d\\psi } {dt} = iA\\psi \(t\) }$$
](A272900_1_En_10_Chapter_Equ48.gif)

(10.37)

in the strong sense if each ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0122.gif)(t) belongs to Dom(A) and

![
$$\\displaystyle{\\lim _{h\\rightarrow 0}\\left \\Vert \\frac{\\psi \(t + h\) -\\psi \(t\)} {h} - iA\\psi \(t\)\\right\\Vert = 0}$$
](A272900_1_En_10_Chapter_Equau.gif)

for every ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq245.gif). If we define ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0123.gif)(t) by ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0124.gif)(t) = e i t A ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0125.gif) 0, for some ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0260.gif) 0 ∈ H, show that ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0127.gif)(t) satisfies (10.37) in the strong sense if and only if ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0128.gif) 0 belongs to Dom(A).

4.

Suppose A is an unbounded self-adjoint operator and suppose that there exists a number ![
$$\\gamma \\in \\mathbb{R}$$
](A272900_1_En_10_Chapter_IEq246.gif) and a nonzero vector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0129.gif) ∈ Dom(A) such that

![
$$\\displaystyle{\\left \\Vert A\\psi -\\gamma \\psi \\right\\Vert <\\varepsilon \\left \\Vert \\psi \\right\\Vert }$$
](A272900_1_En_10_Chapter_Equav.gif)

for some ![
$$\\varepsilon > 0$$
](A272900_1_En_10_Chapter_IEq247.gif). Show that there exists a number ![
$$\\tilde{\\gamma }$$
](A272900_1_En_10_Chapter_IEq248.gif) in the spectrum of A such that ![
$$\\vert \\gamma -\\tilde{\\gamma }\\vert <\\varepsilon$$
](A272900_1_En_10_Chapter_IEq249.gif).

Hint: If no such ![
$$\\tilde{\\gamma }$$
](A272900_1_En_10_Chapter_IEq250.gif) existed, the function ![
$$f\(\\lambda \) := 1/\\vert \\lambda -\\gamma \\vert $$
](A272900_1_En_10_Chapter_IEq251.gif) would satisfy ![
$$\\left \\vert f\(\\lambda \)\\right\\vert \\leq 1/\\varepsilon$$
](A272900_1_En_10_Chapter_IEq252.gif) for all λ ∈ σ(A). Consider, then, the operator f(A), which is nothing but ![
$${\(A -\\gamma I\)}^{-1}$$
](A272900_1_En_10_Chapter_IEq253.gif).

5.

If A is a bounded self-adjoint operator, show that the operator C(A) given by

![
$$\\displaystyle{C\(A\) = \(A + iI\){\(A - iI\)}^{-1}}$$
](A272900_1_En_10_Chapter_Equaw.gif)

is unitary and that 1 is in the resolvent set of C(A). Show also that A can be recovered from C(A) by the formula

![
$$\\displaystyle{A = i\(C\(A\) + I\){\(C\(A\) - I\)}^{-1}.}$$
](A272900_1_En_10_Chapter_Equax.gif)

6.

Show that Lemma 10.22 is false if we do not assume that A and B commute.

7.

Let A be a normal matrix and p a polynomial in two variables. Show by example that an eigenvector for p(A, A ∗) is not necessarily an eigenvector for A.

Note: Nevertheless, the proof of the matrix case of Theorem 10.23 shows that if μ is an eigenvalue for p(A, A ∗), then there exists some eigenvector for p(A, A ∗) with eigenvalue μ that is also an eigenvector for A.

8.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq254.gif) and W is a closed subspace of H that is invariant under A and A ∗.

(a)

Show that ![
$${\(\\left.A\\right\\vert _{W}\)}^{{\\ast}} = \\left.{A}^{{\\ast}}\\right\\vert _{W}$$
](A272900_1_En_10_Chapter_IEq255.gif).

(b)

Show that if A is normal, the restriction of A to W is normal.

9.

(a)

Suppose that H is finite dimensional, A is a normal operator on H, and W is a subspace of H that is invariant under A. Show that W is invariant under A ∗.

(b)

Show by example that the result of Part (a) is false if H is infinite dimensional.

10.

Given ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_10_Chapter_IEq256.gif), suppose that the same vector ![
$$\\psi$$
](A272900_1_En_10_Chapter_IEq0130.gif) is an ![
$$\\varepsilon$$
](A272900_1_En_10_Chapter_IEq257.gif)-almost eigenvector for A with eigenvalue λ and a δ-almost eigenvector for A with eigenvalue μ. Show that ![
$$\\left \\vert \\lambda -\\mu \\right\\vert <\\varepsilon +\\delta$$
](A272900_1_En_10_Chapter_IEq258.gif).

References

[3].

S.J. Bernau, The spectral theorem for unbounded normal operators. Pacific J. Math. 19, 391–406 (1966)CrossRefMATHMathSciNet

[33].

W. Rudin, Functional Analysis, 2nd edn. International Series in Pure and Applied Mathematics (McGraw-Hill, New York, 1991)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_11

© Springer Science+Business Media New York 2013

# 11. The Harmonic Oscillator

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

The harmonic oscillator is an important model for various reasons. In solid-state physics, for example, a crystal is modeled as a large number of coupled harmonic oscillators. Using the notion of "normal modes,"this model is then transformed into independent one-dimensional harmonic oscillators with different frequencies. In the quantum mechanical setting, the excitations of the different normal modes are called phonons.

## 11.1 The Role of the Harmonic Oscillator

The harmonic oscillator is an important model for various reasons. In solid-state physics, for example, a crystal is modeled as a large number of coupled harmonic oscillators. Using the notion of "normal modes," this model is then transformed into independent one-dimensional harmonic oscillators with different frequencies. In the quantum mechanical setting, the excitations of the different normal modes are called phonons.

A free quantum field theory is similarly modeled as a family of coupled harmonic oscillators, except that in the field theory setting we have infinitely many of the oscillators. Even interacting quantum field theories are often described using the harmonic oscillator raising and lowering operators, which are referred to as creation and annihilation operators in the context of field theory.

Our approach to analyzing the harmonic oscillator also introduces the algebraic approach to quantum mechanics, in which algebra (commutation relations between various operators) substantially replaces analysis (differential equations) as the way to solve quantum systems. Most of the effort in analyzing the harmonic oscillator occurs in the algebraic section (Sect. 11.2), with the remaining analytic issues being taken care of in Sects. 11.3 and 11.4.

## 11.2 The Algebraic Approach

In this section we will derive as much information as possible about the Hamiltonian operator for a quantum harmonic oscillator using only the commutation relation between the position and momentum operators,

![
$$\\displaystyle{ \[X,P\] = i\\hslash I. }$$
](A272900_1_En_11_Chapter_Equ1.gif)

(11.1)

Here, as usual, [ ⋅, ⋅] denotes the commutator, given by ![
$$\[A,B\] = AB - BA$$
](A272900_1_En_11_Chapter_IEq1.gif). We consider, then, a harmonic oscillator with Hamiltonian given by

![
$$\\displaystyle{ \\hat{H} = \\frac{{P}^{2}} {2m} + \\frac{k} {2}{X}^{2}, }$$
](A272900_1_En_11_Chapter_Equ2.gif)

(11.2)

where k is a positive constant. Our goal is to see what we can say about the eigenvectors and eigenvalues of ![
$$\\hat{H}$$
](A272900_1_En_11_Chapter_IEq2.gif) using only the fact that X and P are self-adjoint operators satisfying (11.1), without making use of the actual formulas for these operators.

To be honest, we are actually assuming certain domain conditions regarding the operators X and P, in addition to the commutation relation (11.1), namely that the vectors ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq01.gif) in Theorem 11.2 are actually in the domain of X and P (and thus, also, in the domain of the raising and lowering operators). In this section, we follow the usual physics practice of assuming that all the vectors we work with are in the domain of all the relevant operators. This assumption will turn out to be correct in the case we are actually considering, in which X and P are the usual position and momentum operators on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq3.gif). (See Sect. 11.4.) It is a more complicated matter to work out the domain conditions that must be imposed on two self-adjoint operators satisfying (11.1) in order for the argument of the present section to be valid. We will come back to this issue in Chap.​ 14.

Following, again, the convention in the physics literature, we now eliminate the spring constant k in favor of the frequency ![
$$\\omega = \\sqrt{k/m}$$
](A272900_1_En_11_Chapter_IEq4.gif) of the corresponding classical harmonic oscillator. [Solutions to Hamilton's equations with classical Hamiltonian H(x, p) equal to ![
$${p}^{2}/\(2m\) + k{x}^{2}/2$$
](A272900_1_En_11_Chapter_IEq5.gif) are sinusoidal with frequency ![
$$\\sqrt{k/m}$$
](A272900_1_En_11_Chapter_IEq6.gif).] Replacing k by mω 2, we may rewrite (11.2) as

![
$$\\displaystyle{ \\hat{H} = \\frac{1} {2m}\\left \({P}^{2} + {\(m\\omega X\)}^{2}\\right\). }$$
](A272900_1_En_11_Chapter_Equ3.gif)

(11.3)

We now introduce the lowering operator a, given by

![
$$\\displaystyle{ a = \\frac{m\\omega X + iP} {\\sqrt{2\\hslash m\\omega }} }$$
](A272900_1_En_11_Chapter_Equ4.gif)

(11.4)

and its adjoint a ∗, the raising operator," given by

![
$$\\displaystyle{ {a}^{{\\ast}} = \\frac{m\\omega X - iP} {\\sqrt{2\\hslash m\\omega }}. }$$
](A272900_1_En_11_Chapter_Equ5.gif)

(11.5)

The reason for the terminology "raising" and "lowering" is that these operators raise and lower the eigenvalue for the Hamiltonian, as we will see shortly. In the context of quantum field theory, operators very much like a and a ∗ are called creation operators and annihilation operators, respectively, because they map from the n-particle space to either the (n \+ 1)-particle space or the (n − 1)-particle space, thus "creating" or "annihilating" a particle.

In the world of noncommuting operators, ![
$$\(A - B\)\(A + B\)$$
](A272900_1_En_11_Chapter_IEq7.gif) does not equal A 2 − B 2; rather,

![
$$\\displaystyle{\(A - B\)\(A + B\) = {A}^{2} - {B}^{2} + \\left \[A,B\\right\].}$$
](A272900_1_En_11_Chapter_Equa.gif)

Thus, if we compute a ∗ a using (11.1) we get

![
$$\\displaystyle\\begin{array}{rcl}{ a}^{{\\ast}}a& =& \\frac{1} {2\\hslash m\\omega }\\left \({\(m\\omega X\)}^{2} + {P}^{2} + im\\omega \\left \[X,P\\right\]\\right\) {}\\\\ & =& \\frac{1} {\\hslash \\omega } \\frac{1} {2m}\\left \({P}^{2} + {\(m\\omega X\)}^{2}\\right\) -\\frac{1} {2}I. {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ6.gif)

From this we obtain

![
$$\\displaystyle{\\hat{H} = \\hslash \\omega \\left \({a}^{{\\ast}}a + \\frac{1} {2}I\\right\).}$$
](A272900_1_En_11_Chapter_Equb.gif)

The ![
$$\\frac{1} {2}I$$
](A272900_1_En_11_Chapter_IEq8.gif) on the right-hand side of this expression should be thought of as a "quantum correction," in that there would be no such term in the analogous formula for the classical Hamiltonian.

It suffices to work out the spectral properties (eigenvectors and eigenvalues) of a ∗ a. To get back to ![
$$\\hat{H}$$
](A272900_1_En_11_Chapter_IEq9.gif), we keep the same eigenvectors and simply add 1 ∕ 2 to the eigenvalues and then multiply by ![
$$\\hslash \\omega$$
](A272900_1_En_11_Chapter_IEq10.gif). We compute that

![
$$\\displaystyle\\begin{array}{rcl} \[a,{a}^{{\\ast}}\]& =& \\frac{1} {2\\hslash m\\omega }\\left \(\[m\\omega X,-iP\] + \[iP,m\\omega X\]\\right\) \\\\ & =& \\frac{1} {2\\hslash m\\omega }\\left \(\\hslash m\\omega I + \\hslash m\\omega I\\right\) \\\\ & =& I. {}\\end{array}$$
](A272900_1_En_11_Chapter_Equ7.gif)

(11.6)

From this, it is easy to compute that

![
$$\\displaystyle{ \[a,{a}^{{\\ast}}a\] = a }$$
](A272900_1_En_11_Chapter_Equ8.gif)

(11.7)

![
$$\\displaystyle{ \[{a}^{{\\ast}},{a}^{{\\ast}}a\] = -{a}^{{\\ast}}. }$$
](A272900_1_En_11_Chapter_Equ9.gif)

(11.8)

Now, a ∗ a is self-adjoint (or, at the least, symmetric) because ![
$${\({a}^{{\\ast}}a\)}^{{\\ast}} = {a}^{{\\ast}}{a}^{{\\ast}{\\ast}} = {a}^{{\\ast}}a$$
](A272900_1_En_11_Chapter_IEq11.gif). This operator is also non-negative, because

![
$$\\displaystyle{\\left \\langle \\psi,{a}^{{\\ast}}a\\psi \\right\\rangle = \\left \\langle a\\psi,a\\psi \\right\\rangle \\geq 0}$$
](A272900_1_En_11_Chapter_Equc.gif)

for all ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq02.gif). We now come to a key computation, which demonstrates the utility of the operators a and a ∗.

Proposition 11.1.

Suppose that ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq03.gif) is an eigenvector for a ∗ a with eigenvalue λ. Then

![
$$\\displaystyle\\begin{array}{rcl} {a}^{{\\ast}}a\(a\\psi \)& =& \(\\lambda -1\)a\\psi {}\\\\ {a}^{{\\ast}}a\({a}^{{\\ast}}\\psi \)& =& \(\\lambda +1\){a}^{{\\ast}}\\psi. {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ10.gif)

Thus, either ![
$$a\\psi$$
](A272900_1_En_11_Chapter_IEq04.gif) is zero or ![
$$a\\psi$$
](A272900_1_En_11_Chapter_IEq05.gif) is an eigenvector for a ∗ a with eigenvalue λ − 1. Similarly, either ![
$$a^\\ast\\psi$$
](A272900_1_En_11_Chapter_IEq06.gif) is zero or ![
$$a^\\ast\\psi$$
](A272900_1_En_11_Chapter_IEq07.gif) is an eigenvector for a ∗ a with eigenvalue λ \+ 1. That is to say, the operators a ∗ and a raise and lower the eigenvalues of a ∗ a, respectively.

Proof.

Using the commutation relation (11.7), we find that

![
$$\\displaystyle{{a}^{{\\ast}}a\(a\\psi \) = \\left \(a\({a}^{{\\ast}}a\) - a\\right\)\\psi = \(\\lambda -1\)a\\psi.}$$
](A272900_1_En_11_Chapter_Equd.gif)

A similar calculation applies to ![
$$a^\\ast\\psi$$
](A272900_1_En_11_Chapter_IEq08.gif), using (11.8). ■

If ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq088.gif) is an eigenvector for a ∗ a with eigenvalue λ, then

![
$$\\displaystyle{\\lambda \\left \\langle \\psi,\\psi \\right\\rangle = \\left \\langle \\psi,{a}^{{\\ast}}a\\psi \\right\\rangle = \\left \\langle a\\psi,a\\psi \\right\\rangle \\geq 0,}$$
](A272900_1_En_11_Chapter_Eque.gif)

which means that λ ≥ 0. Let us assume that a ∗ a has at least one eigenvector ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq09.gif), with eigenvalue λ, which we expect since a ∗ a is self-adjoint. Since a lowers the eigenvalue of a ∗ a, if we apply a repeatedly to ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq010.gif), we must eventually get zero. After all, if ![
$$a^n\\psi$$
](A272900_1_En_11_Chapter_IEq011.gif) were always nonzero, these vectors would be, for large n, eigenvectors for a ∗ a with negative eigenvalue, which we have seen is impossible.

It follows that there exists some N ≥ 0 such that ![
$${a}^{N}\\psi \\neq 0$$
](A272900_1_En_11_Chapter_IEq012.gif) but ![
$${a}^{N+1}\\psi =0$$
](A272900_1_En_11_Chapter_IEq12.gif). If we define ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq013.gif) by

![
$$\\displaystyle{\\psi _{0} := {a}^{N}\\psi,}$$
](A272900_1_En_11_Chapter_Equf.gif)

then ![
$$a\\psi_0 = 0$$
](A272900_1_En_11_Chapter_IEq014.gif), which means that ![
$${a^\\ast} {a\\psi_0 = 0}$$
](A272900_1_En_11_Chapter_IEq015.gif). Thus, ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq016.gif) is an eigenvector for a ∗ a with eigenvalue 0. (It follows that the original eigenvalue λ must have been equal to the non-negative integer N.)

The conclusion is this: Provided that a ∗ a has at least one eigenvector ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq017.gif), we can find a nonzero vector ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq018.gif) such that

![
$$\\displaystyle{a\\psi _{0} = {a}^{{\\ast}}a\\psi _{ 0} = 0.}$$
](A272900_1_En_11_Chapter_Equg.gif)

Since a ∗ a cannot have negative eigenvalues, we may call ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq019.gif) a "ground state" for a ∗ a, that is, an eigenvector with lowest possible eigenvalue. We may then apply the raising operator a ∗ repeatedly to ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq020.gif) to obtain eigenvectors for a ∗ a with positive eigenvalues.

Theorem 11.2.

If ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq021.gif) is a unit vector with the property that ![
$$a\\psi_0 = 0$$
](A272900_1_En_11_Chapter_IEq022.gif), then the vectors

![
$$\\displaystyle{\\psi _{n} := {\({a}^{{\\ast}}\)}^{n}\\psi _{ 0},\\quad n \\geq 0,}$$
](A272900_1_En_11_Chapter_Equh.gif)

satisfy the following relations for all n, m ≥ 0:

![
$$\\displaystyle\\begin{array}{rcl} {a}^{{\\ast}}\\psi _{ n}& =& \\psi _{n+1} {}\\\\ {a}^{{\\ast}}a\\psi _{ n}& =& n\\psi _{n} {}\\\\ \\left \\langle \\psi _{n},\\psi _{m}\\right\\rangle & =& n!\\delta _{n,m} {}\\\\ a\\psi _{n+1}& =& \(n + 1\)\\psi _{n}. {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ11.gif)

Let us think for a moment about what this is saying. We have an orthogonal "chain" of eigenvectors for a ∗ a with eigenvalues 0, 1, 2,.... , with the norm of ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq023.gif) equal to ![
$$\\sqrt{n!}$$
](A272900_1_En_11_Chapter_IEq13.gif). The raising operator a ∗ shifts us up the chain, while the lowering operator a shifts us down the chain (up to a constant). In particular, the "ground state" ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq024.gif) is annihilated by a. Thus, we have a complete understanding of how a and a ∗ act on this chain of eigenvectors for a ∗ a.

Proof.

The first result is the definition of ![
$$\\psi_{n+1}$$
](A272900_1_En_11_Chapter_IEq025.gif) and the second follows from Proposition 11.1 and the fact that ![
$${a^\\ast} {a\\psi_0} = 0$$
](A272900_1_En_11_Chapter_IEq026.gif). For the third result, if n ≠ m, we use the general result that eigenvectors for a self-adjoint operator (in our case, a ∗ a) with distinct eigenvalues are orthogonal. (This result actually applies to operators that are only symmetric.)

If n = m, we work by induction. For n = 0, ![
$$\\left \\langle \\psi _{0},\\psi _{0}\\right\\rangle = 1$$
](A272900_1_En_11_Chapter_IEq14.gif) is assumed. If we assume ![
$$\\left \\langle \\psi _{n},\\psi _{n}\\right\\rangle = n!$$
](A272900_1_En_11_Chapter_IEq15.gif), we compute that

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \\psi _{n+1},\\psi _{n+1}\\right\\rangle & =& \\left \\langle {a}^{{\\ast}}\\psi _{ n},{a}^{{\\ast}}\\psi _{ n}\\right\\rangle {}\\\\ & =& \\left \\langle \\psi _{n},a{a}^{{\\ast}}\\psi _{ n}\\right\\rangle {}\\\\ & =& \\left \\langle \\psi _{n},\({a}^{{\\ast}}a + 1\)\\psi _{ n}\\right\\rangle {}\\\\ & =& \(n + 1\)\\left \\langle \\psi _{n},\\psi _{n}\\right\\rangle {}\\\\ & =& \(n + 1\)!. {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ12.gif)

Finally, we compute that

![
$$\\displaystyle{a\\psi _{n+1} = a{a}^{{\\ast}}\\psi _{ n} = \\left \({a}^{{\\ast}}a + I\\right\)\\psi _{ n} = \(n + 1\)\\psi _{n},}$$
](A272900_1_En_11_Chapter_Equi.gif)

which establishes the last claimed result. ■

It is now reasonable to ask whether the vectors ![
$$\\left \\{\\psi _{n}\\right\\}_{n=0}^{\\infty }$$
](A272900_1_En_11_Chapter_IEq16.gif) form an orthonormal basis for the quantum Hilbert space. Suppose this is not the case. If we then let V denote the closed span of the ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq0027.gif)'s, V will be invariant under both a and a ∗. Thus, by elementary linear algebra, the orthogonal complement V ⊥ of V will also be invariant under the adjoint operators a ∗ and a, and therefore also under a ∗ a. Therefore, we can begin our analysis anew in V ⊥, with the result that we will obtain a new ground state ![
$$\\phi_0$$
](A272900_1_En_11_Chapter_IEq027.gif) ∈ V ⊥ (satisfying ![
$$a\\phi_0 = 0$$
](A272900_1_En_11_Chapter_IEq028.gif)) that is orthogonal to the original ground state ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq029.gif). If, then, the closed span of the ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq030.gif)'s is not the whole Hilbert space, there will exist at least two independent solutions of the equation ![
$$a\\psi = 0$$
](A272900_1_En_11_Chapter_IEq031.gif). To put this claim the other way around, if it turns out that there is only one solution (up to a constant) of ![
$$a\\psi = 0$$
](A272900_1_En_11_Chapter_IEq032.gif), then we expect that the vectors obtained by applying a ∗ repeatedly to the solution will form an orthogonal basis for our Hilbert space. (Because we are glossing over various technical issues having to do with the domains of various operators, this conclusion should not be regarded as completely rigorous.)

## 11.3 The Analytic Approach

In the preceding section, we analyzed the eigenvectors of the operator a ∗ a as much as possible using only the commutation relation [a, a ∗] = I, which follows from the underlying commutation relation [X, P] = iℏI. To progress further, we must recall the actual formula for the operators a and a ∗.

To simplify our analysis, let us introduce the following natural scale of distance for our problem:

![
$$\\displaystyle{D := \\sqrt{ \\frac{\\hslash } {m\\omega }}.}$$
](A272900_1_En_11_Chapter_Equj.gif)

We then introduce a normalized position variable, measured in units of D,

![
$$\\displaystyle{ \\tilde{x} := \\frac{x} {D}, }$$
](A272900_1_En_11_Chapter_Equ13.gif)

(11.9)

so that

![
$$\\displaystyle{ \\frac{d} {d\\tilde{x}} = \\sqrt{ \\frac{\\hslash } {m\\omega }} \\frac{d} {dx}.}$$
](A272900_1_En_11_Chapter_Equk.gif)

A calculation gives the following simple expressions for the raising and lowering operators:

![
$$\\displaystyle\\begin{array}{rcl} a& =& \\frac{1} {\\sqrt{2}}\\left \(\\tilde{x} + \\frac{d} {d\\tilde{x}}\\right\) \\\\ {a}^{{\\ast}}& =& \\frac{1} {\\sqrt{2}}\\left \(\\tilde{x} - \\frac{d} {d\\tilde{x}}\\right\).{}\\end{array}$$
](A272900_1_En_11_Chapter_Equ14.gif)

(11.10)

Note that the constants m, ω, and ℏ have conveniently disappeared from the formulas.

Given the expression in (11.10), we can easily solve the (first-order, linear) equation ![
$$a\\psi_0 = 0$$
](A272900_1_En_11_Chapter_IEq033.gif) as

![
$$\\displaystyle{ \\psi _{0}\(\\tilde{x}\) = C{e}^{-\\tilde{{x}}^{2}/2 }. }$$
](A272900_1_En_11_Chapter_Equ15.gif)

(11.11)

If we take C to be positive, then our normalization condition determines its value to be ![
$$\\sqrt{\\pi }/D$$
](A272900_1_En_11_Chapter_IEq17.gif), by Proposition A.22. (The normalization condition is that the integral of ![
$${\\left \\vert \\psi _{0}\\right\\vert }^{2}$$
](A272900_1_En_11_Chapter_IEq18.gif) with respect to dx—not ![
$$d\\tilde{x}$$
](A272900_1_En_11_Chapter_IEq19.gif)—should be 1.) We obtain, then,

![
$$\\displaystyle{ \\psi _{0}\(x\) = \\sqrt{\\frac{\\pi m\\omega } {\\hslash }} \\exp \\left \\{-\\frac{m\\omega } {2\\hslash }{x}^{2}\\right\\}. }$$
](A272900_1_En_11_Chapter_Equ16.gif)

(11.12)

It remains only to apply a ∗ repeatedly to ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq034.gif) to get the "excited states" ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq035.gif).

Theorem 11.3.

The ground state ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq036.gif) of the harmonic oscillator is given by ( 11.12 ). The excited states ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq037.gif) are given by

![
$$\\displaystyle{ \\psi _{n} = H_{n}\\ \\psi _{0} }$$
](A272900_1_En_11_Chapter_Equ17.gif)

(11.13)

where H n is a polynomial of degree n given inductively by the formulas

![
$$\\displaystyle\\begin{array}{rcl} H_{0}\(\\tilde{x}\)& =& 1 {}\\\\ H_{n+1}\(\\tilde{x}\)& =& \\frac{1} {\\sqrt{2}}\\left \(2\\tilde{x}H_{n}\(\\tilde{x}\) -\\frac{dH_{n}\(\\tilde{x}\)} {d\\tilde{x}} \\right\). {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ18.gif)

Here, ![
$$\\tilde{x}$$
](A272900_1_En_11_Chapter_IEq20.gif) is the normalized position variable given by ( 11.9 ).

The polynomials H n are essentially (modulo various normalization conventions) the Hermite polynomials.

Proof.

When n = 0, (11.13) reduces to ![
$$\\psi_0 = \\psi_0$$
](A272900_1_En_11_Chapter_IEq038.gif). Assuming that (11.13) holds for some n, we compute ![
$$\\psi_{n+1}$$
](A272900_1_En_11_Chapter_IEq039.gif) as

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{n+1}& =& {a}^{{\\ast}}\\psi _{ n} = \\frac{1} {\\sqrt{2}}\\left \(\\tilde{x}H_{n}\(\\tilde{x}\)C{e}^{-\\tilde{{x}}^{2}/2 } - \\frac{d} {d\\tilde{x}}\\left \[H_{n}\(\\tilde{x}\)C{e}^{-\\tilde{{x}}^{2}/2 }\\right\]\\right\) {}\\\\ & =& \\frac{1} {\\sqrt{2}}\\left \(2\\tilde{x}H_{n}\(\\tilde{x}\) -\\frac{dH_{n}} {d\\tilde{x}} \\right\)C{e}^{-\\tilde{{x}}^{2}/2 } = H_{n+1}\(\\tilde{x}\)\\psi _{0}\(\\tilde{x}\), {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ19.gif)

as claimed. ■

Figure 11.1 shows the ground state of the harmonic oscillator, along with the excited states with n = 5 and n = 30. Each eigenfunction is plotted as a function of the normalized position variable ![
$$\\tilde{x}$$
](A272900_1_En_11_Chapter_IEq21.gif). In each case, the shaded region indicates the extent of the classically allowed region, that is, the range in which a classical particle with energy E n can move. Note that each wave function decays rapidly outside the classically allowed region. In the last image, we can see that frequency of oscillation of the wave function is greatest in the middle of the classically allowed region, while the amplitude of the wave function is greatest near the ends of the classically allowed region. Intuitively, these properties of the wave function reflect that a classical particle with energy E n has largest momentum in the middle of the classically allowed region (where the potential is smallest) and that the classical particle spends more time at the ends of the classically allowed region, since it is moving slowest there. Further development of this sort of reasoning may be found in Chap.​ 15.

Figure 11.1

Harmonic oscillator eigenvectors with n = 0, n = 5, and n = 30. In each case, the classically allowed region is shaded.

## 11.4 Domain Conditions and Completeness

Although the analysis in Sect. 11.2 is typical of what is found in physics texts, it is not completely rigorous from a mathematician's point of view. The main problem is that the lowing operator a, the raising operator a ∗, and the product operator a ∗ a are all unbounded operators. The difficulty in working with unbounded operators is that one constantly has to check that a vector is in the domain of the relevant operator before applying that operator. For example, suppose we have a vector ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq040.gif) in the domain of a and satisfying ![
$$a\\psi_0 = 0$$
](A272900_1_En_11_Chapter_IEq041.gif). We wish to apply the raising operator a ∗ to ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq042.gif) and we then want to argue that

![
$$\\displaystyle{{a}^{{\\ast}}a\({a}^{{\\ast}}\\psi _{ 0}\) = {a}^{{\\ast}}\\psi _{ 0}.}$$
](A272900_1_En_11_Chapter_Equl.gif)

This is easy enough to verify (as we did in the previous section) provided that all vectors are in the domain of the relevant operators. But how do we know that ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq043.gif) is in the domain of a ∗? And even if it is, how do we know that ![
$${a^\\ast}\\psi_0$$
](A272900_1_En_11_Chapter_IEq044.gif) is in the domain of a ∗ a?

These concerns are not just theoretical. Consider a general pair of operators A and B satisfying ![
$$\[A,B\] = i\\hslash I$$
](A272900_1_En_11_Chapter_IEq22.gif). If we try to analyze an operator of the form αA 2 \+ βB 2, for α, β > 0, by the methods of Sect. 11.2, things can easily go awry, as the counterexample in Sect.​ 12.​2 demonstrates. Fortunately, in the case of the ordinary position and momentum operators, the putative eigenfunctions ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq045.gif) for a ∗ a in Theorem 11.3 are very nice functions, in the form of a polynomial times a Gaussian. Thus, there is no difficulty in verifying that these functions are in the domain of any finite product of creation and annihilation operators. It follows that if a and a ∗ are given in terms of the usual position and momentum operators and ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq046.gif) given by (11.12), the relations in Theorem 11.2 indeed hold.

In particular, we can see that the ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq047.gif)'s form an orthogonal set of functions in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq23.gif). Showing that they form an orthogonal basis is also not terribly difficult.

Theorem 11.4.

The functions

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{n}\(x\)& =& H_{n}\(\\tilde{x}\)\\psi _{0}\(\\tilde{x}\) {}\\\\ & =& H_{n}\\left \(\\sqrt{\\frac{m\\omega } {\\hslash }} x\\right\)\\sqrt{\\frac{\\pi m\\omega } {\\hslash }} \\exp \\left \\{-\\frac{m\\omega } {2\\hslash }{x}^{2}\\right\\} {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ20.gif)

form an orthogonal basis for the Hilbert space ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq24.gif).

The following result is the key to the proof.

Lemma 11.5.

For all ![
$$\\alpha \\in \\mathbb{C}$$
](A272900_1_En_11_Chapter_IEq25.gif) , the partial sums of the series

![
$$\\displaystyle{\\sum _{n=0}^{\\infty }\\frac{{\\alpha }^{n}\\tilde{{x}}^{n}} {n!} {e}^{-\\tilde{{x}}^{2}/2 }}$$
](A272900_1_En_11_Chapter_Equm.gif)

converge in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq26.gif) to the function ![
$${e}^{\\alpha \\tilde{x}}{e}^{-\\tilde{{x}}^{2}/2 }$$
](A272900_1_En_11_Chapter_IEq27.gif).

Proof.

We need to show that

![
$$\\displaystyle{{ \\left \\Vert {e}^{\\alpha \\tilde{x}}{e}^{-\\tilde{{x}}^{2}/2 } -\\sum _{n=0}^{N}\\frac{{\\alpha }^{n}\\tilde{{x}}^{n}} {n!} {e}^{-\\tilde{{x}}^{2}/2 }\\right\\Vert }^{2} =\\int { \\left \\vert \\sum _{ n=N+1}^{\\infty }\\frac{{\\alpha }^{n}\\tilde{{x}}^{n}} {n!} {e}^{-\\tilde{{x}}^{2}/2 }\\right\\vert }^{2}d\\tilde{x} }$$
](A272900_1_En_11_Chapter_Equ21.gif)

(11.14)

tends to zero as N tends to infinity. The integrand on the right-hand side of (11.14) tends to zero pointwise. If we can find a suitable dominating function, we can use dominated convergence to conclude that the integral also tends to zero. We see that

![
$$\\displaystyle\\begin{array}{rcl}{ \\left \\vert \\sum _{n=N+1}^{\\infty }\\frac{{\\alpha }^{n}\\tilde{{x}}^{n}} {n!} {e}^{-\\tilde{{x}}^{2}/2 }\\right\\vert }^{2}& \\leq &{ \\left \(\\sum _{ n=0}^{\\infty }\\frac{{\\left \\vert \\alpha \\tilde{x}\\right\\vert }^{n}} {n!} {e}^{-\\tilde{{x}}^{2}/2 }\\right\)}^{2} {}\\\\ & =& {e}^{2\\vert \\alpha \\vert \\vert \\tilde{x}\\vert }{e}^{-\\tilde{{x}}^{2} }. {}\\\\ \\end{array}$$
](A272900_1_En_11_Chapter_Equ22.gif)

Since this last function certainly has finite integral, dominated convergence applies and we are done. ■

Proof of Theorem 11.4.

It is easily seen that the raising and lowering operators map the Schwartz space ![
$$\\mathcal{S}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq28.gif) (Definition A.15) into itself. Furthermore, it is easy to verify (Exercise 1) that

![
$$\\displaystyle{\\left \\langle \\frac{d\\phi } {dx},\\psi \\right\\rangle = \\left \\langle \\phi, \\frac{d\\psi } {dx}\\right\\rangle,}$$
](A272900_1_En_11_Chapter_Equn.gif)

for all ![
$$\\phi,\\psi \\in \\mathcal{S}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq29.gif). From this, we can easily verify that for all ![
$$\\phi,\\psi \\in \\mathcal{S}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq30.gif),

![
$$\\displaystyle{\\left \\langle \\phi,a\\psi \\right\\rangle = \\left \\langle {a}^{{\\ast}}\\phi,\\psi \\right\\rangle }$$
](A272900_1_En_11_Chapter_Equo.gif)

and so also

![
$$\\displaystyle{\\left \\langle \\phi,{a}^{{\\ast}}a\\psi \\right\\rangle = \\left \\langle {a}^{{\\ast}}a\\phi,\\psi \\right\\rangle.}$$
](A272900_1_En_11_Chapter_Equp.gif)

It is evident that both the ground state ![
$$\\psi_0$$
](A272900_1_En_11_Chapter_IEq048.gif) and all the excited states ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq049.gif) occurring in Theorem 11.4 belong to ![
$$\\mathcal{S}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq31.gif). Thus, the proof of Theorem 11.2 is indeed valid. We conclude, then, that the ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq050.gif)'s form an orthogonal set of vectors in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq32.gif) and that they are eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_11_Chapter_IEq33.gif) with the indicated eigenvalues.

It remains to show that the ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq051.gif)'s form an orthogonal basis for ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq34.gif). Let V denote the space of finite linear combinations of the ![
$$\\psi_n$$
](A272900_1_En_11_Chapter_IEq052.gif)'s. Since H n is a polynomial of degree n, it is easily seen that V consists precisely functions of the form

![
$$\\displaystyle{\\psi \(\\tilde{x}\) = p\(\\tilde{x}\){e}^{-\\tilde{{x}}^{2}/2 },}$$
](A272900_1_En_11_Chapter_Equq.gif)

where p is a polynomial.

Lemma 11.5 then shows that ![
$${e}^{ik\\tilde{x}}{e}^{-\\tilde{{x}}^{2}/2 }$$
](A272900_1_En_11_Chapter_IEq35.gif) belongs to the L 2-closure of V for all ![
$$k \\in \\mathbb{R}$$
](A272900_1_En_11_Chapter_IEq36.gif). Thus, if ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq053.gif) is orthogonal to every element of ![
$$\\bar{V }$$
](A272900_1_En_11_Chapter_IEq37.gif), we have

![
$$\\displaystyle{ \\int _{\\mathbb{R}}{e}^{-ik\\tilde{x}}{e}^{-\\tilde{{x}}^{2}/2 }\\psi \(\\tilde{x}\)\\ d\\tilde{x} = 0 }$$
](A272900_1_En_11_Chapter_Equ23.gif)

(11.15)

for all k. Now, since ![
$${e}^{-\\tilde{{x}}^{2}/2 }$$
](A272900_1_En_11_Chapter_IEq38.gif) belongs to ![
$${L}^{\\infty }\(\\mathbb{R}\) \\cap {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq39.gif) and ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq0054.gif) belongs to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq40.gif), their product belongs to ![
$${L}^{2}\(\\mathbb{R}\) \\cap {L}^{1}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq41.gif). Thus, (11.15) tells us that the L 2 Fourier transform of ![
$${e}^{-\\tilde{{x}}^{2}/2 }\\psi \(\\tilde{x}\)$$
](A272900_1_En_11_Chapter_IEq42.gif) is identically zero. Thus, ![
$${e}^{-\\tilde{{x}}^{2}/2 }\\psi \(\\tilde{x}\)$$
](A272900_1_En_11_Chapter_IEq43.gif) must be the zero element of ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq44.gif), by the Plancherel theorem, and so ![
$$\\psi \(\\tilde{x}\) = 0$$
](A272900_1_En_11_Chapter_IEq45.gif) almost everywhere. This shows that V ⊥ = {0}, meaning that ![
$$V$$
](A272900_1_En_11_Chapter_IEq46.gif) is dense in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_11_Chapter_IEq47.gif). ■

## 11.5 Exercises

1.

Show that for any Schwartz functions ![
$$\\phi$$
](A272900_1_En_11_Chapter_IEq054.gif) and ![
$$\\psi$$
](A272900_1_En_11_Chapter_IEq055.gif), we have

![
$$\\displaystyle{\\left \\langle \\phi,a\\psi \\right\\rangle = \\left \\langle {a}^{{\\ast}}\\phi,\\psi \\right\\rangle,}$$
](A272900_1_En_11_Chapter_Equr.gif)

as expected.

Hint: Use integration by parts on the interval [ − A, A] and show that the boundary terms tend to zero as A tends to infinity.

2.

Show that the polynomials H n satisfy the following relations:

![
$$\\displaystyle{H_{n-1}\(y\) = \\frac{1} {n\\sqrt{2}}H_{n}^{{\\prime}}\(y\)}$$
](A272900_1_En_11_Chapter_Equs.gif)

and

![
$$\\displaystyle{H_{n+1}\(y\) = \\frac{1} {\\sqrt{2}}\\left \(2yH_{n}\(y\) - n\\sqrt{2}H_{n-1}\(y\)\\right\).}$$
](A272900_1_En_11_Chapter_Equt.gif)

Hint: Start with the relation ![
$$a\\psi _{n} = n\\psi _{n-1}$$
](A272900_1_En_11_Chapter_IEq48.gif).

3.

Establish the following Rodrigues formula for the polynomials H n :

![
$$\\displaystyle{H_{n}\(y\) = {\(-1\)}^{n}{2}^{-n/2}\\frac{{\\left \( \\frac{d} {dy}\\right\)}^{n}{e}^{-{y}^{2} }} {{e}^{-{y}^{2} }}.}$$
](A272900_1_En_11_Chapter_Equu.gif)

4.

In this exercise, we prove the following claim: The polynomial H n has n distinct real zeros and the zeros of H n "interlace" with the zeros of H n − 1, meaning that there is exactly one zero of H n − 1 between each pair of consecutive zeros of H n .

(a)

Verify the claim for H 1 and H 0.

(b)

Assume, inductively, that H n and H n − 1 have distinct real zeros and that the zeros interlace. Show that H n − 1 alternates in sign at consecutive zeros of H n . Then show that H n \+ 1 and H n − 1 have opposite signs at each zero of H n , so that H n \+ 1 also alternates in sign at consecutive zeros of H n . Conclude that H n \+ 1 must have at least one zero between each pair of consecutive zeros of H n .

Hint: Use Exercise 2.

(c)

Show that H n \+ 1 and H n − 1 have the same sign near ± ∞ but opposite signs at the largest and smallest zeros of H n . Conclude that H n \+ 1 has at least one zero below the smallest zero of H n and at least one zero above the largest zero of H n .

(d)

Conclude that H n \+ 1 has n \+ 1 real zeros that interlace with the zeros of H n .

5.

Let ![
$$\\tilde{\\psi }_{n} =\\psi _{n}/\\left \\Vert \\psi _{n}\\right\\Vert$$
](A272900_1_En_11_Chapter_IEq49.gif) be the normalized nth excited state.

(a)

Let ![
$$\\tilde{X} = X/D$$
](A272900_1_En_11_Chapter_IEq50.gif), where ![
$$D = {\(\\hslash /m\\omega \)}^{1/2}$$
](A272900_1_En_11_Chapter_IEq51.gif). Show that

![
$$\\displaystyle{\\left \\langle \\tilde{{X}}^{2}\\right\\rangle _{ \\tilde{\\psi }_{n}} = n + \\frac{1} {2}.}$$
](A272900_1_En_11_Chapter_Equv.gif)

Hint: Express ![
$$\\tilde{X}$$
](A272900_1_En_11_Chapter_IEq52.gif) in terms of a and a ∗, using (11.10), and then use Theorem 11.2.

(b)

Show that

![
$$\\displaystyle{\\left \\langle X\\right\\rangle _{\\tilde{\\psi }_{n}} = 0}$$
](A272900_1_En_11_Chapter_Equw.gif)

![
$$\\displaystyle{\\Delta _{\\tilde{\\psi }_{n}}X ={ \\left \(\\frac{\\hslash \(n + 1/2\)} {m\\omega } \\right\)}^{1/2}.}$$
](A272900_1_En_11_Chapter_Equx.gif)

(c)

If T and V denote the kinetic energy and potential energy terms, respectively, in (11.3), show that

![
$$\\displaystyle{\\left \\langle T\\right\\rangle _{\\tilde{\\psi }_{n}} = \\left \\langle V \\right\\rangle _{\\tilde{\\psi }_{n}} = \\frac{1} {2}\\hslash \\omega \\left \(n + \\frac{1} {2}\\right\).}$$
](A272900_1_En_11_Chapter_Equy.gif)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_12

© Springer Science+Business Media New York 2013

# 12. The Uncertainty Principle

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In this chapter, we will continue our investigation of the consequences of the commutation relations among the position and momentum operators.

In this chapter, we will continue our investigation of the consequences of the commutation relations among the position and momentum operators. We will mostly consider a particle in ![
$${\\mathbb{R}}^{1},$$
](A272900_1_En_12_Chapter_IEq1.gif) where we have

![
$$\\displaystyle{ \[X,P\] = i\\hslash I. }$$
](A272900_1_En_12_Chapter_Equ1.gif)

(12.1)

We have already seen that much of the analysis of the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_12_Chapter_IEq2.gif) for the quantum harmonic oscillator (given by ![
$$c_{1}{P}^{2} + c_{2}{X}^{2}$$
](A272900_1_En_12_Chapter_IEq3.gif)) can be carried out using only the commutation relation (12.1). There are two other main results that can be derived from these commutation relations: the Heisenberg uncertainty principle and the Stone–von Neumann theorem. The uncertainty principle states that the product of the uncertainty in X and the uncertainty in P cannot be smaller than ℏ ∕ 2. The Stone-von Neumann theorem, meanwhile, states that any two self-adjoint operators A and B satisfying [A, B] = iℏI "look like" several copies of the standard position and momentum operators acting on ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_12_Chapter_IEq4.gif) Both results are true only under certain technical domain conditions, which we will need to examine carefully. We discuss the uncertainty principle in this chapter and the Stone–von Neumann theorem in the next chapter.

The uncertainty principle states that for all ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq01.gif) in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_12_Chapter_IEq5.gif) satisfying certain domain conditions, we have

![
$$\\displaystyle{\(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\) \\geq \\frac{\\hslash } {2},}$$
](A272900_1_En_12_Chapter_Equa.gif)

where, for any observable A, we let ![
$$\\Delta_\\psi A$$
](A272900_1_En_12_Chapter_IEq02.gif) denote the "uncertainty" in measurements of A in the state ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq03.gif) (Definition 3.13). This means that one cannot make both the uncertainty in position and the uncertainty in momentum arbitrarily small in the same state ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq04.gif).

Although we can easily make ![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq05.gif) as small as we want simply be taking ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq06.gif) to be supported in a small interval, if we do that, ![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq07.gif) will be large. Similarly, we can make ![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq08.gif) as small as we like, by taking the momentum wave function ![
$$\\tilde{\\psi }\(p\)$$
](A272900_1_En_12_Chapter_IEq6.gif) (Sect.​ 6.​6) to be supported in a small interval, but then ![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq09.gif) will get large. In the idealized limit in which the position wave function is concentrated at a single point, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq010.gif)(x) would be a multiple of δ(x − a) for some a, in which case, the momentum wave function ![
$$\\tilde{\\psi }\(p\)$$
](A272900_1_En_12_Chapter_IEq7.gif) would be a multiple of ![
$${e}^{-ipa/\\hslash }.$$
](A272900_1_En_12_Chapter_IEq8.gif) In that case, ![
$$\\vert \\tilde{\\psi }\(p\){\\vert }^{2}$$
](A272900_1_En_12_Chapter_IEq9.gif) is constant, meaning that the momentum wave function is completely spread out over the whole real line.

This uncertainty principle may be interpreted as saying that it is impossible to simultaneously measure the position and momentum of a quantum particle. After all, we have said (Axiom 4) that if we perform a measurement of an observable A with a discrete spectrum, then immediately after the measurement the state ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq011.gif) of the system should be an eigenvector for A. If A has a continuous spectrum, this principle is replaced by the requirement that after the measurement, the uncertainty in A should very small. If we could measure both the position and the momentum of the particle simultaneously with arbitrary precision, then after the measurement, both ΔX and ΔP would have to be very small, violating the uncertainty principle.

Now, on the scale of everyday life, Planck's constant is very small. If, for example, we measure mass in units of grams, distance in units of centimeters, and time in units of seconds, then ![
$$\\hslash $$
](A272900_1_En_12_Chapter_IEq10.gif) has the numerical value of 1. 054 ×10− 27. Thus, on "macroscopic" scales of energy and momentum, it is possible for the uncertainties in position and momentum both to be very small. But on the atomic scale, the uncertainty principle puts a substantial limitation on how localized the position and momentum of a particle can be.

In Sect. 12.1, we prove a version of the uncertainty principle for any two operators A and B satisfying [A, B] = iℏI, under a seemingly innocuous assumption on the domains of the operators involved. In Sect. 12.2, however, we see that the domain assumptions are not so innocuous after all. In that section, we encounter two operators satisfying [A, B] = iℏI on a dense subspace of the Hilbert space, along with a vector ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq012.gif) such that the uncertainty in A is finite and the uncertainty in B is zero. The existence of such a vector is surely contrary to the spirit of the uncertainty principle, even though it does not violate the version of the uncertainty principle proved in Sect. 12.1. (The vector ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq013.gif) in Sect. 12.2 does not satisfy the domain assumptions of Theorem 12.4.) Finally, in Sect. 12.3, we show that for the usual position and momentum operators on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_12_Chapter_IEq11.gif), no such counterexamples occur: If ![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq004.gif) and ![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq015.gif) are both defined, then (![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq016.gif))(![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq017.gif)) ≥ ℏ ∕ 2.

## 12.1 Uncertainty Principle, First Version

In this section, it is essential that we make sure that all vectors are in the domains of the various operators we want to apply to these vectors. With this concern in mind, we make the following definition. (Compare Definition 9.36.)

Definition 12.1.

If A and B are unbounded operators on H, define AB to be the operator with domain

![
$$\\displaystyle{\\mathrm{Dom}\(AB\) = \\left \\{\\psi \\in \\mathrm{ Dom}\(B\)\\left \\vert B\\psi \\in \\mathrm{ Dom}\(A\)\\right.\\right\\}}$$
](A272900_1_En_12_Chapter_Equb.gif)

and given by (AB)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq018.gif) = A(B ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq241.gif)).

Even if Dom(A) and Dom(B) are dense in H, it could happen that Dom(AB) is not dense in H.

Recall (Definition 3.13) that the uncertainty of a symmetric operator A in a state ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq020.gif) is defined to be

![
$$\\displaystyle{ {\(\\Delta _{\\psi }A\)}^{2} = \\left \\langle {\\left \(A -\\left \\langle A\\right\\rangle _{\\psi }I\\right\)}^{2}\\right\\rangle _{ \\psi }. }$$
](A272900_1_En_12_Chapter_Equ2.gif)

(12.2)

As written, this definition requires that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq021.gif) belong to the domain of ![
$${\(A -\\left \\langle A\\right\\rangle _{\\psi }I\)}^{2},$$
](A272900_1_En_12_Chapter_IEq12.gif) which is the same as the domain of A 2. However, since we assume that A is symmetric, then ![
$$\\left \\langle A\\right\\rangle _{\\psi } = \\left \\langle \\psi,A\\psi \\right\\rangle$$
](A272900_1_En_12_Chapter_IEq13.gif) is real, so that ![
$$A -\\left \\langle A\\right\\rangle _{\\psi }I$$
](A272900_1_En_12_Chapter_IEq14.gif) is again symmetric. Thus, (12.2) can be rewritten as

![
$$\\displaystyle{{\(\\Delta _{\\psi }A\)}^{2} = \\left \\langle \(A -\\left \\langle A\\right\\rangle _{\\psi }I\)\\psi,\(A -\\left \\langle A\\right\\rangle _{\\psi }I\)\\psi \\right\\rangle.}$$
](A272900_1_En_12_Chapter_Equc.gif)

Having written the uncertainty in this way, it is natural to extend the definition of uncertainty to vectors that belong only to Dom(A), as follows.

Definition 12.2.

If A is a symmetric operator on H, then for all unit vectors ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq022.gif) in Dom(A), the uncertainty ![
$$\\Delta_\\psi A$$
](A272900_1_En_12_Chapter_IEq023.gif) of A in the state ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq024.gif) is given by

![
$$\\displaystyle{ {\(\\Delta _{\\psi }A\)}^{2} = \\left \\langle \(A -\\left \\langle A\\right\\rangle _{\\psi }I\)\\psi,\(A -\\left \\langle A\\right\\rangle _{\\psi }I\)\\psi \\right\\rangle. }$$
](A272900_1_En_12_Chapter_Equ3.gif)

(12.3)

By expanding out the right-hand side of (12.3), we see that the uncertainty may also be computed as

![
$$\\displaystyle{{\(\\Delta _{\\psi }A\)}^{2} = \\left \\langle A\\psi,A\\psi \\right\\rangle - {\(\\left \\langle \\psi,A\\psi \\right\\rangle \)}^{2}.}$$
](A272900_1_En_12_Chapter_Equd.gif)

Compare ([3.​24).] Of course, if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq025.gif) happens to be in the domain of A 2, then Definition 12.2 agrees with (12.2).

Proposition 12.3.

If A is a symmetric operator on H , then for all unit vectors ![
$$ \\psi\\epsilon $$
](A272900_1_En_12_Chapter_IEq216.gif) Dom (A), we have ![
$$\\Delta_\\psi A = 0$$
](A272900_1_En_12_Chapter_IEq287.gif) if and only if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0001.gif) is an eigenvector for A.

Proof.

If ![
$$\\Delta_\\psi A$$
](A272900_1_En_12_Chapter_IEq026.gif) = 0, then from (12.3), we see that ![
$$\(A -\\left \\langle A\\right\\rangle _{\\psi }I\)\\psi = 0,$$
](A272900_1_En_12_Chapter_IEq15.gif) meaning that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq027.gif) is an eigenvector for A with eigenvalue ![
$$\\left \\langle A\\right\\rangle _{\\psi }.$$
](A272900_1_En_12_Chapter_IEq16.gif) Conversely, if ![
$$A\\psi = \\lambda\\psi$$
](A272900_1_En_12_Chapter_IEq028.gif) for some λ, then ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle =\\lambda \\left \\langle \\psi,\\psi \\right\\rangle =\\lambda.$$
](A272900_1_En_12_Chapter_IEq17.gif) Thus, ![
$$\(A -\\left \\langle A\\right\\rangle _{\\psi }I\)\\psi = 0,$$
](A272900_1_En_12_Chapter_IEq18.gif) which, by (12.3), means that ![
$$\\Delta_\\psi A = 0$$
](A272900_1_En_12_Chapter_IEq029.gif). ■

As discussed in the introduction to this chapter, we expect that immediately after a measurement of an observable A, the state of the system will have very small uncertainty for A. Indeed, if A has discrete spectrum, we expect that the state of the system will be an eigenvector for A. Even in the case of a continuous spectrum, we expect that the uncertainty in A can be made as small as one wishes, by making more and more precise measurements. Suppose now that one wishes to observe simultaneously two (or more) different observables, represented by operators A and B. In the case of a discrete spectrum, the system after the measurement should be simultaneously an eigenvector for A and an eigenvector for B. In the case where A and B commute, this idea is reasonable. There is a version of the spectral theorem for commuting self-adjoint operators; in the case of discrete spectrum, it says that two commuting self-adjoint operators have an orthonormal basis of simultaneous eigenvectors with real eigenvalues. (In the case of unbounded operators, there are, as usual, technical domain conditions in defining what it means for two self-adjoint operators to commute.)

In the case where A and B do not commute, they do not need to have any simultaneous eigenvectors. Certainly, A and B cannot have an orthonormal basis of simultaneous eigenvectors, or they would in fact commute. The lack of simultaneous eigenvectors suggests, then, that it is simply not possible to make a simultaneous measurement of two self-adjoint operators unless they commute. In standard physics terminology, the quantities A and B are said to be "incommensurable," meaning not capable of being measured at the same time. (See Exercise 2 for a classification of the simultaneous eigenvectors of a representative pair of noncommuting operators.)

In the case of a continuous spectrum, the notion of an eigenvector is replaced by the notion of a state with very small uncertainty for the relevant operator. In light of our discussion of simultaneous eigenvectors, we may expect that for noncommuting operators, it may be difficult to find states where the uncertainties of both operators are small. This expectation is realized in the following version of the uncertainty principle.

Theorem 12.4.

Suppose A and B are symmetric operators and ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq217.gif) is a unit vector belonging to ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\).$$
](A272900_1_En_12_Chapter_IEq19.gif) Then

![
$$\\displaystyle{ {\(\\Delta _{\\psi }A\)}^{2}{\(\\Delta _{\\psi }B\)}^{2} \\geq \\frac{1} {4}{\\left \\vert \\left \\langle \[A,B\]\\right\\rangle _{\\psi }\\right\\vert }^{2}. }$$
](A272900_1_En_12_Chapter_Equ4.gif)

(12.4)

Note that if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq030.gif) ∈ Dom(AB) then in particular, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq031.gif) ∈ Dom(B), and if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq032.gif) ∈ Dom(BA) then ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq033.gif) ∈ Dom(A). Thus, the assumptions on ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0034.gif) are sufficient to guarantee that ![
$$\\Delta_\\psi A$$
](A272900_1_En_12_Chapter_IEq034.gif) and ![
$$\\Delta_\\psi B$$
](A272900_1_En_12_Chapter_IEq035.gif) make sense as in Definition 12.2.

Proof.

Define operators A ′ and B ′ by ![
$${A}^{{\\prime}} := A -\\left \\langle \\psi,A\\psi \\right\\rangle I$$
](A272900_1_En_12_Chapter_IEq20.gif) and ![
$${B}^{{\\prime}} := B -\\left \\langle \\psi,B\\psi \\right\\rangle I$$
](A272900_1_En_12_Chapter_IEq21.gif). (We use the same domains for A ′ and B ′ as for A and B, and it is easily verified that A ′ and B ′ are still symmetric on those domains.) Then by the Cauchy–Schwarz inequality, we obtain

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle {A}^{{\\prime}}\\psi,{A}^{{\\prime}}\\psi \\right\\rangle \\left \\langle {B}^{{\\prime}}\\psi,{B}^{{\\prime}}\\psi \\right\\rangle & \\geq &{ \\left \\vert \\left \\langle {A}^{{\\prime}}\\psi,{B}^{{\\prime}}\\psi \\right\\rangle \\right\\vert }^{2}{}\\end{array}$$
](A272900_1_En_12_Chapter_Equ5.gif)

(12.5)

![
$$\\displaystyle\\begin{array}{rcl} & \\geq &{ \\left \\vert \\mathrm{Im}\\left \\langle {A}^{{\\prime}}\\psi,{B}^{{\\prime}}\\psi \\right\\rangle \\right\\vert }^{2}{}\\end{array}$$
](A272900_1_En_12_Chapter_Equ6.gif)

(12.6)

![
$$\\displaystyle\\begin{array}{rcl} & =& \\frac{1} {4}{\\left \\vert \\left \\langle {A}^{{\\prime}}\\psi,{B}^{{\\prime}}\\psi \\right\\rangle -\\left \\langle {B}^{{\\prime}}\\psi,{A}^{{\\prime}}\\psi \\right\\rangle \\right\\vert }^{2}.{}\\end{array}$$
](A272900_1_En_12_Chapter_Equ7.gif)

(12.7)

The assumptions on ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq036.gif) guarantee that ![
$$B\\psi$$
](A272900_1_En_12_Chapter_IEq037.gif) ∈ Dom(A) and hence also that ![
$$B^\\prime\\psi$$
](A272900_1_En_12_Chapter_IEq038.gif) ∈ Dom(A ′ ), and similarly with A ′ and B ′ reversed. Since A ′ and B ′ are symmetric, we may rewrite (12.7) as

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle {A}^{{\\prime}}\\psi,{A}^{{\\prime}}\\psi \\right\\rangle \\left \\langle {B}^{{\\prime}}\\psi,{B}^{{\\prime}}\\psi \\right\\rangle & \\geq & \\frac{1} {4}{\\left \\vert \\left \\langle \\psi,{A}^{{\\prime}}{B}^{{\\prime}}\\psi \\right\\rangle -\\left \\langle \\psi,{B}^{{\\prime}}{A}^{{\\prime}}\\psi \\right\\rangle \\right\\vert }^{2} {}\\\\ & =& \\frac{1} {4}{\\left \\vert \\left \\langle \\psi,\[{A}^{{\\prime}},{B}^{{\\prime}}\]\\psi \\right\\rangle \\right\\vert }^{2}. {}\\\\ \\end{array}$$
](A272900_1_En_12_Chapter_Equ8.gif)

Now, since the identity operator commutes with everything, the commutator of A ′ and B ′ is the same as the commutator of A and B. Furthermore, ![
$$\\left \\langle {A}^{{\\prime}}\\psi,{A}^{{\\prime}}\\psi \\right\\rangle$$
](A272900_1_En_12_Chapter_IEq22.gif) is nothing but (![
$$\\Delta_\\psi A$$
](A272900_1_En_12_Chapter_IEq039.gif))2 and similarly for B. Thus, we obtain

![
$$\\displaystyle{{\(\\Delta _{\\psi }A\)}^{2}{\(\\Delta _{\\psi }B\)}^{2} \\geq \\frac{1} {4}{\\left \\vert \\left \\langle \\psi,\[A,B\]\\psi \\right\\rangle \\right\\vert }^{2},}$$
](A272900_1_En_12_Chapter_Eque.gif)

which is what we wanted to prove. ■

We now specialize Theorem 12.4 to the case in which the commutator is iℏI and take the square root of both sides.

Corollary 12.5.

Suppose A and B are symmetric operators satisfying

![
$$\\displaystyle{\[A,B\] = i\\hslash I}$$
](A272900_1_En_12_Chapter_Equf.gif)

on ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\).$$
](A272900_1_En_12_Chapter_IEq23.gif) Then if ![
$$\\psi \\in \\mathrm{ Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\)$$
](A272900_1_En_12_Chapter_IEq24.gif) is a unit vector, we have

![
$$\\displaystyle{ \(\\Delta _{\\psi }A\)\(\\Delta _{\\psi }B\) \\geq \\frac{\\hslash } {2}. }$$
](A272900_1_En_12_Chapter_Equ9.gif)

(12.8)

In particular, for all unit vectors ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_12_Chapter_IEq25.gif) in ![
$$\\mathrm{Dom}\(XP\) \\cap \\mathrm{ Dom}\(PX\),$$
](A272900_1_En_12_Chapter_IEq26.gif) we have

![
$$\\displaystyle{ \(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\) \\geq \\frac{\\hslash } {2}. }$$
](A272900_1_En_12_Chapter_Equ10.gif)

(12.9)

Note that the factor of ℏ appearing on the right-hand side of (12.8) is really just ![
$$\\left \\vert \\left \\langle \\psi,\[A,B\]\\psi \\right\\rangle \\right\\vert.$$
](A272900_1_En_12_Chapter_IEq27.gif) Since, however, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0160.gif) is a unit vector and [A, B] = iℏI, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq041.gif) drops out of the right-hand side of our inequality. We see then that both sides of (12.9) make sense whenever ![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq042.gif) and ![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq043.gif) make sense, namely, whenever ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq044.gif) belongs to Dom(X) and to Dom(P). (Recall Definition 12.2.) On the other hand, the proof that we have given for (12.9) requires ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq045.gif) to be in both Dom(XP) and Dom(PX). Nevertheless, it is natural to ask whether (12.9) holds for all ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq046.gif) in Dom(X) ∩ Dom(P). We may similarly ask whether (12.8) holds for all ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq047.gif) in ![
$$\\mathrm{Dom}\(A\) \\cap \\mathrm{ Dom}\(B\).$$
](A272900_1_En_12_Chapter_IEq28.gif) As we will see in Sects. 12.2 and 12.3, the answer to the first question is yes and the answer to the second question is no.

Meanwhile, it is of interest to investigate "minimum uncertainty states," that is, states ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq048.gif) for which the inequality (12.4) is an equality.

Proposition 12.6.

If A and B are symmetric and ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq218.gif) is a unit vector in ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\),$$
](A272900_1_En_12_Chapter_IEq29.gif) equality holds in ( 12.4 ) if and only if one of the following holds: (1) ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq219.gif) is an eigenvector for A, (2) ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq220.gif) is an eigenvector for B, or (3) ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq221.gif) is an eigenvector for an operator of the form

![
$$\\displaystyle{A - i\\gamma B}$$
](A272900_1_En_12_Chapter_Equg.gif)

for some nonzero real number γ.

In the case A = X and B = P, we will consider examples where equality holds in Sect. 12.4.

Proof.

To get equality in (12.4), we must have equality in both (12.5) and (12.6). Equality in (12.5) occurs if and only if ![
$$A^\\prime\\psi = 0$$
](A272900_1_En_12_Chapter_IEq050.gif) or ![
$$B^\\prime\\psi = 0$$
](A272900_1_En_12_Chapter_IEq051.gif) or ![
$$A^\\prime\\psi = c{B^\\prime}\\psi$$
](A272900_1_En_12_Chapter_IEq052.gif) for some nonzero constant c. If ![
$$A^\\prime\\psi$$
](A272900_1_En_12_Chapter_IEq053.gif) is zero, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq054.gif) is an eigenvector for ![
$$A$$
](A272900_1_En_12_Chapter_IEq30.gif) with eigenvalue ![
$$\\left \\langle A\\right\\rangle _{\\psi }.$$
](A272900_1_En_12_Chapter_IEq31.gif) In that case, equality holds in (12.6) as well. Conversely, if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq055.gif) is an eigenvector for A with some eigenvalue λ, then ![
$$\\left \\langle A\\right\\rangle _{\\psi } =\\lambda$$
](A272900_1_En_12_Chapter_IEq32.gif) and ![
$$A^\\prime\\psi = 0$$
](A272900_1_En_12_Chapter_IEq056.gif). Similarly, ![
$$B^\\prime\\psi = 0$$
](A272900_1_En_12_Chapter_IEq057.gif) if and only if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq058.gif) is an eigenvector for B.

Meanwhile, suppose ![
$$A^\\prime\\psi$$
](A272900_1_En_12_Chapter_IEq059.gif) and ![
$$B^\\prime\\psi$$
](A272900_1_En_12_Chapter_IEq060.gif) are nonzero and ![
$$A^\\prime\\psi = c{B^\\prime}\\psi$$
](A272900_1_En_12_Chapter_IEq061.gif), so that equality holds in (12.5). Then equality holds (12.6) if and only if c = iγ for some nonzero ![
$$\\gamma \\in \\mathbb{R}.$$
](A272900_1_En_12_Chapter_IEq33.gif) Thus, when ![
$$A^\\prime\\psi$$
](A272900_1_En_12_Chapter_IEq062.gif) and ![
$$B^\\prime\\psi$$
](A272900_1_En_12_Chapter_IEq063.gif) are nonzero, we get equality in (12.4) if and only if

![
$$\\displaystyle{ {A}^{{\\prime}}\\psi = i\\gamma {B}^{{\\prime}}\\psi }$$
](A272900_1_En_12_Chapter_Equ11.gif)

(12.10)

for some nonzero real number γ. Recalling the definition of A ′ and B ′ , (12.10) says that

![
$$\\displaystyle{ \(A -\\left \\langle \\psi,A\\psi \\right\\rangle I\)\\psi = i\\gamma \(B -\\left \\langle \\psi,B\\psi \\right\\rangle I\)\\psi }$$
](A272900_1_En_12_Chapter_Equ12.gif)

(12.11)

or

![
$$\\displaystyle{ \(A - i\\gamma B\)\\psi =\\lambda \\psi, }$$
](A272900_1_En_12_Chapter_Equ13.gif)

(12.12)

where ![
$$\\lambda = \\left \\langle \\psi,A\\psi \\right\\rangle - i\\gamma \\left \\langle \\psi,B\\psi \\right\\rangle.$$
](A272900_1_En_12_Chapter_IEq34.gif)

Thus, if (12.11) holds, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq064.gif) is an eigenvector of A − iγB. Conversely, if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq065.gif) is an eigenvector for A − iγB with some eigenvalue ![
$$\\lambda = c + id$$
](A272900_1_En_12_Chapter_IEq35.gif) in ![
$$\\mathbb{C},$$
](A272900_1_En_12_Chapter_IEq36.gif) then

![
$$\\displaystyle{ \(c + id\){\\left \\Vert \\psi \\right\\Vert }^{2} = \\left \\langle \\psi,\(A - i\\gamma B\)\\psi \\right\\rangle = \\left \\langle \\psi,A\\psi \\right\\rangle - i\\gamma \\left \\langle \\psi,B\\psi \\right\\rangle. }$$
](A272900_1_En_12_Chapter_Equ14.gif)

(12.13)

Since A and B are assumed to be symmetric and ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq066.gif) is a unit vector, we may equate real and imaginary parts in (12.13) to obtain

![
$$\\displaystyle{c = \\left \\langle \\psi,A\\psi \\right\\rangle ;\\quad d = -\\gamma \\left \\langle \\psi,B\\psi \\right\\rangle.}$$
](A272900_1_En_12_Chapter_Equh.gif)

From this we can see that (12.11) and (12.10) hold, and thus equality holds in (12.4). ■

## 12.2 A Counterexample

In this section, we consider the Hilbert space L 2[ − 1, 1]. As our "position" operator, we use the usual formula,

![
$$\\displaystyle{A\\psi \(x\) = x\\psi \(x\).}$$
](A272900_1_En_12_Chapter_Equi.gif)

Note that A is a bounded operator, because we restrict x to the bounded interval [ − 1, 1]. As such, A is defined (and self-adjoint) on the whole Hilbert space ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_12_Chapter_IEq37.gif) As our "momentum" operator, we again use the usual formula,

![
$$\\displaystyle{B = -i\\hslash \\frac{d} {dx}.}$$
](A272900_1_En_12_Chapter_Equj.gif)

As the domain of B we will take the space of continuously differentiable functions ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq067.gif) on [ − 1, 1] satisfying the periodic boundary condition,

![
$$\\displaystyle{ \\psi \(-1\) =\\psi \(1\). }$$
](A272900_1_En_12_Chapter_Equ15.gif)

(12.14)

To verify that B is symmetric, note that for any C 1 functions ![
$${\\phi}$$
](A272900_1_En_12_Chapter_IEq211.gif) and ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq068.gif), we have

![
$$\\displaystyle{\\int _{-1}^{1}\\overline{\\phi \(x\)} \\frac{d\\psi } {dx}\\ dx = \\overline{\\phi \(1\)}\\psi \(1\) -\\overline{\\phi \(-1\)}\\psi \(-1\) -\\int _{-1}^{1}\\overline{ \\frac{d\\phi } {dx}}\\psi \(x\)\\ dx.}$$
](A272900_1_En_12_Chapter_Equk.gif)

If both ![
$$\\phi$$
](A272900_1_En_12_Chapter_IEq069.gif) and ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq070.gif) satisfy the periodic boundary condition (12.14), the boundary terms cancel out to zero. This shows that the operator d ∕ dx is skew-symmetric on Dom(B), from which it follows that ![
$$-i\\hslash d/dx$$
](A272900_1_En_12_Chapter_IEq38.gif) is symmetric on Dom(B). Actually, since the functions

![
$$\\displaystyle{ \\psi _{n}\(x\) := \\frac{1} {\\sqrt{2}}{e}^{\\pi inx},\\quad n \\in \\mathbb{Z}, }$$
](A272900_1_En_12_Chapter_Equ16.gif)

(12.15)

constitute an orthonormal basis of eigenvectors for B with real eigenvalues, B is essentially self-adjoint, by Example 9.25.

Now, for all ![
$$\\psi \\in \\mathrm{ Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\)$$
](A272900_1_En_12_Chapter_IEq39.gif) we have, by direct calculation,

![
$$\\displaystyle{ AB\\psi - BA\\psi = i\\hslash \\psi, }$$
](A272900_1_En_12_Chapter_Equ17.gif)

(12.16)

just as for the usual position and momentum operators. Furthermore, ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\)$$
](A272900_1_En_12_Chapter_IEq40.gif) is dense in H, since it contains all continuously differentiable functions ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq071.gif) such that ![
$$\\psi \(0\) =\\psi \(1\) = 0.$$
](A272900_1_En_12_Chapter_IEq41.gif) Consider, now, the function ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq072.gif)(x) in (12.15), for some integer n. Clearly, ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq073.gif) is in the domain of B, since B ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq222.gif) n is just a multiple of ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq074.gif). Since ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq075.gif) is an eigenvector for B, the uncertainty of B in the state ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq076.gif) is zero! Meanwhile, since A is bounded, the uncertainty of A is well defined and finite. Thus, ![
$$\\Delta _{\\psi _{n}}A$$
](A272900_1_En_12_Chapter_IEq42.gif) and ![
$$\\Delta _{\\psi _{n}}B$$
](A272900_1_En_12_Chapter_IEq43.gif) are both unambiguously defined and

![
$$\\displaystyle{ \(\\Delta _{\\psi _{n}}A\)\(\\Delta _{\\psi _{n}}B\) = 0. }$$
](A272900_1_En_12_Chapter_Equ18.gif)

(12.17)

How can (12.17) hold? Is it not, in light of (12.16), a violation of (12.8) in Corollary 12.5? The answer is no, for the reason that ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq077.gif) does not satisfy the domain assumptions in that corollary. Specifically, ![
$$A\\psi_n$$
](A272900_1_En_12_Chapter_IEq078.gif) is not in the domain of B, since ![
$$A\\psi_n$$
](A272900_1_En_12_Chapter_IEq079.gif) is does not satisfy the periodic boundary condition in the definition of Dom(B). Thus, ![
$$\\psi_n$$
](A272900_1_En_12_Chapter_IEq080.gif) does not belong to Dom(BA).

Although it does not contradict Corollary 12.5, (12.17) certainly violates the spirit of the uncertainty principle. In the next section, we will show that no such strange counterexamples occur for the usual position and momentum operators.

## 12.3 Uncertainty Principle, Second Version

In this section, we will see that if A and B are taken to be the usual position and momentum operators X and P, the uncertainty principle holds whenever ![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq081.gif) and ![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq082.gif) are defined. We continue to use Definition 12.2 for the definition of the uncertainty in any operator, in which case, for ![
$$\\Delta_\\psi X$$
](A272900_1_En_12_Chapter_IEq083.gif) and ![
$$\\Delta_\\psi P$$
](A272900_1_En_12_Chapter_IEq084.gif) to be defined, we require only that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq085.gif) belong to Dom(X) and Dom(P).

We are now ready to formulate the strong version of the uncertainty principle.

Theorem 12.7.

Suppose ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq223.gif) is a unit vector in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_12_Chapter_IEq44.gif) belonging to ![
$$\\mathrm{Dom}\(X\) \\cap \\mathrm{ Dom}\(P\).$$
](A272900_1_En_12_Chapter_IEq45.gif) Then

![
$$\\displaystyle{ \(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\) \\geq \\frac{\\hslash } {2}, }$$
](A272900_1_En_12_Chapter_Equ19.gif)

(12.18)

where Δ ![
$$ {\\psi} $$
](A272900_1_En_12_Chapter_IEq224.gif) X and Δ ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq225.gif) P are given by Definition 12.2.

Proof.

According to Stone's theorem and Example 10.16, the operator P is ![
$$\\hslash $$
](A272900_1_En_12_Chapter_IEq46.gif) times the infinitesimal generator of the group U( ⋅) of translations. That is to say, for all ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq086.gif) ∈ Dom(P), we have

![
$$\\displaystyle{\(P\\psi \)\(x\) = -i\\hslash \\lim _{a\\rightarrow 0}\\frac{\\psi \(x + a\) -\\psi \(x\)} {a},}$$
](A272900_1_En_12_Chapter_Equl.gif)

where the limit is in the L 2 norm sense. Thus,

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle X\\psi,P\\psi \\right\\rangle & =& \\lim _{a\\rightarrow 0}\\left \\langle X\\psi,-i\\hslash \\left \(\\frac{\\psi \(x + a\) -\\psi \(x\)} {a} \\right\)\\right\\rangle {}\\\\ & =& \\lim _{a\\rightarrow 0}\\left \(\\frac{1} {a}\\left \\langle x\\psi \(x\),-i\\hslash \\psi \(x + a\)\\right\\rangle + \\frac{i\\hslash } {a} \\left \\langle X\\psi,\\psi \\right\\rangle \\right\) {}\\\\ & =& \\lim _{a\\rightarrow 0}\\left \(\\frac{1} {a}\\left \\langle i\\hslash \(y - a\)\\psi \(y - a\),\\psi \(y\)\\right\\rangle + \\frac{i\\hslash } {a} \\left \\langle X\\psi,\\psi \\right\\rangle \\right\), {}\\\\ \\end{array}$$
](A272900_1_En_12_Chapter_Equ20.gif)

where in the last step we have made the change of variable ![
$$y = x + a.$$
](A272900_1_En_12_Chapter_IEq47.gif)

If we rename the variable of integration back to x, we get

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \\langle X\\psi,P\\psi \\right\\rangle \\\\ & =& \\lim _{a\\rightarrow 0}\\left \(\\left \\langle i\\hslash X\\left \(\\frac{\\psi \(x - a\) -\\psi \(x\)} {a} \\right\),\\psi \(x\)\\right\\rangle + i\\hslash \\left \\langle \\psi \(x - a\),\\psi \(x\)\\right\\rangle \\right\) \\\\ & =& \\lim _{a\\rightarrow 0}\\left \(\\left \\langle i\\hslash \\left \(\\frac{\\psi \(x - a\) -\\psi \(x\)} {a} \\right\),X\\psi \(x\)\\right\\rangle + i\\hslash \\left \\langle \\psi \(x - a\),\\psi \(x\)\\right\\rangle \\right\) \\\\ & =& \\left \\langle P\\psi,X\\psi \\right\\rangle + i\\hslash \\left \\langle \\psi,\\psi \\right\\rangle. {}\\end{array}$$
](A272900_1_En_12_Chapter_Equ21.gif)

(12.19)

In the second equality, we have used that X is symmetric and that (check) if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq087.gif) ∈ Dom(X), then ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq088.gif)(x − a) ∈ Dom(X) for each fixed a. In the last equality, we get a minus sign from having ![
$$\\psi \(x - a\) -\\psi \(x\)$$
](A272900_1_En_12_Chapter_IEq48.gif) rather than ![
$$\\psi \(x + a\) -\\psi \(x\),$$
](A272900_1_En_12_Chapter_IEq49.gif) and we use that translation is strongly continuous.

It should be noted that (12.19) is precisely what we would get by formally moving X to the right-hand side of the inner product, using the commutation relation ![
$$XP - PX = i\\hslash I,$$
](A272900_1_En_12_Chapter_IEq50.gif) and then moving P to the left-hand side of the inner product. But to make that calculation rigorous, we would need to assume that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq089.gif) is in the domain of XP and the domain of PX. In (12.19), on the other hand, we have obtained the desired conclusion assuming only that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq090.gif) is in the domain of X and in the domain of P.

Having obtained (12.19), we can easily verify that for any real constants α and β, we have

![
$$\\displaystyle{ \\left \\langle \(X -\\alpha I\)\\psi,\(P -\\beta I\)\\psi \\right\\rangle = \\left \\langle \(P -\\beta I\)\\psi,\(X -\\alpha I\)\\psi \\right\\rangle + i\\hslash \\left \\langle \\psi,\\psi \\right\\rangle. }$$
](A272900_1_En_12_Chapter_Equ22.gif)

(12.20)

Solving (12.20) for ![
$$\\left \\langle \\psi,\\psi \\right\\rangle$$
](A272900_1_En_12_Chapter_IEq51.gif) gives

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle \\psi,\\psi \\right\\rangle & =& \\frac{1} {i\\hslash }\\left \(\\left \\langle \(X -\\alpha I\)\\psi,\(P -\\beta I\)\\psi \\right\\rangle -\\left \\langle \(P -\\beta I\)\\psi,\(X -\\alpha I\)\\psi \\right\\rangle \\right\) \\\\ & =& \\frac{2} {\\hslash }\\mathrm{Im}\\left \\langle \(X -\\alpha I\)\\psi,\(P -\\beta I\)\\psi \\right\\rangle \\\\ & \\leq & \\frac{2} {\\hslash }\\left \\Vert \(X -\\alpha I\)\\psi \\right\\Vert \\left \\Vert \(P -\\beta I\)\\psi \\right\\Vert, {}\\end{array}$$
](A272900_1_En_12_Chapter_Equ23.gif)

(12.21)

by the Cauchy–Schwarz inequality. If ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq091.gif) is a unit vector and we take ![
$$\\alpha = \\left \\langle X\\right\\rangle _{\\psi },$$
](A272900_1_En_12_Chapter_IEq52.gif) and ![
$$\\beta = \\left \\langle P\\right\\rangle _{\\psi }$$
](A272900_1_En_12_Chapter_IEq53.gif), then ![
$${\\left \\Vert \(X -\\alpha I\)\\psi \\right\\Vert }^{2} = {\(\\Delta _{\\psi }X\)}^{2}$$
](A272900_1_En_12_Chapter_IEq54.gif) and ![
$${\\left \\Vert \(P -\\beta I\)\\psi \\right\\Vert }^{2} = {\(\\Delta _{\\psi }P\)}^{2}.$$
](A272900_1_En_12_Chapter_IEq55.gif) Thus, we get

![
$$\\displaystyle{1 \\leq \\frac{2} {\\hslash }\(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\),}$$
](A272900_1_En_12_Chapter_Equm.gif)

which is equivalent to what we want to prove. ■

We know from Sect. 12.2 that the strong form of the uncertainty principle does not hold if X and P are replaced by two arbitrary operators satisfying ![
$$AB - BA = ihI$$
](A272900_1_En_12_Chapter_IEq56.gif) on ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\),$$
](A272900_1_En_12_Chapter_IEq57.gif) even if ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\)$$
](A272900_1_En_12_Chapter_IEq58.gif) is dense in H. Nevertheless, if we look carefully at the proof of Theorem 12.7, we can see what assumptions we would need on A and B to make the proof go through in a more general setting.

Theorem 12.8.

Suppose A and B are self-adjoint operators on H . Suppose that for all ![
$$a \\in \\mathbb{R}$$
](A272900_1_En_12_Chapter_IEq59.gif) and ![
$$ \\psi\\epsilon $$
](A272900_1_En_12_Chapter_IEq226.gif) Dom (A), we have that e iaB ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq092.gif) belongs to Dom (A) and that

![
$$\\displaystyle{ A{e}^{iaB}\\psi = {e}^{iaB}A\\psi - \\hslash a{e}^{iaB}\\psi. }$$
](A272900_1_En_12_Chapter_Equ24.gif)

(12.22)

Then for all unit vectors ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq228.gif) in ![
$$\\mathrm{Dom}\(A\) \\cap \\mathrm{ Dom}\(B\),$$
](A272900_1_En_12_Chapter_IEq60.gif) we have

![
$$\\displaystyle{\(\\Delta _{\\psi }A\)\(\\Delta _{\\psi }B\) \\geq \\frac{\\hslash } {2},}$$
](A272900_1_En_12_Chapter_Equn.gif)

where Δ A and Δ ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq230.gif) B are defined by Definition 12.2.

The relation

![
$$\\displaystyle{ {e}^{iaB}A = A{e}^{iaB} + \\hslash a{e}^{iaB},\\quad a \\in \\mathbb{R}, }$$
](A272900_1_En_12_Chapter_Equ25.gif)

(12.23)

which holds on Dom(A), is a "semi-exponentiated" form of the canonical commutation relations. As shown in Exercise 6, there is a formal argument (ignoring domain issues) that the commutation relations ![
$$\[A,B\] = i\\hslash I$$
](A272900_1_En_12_Chapter_IEq61.gif) ought to imply the relations (12.22). Nevertheless, as Exercise 7 shows, this formal argument does not always give the correct conclusion. In Sect.​ 14.​2, we will encounter a "fully exponentiated" form of the canonical commutation relations, in which both A and B are exponentiated.

Proof.

See Exercise 5. ■

Corollary 12.9.

For any j = 1,...n and any unit vector ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_12_Chapter_IEq62.gif) with ![
$$\\psi \\in \\mathrm{ Dom}\(X_{j}\) \\cap \\mathrm{ Dom}\(P_{j}\),$$
](A272900_1_En_12_Chapter_IEq63.gif) we have

![
$$\\displaystyle{\(\\Delta _{\\psi }X_{j}\)\(\\Delta _{\\psi }P_{j}\) \\geq \\frac{\\hslash } {2}.}$$
](A272900_1_En_12_Chapter_Equo.gif)

Proof.

In the case that A = X j and B = P j , we have ![
$$\({e}^{iaB/\\hslash }\\psi \)\(\\mathbf{x}\) =\\psi \(\\mathbf{x} + a\\mathbf{e}_{j}\),$$
](A272900_1_En_12_Chapter_IEq64.gif) by Exercise 2 in Chap.​ 10. Thus, in this case, (12.22) says that

![
$$\\displaystyle{\(x_{j} + a\)\\psi \(\\mathbf{x} + a\\mathbf{e}_{j}\) = x_{j}\\psi \(\\mathbf{x} + a\\mathbf{e}_{j}\) + a\\psi \(\\mathbf{x} + a\\mathbf{e}_{j}\),}$$
](A272900_1_En_12_Chapter_Equp.gif)

which is true. ■

## 12.4 Minimum Uncertainty States

In this section, we look at the states that give equality in the uncertainty principle. Such states are known as minimum uncertainty states or coherent states. As in the general setting of Proposition 12.6, the condition for a equality is an eigenvector condition. That is to say, even though in Theorem 12.7, we allow ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq093.gif)'s that are not ![
$$\\mathrm{Dom}\(XP\) \\cap \\mathrm{ Dom}\(PX\),$$
](A272900_1_En_12_Chapter_IEq65.gif) we do not get any new minimum uncertainty states by this weakening of our domain assumptions.

Proposition 12.10.

A unit vector ![
$$\\psi \\in \\mathrm{ Dom}\(X\) \\cap \\mathrm{ Dom}\(P\)$$
](A272900_1_En_12_Chapter_IEq66.gif) satisfies

![
$$\\displaystyle{\(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\) = \\frac{\\hslash } {2}}$$
](A272900_1_En_12_Chapter_Equq.gif)

if and only if ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq231.gif) satisfies

![
$$\\displaystyle{ \(X + i\\delta P\)\\psi =\\lambda \\psi }$$
](A272900_1_En_12_Chapter_Equ26.gif)

(12.24)

for some nonzero real number δ and some complex number λ.

For convenience, we have made the substitution ![
$$\\delta = -\\gamma$$
](A272900_1_En_12_Chapter_IEq67.gif) in (12.24) relative to Proposition 12.6.

Proof.

All the relations in the proof of Theorem 12.7 are equalities, except for the inequality in the last line of (12.21). Equality will hold in that line if and only if one of (X − α I)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq094.gif) and (P − β I)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq095.gif) is zero or (P − β I)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq096.gif) is a pure-imaginary multiple of (X − α I)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq097.gif). Now, if ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq099.gif) is a unit vector in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_12_Chapter_IEq71.gif), then neither ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0100.gif) nor the Fourier transform of ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0101.gif) can be supported at a single point; thus, neither (X − α I)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0102.gif) nor (P − β I)![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0103.gif) can be zero. We are left, then, with the condition that

![
$$\\displaystyle{ \(X -\\alpha I\)\\psi = i\\gamma \(P -\\beta I\)\\psi, }$$
](A272900_1_En_12_Chapter_Equ27.gif)

(12.25)

where γ is a nonzero real number, ![
$$\\alpha = \\left \\langle A\\right\\rangle _{\\psi }$$
](A272900_1_En_12_Chapter_IEq72.gif) and ![
$$\\beta = \\left \\langle B\\right\\rangle _{\\psi }.$$
](A272900_1_En_12_Chapter_IEq73.gif) As in the proof of Proposition 12.6, (12.25) is equivalent to the assertion that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0104.gif) is an eigenvector for the operator X − iγ P. Letting ![
$$\\delta = -\\gamma$$
](A272900_1_En_12_Chapter_IEq74.gif) gives the desired result. ■

Proposition 12.11.

If the parameter δ in ( 12.24 ) is negative, there are no nonzero solutions to ( 12.24 ). If the parameter δ is positive, there exists a unique (up to multiplication by a constant) solution ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq238.gif) δ,λ to ( 12.24 ) for every complex number λ. The function ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq239.gif) δ,λ has the following additional properties

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle X\\right\\rangle & =& \\mathrm{Re}\\lambda {}\\\\ \\left \\langle P\\right\\rangle & =& \\frac{1} {\\delta } \\mathrm{Im}\\lambda {}\\\\ \\frac{\\Delta X} {\\Delta P}& =& \\delta. {}\\\\ \\end{array}$$
](A272900_1_En_12_Chapter_Equ28.gif)

Explicitly, we have

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{\\delta,\\lambda }\(x\)& =& c_{1}\\exp \\left \\{-\\frac{{\(x-\\lambda \)}^{2}} {2\\delta \\hslash } \\right\\} {}\\\\ & =& c_{2}\\exp \\left \\{-\\frac{{\(x -\\left \\langle X\\right\\rangle \)}^{2}} {2\\delta \\hslash } \\right\\}\\exp \\left \\{\\frac{i\\left \\langle P\\right\\rangle x} {\\hslash } \\right\\}, {}\\\\ \\end{array}$$
](A272900_1_En_12_Chapter_Equ29.gif)

where all expectation values are taken in the state ![
$$ {\\psi}$$
](A272900_1_En_12_Chapter_IEq240.gif) δ,λ.

Note that among states with ![
$$\(\\Delta X\)\(\\Delta P\) = \\hslash /2,$$
](A272900_1_En_12_Chapter_IEq80.gif) we can arrange for Δ X ∕ Δ P to be any positive real number, and once we have chosen Δ X ∕ Δ P, we can then arrange for ![
$$\\left \\langle X\\right\\rangle$$
](A272900_1_En_12_Chapter_IEq81.gif) and ![
$$\\left \\langle P\\right\\rangle$$
](A272900_1_En_12_Chapter_IEq82.gif) to be any two real numbers. On the other hand, once Δ X ∕ Δ P and ![
$$\\left \\langle X\\right\\rangle$$
](A272900_1_En_12_Chapter_IEq83.gif) and ![
$$\\left \\langle P\\right\\rangle$$
](A272900_1_En_12_Chapter_IEq84.gif) have been specified, there is a unique quantum state with ![
$$\(\\Delta X\)\(\\Delta P\) = \\hslash /2.$$
](A272900_1_En_12_Chapter_IEq85.gif) In Figs. 12.1–12.3, we have plotted the real part of ![
$$\\psi_{\\delta,\\lambda}$$
](A272900_1_En_12_Chapter_IEq00105.gif) for several different values of the parameters, in a system of units for which ![
$$\\hslash = 1.$$
](A272900_1_En_12_Chapter_IEq86.gif)

Figure 12.1

Minimum uncertainty state with ![
$$\\left \\langle X\\right\\rangle = 1,$$
](A272900_1_En_12_Chapter_IEq68.gif) ![
$$\\left \\langle P\\right\\rangle = 0,$$
](A272900_1_En_12_Chapter_IEq69.gif) and ![
$$\\Delta X = 1/2.$$
](A272900_1_En_12_Chapter_IEq70.gif)

Figure 12.2

Minimum uncertainty state with ![
$$\\left \\langle X\\right\\rangle = 1,$$
](A272900_1_En_12_Chapter_IEq75.gif) ![
$$\\left \\langle P\\right\\rangle = 10,$$
](A272900_1_En_12_Chapter_IEq76.gif) and ![
$$\\Delta X = 1/2$$
](A272900_1_En_12_Chapter_IEq77.gif).

Figure 12.3

Minimum uncertainty state with ![
$$\\left \\langle X\\right\\rangle = 1,$$
](A272900_1_En_12_Chapter_IEq78.gif) ![
$$\\left \\langle P\\right\\rangle = 20,$$
](A272900_1_En_12_Chapter_IEq79.gif) and Δ X = 1.

Proof.

The equation ![
$$\(X + i\\delta P\)\\psi =\\lambda \\psi$$
](A272900_1_En_12_Chapter_IEq87.gif) amounts to

![
$$\\displaystyle{ x\\psi +\\delta \\hslash \\frac{d\\psi } {dx} =\\lambda \\psi \(x\), }$$
](A272900_1_En_12_Chapter_Equ30.gif)

(12.26)

where ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0105.gif) is assumed to be in the domain of P, so that the distributional derivative of ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0106.gif) is an L 2 function. If ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0107.gif) were smooth, then the unique solution to (12.26) would be the function ![
$$\\psi_{\\delta,\\lambda}$$
](A272900_1_En_12_Chapter_IEq0108.gif) given in the proposition, which is square-integrable if and only if δ > 0. Even (12.26) is only assumed to hold in the distribution sense, the argument in the proof of Proposition 9.29 (with ![
$${e}^{-x/\\hslash }\\psi \(x\)$$
](A272900_1_En_12_Chapter_IEq88.gif) replaced by ![
$$\\exp \[{\(x-\\lambda \)}^{2}/\(2\\delta \\hslash \)\]\\psi \(x\)$$
](A272900_1_En_12_Chapter_IEq89.gif)) shows that there are no additional solutions. The formulas for ![
$$\\left \\langle X\\right\\rangle,$$
](A272900_1_En_12_Chapter_IEq90.gif) ![
$$\\left \\langle P\\right\\rangle,$$
](A272900_1_En_12_Chapter_IEq91.gif) and Δ X ∕ Δ P can be computed either by tracing through the arguments in the proof of Theorem 12.7 or by direct calculation with the formula for ![
$$\\psi_{\\delta,\\lambda}$$
](A272900_1_En_12_Chapter_IEq0109.gif). ■

## 12.5 Exercises

1.

Let α be a positive real number. Show that the following "additive" version of the uncertainty principle holds for all unit vectors ![
$$\\psi \\in \\mathrm{ Dom}\(X\) \\cap \\mathrm{ Dom}\(P\)$$
](A272900_1_En_12_Chapter_IEq92.gif) :

![
$$\\displaystyle{\\alpha \\Delta _{\\psi }X + \\frac{1} {\\alpha } \\Delta _{\\psi }P \\geq \\sqrt{2\\hslash }.}$$
](A272900_1_En_12_Chapter_Equr.gif)

2.

In this exercise, we classify the simultaneous eigenvectors of the noncommuting operators ![
$$\\hat{J}_{1}$$
](A272900_1_En_12_Chapter_IEq93.gif) and ![
$$\\hat{J}_{2}.$$
](A272900_1_En_12_Chapter_IEq94.gif) Let ![
$$\\hat{J}_{1},$$
](A272900_1_En_12_Chapter_IEq95.gif) ![
$$\\hat{J}_{2},$$
](A272900_1_En_12_Chapter_IEq96.gif) and ![
$$\\hat{J}_{3}$$
](A272900_1_En_12_Chapter_IEq97.gif) denote the angular momentum operators on ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_12_Chapter_IEq98.gif) as defined in Sect.​ 3.​10. Suppose ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq00110.gif) is in the domain of any product ![
$$\\hat{J}_{j}\\hat{J}_{k}$$
](A272900_1_En_12_Chapter_IEq99.gif) of two angular momentum operators. (For example, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0110.gif) could be a Schwartz function.) Suppose also that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0120.gif) is an eigenvector for ![
$$\\hat{J}_{1}$$
](A272900_1_En_12_Chapter_IEq100.gif) and for ![
$$\\hat{J}_{2}$$
](A272900_1_En_12_Chapter_IEq101.gif) with eigenvalues α and β, respectively.

(a)

Using the commutation relations in Exercise 10 in Chap. 3, show that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0130.gif) is an eigenvector for ![
$$\\hat{J}_{3}$$
](A272900_1_En_12_Chapter_IEq102.gif) with eigenvalue 0.

(b)

Show that the eigenvalues α and β for ![
$$\\hat{J}_{1}$$
](A272900_1_En_12_Chapter_IEq103.gif) and ![
$$\\hat{J}_{2}$$
](A272900_1_En_12_Chapter_IEq104.gif) must be zero.

(c)

What type of function ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_12_Chapter_IEq105.gif) satisfies ![
$$\\hat{J}_{j}\\psi = 0$$
](A272900_1_En_12_Chapter_IEq106.gif) for j = 1, 2, 3?

3.

Given any unit vector ![
$$\\psi \\in \\mathrm{ Dom}\(X\) \\cap \\mathrm{ Dom}\(P\),$$
](A272900_1_En_12_Chapter_IEq107.gif) consider another vector ![
$${\\phi}$$
](A272900_1_En_12_Chapter_IEq212.gif) given by

![
$$\\displaystyle{\\phi \(x\) = {e}^{ibx/\\hslash }\\psi \(x - a\).}$$
](A272900_1_En_12_Chapter_Equs.gif)

Show that ![
$${\\phi}$$
](A272900_1_En_12_Chapter_IEq213.gif) is a unit vector belonging to ![
$$\\mathrm{Dom}\(X\) \\cap \\mathrm{ Dom}\(P\)$$
](A272900_1_En_12_Chapter_IEq108.gif) and that

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle X\\right\\rangle _{\\phi }& =& \\left \\langle X\\right\\rangle _{\\psi } + a {}\\\\ \\Delta _{\\phi }X& =& \\Delta _{\\psi }X {}\\\\ \\end{array}$$
](A272900_1_En_12_Chapter_Equ31.gif)

and

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle P\\right\\rangle _{\\phi }& =& \\left \\langle P\\right\\rangle _{\\psi } + b {}\\\\ \\Delta _{\\phi }P& =& \\Delta _{\\psi }P. {}\\\\ \\end{array}$$
](A272900_1_En_12_Chapter_Equ32.gif)

4.

We have seen that a unit vector ![
$$\\psi \\in \\mathrm{ Dom}\(X\) \\cap \\mathrm{ Dom}\(P\)$$
](A272900_1_En_12_Chapter_IEq109.gif) is a minimum uncertainty state [i.e., ![
$$\(\\Delta _{\\psi }X\)\(\\Delta _{\\psi }P\) = \\hslash /2$$
](A272900_1_En_12_Chapter_IEq110.gif)] if and only if there exists some δ > 0 such that ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0140.gif) is an eigenvector of the operator X \+ i δ P. In that case, ![
$$\\psi$$
](A272900_1_En_12_Chapter_IEq0150.gif) is also an eigenvector for any operator of the form c(X \+ i δ P), with c being a nonzero constant. Consider, then, some fixed δ > 0 and define an operator a by the formula

![
$$\\displaystyle{a = \\frac{\\frac{1} {\\delta } \(X + i\\delta P\)} {\\sqrt{2\\hslash /\\delta }}.}$$
](A272900_1_En_12_Chapter_Equt.gif)

Then a is just the annihilation operator, as defined in Chap.​ 11, for a harmonic oscillator with ![
$$m\\omega = 1/\\delta.$$
](A272900_1_En_12_Chapter_IEq111.gif) Thus, a and its adjoint a ∗ satisfy the relation [a, a ∗] = I, and we have the "chain" of eigenvectors ![
$$\\psi _{n} \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_12_Chapter_IEq112.gif) satisfying the properties listed in Theorem 11.2.

(a)

For any ![
$$\\lambda \\in \\mathbb{C},$$
](A272900_1_En_12_Chapter_IEq113.gif) find constants c n so that the vector

![
$$\\displaystyle{\\phi _{\\lambda } :=\\sum _{ n=0}^{\\infty }c_{ n}\\psi _{n}}$$
](A272900_1_En_12_Chapter_Equu.gif)

is an eigenvector for a with eigenvalue λ. Show that the resulting series converges in H.

(b)

Let ![
$${\\phi}$$
](A272900_1_En_12_Chapter_IEq214.gif) λ denote the eigenvector obtained in Part (a), normalized so that c 0 = 1. Show that

![
$$\\displaystyle{\\phi _{\\lambda } = {e}^{\\lambda {a}^{{\\ast}} }\\phi _{0},}$$
](A272900_1_En_12_Chapter_Equv.gif)

where the exponential is defined by

![
$$\\displaystyle{{e}^{\\lambda {a}^{{\\ast}} }\\phi _{0} =\\sum _{ n=0}^{\\infty }\\frac{{\\lambda }^{n}} {n!}{\({a}^{{\\ast}}\)}^{n}\\phi _{ 0}.}$$
](A272900_1_En_12_Chapter_Equw.gif)

with convergence in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_12_Chapter_IEq114.gif)

5.

Prove Theorem 12.8, following the outline of the proof of Theorem 12.7. Recall from Sect.​ 10.​2 that ![
$$B/\\hslash $$
](A272900_1_En_12_Chapter_IEq115.gif) is the infinitesimal generator of the one-parameter unitary group ![
$$U\(a\) := {e}^{iaB/\\hslash }.$$
](A272900_1_En_12_Chapter_IEq116.gif)

6.

If X and Y are bounded operators, we may define ad X (Y) = [X, Y ], where ![
$$\[X,Y \] = XY - Y X.$$
](A272900_1_En_12_Chapter_IEq117.gif) Thus, say, (ad X )3(Y) = [X, [X, [X, Y ]]]. It is not hard to show that for any bounded operators Y and X, we have

![
$$\\displaystyle\\begin{array}{rcl}{ e}^{X}Y {e}^{-X}& =& {e}^{\\mathrm{ad}_{X} }\(Y \) \\\\ & =& Y + \[X,Y \] + \\frac{\[X,\[X,Y \]\]} {2!} + \\frac{\[X,\[X,\[X,Y \]\]\]} {3!} + \\cdots \\,. {}\\end{array}$$
](A272900_1_En_12_Chapter_Equ33.gif)

(12.27)

(See Proposition 2.25 and Exercise 2.19 of [21].)

Suppose A and B are unbounded self-adjoint operators satisfying ![
$$\[A,B\] = i\\hslash I$$
](A272900_1_En_12_Chapter_IEq118.gif) on ![
$$\\mathrm{Dom}\(AB\) \\cap \\mathrm{ Dom}\(BA\).$$
](A272900_1_En_12_Chapter_IEq119.gif) Show that if we could apply (12.27) with ![
$$X = iaB/\\hslash $$
](A272900_1_En_12_Chapter_IEq120.gif) and Y = A (even though X and Y are unbounded), then A and B would satisfy (12.22).

7.

Let A be the operator in Sect. 12.2, and let B be the unique self-adjoint extension of the operator B in that section. Show that the operators ![
$$X = iaB/\\hslash $$
](A272900_1_En_12_Chapter_IEq121.gif) and Y = A do not satisfy (12.27).

Note: This result shows the hazards involved formally applying results for bounded operators to unbounded operators.

Hint: Show that the unitary operators ![
$$U\(a\) :=\\exp \(iaB/\\hslash \)$$
](A272900_1_En_12_Chapter_IEq122.gif) consist of "translation with wrap around," first on the eigenvectors of B and then on the whole Hilbert space.

References

[21].

B.C. Hall, Lie Groups, Lie Algebras, and Representations: An Elementary Introduction. Graduate Texts in Mathematics, vol. 222 (Springer, New York, 2003)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_13

© Springer Science+Business Media New York 2013

# 13. Quantization Schemes for Euclidean Space

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

One of the axioms of quantum mechanics states, "To each real-valued function f on the classical phase space there is associated a self-adjoint operator ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq01.gif) on the quantum Hilbert space." The attentive reader will note that we have not, up to this point, given a general procedure for constructing ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq02.gif) from f.If we call ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq03.gif) the quantization of f,then we have only discussed the quantizations of a few very special classical observables, such as position, momentum, and energy.

## 13.1 Ordering Ambiguities

One of the axioms of quantum mechanics states, "To each real-valued function f on the classical phase space there is associated a self-adjoint operator ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq1.gif) on the quantum Hilbert space." The attentive reader will note that we have not, up to this point, given a general procedure for constructing ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq2.gif) from f. If we call ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq3.gif) the quantization of f, then we have only discussed the quantizations of a few very special classical observables, such as position, momentum, and energy.

Let us now think about what would go into quantizing a (more-or-less) general observable. Let us consider for simplicity a particle moving in ![
$${\\mathbb{R}}^{1}$$
](A272900_1_En_13_Chapter_IEq4.gif) and let us assume that quantizations of x and p are the usual position and momentum operators X and P. What should the quantization of, say, xp be? Classically, xp and px are the same, but quantum mechanically, XP does not equal PX. Furthermore, neither XP nor PX is self-adjoint, because ![
$${\(XP\)}^{{\\ast}} = {P}^{{\\ast}}{X}^{{\\ast}} = PX,$$
](A272900_1_En_13_Chapter_IEq5.gif) and PX≠XP. In this case, then, a reasonable candidate for the quantization would be

![
$$\\displaystyle{\\widehat{xp} = \\frac{1} {2}\(XP + PX\).}$$
](A272900_1_En_13_Chapter_Equa.gif)

The significance of this simple example is that the failure of commutativity among quantum operators creates an ambiguity in the quantization process. It does not make sense to simply "replace x by X and p by P everywhere in the formula," since the ordering of position and momentum makes no difference on the classical side, but it does on the quantum side. Up to this point, we have not really had to confront this ambiguity, because of the special form of the observables we have quantized. The Hamiltonian, for example, is typically of the form H(x, p) = p 2 ∕ (2m) + V (x). Since each term contains only x or only p, it is natural to quantize H to ![
$$\\hat{H} = {P}^{2}/\(2m\) + V \(X\),$$
](A272900_1_En_13_Chapter_IEq6.gif) where V (X) may be defined by the functional calculus or simply as multiplication by V (x). In defining the angular momentum operators, we do encounter products of position and momentum, but never of the same component of position and momentum. For a particle in ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_13_Chapter_IEq7.gif) for example, we have, ![
$$J = x_{1}p_{2} - x_{2}p_{1}.$$
](A272900_1_En_13_Chapter_IEq8.gif) On the quantum side, X 1 commutes with P 2 and X 2 with P 2, and thus there is no ambiguity: ![
$$X_{1}P_{2} - X_{2}P_{1}$$
](A272900_1_En_13_Chapter_IEq9.gif) is the same as ![
$$P_{2}X_{1} - P_{1}X_{2}.$$
](A272900_1_En_13_Chapter_IEq10.gif)

When we turn to the quantization of a general observable, however, we must confront the ordering ambiguity directly. Groenewold's theorem (Sect. 13.4) suggests that there is no single "perfect" quantization scheme. Nevertheless, there is one that is generally acknowledged as having the best properties, the Weyl quantization, and we spend most of our time with that particular scheme. Other quantization schemes do also play a role in physics, however; Wick-ordered quantization, notably, plays an important role in quantum field theory. (In quantum field theory, the replacement of certain Weyl-quantized operators with their Wick-quantized counterparts is interpreted as a type of renormalization.)

## 13.2 Some Common Quantization Schemes

In this section, we consider several of the most commonly used quantization schemes. For simplicity, we limit our attention to systems with one degree of freedom and to classical observables that are polynomials in x and p. (We consider the Weyl quantization in greater generality in Sect. 13.3.) Furthermore, we resolve in this section not to worry about domain questions and simply to use ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq11.gif) as the domain for all of our operators. Thus, in this section, equality of operators means equality as maps of ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq12.gif) to itself. It should be noted that the operators of the sort we will be considering may very well fail to be essentially self-adjoint, even if they are symmetric. Section 9.​10 shows, for example, that the operator P 2 − cX 4, for c > 0, is not essentially self-adjoint on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\).$$
](A272900_1_En_13_Chapter_IEq13.gif) We follow the terminology of harmonic analysis by referring to a classical symbol f as the symbol of its quantization ![
$$\\hat{f}.$$
](A272900_1_En_13_Chapter_IEq14.gif) Once we have discussed each quantization scheme briefly, we will formalize the definitions of all the schemes in Definition 13.1.

The simplest approach to quantization is to choose, once and for all, which to put first, the position or the momentum operators. We may, for example, choose to put the momentum operators to the right, acting first, and the position operators to the left, acting second. In this approach, a polynomial in x and p will quantize to a differential operator in "standard form," with all the derivatives acting first, followed by multiplication operators. In harmonic analysis, there is a method for extending this quantization scheme to more-or-less arbitrary symbols, f. For a general (nonpolynomial) symbol f, the resulting operator ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq15.gif) is known as a pseudodifferential operator.

A serious drawback of the pseudodifferential quantization is that even when the symbol f is real-valued, the operator ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq16.gif) it produces is typically not self-adjoint (or even symmetric). If, for example, f(x, p) = xp, then the associated operator is XP, the adjoint of which is PX, which is not equal to XP. The simplest way to fix this problem is to symmetrize the operator by taking half the sum of the operator and its adjoint.

The Weyl quantization, meanwhile, takes more seriously the possibility of different orderings of X and P, by considering all possible orderings. Thus, in quantizing, say, x 2 p 2, the Weyl quantization will give

![
$$\\displaystyle{\\frac{1} {6}\({X}^{2}{P}^{2} + XPXP + X{P}^{2}X + P{X}^{2}P + PXPX + {P}^{2}{X}^{2}\).}$$
](A272900_1_En_13_Chapter_Equb.gif)

For a general monomial, the Weyl quantization similarly averages all the possible orderings of the position and momentum operators.

For Wick-ordered and anti-Wick-ordered quantization, we no longer regard the position and momentum operators as the "basic" operators, but rather the creation and annihilation operators. Specifically, given any positive real number α, we introduce complex coordinates on the classical phase space by

![
$$\\displaystyle\\begin{array}{rcl} z& =& x - i\\alpha p \\\\ \\bar{z}& =& x + i\\alpha p.{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ1.gif)

(13.1)

(Although it would seem more natural to define z to be x \+ i α p, this choice would lead to problems later, especially with the Segal–Bargmann transform.) We then consider the corresponding quantum operators, which we call the raising and lowering operators:

![
$$\\displaystyle\\begin{array}{rcl}{ a}^{{\\ast}}& =& X - i\\alpha P \\\\ a& =& X + i\\alpha P.{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ2.gif)

(13.2)

In comparing these operators to the ones defined in the context of the harmonic oscillator, we should think of α as corresponding to 1 ∕ (mω). Even with this identification, however, the operators in (13.2) differ by a constant from the raising and lowering operators of Chap.​ 11. [The overall normalization of the raising and lowering operators is not important in this context, provided that we are consistent in the normalization between (13.1) and (13.2).] In particular, the commutator of a and a ∗ is not I but rather ![
$$2\\alpha \\hslash I.$$
](A272900_1_En_13_Chapter_IEq17.gif)

In Wick-ordered quantization, we begin by expressing the classical observable f in terms of z and ![
$$\\bar{z}$$
](A272900_1_En_13_Chapter_IEq18.gif) rather than in terms of ![
$$x$$
](A272900_1_En_13_Chapter_IEq19.gif) and p. When we quantize, we put all the lowering operators (coming from the factors of ![
$$\\bar{z}$$
](A272900_1_En_13_Chapter_IEq20.gif) in f) to the right, acting first, and the raising operators (coming from the factors of z in f) to the left, acting second. This approach to quantization is useful in quantum field theory, where letting the lowering operators act first can cause certain otherwise ill-defined expressions to become well defined. In anti-Wick-ordered quantization, we do the reverse, putting the raising operators to the right, acting first. Although anti-Wick-ordered quantization seems singular in the context of quantum field theory, in systems with finitely many degrees of freedom, it is actually better behaved than Wick-ordered quantization.

Definition 13.1.

Define several different quantization schemes for symbols that are polynomials in x and p as follows. Each scheme is uniquely determined—as a map from polynomials on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_13_Chapter_IEq21.gif) into operators on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq22.gif)—by the indicated formulas.

1.

Pseudodifferential operator quantization:

![
$$\\displaystyle{Q\({x}^{j}{p}^{k}\) = {X}^{j}{P}^{k}.}$$
](A272900_1_En_13_Chapter_Equc.gif)

2.

Symmetrized pseudodifferential operator quantization:

![
$$\\displaystyle{Q\({x}^{j}{p}^{k}\) = \\frac{1} {2}\({X}^{j}{P}^{k} + {P}^{k}{X}^{j}\).}$$
](A272900_1_En_13_Chapter_Equd.gif)

3.

Weyl quantization:

![
$$\\displaystyle{Q\({x}^{j}{p}^{k}\) = \\frac{1} {\(j + k\)!}\\sum _{\\sigma \\in S_{j+k}}\\sigma \\left \(X,X,\\ldots,X,P,P,\\ldots,P\\right\),}$$
](A272900_1_En_13_Chapter_Eque.gif)

where for any operators ![
$$A_{1},A_{2},\\ldots,A_{n}$$
](A272900_1_En_13_Chapter_IEq23.gif) and any σ ∈ S n , we define

![
$$\\displaystyle{ \\sigma \(A_{1},A_{2},\\ldots,A_{n}\) = A_{\\sigma \(1\)}A_{\\sigma \(2\)}\\cdots A_{\\sigma \(n\)}. }$$
](A272900_1_En_13_Chapter_Equ3.gif)

(13.3)

4.

Wick-ordered quantization with parameter α:

![
$$\\displaystyle{Q\({\(x + i\\alpha p\)}^{j}{\(x - i\\alpha p\)}^{k}\) = {\(X - i\\alpha P\)}^{k}{\(X + i\\alpha P\)}^{j},\\quad \\alpha > 0.}$$
](A272900_1_En_13_Chapter_Equf.gif)

5.

Anti-Wick-ordered quantization with parameter α:

![
$$\\displaystyle{Q\({\(x + i\\alpha p\)}^{j}{\(x - i\\alpha p\)}^{k}\) = {\(X + i\\alpha P\)}^{j}{\(X - i\\alpha P\)}^{k},\\quad \\alpha > 0.}$$
](A272900_1_En_13_Chapter_Equg.gif)

In applications, the most useful quantization schemes are the Wick-ordered, anti-Wick-ordered, and Weyl schemes. All of the quantization schemes in Definition 13.1 except the pseudodifferential operator quantization have the property of mapping real-valued polynomials to symmetric operators on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\).$$
](A272900_1_En_13_Chapter_IEq24.gif) (See Exercise 3 in the case of the Wick- and anti-Wick-ordered quantizations.)

In comparing the different quantization schemes, it is important to recognize that two different expressions may describe the same operator. We may calculate, for example, that

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {2}\(X{P}^{2} + {P}^{2}X\)& =& \\frac{1} {2}\(PXP + \[X,P\]P + PXP - P\[X,P\]\) {}\\\\ & =& PXP, {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ4.gif)

since [X, P] is a multiple of the identity and thus commutes with P. As a result, we can eliminate the P X P term in the Weyl quantization of xp 2, with the result that

![
$$\\displaystyle{ Q_{\\mathrm{Weyl}}\(x{p}^{2}\) = \\frac{1} {3}\(X{P}^{2} + PXP + {P}^{2}X\) = \\frac{1} {2}\(X{P}^{2} + {P}^{2}X\), }$$
](A272900_1_En_13_Chapter_Equ5.gif)

(13.4)

which coincides, in this very special case, with the symmetrized pseudodifferential quantization of xp 2.

Example 13.2.

If f(x, p) = x 2, then the Weyl, Wick-ordered and anti-Wick-ordered quantizations of f are as follows:

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\({x}^{2}\)& =& {X}^{2} {}\\\\ Q_{\\mathrm{Wick}}\({x}^{2}\)& =& {X}^{2} -\\frac{1} {2}\\alpha \\hslash I {}\\\\ Q_{\\mathrm{anti-Wick}}\({x}^{2}\)& =& {X}^{2} + \\frac{1} {2}\\alpha \\hslash I. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ6.gif)

Proof.

The value for Q Weyl(x 2) is apparent. To compute the Wick- and anti-Wick-ordered quantizations, we first write x as ![
$$\(z +\\bar{ z}\)/2,$$
](A272900_1_En_13_Chapter_IEq25.gif) so that

![
$$\\displaystyle{{x}^{2} = \\frac{{\(z +\\bar{ z}\)}^{2}} {4} = \\frac{1} {4}\({z}^{2} + 2z\\bar{z} +\\bar{ {z}}^{2}\).}$$
](A272900_1_En_13_Chapter_Equh.gif)

Thus, we have, for example,

![
$$\\displaystyle{Q_{\\mathrm{Wick}}\({x}^{2}\) = \\frac{1} {4}\\left \({\(X - i\\alpha P\)}^{2} + 2\(X - i\\alpha P\)\(X + i\\alpha P\) + {\(X + i\\alpha P\)}^{2}\\right\).}$$
](A272900_1_En_13_Chapter_Equi.gif)

When we expand this expression out, the P 2 terms cancel, and the XP and PX terms from (X − iαP)2 will cancel with the XP and PX terms from (X \+ iαP)2. Thus, we will be left with X 2 terms and the XP and PX terms from the cross-term above:

![
$$\\displaystyle{Q_{\\mathrm{Wick}}\({x}^{2}\) = \\frac{1} {4}\\left \(4{X}^{2} + 2i\\alpha \[X,P\]\\right\).}$$
](A272900_1_En_13_Chapter_Equj.gif)

Using the commutation relation between X and P gives the desired result. The calculation of Q antiWick(x 2) is identical except that the order of the factors in the cross-term is reversed, which gives the opposite sign for the [X, P] term.

Proposition 13.3.

The Weyl quantization—viewed as a linear map of the space of polynomials on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_13_Chapter_IEq26.gif) into operators on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq27.gif) —is uniquely characterized by the following identity:

![
$$\\displaystyle{ Q_{\\mathrm{Weyl}}\({\(ax + bp\)}^{j}\) = {\(aX + bP\)}^{j} }$$
](A272900_1_En_13_Chapter_Equ7.gif)

(13.5)

for all non-negative integers j and all ![
$$a,b \\in \\mathbb{C}.$$
](A272900_1_En_13_Chapter_IEq28.gif)

Proof.

The Weyl quantization is easily seen to satisfy the identity

![
$$\\displaystyle\\begin{array}{rcl} & & Q_{\\mathrm{Weyl}}\(\(a_{1}x + b_{1}p\)\\cdots \(a_{j}x + b_{j}p\)\) \\\\ & =& \\frac{1} {j!}\\sum _{\\sigma \\in S_{j}}\\sigma \(a_{1}X + b_{1}P,\\ldots,a_{j}X + b_{j}P\),{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ8.gif)

(13.6)

for all sequences a 1,..., a j and b 1,..., b j of complex numbers, where the expression σ(⋅, ⋅,..., ⋅) is defined by (13.3). Specializing to the case where all the a j 's are equal to a and all the b j 's are equal to b gives (13.5). Conversely, suppose that Q is any linear map of polynomials into operators on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq29.gif) satisfying Q((ax \+ bp) j ) = (aX \+ bP) j for all a, b, and j. For each j, let V j denote the space of homogeneous polynomials f of degree j such that Q(f) = Q Weyl(f). Then V j contains all polynomials of the form (ax \+ bp) j , and thus, by Exercise 1, V j consists of all homogeneous polynomials of degree j, so that Q = Q Weyl.

Proposition 13.4.

The Weyl quantization satisfies

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(xg\)& =& Q_{\\mathrm{Weyl}}\(x\)Q_{\\mathrm{Weyl}}\(g\) -\\frac{i\\hslash } {2} Q_{\\mathrm{Weyl}}\\left \(\\frac{\\partial g} {\\partial p}\\right\){}\\end{array}$$
](A272900_1_En_13_Chapter_Equ9.gif)

(13.7)

![
$$\\displaystyle\\begin{array}{rcl} & =& Q_{\\mathrm{Weyl}}\(g\)Q_{\\mathrm{Weyl}}\(x\) + \\frac{i\\hslash } {2} Q_{\\mathrm{Weyl}}\\left \(\\frac{\\partial g} {\\partial p}\\right\){}\\end{array}$$
](A272900_1_En_13_Chapter_Equ10.gif)

(13.8)

and

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(pg\)& =& Q_{\\mathrm{Weyl}}\(p\)Q_{\\mathrm{Weyl}}\(g\) + \\frac{i\\hslash } {2} Q_{\\mathrm{Weyl}}\\left \(\\frac{\\partial g} {\\partial x}\\right\){}\\end{array}$$
](A272900_1_En_13_Chapter_Equ11.gif)

(13.9)

![
$$\\displaystyle\\begin{array}{rcl} & =& Q_{\\mathrm{Weyl}}\(g\)Q_{\\mathrm{Weyl}}\(p\) -\\frac{i\\hslash } {2} Q_{\\mathrm{Weyl}}\\left \(\\frac{\\partial g} {\\partial x}\\right\){}\\end{array}$$
](A272900_1_En_13_Chapter_Equ12.gif)

(13.10)

for all polynomials g in x and p.

It should be noted that the formulas for the Weyl quantization in Proposition 13.4 may not give the same "expression" for Q Weyl(f) as does Definition 13.1, but it does give the same operator. [Compare (13.4).]

Proof.

Suppose A = (a 1 X \+ b 1 P) and B = (a 2 X \+ b 2 P). Then [A, B] is a multiple of I, from which we can easily verify that

![
$$\\displaystyle{A{B}^{j} = {B}^{k}A{B}^{j-k} + k\[A,B\]{B}^{j-1},}$$
](A272900_1_En_13_Chapter_Equk.gif)

for 0 ≤ k ≤ j. If we sum this relation over k and divide by j \+ 1, we obtain

![
$$\\displaystyle{ A{B}^{j} = \\frac{1} {j + 1}\\sum _{k=0}^{j}{B}^{k}A{B}^{j-k} + \\frac{1} {j + 1} \\frac{j\(j + 1\)} {2} \[A,B\]{B}^{j-1}. }$$
](A272900_1_En_13_Chapter_Equ13.gif)

(13.11)

Now, A is the Weyl quantization of (a 1 X \+ b 1 p) and B j is the Weyl quantization of ![
$${\(a_{2}x + b_{2}p\)}^{j},$$
](A272900_1_En_13_Chapter_IEq30.gif) and both terms on the right-hand side of (13.11) are easily recognized as Weyl quantizations. Thus, after rearranging the terms and evaluating the commutator, (13.11) becomes,

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(\(a_{1}x + b_{1}p\){\(a_{2}x + b_{2}p\)}^{j}\) \\qquad \\quad \\quad \\,\\,\\, \\cr\\\\ = Q_{\\mathrm{Weyl}}\(a_{1}x + b_{1}p\)Q_{\\mathrm{Weyl}}\({\(a_{2}x + b_{2}p\)}^{j}\) \\,\\,\\,\\, \\cr\\\\ - i\\hslash \\frac{j} {2}\(a_{1}b_{2} - a_{2}b_{1}\)Q_{\\mathrm{Weyl}}\({\(a_{1}x + b_{1}p\)}^{j-1}\).{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ14.gif)

(13.12)

Meanwhile, if we run the same argument starting with B j A we obtain a similar result:

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(\(a_{1}x + b_{1}p\){\(a_{2}x + b_{2}p\)}^{j}\) \\qquad \\quad \\quad \\,\\,\\,\\cr\\\\ = Q_{\\mathrm{Weyl}}\({\(a_{2}x + b_{2}p\)}^{j}\)Q_{\\mathrm{ Weyl}}\(a_{1}x + b_{1}p\) \\,\\,\\,\\, \\cr\\\\ + i\\hslash \\frac{j} {2}\(a_{1}b_{2} - a_{2}b_{1}\)Q_{\\mathrm{Weyl}}\({\(a_{1}x + b_{1}p\)}^{j-1}\).{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ15.gif)

(13.13)

If we specialize to the case (a 1, b 1) = (1, 0) and (a 2, b 2) = (a, b), we get

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(x{\(ax + bp\)}^{j}\)& =& Q_{\\mathrm{ Weyl}}\(x\)Q_{\\mathrm{Weyl}}\({\(ax + bp\)}^{j}\) \\\\ & -& i\\hslash \\frac{j} {2}bQ_{\\mathrm{Weyl}}\({\(ax + bp\)}^{j-1}\),{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ16.gif)

(13.14)

where the last term on the right-hand side of (13.14) is ![
$$-i\\hslash /2$$
](A272900_1_En_13_Chapter_IEq31.gif) times the Weyl quantization of ∂(ax \+ bp) j ∕ ∂ p. Thus, (13.14) is precisely (13.7) in the case g(x, p) = (ax \+ bp) j . We can then see from Exercise 1 that (13.7) hold for all polynomials g. The proofs of (13.8), (13.9), and (13.10) are similar.

## 13.3 The Weyl Quantization for ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_13_Chapter_IEq32.gif)

In this section, we study the Weyl quantization on a much larger class of symbols (i.e., classical observables) than the polynomial symbols considered in the previous section. We also generalize from symbols defined on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_13_Chapter_IEq33.gif) to symbols defined on ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_13_Chapter_IEq34.gif)

### 13.3.1 Heuristics

It is a straightforward matter to extent the Weyl quantization on polynomials from ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_13_Chapter_IEq35.gif) to ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_13_Chapter_IEq36.gif) This extended quantization will satisfy

![
$$\\displaystyle{ Q_{\\mathrm{Weyl}}\({\(\\mathbf{a} \\cdot \\mathbf{p} + \\mathbf{b} \\cdot \\mathbf{p}\)}^{j}\) = {\(\\mathbf{a} \\cdot \\mathbf{X} + \\mathbf{b} \\cdot \\mathbf{P}\)}^{j} }$$
](A272900_1_En_13_Chapter_Equ17.gif)

(13.15)

for all ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_13_Chapter_IEq37.gif) and all non-negative integers j, as in Proposition 13.3 in the n = 1 case. Suppose we wish to extend Q Weyl to certain nonpolynomial symbols, starting with complex exponentials. If we multiply (13.15) by (i) j ∕ j! and sum on j, we would expect to have

![
$$\\displaystyle{ Q_{\\mathrm{Weyl}}\\left \({e}^{i\(\\mathbf{a}\\cdot \\mathbf{x}+\\mathbf{b}\\cdot \\mathbf{p}\)}\\right\) = {e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}. }$$
](A272900_1_En_13_Chapter_Equ18.gif)

(13.16)

Now, if f is any sufficiently nice function on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_13_Chapter_IEq38.gif) we can expand f as an integral involving functions of the form exp(i(a ⋅x \+ b ⋅p)), by using the Fourier transform:

![
$$\\displaystyle{f\(\\mathbf{x},\\mathbf{p}\) = {\(2\\pi \)}^{-n}\\int _{{ \\mathbb{R}}^{2n}}\\hat{f}\(\\mathbf{a},\\mathbf{b}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{x}+\\mathbf{b}\\cdot \\mathbf{p}\)}\\ d\\mathbf{a}\\ d\\mathbf{b},}$$
](A272900_1_En_13_Chapter_Equl.gif)

where ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq39.gif) is the Fourier transform of f. In light of (13.16), it is then natural to define

![
$$\\displaystyle{ Q_{\\mathrm{Weyl}}\(f\) = {\(2\\pi \)}^{-n}\\int _{{ \\mathbb{R}}^{2n}}\\hat{f}\(\\mathbf{a},\\mathbf{b}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}\\ d\\mathbf{a}\\ d\\mathbf{b}. }$$
](A272900_1_En_13_Chapter_Equ19.gif)

(13.17)

Before proceeding, let us pause for a moment to compute the operator exp(i(a ⋅X \+ b ⋅P)). If A and B are bounded operators that commute with their commutator (i.e., such that [A, [A, B]] = [B, [A, B]] = 0), then

![
$$\\displaystyle{ {e}^{A+B} = {e}^{-\[A,B\]/2}{e}^{A}{e}^{B}. }$$
](A272900_1_En_13_Chapter_Equ20.gif)

(13.18)

(See Theorem 14.1, which is proved in Sect.​ 3.​1 of [21]. Equation (13.18) is a special case of the Baker–Campbell–Hausdorff Formula.) If we formally apply (13.18) with A = i a ⋅X and B = i b ⋅P (even though these are unbounded operators), we obtain

![
$$\\displaystyle{ {e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P\)}} = {e}^{i\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2}{e}^{i\\mathbf{a}\\cdot \\mathbf{X}}{e}^{i\\mathbf{b}\\cdot \\mathbf{P}}. }$$
](A272900_1_En_13_Chapter_Equ21.gif)

(13.19)

Meanwhile, by Example 10.16 in Sect.​ 10.​2, we know that

![
$$\\displaystyle{\({e}^{i\\mathbf{b}\\cdot \\mathbf{P}}\\psi \)\(\\mathbf{x}\) =\\psi \(\\mathbf{x} + \\hslash \\mathbf{b}\).}$$
](A272900_1_En_13_Chapter_Equm.gif)

Thus, we may reasonably hope that

![
$$\\displaystyle{ \\left \({e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P\)}}\\psi \\right\)\(\\mathbf{x}\) = {e}^{i\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2}{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}\\psi \\left \(\\mathbf{x} + \\hslash \\mathbf{b}\\right\). }$$
](A272900_1_En_13_Chapter_Equ22.gif)

(13.20)

In general, we get incorrect results if we formally apply results for bounded operators to operators that are unbounded. In this case, however, the result of the formal calculation is correct. The simplest way to prove this is to replace a and b by t a and t b on the right-hand side of (13.19) and to check that the result is a strongly continuous one-parameter unitary group.

Proposition 13.5.

For all a and b in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_13_Chapter_IEq40.gif) the operators U a, b (t) on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq41.gif) given by

![
$$\\displaystyle{ \(U_{\\mathbf{a},\\mathbf{b}}\(t\)\\psi \)\(\\mathbf{x}\) = {e}^{i{t}^{2}\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2 }{e}^{it\\mathbf{a}\\cdot \\mathbf{x}}\\psi \\left \(\\mathbf{x} + t\\hslash \\mathbf{b}\\right\) }$$
](A272900_1_En_13_Chapter_Equ23.gif)

(13.21)

form a strongly continuous one-parameter unitary group. The infinitesimal generator of this group coincides with a ⋅ X + b ⋅ P on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq42.gif) and is essentially self-adjoint on this domain. Thus, if a ⋅ X + b ⋅ P denotes the unique self-adjoint extension of the infinitesimal generator on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq43.gif) it follows from Stone's theorem that

![
$$\\displaystyle{{e}^{it\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P\)}} = {e}^{i{t}^{2}\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2 }{e}^{it\\mathbf{a}\\cdot \\mathbf{X}}{e}^{it\\mathbf{b}\\cdot \\mathbf{P}}}$$
](A272900_1_En_13_Chapter_Equn.gif)

for all ![
$$t \\in \\mathbb{R}.$$
](A272900_1_En_13_Chapter_IEq44.gif) In particular, ( 13.19 ) and ( 13.20 ) hold.

Proof.

It is apparent that U a, b is unitary for each a and b, and it is a simple direct computation to show that it is indeed a unitary group. Strong continuity is proved in the usual way using a dense subspace, as in the proof of Example 10.12. When ![
$$\\psi$$
](A272900_1_En_13_Chapter_IEq001.gif) is in ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq45.gif) it is easy to differentiate the right-hand side of (13.21) with respect to t at t = 0 to obtain the formula for the infinitesimal generator. Finally, the essential self-adjointness of a ⋅X \+ b ⋅P on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq46.gif) is precisely the content of Proposition 9.40.

With the computation of the operator e i(a ⋅X \+ b ⋅P) in hand, we return to our analysis of the proposed formula (13.17) for the general Weyl quantization. If the Fourier transform of f is in ![
$${L}^{1}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_13_Chapter_IEq47.gif) we can regard the right-hand side of (13.17) as an absolutely convergent "Bochner" integral with values in the Banach space ![
$$\\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_13_Chapter_IEq48.gif) For our purposes, however, it is more convenient to think of operators on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq49.gif) as integral operators and to write down a formula for the integral kernel of Q Weyl(f) in terms of f itself. (But see Exercise 7.)

At a formal level, the operator mapping ![
$$\\psi$$
](A272900_1_En_13_Chapter_IEq002.gif) to ![
$${e}^{i\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2}{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}\\psi \\left \(\\mathbf{x} + \\hslash \\mathbf{b}\\right\)$$
](A272900_1_En_13_Chapter_IEq50.gif) may be thought of as an "integral" operator, with integral kernel given by

![
$$\\displaystyle{ {e}^{i\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2}{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}\\delta _{ n}\(\\mathbf{x} + \\hslash \\mathbf{b} -\\mathbf{y}\), }$$
](A272900_1_En_13_Chapter_Equ24.gif)

(13.22)

where δ n is an n-dimensional delta-function (the n-dimensional analog of the distribution in Example A.26). Thus, it should be possible to obtain the integral kernel of Q Weyl(f) by integrating the preceding expression against ![
$$\\hat{f}\(\\mathbf{a},\\mathbf{b}\).$$
](A272900_1_En_13_Chapter_IEq51.gif) To evaluate the resulting integral, we make the change of variable ![
$$\\mathbf{c} = \\hslash \\mathbf{b},$$
](A272900_1_En_13_Chapter_IEq52.gif) in which case we obtain

![
$$\\displaystyle\\begin{array}{rcl} & {\(2\\pi \\hslash \)}^{-n}\\int _{{ \\mathbb{R}}^{n}}\\int _{{\\mathbb{R}}^{n}}{e}^{i\(\\mathbf{a}\\cdot \\mathbf{\\beta }\)/2}{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}\\delta _{ n}\(\\mathbf{x} + \\mathbf{c} -\\mathbf{y}\)\\hat{f}\(\\mathbf{a},\\mathbf{c}/\\hslash \)\\ d\\mathbf{c}\\ d\\mathbf{a}\\quad\\quad\\cr\\\\ &= {\(2\\pi \\hslash \)}^{-n}\\int _{{ \\mathbb{R}}^{n}}{e}^{i\(\\mathbf{a}\\cdot \(\\mathbf{y}-\\mathbf{x}\)\)/2}{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}\\hat{f}\(\\mathbf{a},\(\\mathbf{y} -\\mathbf{x}\)/\\hslash \)\\ d\\mathbf{a}\\qquad\\quad \\quad\\quad\\cr\\\\& = {\\hslash }^{-n}{\(2\\pi \)}^{-n/2}\\left \[{\(2\\pi \)}^{-n/2}\\int _{{ \\mathbb{R}}^{n}}{e}^{i\\mathbf{a}\\cdot \(\\mathbf{x}+\\mathbf{y}\)\\mathbf{/2}}\\hat{f}\(\\mathbf{a},\(\\mathbf{y} -\\mathbf{x}\)/\\hslash \)\\ d\\mathbf{a}\\right\]\\mathbf{.}{}\\end{array}$$ 
](A272900_1_En_13_Chapter_Equ25.gif)

(13.23)

We may recognize the integral in square brackets in the last line of (13.23) as undoing the Fourier transform of f in the x-variable, leaving us with the partial Fourier transform of f in the p variable, evaluated at the points (x \+ y) ∕ 2, ![
$$\(\\mathbf{y} -\\mathbf{x}\)/\\hslash.$$
](A272900_1_En_13_Chapter_IEq53.gif) (The partial Fourier transform means the ordinary Fourier transform with respect to one of the variables, with the other variable fixed.) Thus, we expect that Q Weyl(f) should be the integral operator with integral kernel κ f given by

![
$$\\displaystyle{ \\kappa _{f}\(\\mathbf{x},\\mathbf{y}\) = {\(2\\pi \\hslash \)}^{-n}\\int _{{ \\mathbb{R}}^{n}}f\(\(\\mathbf{x} + \\mathbf{y}\)/2,\\mathbf{p}\){e}^{-i\(\\mathbf{y}-\\mathbf{x}\)\\cdot \\mathbf{p}/\\hslash }\\ d\\mathbf{p}. }$$
](A272900_1_En_13_Chapter_Equ26.gif)

(13.24)

### 13.3.2 The L 2 Theory

With the preceding calculations as motivation, we now define Q Weyl(f) to be the integral operator with kernel κ f , beginning with the case in which f belongs to ![
$${L}^{2}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_13_Chapter_IEq54.gif) The resulting operators will turn out to be Hilbert–Schmidt operators on ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_13_Chapter_IEq55.gif)

If H is a Hilbert space and ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_13_Chapter_IEq56.gif) is a non-negative self-adjoint operator on H, then it can be shown that A has a well-defined (but possibly infinite) trace. What this means is that the value of

![
$$\\displaystyle{\\mathrm{trace}\(A\) :=\\sum _{j}\\left \\langle e_{j},Ae_{j}\\right\\rangle }$$
](A272900_1_En_13_Chapter_Equo.gif)

is the same for each orthonormal basis {e j } of H. Note that since A is a non-negative operator, ![
$$\\left \\langle e_{j},Ae_{j}\\right\\rangle$$
](A272900_1_En_13_Chapter_IEq57.gif) is a non-negative real number, so that the sum is always defined, but may have the value + ∞.

Now, if A is any bounded operator, then A ∗ A is self-adjoint and non-negative. We say that A is Hilbert–Schmidt if

![
$$\\displaystyle{\\mathrm{trace}\({A}^{{\\ast}}A\) < \\infty.}$$
](A272900_1_En_13_Chapter_Equp.gif)

Given two Hilbert–Schmidt operators A and B, it can be shown that A ∗ B is a trace-class operator, meaning that the sum

![
$$\\displaystyle{\\mathrm{trace}\({A}^{{\\ast}}B\) :=\\sum _{ j=1}^{\\infty }\\left \\langle e_{ j},{A}^{{\\ast}}Be_{ j}\\right\\rangle }$$
](A272900_1_En_13_Chapter_Equq.gif)

is absolutely convergent and the value of the sum is independent of the choice of orthonormal basis. We define the Hilbert–Schmidt inner product of A and B and the associated Hilbert–Schmidt norm of A by

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle A,B\\right\\rangle _{\\mathrm{HS}}& :=& \\mathrm{trace}\({A}^{{\\ast}}B\) {}\\\\ \\left \\Vert A\\right\\Vert _{\\mathrm{HS}}& :=& \\sqrt{\\mathrm{trace }\({A}^{{\\ast} } A\)}. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ27.gif)

It can be shown that the space of Hilbert–Schmidt operators on H forms a Hilbert space with respect to the Hilbert–Schmidt inner product. (See Sect.​ 19.​2 for more details.) We denote the space of Hilbert–Schmidt operators on H by HS(H).

We will make use of the following standard (and elementary) result characterizing Hilbert–Schmidt operators on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq58.gif) in terms of integral operators. (See, for example, Theorem VI.23 in Volume I of [34].)

Proposition 13.6.

If κ is in ![
$${L}^{2}\({\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq59.gif) then for every ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq60.gif) the integral

![
$$\\displaystyle{ A_{\\kappa }\(\\psi \)\(\\mathbf{x}\) :=\\int _{{\\mathbb{R}}^{n}}\\kappa \(\\mathbf{x},\\mathbf{y}\)\\psi \(\\mathbf{y}\)\\ d\\mathbf{y} }$$
](A272900_1_En_13_Chapter_Equ28.gif)

(13.25)

is absolutely convergent for almost every ![
$$\\mathbf{x} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_13_Chapter_IEq61.gif) , and A κ (ψ) also belongs to ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_13_Chapter_IEq62.gif) Furthermore, the operator A κ is a Hilbert–Schmidt operator on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq63.gif) and

![
$$\\displaystyle{\\left \\Vert A_{\\kappa }\\right\\Vert _{\\mathrm{HS}} = \\left \\Vert \\kappa \\right\\Vert _{{L}^{2}\({\\mathbb{R}}^{n}\\times {\\mathbb{R}}^{n}\)}.}$$
](A272900_1_En_13_Chapter_Equr.gif)

Conversely, for any Hilbert–Schmidt operator A on ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq64.gif) there exists a unique ![
$$\\kappa \\in {L}^{2}\({\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq65.gif) such that A = A κ

We are now ready, using discussion in Sect. 13.3.1 as motivation, to define the Weyl quantization of L 2 symbols.

Definition 13.7.

For all ![
$$f \\in {L}^{2}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_13_Chapter_IEq66.gif) define ![
$$\\kappa _{f} : {\\mathbb{R}}^{2n} \\rightarrow \\mathbb{C}$$
](A272900_1_En_13_Chapter_IEq67.gif) by

![
$$\\displaystyle{ \\kappa _{f}\(\\mathbf{x},\\mathbf{y}\) = {\(2\\pi \\hslash \)}^{-n}\\int _{{ \\mathbb{R}}^{n}}f\(\(\\mathbf{x} + \\mathbf{y}\)/2,\\mathbf{p}\){e}^{-i\(\\mathbf{y}-\\mathbf{x}\)\\cdot \\mathbf{p}/\\hslash }\\ d\\mathbf{p}, }$$
](A272900_1_En_13_Chapter_Equ29.gif)

(13.26)

and define the Weyl quantization of f, as an operator on ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq68.gif) by

![
$$\\displaystyle{Q_{\\mathrm{Weyl}}\(f\) = A_{\\kappa _{f}},}$$
](A272900_1_En_13_Chapter_Equs.gif)

where ![
$$A_{\\kappa _{f}}$$
](A272900_1_En_13_Chapter_IEq69.gif) is defined by (13.25).

The integral in (13.26) is not necessarily absolutely convergent, and should be understood as computing a partial Fourier transform. Thus, we should, strictly speaking, replace the right-hand side of (13.26) with

![
$$\\displaystyle{ \\lim _{R\\rightarrow \\infty }\\ {\(2\\pi \\hslash \)}^{-n}\\int _{ \\left \\vert \\mathbf{p}\\right\\vert \\leq R}f\(\(\\mathbf{x} + \\mathbf{y}\)/2,\\mathbf{p}\){e}^{-i\(\\mathbf{y}-\\mathbf{x}\)\\cdot \\mathbf{p}/\\hslash }\\ d\\mathbf{p,} }$$
](A272900_1_En_13_Chapter_Equ30.gif)

(13.27)

where the limit is in the norm topology of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_13_Chapter_IEq70.gif) [The partial Fourier transform maps the Schwartz space ![
$$\\mathcal{S}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq71.gif) to itself. By Fubini's theorem and the Plancherel formula for ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_13_Chapter_IEq72.gif) the partial Fourier transform is an L 2-isometry and extends to a unitary map of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq73.gif) to itself. This unitary map can be computed by the usual formula on functions in ![
$${L}^{1} \\cap {L}^{2}$$
](A272900_1_En_13_Chapter_IEq74.gif) and can be computed by the limiting formula similar to (13.27) in general.]

In words, we may describe the procedure for computing κ f at a point (x 1, x 2) in ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_13_Chapter_IEq75.gif) as follows. First, compute the partial Fourier transform ![
$$\\mathcal{F}_{\\mathbf{p}}$$
](A272900_1_En_13_Chapter_IEq76.gif) of f(x, p) in the p-variable, resulting in the function ![
$$\(\\mathcal{F}_{\\mathbf{p}}f\)\(\\mathbf{x},\\mathbf{\\xi }\).$$
](A272900_1_En_13_Chapter_IEq77.gif) Then evaluate ![
$$\\mathcal{F}_{\\mathbf{p}}f$$
](A272900_1_En_13_Chapter_IEq78.gif) at the point x = (x 1 \+ x 2) ∕ 2, ![
$$\\mathbf{\\xi } = \({\\mathbf{x}}^{2} -{\\mathbf{x}}^{1}\)/\\hslash.$$
](A272900_1_En_13_Chapter_IEq79.gif) Finally, multiply the result by ![
$${\\hslash }^{-n}{\(2\\pi \)}^{-n/2}$$
](A272900_1_En_13_Chapter_IEq80.gif) to get

![
$$\\displaystyle{ \\kappa _{f}\({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\) = {\\hslash }^{-n}{\(2\\pi \)}^{-n/2}\(\\mathcal{F}_{\\mathbf{ p}}f\)\(\({\\mathbf{x}}^{1} +{ \\mathbf{x}}^{2}\)/2,\({\\mathbf{x}}^{2} -{\\mathbf{x}}^{1}\)/\\hslash \). }$$
](A272900_1_En_13_Chapter_Equ31.gif)

(13.28)

Theorem 13.8.

The map Q Weyl is a constant multiple of a unitary map of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq81.gif) onto ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\).$$
](A272900_1_En_13_Chapter_IEq82.gif) The inverse map ![
$$Q_{\\mathrm{Weyl}}^{-1} :\\mathrm{ HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq83.gif) is given by

![
$$\\displaystyle{Q_{\\mathrm{Weyl}}^{-1}\(A\)\(\\mathbf{x},\\mathbf{p}\) = {\\hslash }^{n}\\int _{{ \\mathbb{R}}^{n}}\\kappa \(\\mathbf{x} - \\hslash \\mathbf{b}/2,\\mathbf{x} + \\hslash \\mathbf{b}/2\){e}^{i\\mathbf{b}\\cdot \\mathbf{p}}\\ d\\mathbf{b},}$$
](A272900_1_En_13_Chapter_Equt.gif)

where κ is the integral kernel of A as in Proposition 13.6.

Furthermore, for all ![
$$f \\in {L}^{2}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_13_Chapter_IEq84.gif) we have ![
$$Q_{\\mathrm{Weyl}}\(\\bar{f}\) = Q_{\\mathrm{Weyl}}{\(f\)}^{{\\ast}}$$
](A272900_1_En_13_Chapter_IEq85.gif) ; in particular, Q Weyl (f) is self-adjoint if f is real valued.

Properly speaking, the integral in the theorem should be understood as an L 2 limit, as in (13.27). The fact that Q Weyl is unitary (up to a constant) tells us that for an appropriate constant c, the operators ce i(a ⋅X \+ b ⋅P) form an "orthonormal basis in the continuous sense" for the Hilbert space ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\).$$
](A272900_1_En_13_Chapter_IEq86.gif) (Compare Sect.​ 6.​6.​)

It is possible, using the same formulas, to extend the notion of Weyl quantization to symbols belonging the space of tempered distributions, that is, the space of continuous linear functionals on ![
$$\\mathcal{S}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_13_Chapter_IEq87.gif) We will not, however, develop this construction here. See [11] for more information.

Proof.

Proposition 13.6 gives a unitary identification of ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\)$$
](A272900_1_En_13_Chapter_IEq88.gif) with ![
$${L}^{2}\({\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n}\).$$
](A272900_1_En_13_Chapter_IEq89.gif) Thus, it suffices to show that the map f ↦ κ f is a multiple of a unitary map. This result holds because the partial Fourier transform is a unitary map of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq90.gif) to itself and composition with an invertible linear map is a constant multiple of a unitary map. The inverse of the map f ↦ κ f is obtained by inverting the linear map and undoing the partial Fourier transform. Finally, it is apparent from (13.26) that

![
$$\\displaystyle{\\kappa _{\\bar{f}}\(\\mathbf{x},\\mathbf{y}\) = \\overline{\\kappa _{f}\(\\mathbf{y},\\mathbf{x}\)}.}$$
](A272900_1_En_13_Chapter_Equu.gif)

This, along with Exercise 6, shows that ![
$$Q_{\\mathrm{Weyl}}\(\\bar{f}\) = Q_{\\mathrm{Weyl}}{\(f\)}^{{\\ast}}.$$
](A272900_1_En_13_Chapter_IEq91.gif)

### 13.3.3 The Composition Formula

If f and g are L 2 functions on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_13_Chapter_IEq92.gif) then Q Weyl(f) and Q Weyl(g) are Hilbert–Schmidt operators, in which case their product is again Hilbert–Schmidt. (Indeed, the product of a Hilbert–Schmidt operator and a bounded operator is always Hilbert–Schmidt.) Thus, since Q Weyl is a bijection of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq93.gif) with ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\),$$
](A272900_1_En_13_Chapter_IEq94.gif) there is a unique L 2 function, which we denote by f ⋆ g, such that

![
$$\\displaystyle{ Q_{\\mathrm{Weyl}}\(f\)Q_{\\mathrm{Weyl}}\(g\) = Q_{\\mathrm{Weyl}}\(f \\star g\). }$$
](A272900_1_En_13_Chapter_Equ32.gif)

(13.29)

(Of course, the operator ⋆ , like the Weyl quantization itself, depends on ![
$$\\hslash,$$
](A272900_1_En_13_Chapter_IEq95.gif) but we suppress this dependence in the notation.)

Proposition 13.9.

The Moyal product f ⋆ g may be characterized in terms of the Fourier transform as

![
$$\\displaystyle\\begin{array}{rcl} \\widehat{\(f \\star g\)}\(\\mathbf{a},\\mathbf{b}\)& =& {\(2\\pi \)}^{-n}\\iint {e}^{-i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 } {}\\\\ & \\times & \\hat{f}\(\\mathbf{a} -{\\mathbf{a}}^{{\\prime}},\\mathbf{b} -{\\mathbf{b}}^{{\\prime}}\)\\hat{g}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)\\ d{\\mathbf{a}}^{{\\prime}}\\ d{\\mathbf{b}}^{{\\prime}}, {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ33.gif)

where both integrals are over ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_13_Chapter_IEq96.gif)

Note that if we set ![
$$\\hslash = 0$$
](A272900_1_En_13_Chapter_IEq97.gif) in the above formula, ![
$$\\widehat{f \\star g}$$
](A272900_1_En_13_Chapter_IEq98.gif) reduces to (2π)− n times the convolution of ![
$$\\hat{f}$$
](A272900_1_En_13_Chapter_IEq99.gif) and ![
$$\\hat{g},$$
](A272900_1_En_13_Chapter_IEq100.gif) which is nothing but the Fourier transform of fg. It is thus not difficult to show (Exercise 10) that

![
$$\\displaystyle{\\lim _{\\hslash \\rightarrow {0}^{+}}f \\star g = fg.}$$
](A272900_1_En_13_Chapter_Equv.gif)

That is to say, the Moyal product f ⋆ g is a "deformation" of the ordinary pointwise product of functions on ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_13_Chapter_IEq101.gif) More generally, the Moyal product can be expanded in an asymptotic expansion in powers of ![
$$\\hslash,$$
](A272900_1_En_13_Chapter_IEq102.gif) as explained in Sect.​ 2.​3 of [11]. This expansion terminates in the case that f and g are both polynomials.

Proof.

It is, of course, possible to obtain this formula using kernel functions. It is, however, easier to work with the (13.17), which can be shown (Exercise 7) to give the same result as Definition 13.7 when f is a Schwartz function. We assume standard properties of the Bochner integral for functions with values in a Banach space [in our case, ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_13_Chapter_IEq103.gif)], which are similar to those of the Lebesgue integral. (See, for example, Sect. V.5 of [46].)

We have, then,

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(f\)Q_{\\mathrm{Weyl}}\(g\)& =& {\(2\\pi \)}^{-n}\\iint \\hat{f}\(\\mathbf{a},\\mathbf{b}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}\\ d\\mathbf{a}\\ d\\mathbf{b} \\\\ & \\times & {\(2\\pi \)}^{-n}\\iint \\hat{g}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\){e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{X}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{P}\) }\\ d{\\mathbf{a}}^{{\\prime}}\\ d{\\mathbf{b}}^{{\\prime}}.{}\\end{array}$$
](A272900_1_En_13_Chapter_Equ34.gif)

(13.30)

Now, it is an easy calculation to verify, using Proposition 13.5, that

![
$$\\displaystyle{ {e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{X}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{P}\) } = {e}^{\\mathbf{-}i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }{e}^{i\(\(\\mathbf{a}+{\\mathbf{a}}^{{\\prime}}\)\\cdot \\mathbf{X}+\(\\mathbf{b}+{\\mathbf{b}}^{{\\prime}}\)\\cdot \\mathbf{P\)} }, }$$
](A272900_1_En_13_Chapter_Equ35.gif)

(13.31)

which is what one obtains by formally applying the special case of the Baker–Campbell–Hausdorff formula in (13.18). Thus, we may combine the integrals in (13.30) to obtain

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(f\)Q_{\\mathrm{Weyl}}\(g\)& =& {\(2\\pi \)}^{-2n}\\mathop{\\iint \\iint }\\nolimits {e}^{-i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }{e}^{i\(\(\\mathbf{a}+{\\mathbf{a}}^{{\\prime}}\)\\cdot \\mathbf{X}+\(\\mathbf{b}+{\\mathbf{b}}^{{\\prime}}\)\\cdot \\mathbf{P\)} } {}\\\\ & \\times & \\hat{f}\(\\mathbf{a},\\mathbf{b}\)\\hat{g}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)\\ d\\mathbf{a}\\ d\\mathbf{b}\\ d{\\mathbf{a}}^{{\\prime}}\\ d{\\mathbf{b}}^{{\\prime}}. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ36.gif)

By introducing new variables c = a \+ a ′ and d = b \+ b ′ in the a and b integrals and reversing the order of integration, we obtain, after simplifying the exponent,

![
$$\\displaystyle\\begin{array}{rcl} & Q_{\\mathrm{Weyl}}\(f\)Q_{\\mathrm{Weyl}}\(g\) {}\\cr\\\\ & \\qquad \\qquad \\qquad \\qquad \\quad = {\(2\\pi \)}^{-n}\\iint \[{\(2\\pi \)}^{-n}\\iint {e}^{-i\\hslash \(\\mathbf{c}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{d}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 } {}\\cr\\\\ & \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\qquad \\quad \\times \\hat{f}\(\\mathbf{c} -{\\mathbf{a}}^{{\\prime}},\\mathbf{d} -{\\mathbf{b}}^{{\\prime}}\)\\hat{g}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)\\ d{\\mathbf{a}}^{{\\prime}}\\ d{\\mathbf{b}}^{{\\prime}}\]\\ {e}^{i\(\\mathbf{c}\\cdot \\mathbf{X}+\\mathbf{d}\\cdot \\mathbf{P\)}}\\ d\\mathbf{c}\\ d\\mathbf{d}. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ37.gif)

From this and (13.17), we see that Q Weyl(f)Q Weyl(g) is the Weyl quantization of the function whose Fourier transform is the quantity in square brackets above, which is what we wanted to show.

Proposition 13.10.

The Moyal product f ⋆ g extends to a continuous map of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\) \\times {L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq104.gif) into ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq105.gif) and the composition formula ( 13.29 ) holds for all f and g in ![
$${L}^{2}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_13_Chapter_IEq106.gif)

Proof.

A standard inequality asserts that for any two Hilbert–Schmidt operators A and B, we have

![
$$\\displaystyle{\\left \\Vert AB\\right\\Vert _{\\mathrm{HS}} \\leq \\left \\Vert A\\right\\Vert _{\\mathrm{HS}}\\left \\Vert B\\right\\Vert _{\\mathrm{HS}}.}$$
](A272900_1_En_13_Chapter_Equw.gif)

It follows that the product map (A, B) ↦ AB is a continuous map of ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\) \\times \\mathrm{ HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\)$$
](A272900_1_En_13_Chapter_IEq107.gif) to ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\).$$
](A272900_1_En_13_Chapter_IEq108.gif) Meanwhile, the Weyl quantization is a constant multiple of a unitary map from ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq109.gif) to ![
$$\\mathrm{HS}\({L}^{2}\({\\mathbb{R}}^{n}\)\).$$
](A272900_1_En_13_Chapter_IEq110.gif) For Schwartz functions f and g, the Moyal product is nothing but

![
$$\\displaystyle{ f \\star g = Q_{\\mathrm{Weyl}}^{-1}\(Q_{\\mathrm{ Weyl}}\(f\)Q_{\\mathrm{Weyl}}\(g\)\). }$$
](A272900_1_En_13_Chapter_Equ38.gif)

(13.32)

The right-hand side of (13.32) provides the desired continuous extension of f ⋆ g. Clearly, the composition formula (13.29) holds for this extension.

### 13.3.4 Commutation Relations

In quantum mechanics, the commutator of two operators (divided by ![
$$i\\hslash $$
](A272900_1_En_13_Chapter_IEq111.gif)) plays a role similar to that of the Poisson bracket in classical mechanics. Thus, we may naturally ask: To what extent does the Weyl quantization (or any other quantization scheme) map Poisson brackets to commutators? The short answer is: Not always. Indeed, as we will see in Sect. 13.4, no "reasonable" quantization scheme can give an exact correspondence between {f, g} on the classical side and ![
$$\[A,B\]/\(i\\hslash \)$$
](A272900_1_En_13_Chapter_IEq112.gif) on the quantum side. Nevertheless, such an exact correspondence does hold for various special classes of symbols. If we consider, for example, the class of symbols that depend only on x and not on p, then on the classical side, all such functions Poisson commute. The Weyl quantization maps such functions f(x) to the operator of multiplication by f(x), and thus the quantizations of any two such functions commute. A more interesting (in particular, noncommutative) example is as follows.

Proposition 13.11.

Suppose f is a polynomial in x and p of degree at most 2 and g is an arbitrary polynomial in x and p . Then

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\\left \[Q_{\\mathrm{Weyl}}\(f\),Q_{\\mathrm{Weyl}}\(g\)\\right\] = Q_{\\mathrm{Weyl}}\(\\{f,g\\}\), }$$
](A272900_1_En_13_Chapter_Equ39.gif)

(13.33)

where {f,g} is the Poisson bracket of f and g.

Here, we define the Weyl quantization by the obvious n-variable extension of Definition 13.1, and we regard all operators as operating simply on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_13_Chapter_IEq113.gif) See Exercise 8 for another class of symbols on which (13.33) holds. Although the requirement that g be a polynomial can be relaxed, we will not attempt to obtain the optimal version of the result.

Proof.

For notational simplicity, we abbreviate Q Weyl(f) to Q(f) for the duration of the proof. If f has degree zero, then both sides of the desired equality are zero. Turning to case in which f has degree 1, we use the n-variable extension of Proposition 13.4, the proof of which is essentially the same as the 1-variable result. The result is as follows:

![
$$\\displaystyle\\begin{array}{rcl} Q\(x_{j}g\)& =& Q\(x_{j}\)Q\(g\) -\\frac{i\\hslash } {2} Q\\left \( \\frac{\\partial g} {\\partial p_{j}}\\right\) {}\\\\ & =& Q\(g\)Q\(x_{j}\) + \\frac{i\\hslash } {2} Q\\left \( \\frac{\\partial g} {\\partial p_{j}}\\right\). {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ40.gif)

By subtracting these two formulas and rearranging, we get

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[Q\(x_{j}\),Q\(g\)\] = Q\\left \( \\frac{\\partial g} {\\partial p_{j}}\\right\) = Q\(\\{x_{j},g\\}\).}$$
](A272900_1_En_13_Chapter_Equx.gif)

A very similar argument establishes the desired result when f = p j and thus for all homogeneous polynomials of degree 1.

Suppose now that f 1 and f 2 are homogeneous polynomials of degree 1 in x and p. Then it follows easily from Proposition 13.4 that for any polynomial h, we have

![
$$\\displaystyle{ Q\(f_{j}h\) = \\frac{1} {2}\(Q\(f_{j}\)Q\(h\) + Q\(h\)Q\(f_{j}\)\),\\quad j = 1,2. }$$
](A272900_1_En_13_Chapter_Equ41.gif)

(13.34)

In particular, we have

![
$$\\displaystyle{ Q\(f_{1}f_{2}\) = \\frac{1} {2}\(Q\(f_{1}\)Q\(f_{2}\) + Q\(f_{2}\)Q\(f_{1}\)\). }$$
](A272900_1_En_13_Chapter_Equ42.gif)

(13.35)

Using (13.35) and the product rule for commutators (Proposition 3.15), we have

![
$$\\displaystyle\\begin{array}{rcl} & \\frac{1} {i\\hslash }\[Q\(f_{1}f_{2}\),Q\(g\)\] {}\\cr\\\\ &\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad \\quad= \\frac{1} {2i\\hslash }\(\[Q\(f_{1}\),Q\(g\)\]Q\(f_{2}\) + Q\(f_{1}\)\[Q\(f_{2}\),Q\(g\)\] {}\\cr\\\\ & \\qquad\\qquad\\qquad\\qquad\\qquad\\quad\\,\\,\\,\\,+ \[Q\(f_{2}\),Q\(g\)\]Q\(f_{1}\) + Q\(f_{2}\)\[Q\(f_{1}\),Q\(g\)\]\). {}\\\\ \\end{array}$$ 
](A272900_1_En_13_Chapter_Equ43.gif)

Using the degree-1 case of the result we are trying to prove, along with (13.34), we get

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {i\\hslash }\[Q\(f_{1}f_{2}\),Q\(g\)\]& =& \\frac{1} {2}\(Q\(\\{f_{1},g\\}\)Q\(f_{2}\) + Q\(f_{1}\)Q\(\\{f_{2},g\\}\) \\\\ & +& Q\(\\{f_{2},g\\}\)Q\(f_{1}\) + Q\(f_{2}\)Q\(\\{f_{1},g\\}\)\) \\\\ & =& Q\(f_{2}\\{f_{1},g\\}\) + Q\(f_{1}\\{f_{2},g\\}\) \\\\ & =& Q\(\\{f_{1}f_{2},g\\}\), {}\\end{array}$$
](A272900_1_En_13_Chapter_Equ44.gif)

(13.36)

where in the last equality we have used the product rule for the Poisson bracket. We have now established the desired result when f is a homogeneous polynomial of degree 0, 1, or 2.

At first glance, it appears that one could extend the result to the case where f has degree 3, by considering three homogenous polynomials f 1, f 2, and f 3 of degree 1 and symmetrizing as in (13.35). The argument breaks down, however, because the Q(f j )'s do not commute. The Q(f j )'s will not always occur in the correct order to allow us to pull the f j 's back inside the Weyl quantization, the way we did in (13.36) in the degree-2 case. Indeed, an elementary but tedious calculations shows that

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[Q_{\\mathrm{Weyl}}\({x}^{2}p\),Q_{\\mathrm{ Weyl}}\(x{p}^{2}\)\] = 3{X}^{2}{P}^{2} - 6i\\hslash XP - {\\hslash }^{2}I,}$$
](A272900_1_En_13_Chapter_Equy.gif)

whereas

![
$$\\displaystyle{Q_{\\mathrm{Weyl}}\(\\{{x}^{2}p,x{p}^{2}\\}\) = 3{X}^{2}{P}^{2} - 6i\\hslash XP -\\frac{3} {2}{\\hslash }^{2}I,}$$
](A272900_1_En_13_Chapter_Equz.gif)

so that the two expressions differ by ![
$${\\hslash }^{2}I/2.$$
](A272900_1_En_13_Chapter_IEq114.gif)

We conclude this section with a brief glimpse of an important "equivariance" property of the Weyl quantization. Note that the Poisson bracket of two real valued homogeneous polynomials of degree 2 is again real valued and homogeneous of degree 2. The space of real homogeneous polynomials of degree 2 thus forms a Lie algebra (Sect.​ 16.​3) with respect to the Poisson bracket. This Lie algebra is naturally isomorphic to the Lie algebra ![
$$\\mathsf{sp}\(n; \\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq115.gif) of Lie group ![
$$\\mathsf{Sp}\(n; \\mathbb{R}\),$$
](A272900_1_En_13_Chapter_IEq116.gif) the real symplectic group. This group is the group of invertible linear transformations that preserve a skew-symmetric form on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_13_Chapter_IEq117.gif). See Chap.​ 16 for information about Lie groups and their Lie algebras.

If we apply Proposition 13.11 in the case in which both f and g are homogeneous of degree 2, we see that the map π(f) : = Q Weyl(f) is a representation of ![
$$\\mathsf{sp}\(n; \\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq118.gif) in the space of skew-symmetric operators on ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_13_Chapter_IEq119.gif) It can be shown that associated to this representation of ![
$$\\mathsf{sp}\(n; \\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq120.gif) there is a projective unitary representation Π of the group ![
$$\\mathsf{Sp}\(n; \\mathbb{R}\),$$
](A272900_1_En_13_Chapter_IEq121.gif) known as the metaplectic representation. (See, again, Chap.​ 16 for definitions.) Proposition 13.11 is the infinitesimal version of the following equivariance property of the Weyl quantization: For all ![
$$A \\in \\mathsf{Sp}\(n; \\mathbb{R}\)$$
](A272900_1_En_13_Chapter_IEq122.gif) and all ![
$$f \\in {L}^{2}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_13_Chapter_IEq123.gif) we have

![
$$\\displaystyle{Q_{\\mathrm{Weyl}}\(f \\circ {A}^{-1}\) = \\Pi \(A\)Q_{\\mathrm{ Weyl}}\(f\)\\Pi {\(A\)}^{-1}.}$$
](A272900_1_En_13_Chapter_Equaa.gif)

See Theorem 2.15 and Chap.​ 4 of [11] [where our Π(A) corresponds to μ((A ∗)− 1) in Folland's notation] for this result and much more about the metaplectic representation.

## 13.4 The "No Go" Theorem of Groenewold

In Sect. 13.3.4, we noted that the Weyl quantization on polynomials satisfies

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[Q_{\\mathrm{Weyl}}\(f\),Q_{\\mathrm{Weyl}}\(g\)\] = Q_{\\mathrm{Weyl}}\(\\{f,g\\}\), }$$
](A272900_1_En_13_Chapter_Equ45.gif)

(13.37)

provided that f is a polynomial of degree 2, but not in general. One might think that the failure of (13.37) represents a shortcoming in the definition of the Weyl quantization, which could be remedied by an alternative definition. In this section, however, we will see that no quantization scheme that maps x j and p j to the usual position and momentum operators X j and P j can satisfy (13.37) for general polynomials in x and p. This sort of nonexistence result, of a construct satisfying seemingly natural and desirable conditions, is referred to in the physics literature as a "no go" theorem.

In light of this result, one might think that perhaps the position and momentum operators should be defined differently, possibly with an accompanying change in the choice of the quantum Hilbert space. Indeed, there is a map Q that satisfies (13.37) for all f and g, namely the prequantization map described in Sect.​ 23.​3.​ The prequantization map accomplishes this feat by drastically enlarging the quantum Hilbert space, from ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq124.gif) to ![
$${L}^{2}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_13_Chapter_IEq125.gif) The Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq126.gif) is considered to be "too big" from a physical standpoint, which explains why the map Q is only "prequantization" rather than "quantization." (The prequantization map has a number of other undesirable features that are described in Sect.​ 23.​3.​) If one imposes a natural "smallness" assumption on the quantum Hilbert space (irreducibility under the action of the position and momentum operators), then the Stone–von Neumann theorem will tell us that (modulo certain technical domain assumptions) any choice of position and momentum operators satisfying the canonical commutation relations is unitarily equivalent to the usual ones.

The upshot of the discussion in the two preceding paragraphs is that there is no physically reasonable quantization scheme that satisfies (13.37) for all (polynomial) functions f and g.

We turn, now, to Groenewold's "no go" theorem. We need to make domain assumptions, so that it makes sense to compute the commutators of the quantized operators. The simplest approach is to assume that the quantization Q(f) of any polynomial f will be in the algebra generated by the X's and P's, and thus that Q(f) will be a differential operator with polynomial coefficients. There is a variant of this result, known as van Hove's theorem, that proves a similar "no go" result under a more general assumption about the form of the quantized operators. See [15] for a rigorous proof of van Hove's theorem.

Definition 13.12.

For any k ≥ 0, let ![
$$\\mathcal{P}_{k}$$
](A272900_1_En_13_Chapter_IEq127.gif) denote the space of homogeneous polynomials of degree k and let ![
$$\\mathcal{P}_{\\leq k}$$
](A272900_1_En_13_Chapter_IEq128.gif) denote the space of all polynomials of degree at most k.

Theorem 13.13 (Groenewold's Theorem).

Let ![
$$\\mathcal{D}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq129.gif) denote the space of differential operators on ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_13_Chapter_IEq130.gif) with polynomial coefficients. There does not exist a linear map ![
$$Q : \\mathcal{P}_{\\leq 4} \\rightarrow $$
](A272900_1_En_13_Chapter_IEq131.gif) ![
$$\\mathcal{D}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq132.gif) with the following properties.

1.

Q(1) = I.

2.

Q(x j ) = X j and Q(p j ) = P j

3.

For all f and g in ![
$$\\mathcal{P}_{\\leq 3},$$
](A272900_1_En_13_Chapter_IEq133.gif) we have

![
$$\\displaystyle{ Q\(\\{f,g\\}\) = \\frac{1} {i\\hslash }\[Q\(f\),Q\(g\)\]. }$$
](A272900_1_En_13_Chapter_Equ46.gif)

(13.38)

Note that in Property 3 of the theorem, we assume that f and g belong to ![
$$\\mathcal{P}_{\\leq 3}$$
](A272900_1_En_13_Chapter_IEq134.gif) rather than ![
$$\\mathcal{P}_{\\leq 4}.$$
](A272900_1_En_13_Chapter_IEq135.gif) This assumption guarantees that {f, g} belongs to ![
$$\\mathcal{P}_{\\leq 4}$$
](A272900_1_En_13_Chapter_IEq136.gif), so that the left-hand side of (13.38) is defined.

Our strategy in proving Groenewold's theorem is the following. We know (Proposition 13.11) that the Weyl quantization satisfies (13.38) if f has degree at most 2 and g has degree at most 3. Using this result, we can show that any map Q satisfying the properties in Theorem 13.13 must coincide with the Weyl quantization on ![
$$\\mathcal{P}_{\\leq 3}.$$
](A272900_1_En_13_Chapter_IEq137.gif) We then identify a polynomial ![
$$f \\in \\mathcal{P}_{4}$$
](A272900_1_En_13_Chapter_IEq138.gif) that can be expressed as a Poisson bracket in two different ways, f = { g, h} = { g ′ , h ′ }, with g, h, g ′ , and h ′ in ![
$$\\mathcal{P}_{3}.$$
](A272900_1_En_13_Chapter_IEq139.gif) Upon calculating that [Q Weyl(g), Q Weyl(h)] does not coincide with ![
$$\[Q_{\\mathrm{Weyl}}\({g}^{{\\prime}}\),Q_{\\mathrm{Weyl}}\({h}^{{\\prime}}\)\],$$
](A272900_1_En_13_Chapter_IEq140.gif) we will have a contradiction.

The proof will consist of several lemmas, followed by the coup de grâce.

Lemma 13.14.

Consider an element A of ![
$$\\mathcal{D}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq141.gif) expressed as

![
$$\\displaystyle{A =\\sum _{\\mathbf{k}}f_{\\mathbf{k}}\(\\mathbf{x}\){\\left \( \\frac{\\partial } {\\partial \\mathbf{x}}\\right\)}^{\\mathbf{k}},}$$
](A272900_1_En_13_Chapter_Equab.gif)

where k ranges over multi-indices, where the f k 's are polynomials, and where only finitely many of the f k 's are nonzero. Then A is the zero operator on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq142.gif) only if each of the f k 's is zero.

Proof.

For each multi-index k, let ![
$$\\left \\vert \\mathbf{k}\\right\\vert = k_{1} + \\cdots + k_{n}.$$
](A272900_1_En_13_Chapter_IEq143.gif) Suppose not all the f k 's are zero, let N be the smallest non-negative integer for which f k is nonzero for some k with ![
$$\\left \\vert \\mathbf{k}\\right\\vert = N,$$
](A272900_1_En_13_Chapter_IEq144.gif) and let k 0 be some multi-index with ![
$$\\left \\vert \\mathbf{k}_{0}\\right\\vert = N$$
](A272900_1_En_13_Chapter_IEq145.gif) and ![
$$f_{\\mathbf{k}_{0}}\\neq 0.$$
](A272900_1_En_13_Chapter_IEq146.gif) Let us apply A to a function g that is equal, in a neighborhood of the origin, to ![
$${\\mathbf{x}}^{\\mathbf{k}_{0}}.$$
](A272900_1_En_13_Chapter_IEq147.gif) Then all the terms in Ag other than the ![
$$f_{\\mathbf{k}_{0}}$$
](A272900_1_En_13_Chapter_IEq0147.gif) term will be zero in a neighborhood of the origin, whereas the ![
$$f_{\\mathbf{k}_{0}}$$
](A272900_1_En_13_Chapter_IEq148.gif) term will be a nonzero constant in a neighborhood of the origin. Thus, A is not the zero operator.

Lemma 13.15.

If A belongs to ![
$$\\mathcal{D}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq149.gif) and A commutes with X j and P j for all j = 1,...,n, then A = cI for some ![
$$c \\in \\mathbb{C}.$$
](A272900_1_En_13_Chapter_IEq150.gif)

Proof.

We may easily prove by induction that

![
$$\\displaystyle{{\\left \( \\frac{\\partial } {\\partial x_{j}}\\right\)}^{k}\(x_{ j}g\(\\mathbf{x}\)\) = k{\\left \( \\frac{\\partial } {\\partial x_{j}}\\right\)}^{k-1}g\(\\mathbf{x}\) + x_{ j}{\\left \( \\frac{\\partial } {\\partial x_{j}}\\right\)}^{k}g\(\\mathbf{x}\)}$$
](A272900_1_En_13_Chapter_Equac.gif)

for any polynomial g. Thus, for any multi-index k, we have

![
$$\\displaystyle{ \\left \[f\(\\mathbf{x}\){\\left \( \\frac{\\partial } {\\partial \\mathbf{x}}\\right\)}^{\\mathbf{k}},X_{ j}\\right\] = k_{j}f\(\\mathbf{x}\){\\left \( \\frac{\\partial } {\\partial \\mathbf{x}}\\right\)}^{\\mathbf{k}-\\mathbf{e}_{j} }. }$$
](A272900_1_En_13_Chapter_Equ47.gif)

(13.39)

Suppose A is a nonzero element of ![
$$\\mathcal{D}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq151.gif) that commutes with each X j . If deg(A) = M, consider a nonzero term in A of degree M:

![
$$\\displaystyle{f_{\\mathbf{k}_{0}}\(\\mathbf{x}\){\\left \( \\frac{\\partial } {\\partial \\mathbf{x}}\\right\)}^{\\mathbf{k}_{0} },\\quad \\left \\vert \\mathbf{k}_{0}\\right\\vert = M,\\ f_{\\mathbf{k}_{0}}\\neq 0.}$$
](A272900_1_En_13_Chapter_Equad.gif)

If M > 0, we can pick some j such that the jth entry of k 0 is nonzero. By (13.39) and our assumption on A, we have

![
$$\\displaystyle{0 = \[A,X_{j}\] = \(\\mathbf{k}_{0}\)_{j}f_{\\mathbf{k}_{0}}\(\\mathbf{x}\){\\left \( \\frac{\\partial } {\\partial \\mathbf{x}}\\right\)}^{\\mathbf{k}_{0} -\\mathbf{e}_{j} } + \\text{ other terms,}}$$
](A272900_1_En_13_Chapter_Equae.gif)

where the other terms involve multi-indices of the form k − e j , with k≠k 0. Thus, by Lemma 13.14, [A, X j ] is not the zero operator.

We see, then, that any ![
$$A \\in \\mathcal{D}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq152.gif) that commutes with each X j must be of degree zero; that is, A must simply be multiplication by some polynomial f(x). If, in addition, A commutes with each P j , then

![
$$\\displaystyle{0 = \[f\(\\mathbf{x}\),P_{j}\] = i\\hslash \\frac{\\partial f} {\\partial x_{j}}\(\\mathbf{x}\).}$$
](A272900_1_En_13_Chapter_Equaf.gif)

Thus, actually, f must be constant and A is a multiple of the identity operator.

Lemma 13.16.

For any ![
$$f \\in \\mathcal{P}_{2},$$
](A272900_1_En_13_Chapter_IEq153.gif) there exist g 1 ,...,g j and h 1 ,...,h j in ![
$$\\mathcal{P}_{2}$$
](A272900_1_En_13_Chapter_IEq154.gif) such that

![
$$\\displaystyle{f =\\{ g_{1},h_{1}\\} + \\cdots +\\{ g_{j},h_{j}\\}.}$$
](A272900_1_En_13_Chapter_Equag.gif)

Furthermore, for any ![
$${f}^{{\\prime}}\\in \\mathcal{P}_{3},$$
](A272900_1_En_13_Chapter_IEq155.gif) there exist elements ![
$$g_{1}^{{\\prime}},\\ldots,g_{k}^{{\\prime}}$$
](A272900_1_En_13_Chapter_IEq156.gif) of ![
$$\\mathcal{P}_{3}$$
](A272900_1_En_13_Chapter_IEq157.gif) and ![
$$h_{1}^{{\\prime}},\\ldots,h_{k}^{{\\prime}}$$
](A272900_1_En_13_Chapter_IEq158.gif) of ![
$$\\mathcal{P}_{2}$$
](A272900_1_En_13_Chapter_IEq159.gif) such that

![
$$\\displaystyle{{f}^{{\\prime}} =\\{ g_{ 1}^{{\\prime}},h_{ 1}^{{\\prime}}\\} + \\cdots +\\{ g_{ k}^{{\\prime}},h_{ k}^{{\\prime}}\\}.}$$
](A272900_1_En_13_Chapter_Equah.gif)

Proof.

See Exercise 12.

Lemma 13.17.

If Q satisfies the conditions in Theorem 13.13, then Q coincides with Q Weyl on ![
$$\\mathcal{P}_{\\leq 3}.$$
](A272900_1_En_13_Chapter_IEq160.gif)

Proof.

Our argument leans heavily on Proposition 13.11. Note that, by assumption, Q coincides with Q Weyl on ![
$$\\mathcal{P}_{\\leq 1}.$$
](A272900_1_En_13_Chapter_IEq161.gif) For ![
$$f \\in \\mathcal{P}_{2},$$
](A272900_1_En_13_Chapter_IEq162.gif) let us write Q(f) as

![
$$\\displaystyle{Q\(f\) = Q_{\\mathrm{Weyl}}\(f\) + A_{f}.}$$
](A272900_1_En_13_Chapter_Equai.gif)

For any ![
$$g \\in \\mathcal{P}_{\\leq 1},$$
](A272900_1_En_13_Chapter_IEq163.gif) we have, by (13.38) and Proposition 13.11,

![
$$\\displaystyle\\begin{array}{rcl} Q\(\\{f,g\\}\)& =& \\frac{1} {i\\hslash }\[Q\(f\),Q\(g\)\] \\\\ & =& \\frac{1} {i\\hslash }\[Q_{\\mathrm{Weyl}}\(f\),Q_{\\mathrm{Weyl}}\(g\)\] + \\frac{1} {i\\hslash }\[A_{f},Q_{\\mathrm{Weyl}}\(g\)\] \\\\ & =& Q_{\\mathrm{Weyl}}\(\\{f,g\\}\) + \\frac{1} {i\\hslash }\[A_{f},Q_{\\mathrm{Weyl}}\(g\)\] \\\\ & =& Q\(\\{f,g\\}\) + \\frac{1} {i\\hslash }\[A_{f},Q_{\\mathrm{Weyl}}\(g\)\], {}\\end{array}$$
](A272900_1_En_13_Chapter_Equ48.gif)

(13.40)

since ![
$$\\{f,g\\} \\in \\mathcal{P}_{\\leq 1}.$$
](A272900_1_En_13_Chapter_IEq164.gif) Thus, [A f , Q Weyl(g)] = 0 for every ![
$$g \\in \\mathcal{P}_{1},$$
](A272900_1_En_13_Chapter_IEq165.gif) and so, by Lemma 13.15, we must have A f = c f I for some constant c f .

Now, if h is in ![
$$\\mathcal{P}_{2},$$
](A272900_1_En_13_Chapter_IEq166.gif) we have, by the just-established result and Proposition 13.11,

![
$$\\displaystyle\\begin{array}{rcl} Q\(\\{f,h\\}\)& =& \\frac{1} {i\\hslash }\[Q\(f\),Q\(h\)\] \\\\ & =& \\frac{1} {i\\hslash }\[Q_{\\mathrm{Weyl}}\(f\) + c_{f}I,Q_{\\mathrm{Weyl}}\(h\) + c_{h}I\] \\\\ & =& \\frac{1} {i\\hslash }\[Q_{\\mathrm{Weyl}}\(f\),Q_{\\mathrm{Weyl}}\(h\)\] \\\\ & =& Q_{\\mathrm{Weyl}}\(\\{f,h\\}\). {}\\end{array}$$
](A272900_1_En_13_Chapter_Equ49.gif)

(13.41)

That is to say, Q and Q Weyl agree on elements of ![
$$\\mathcal{P}_{2}$$
](A272900_1_En_13_Chapter_IEq167.gif) of the form {f, h}, for ![
$$f,h \\in \\mathcal{P}_{2}.$$
](A272900_1_En_13_Chapter_IEq168.gif) Thus, by Lemma 13.16, Q and Q Weyl agree on all of ![
$$\\mathcal{P}_{2},$$
](A272900_1_En_13_Chapter_IEq169.gif) and so on all of ![
$$\\mathcal{P}_{\\leq 2}.$$
](A272900_1_En_13_Chapter_IEq170.gif)

We now use the ![
$$\\mathcal{P}_{\\leq 2}$$
](A272900_1_En_13_Chapter_IEq171.gif) case of the lemma to establish the ![
$$\\mathcal{P}_{3}$$
](A272900_1_En_13_Chapter_IEq172.gif) case. Given ![
$$f \\in \\mathcal{P}_{3},$$
](A272900_1_En_13_Chapter_IEq173.gif) we write Q(f) = Q Weyl(f) + B f . Given ![
$$g \\in \\mathcal{P}_{\\leq 1},$$
](A272900_1_En_13_Chapter_IEq174.gif) we have ![
$$\\{f,g\\} \\in \\mathcal{P}_{\\leq 2}.$$
](A272900_1_En_13_Chapter_IEq175.gif) Thus, we may argue as in (13.40), applying the just-established ![
$$\\mathcal{P}_{\\leq 2}$$
](A272900_1_En_13_Chapter_IEq176.gif) case of the lemma to {f, g} in the last step. The conclusion is that [B f , Q(g)] = 0 for all ![
$$f \\in \\mathcal{P}_{\\leq 2}$$
](A272900_1_En_13_Chapter_IEq177.gif) and thus, by Lemma 13.15, that B f = d f I for some constant d f . Meanwhile, if ![
$$h \\in \\mathcal{P}_{2},$$
](A272900_1_En_13_Chapter_IEq178.gif) we argue as in (13.41), but with c f replaced by d f and with c h now known to be zero. The conclusion is that Q agrees with Q Weyl for all elements of ![
$$\\mathcal{P}_{3}$$
](A272900_1_En_13_Chapter_IEq179.gif) of the form {f, h} with ![
$$f \\in \\mathcal{P}_{3}$$
](A272900_1_En_13_Chapter_IEq180.gif) and ![
$$h \\in \\mathcal{P}_{2},$$
](A272900_1_En_13_Chapter_IEq181.gif) and thus, by Lemma 13.16, for all elements of ![
$$\\mathcal{P}_{3}.$$
](A272900_1_En_13_Chapter_IEq182.gif)

Proof of Theorem 13.13.

Assume, toward a contradiction, that a map Q as in the theorem exists. Let f be the polynomial given by

![
$$\\displaystyle{f\(\\mathbf{x},\\mathbf{p}\) = x_{1}^{2}p_{ 1}^{2}.}$$
](A272900_1_En_13_Chapter_Equaj.gif)

We observe that f can be written in two different ways as a Poisson bracket:

![
$$\\displaystyle{x_{1}^{2}p_{ 1}^{2} = \\frac{1} {9}\\{x_{1}^{3},p_{ 1}^{3}\\} = \\frac{1} {3}\\{x_{1}^{2}p_{ 1},x_{1}p_{1}^{2}\\}.}$$
](A272900_1_En_13_Chapter_Equak.gif)

Thus, by Lemma 13.17, we must have

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {9}\[Q_{\\mathrm{Weyl}}\(x_{1}^{3}\),Q_{\\mathrm{ Weyl}}\(p_{1}^{3}\)\]& =& i\\hslash Q\(x_{ 1}^{2}p_{ 1}^{2}\) {}\\\\ & =& \\frac{1} {3}\[Q_{\\mathrm{Weyl}}\(x_{1}^{2}p_{ 1}\),Q_{\\mathrm{Weyl}}\(x_{1}p_{1}^{2}\)\]. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ50.gif)

On the other hand, if we apply both commutators to the constant function 1 (or to a function equal to 1 in a neighborhood of the origin), we obtain

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {9}\[Q_{\\mathrm{Weyl}}\(x_{1}^{3}\),Q_{\\mathrm{ Weyl}}\(p_{1}^{3}\)\]\\mathbf{1}& =& \\frac{1} {9}\(X_{1}^{3}P_{ 1}^{3} - P_{ 1}^{3}X_{ 1}^{3}\)\\mathbf{1} {}\\\\ & =& -\\frac{1} {9}{\(-i\\hslash \)}^{3}6 \\cdot \\mathbf{1}. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ51.gif)

Meanwhile, if we compute the quantizations as in (13.4) and then drop all terms involving P 1 1, we obtain (after a small computation)

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {3}\[Q_{\\mathrm{Weyl}}\(x_{1}^{2}p_{ 1}\),Q_{\\mathrm{Weyl}}\(x_{1}p_{1}^{2}\)\]\\mathbf{1}& =& \\frac{1} {12}\(X_{1}^{2}P_{ 1}^{3}X_{ 1} + P_{1}X_{1}^{2}P_{ 1}^{2}X_{ 1}\)\\mathbf{1} {}\\\\ & -& \\frac{1} {12}\(X_{1}P_{1}^{3}X_{ 1}^{2} + P_{ 1}^{2}X_{ 1}P_{1}X_{1}^{2}\)\\mathbf{1} {}\\\\ & =& -\\frac{1} {12}P_{1}^{2}X_{ 1}P_{1}X_{1}^{2}\\mathbf{1} {}\\\\ & =& -\\frac{1} {12}{\(-i\\hslash \)}^{3}4 \\cdot \\mathbf{1}. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ52.gif)

Since 6 ∕ 9 does not equal 4 ∕ 12, we have a contradiction.

## 13.5 Exercises

1.

Let ![
$$\\mathcal{P}_{j}$$
](A272900_1_En_13_Chapter_IEq183.gif) denote the space of complex-valued homogeneous polynomials on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_13_Chapter_IEq184.gif) of degree j. Then ![
$$\\mathcal{P}_{j}$$
](A272900_1_En_13_Chapter_IEq185.gif) is a complex vector space of dimension j \+ 1, which we may identify with ![
$${\\mathbb{C}}^{j+1}$$
](A272900_1_En_13_Chapter_IEq186.gif) using the obvious basis for ![
$$\\mathcal{P}_{j}.$$
](A272900_1_En_13_Chapter_IEq187.gif) Let V j denote the complex subspace of ![
$$\\mathcal{P}_{j}$$
](A272900_1_En_13_Chapter_IEq188.gif) spanned by polynomials of the form (ax \+ bp) j , with ![
$$a,b \\in \\mathbb{C}.$$
](A272900_1_En_13_Chapter_IEq189.gif) Show that ![
$$V _{j} = \\mathcal{P}_{j}.$$
](A272900_1_En_13_Chapter_IEq190.gif)

Hint: Since every subspace of ![
$${\\mathbb{C}}^{j+1}$$
](A272900_1_En_13_Chapter_IEq191.gif) is (topologically) closed, if γ(t) is a smooth curve in V j , the derivative γ ′ (t) will also lie in V j .

2.

Show that symmetrized pseudodifferential operator quantization of x 2 p 2 is equal to ![
$$Q_{\\mathrm{Weyl}}\({x}^{2}{p}^{2}\) - {\\hslash }^{2}/2.$$
](A272900_1_En_13_Chapter_IEq192.gif)

3.

Show that Wick-ordered and anti-Wick-ordered quantizations map real-valued polynomials to symmetric operators on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\).$$
](A272900_1_En_13_Chapter_IEq193.gif)

Hint: Compare the values of each quantization scheme on ![
$${z}^{k}\\bar{{z}}^{l}$$
](A272900_1_En_13_Chapter_IEq194.gif) and on ![
$$\\overline{\({z}^{k}\\bar{{z}}^{l}\)}.$$
](A272900_1_En_13_Chapter_IEq195.gif)

4.

Consider a classical harmonic oscillator with Hamiltonian

![
$$\\displaystyle{H\(x,p\) = \\frac{{p}^{2}} {2m} + \\frac{1} {2}{m\\omega }^{2}{x}^{2} = \\frac{1} {2}{m\\omega }^{2}\\left \({x}^{2} +{ \\left \( \\frac{p} {m\\omega }\\right\)}^{2}\\right\),}$$
](A272900_1_En_13_Chapter_Equal.gif)

where ω is the frequency of the oscillator. Consider the Wick- and anti-Wick-ordered quantizations with parameter α = 1 ∕ (mω). Show that

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Wick}}\(H\)& =& Q_{\\mathrm{Weyl}}\(H\) -\\frac{1} {2}\\hslash \\omega {}\\\\ Q_{\\mathrm{anti-Wick}}\(H\)& =& Q_{\\mathrm{Weyl}}\(H\) + \\frac{1} {2}\\hslash \\omega. {}\\\\ \\end{array}$$
](A272900_1_En_13_Chapter_Equ53.gif)

5.

Let U a, b (t) be as in Proposition 13.5. Show by direct calculation that these operators form a one-parameter unitary group.

6.

Given ![
$$\\kappa \\in {L}^{2}\({\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq196.gif) let A κ denote the associated integral operator on ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq197.gif) as in Proposition 13.6. Show that the adjoint A ∗ of A is also an integral operator, with integral kernel κ ′ given by

![
$$\\displaystyle{{\\kappa }^{{\\prime}}\(\\mathbf{x},\\mathbf{y}\) = \\overline{\\kappa \(\\mathbf{y},\\mathbf{x}\)}.}$$
](A272900_1_En_13_Chapter_Equam.gif)

7.

Suppose that ![
$$f \\in {L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_13_Chapter_IEq198.gif) and that ![
$$\\hat{f} \\in {L}^{1}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_13_Chapter_IEq199.gif) Then the right-hand side of (13.17) may be understood as an absolutely convergent "Bochner" integral with values in the Banach space ![
$$\\mathcal{B}\({L}^{2}\({\\mathbb{R}}^{n}\)\).$$
](A272900_1_En_13_Chapter_IEq200.gif) Show that Q Weyl(f) as defined by (13.17) coincides with Q Weyl(f) as defined in Definition 13.7.

Hint: The Bochner integral commutes with applying a bounded linear functional. Use this result with the linear functional ![
$$\\Lambda _{\\phi,\\psi }\(A\) := \\left \\langle \\phi,A\\psi \\right\\rangle$$
](A272900_1_En_13_Chapter_IEq201.gif) on ![
$$\\mathcal{B}\({L}^{2}\({\\mathbb{R}}^{n}\)\).$$
](A272900_1_En_13_Chapter_IEq202.gif) Then use the expression in (13.23) for κ f , which follows from Definition 13.7 by applying a partial Fourier transform.

8.

(a)

Show that for any polynomial f in one variable, we have

![
$$\\displaystyle{Q_{\\mathrm{Weyl}}\(f\(x\)p\) = f\(X\)P -\\frac{i\\hslash } {2} {f}^{{\\prime}}\(X\).}$$
](A272900_1_En_13_Chapter_Equan.gif)

(b)

Show that for any two polynomials f and g, the Poisson bracket {f(x)p, g(x)p} is of the form h(x)p for some polynomial h.

(c)

Show that for any two polynomials f and g, we have

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\\left \[Q_{\\mathrm{Weyl}}\(f\(x\)p\),Q_{\\mathrm{Weyl}}\(g\(x\)p\)\\right\] = Q_{\\mathrm{Weyl}}\(\\{f\(x\)p,g\(x\)p\\}\).}$$
](A272900_1_En_13_Chapter_Equao.gif)

9.

(a)

Given ![
$$\\phi$$
](A272900_1_En_13_Chapter_IEq0001.gif) and ![
$$\\psi$$
](A272900_1_En_13_Chapter_IEq00003.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_13_Chapter_IEq203.gif) let ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_13_Chapter_IEq204.gif) be the operator defined in Notation 3.27. Show that ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_13_Chapter_IEq205.gif) can be expressed as an integral operator as in Proposition 13.6 and determine the associated integral kernel ![
$$\\kappa.$$
](A272900_1_En_13_Chapter_IEq206.gif)

(b)

For σ > 0, let ![
$$\\psi _{\\sigma } \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq207.gif) be given by the expression

![
$$\\displaystyle{\\psi _{\\sigma }\(\\mathbf{x}\) = {\(\\pi \\sigma \)}^{-n/4}{e}^{-{\\left \\vert \\mathbf{x}\\right\\vert }^{2}/\(2\\sigma \) }.}$$
](A272900_1_En_13_Chapter_Equap.gif)

Using Proposition A.22, show that ![
$$\\psi$$
](A272900_1_En_13_Chapter_IEq00002.gif) σ is a unit vector in ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_13_Chapter_IEq208.gif) and that the Weyl symbol of the corresponding one-dimensional projection operator ![
$$\\left \\vert \\psi _{\\sigma }\\right\\rangle \\left \\langle \\psi _{\\sigma }\\right\\vert$$
](A272900_1_En_13_Chapter_IEq209.gif) is given by

![
$$\\displaystyle{Q_{\\mathrm{Weyl}}^{-1}\(\\left \\vert \\psi _{\\sigma }\\right\\rangle \\left \\langle \\psi _{\\sigma }\\right\\vert \) = {2}^{n}{e}^{-{\\left \\vert \\mathbf{x}\\right\\vert }^{2}/\\sigma }{e}^{-\\sigma {\\left \\vert \\mathbf{p}\\right\\vert }^{2}/{\\hslash }^{2} }.}$$
](A272900_1_En_13_Chapter_Equaq.gif)

Note: If we give σ the value ![
$$\\hslash /\(m\\omega \),$$
](A272900_1_En_13_Chapter_IEq210.gif) the Gaussian function ![
$$\\psi$$
](A272900_1_En_13_Chapter_IEq00001.gif) α may be thought of as the ground state for an n-dimensional harmonic oscillator. (Compare the functions in Theorem 11.3.) The computation in this exercise plays an important role in the proof of the Stone–von Neumann theorem in Chap. 14.8.

10.

If f and g are Schwartz functions on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_13_Chapter_IEq211.gif) show that ![
$$\\widehat{f \\star g}$$
](A272900_1_En_13_Chapter_IEq212.gif) converges in the L 1 norm to ![
$${\(2\\pi \)}^{-n}\\hat{f} {\\ast}\\hat{ g},$$
](A272900_1_En_13_Chapter_IEq213.gif) where ∗ denotes convolution. Conclude that f ⋆ g converges uniformly to fg as ![
$$\\hslash $$
](A272900_1_En_13_Chapter_IEq214.gif) tends to zero.

11.

Suppose that f(p, q) is a homogeneous polynomial of degree 2. Show that for each t, the Hamiltonian flow Φ t associated with f is a linear map of ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_13_Chapter_IEq215.gif) to itself.

12.

Prove Lemma 13.16.

Hint: Let ![
$$g_{1} \\in \\mathcal{P}_{2}$$
](A272900_1_En_13_Chapter_IEq216.gif) be given by

![
$$\\displaystyle{g_{1}\(\\mathbf{x},\\mathbf{p}\) =\\sum _{ j=1}^{n}x_{ j}p_{j}.}$$
](A272900_1_En_13_Chapter_Equar.gif)

Show that for any monomial of the form ![
$${\\mathbf{x}}^{\\mathbf{j}}{\\mathbf{p}}^{\\mathbf{k}},$$
](A272900_1_En_13_Chapter_IEq217.gif) we have ![
$$\\{g_{1},{\\mathbf{x}}^{\\mathbf{j}}{\\mathbf{p}}^{\\mathbf{k}}\\} = \(\\left \\vert \\mathbf{k}\\right\\vert -\\left \\vert \\mathbf{j}\\right\\vert \){\\mathbf{x}}^{\\mathbf{j}}{\\mathbf{p}}^{\\mathbf{k}}.$$
](A272900_1_En_13_Chapter_IEq218.gif) Thus, most of the standard basis elements f for ![
$$\\mathcal{P}_{2}$$
](A272900_1_En_13_Chapter_IEq219.gif) and all of the standard basis elements f for ![
$$\\mathcal{P}_{3}$$
](A272900_1_En_13_Chapter_IEq220.gif) can be obtained as nonzero multiples of {g 1, f}.

References

[11].

G.B. Folland, Harmonic Analysis in Phase Space. Annals of Mathematics Studies, vol. 122 (Princeton University Press, Princeton, 1989)

[15].

M.J. Gotay, On the Groenewold-Van Hove problem for ℝ 2n . J. Math. Phys. 40, 2107–2116 (1999)CrossRefMATHMathSciNet

[21].

B.C. Hall, Lie Groups, Lie Algebras, and Representations: An Elementary Introduction. Graduate Texts in Mathematics, vol. 222 (Springer, New York, 2003)

[34].

M. Reed, B. Simon, Methods of Modern Mathematical Physics. Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)

[46].

K. Yosida, Functional Analysis, 4th edn. (Springer, New York, 1980)CrossRefMATH
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_14

© Springer Science+Business Media New York 2013

# 14. The Stone–von Neumann Theorem

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

The Stone–von Neumann theorem is a uniqueness theorem for operators satisfying the canonical commutation relations. Suppose A and B are two self-adjoint operators on H satisfying ![
$$\[A,B\] = i\\hslash I.$$
](A272900_1_En_14_Chapter_IEq1001.gif) Suppose also that A and B act irreducibly on H,meaning that the only closed subspaces of H invariant under A and B are {0} and H.Then provided that certain technical assumptions hold (the exponentiated commutation relations)

The Stone–von Neumann theorem is a uniqueness theorem for operators satisfying the canonical commutation relations. Suppose A and B are two self-adjoint operators on H satisfying ![
$$\[A,B\] = i\\hslash I.$$
](A272900_1_En_14_Chapter_IEq1.gif) Suppose also that A and B act irreducibly on H, meaning that the only closed subspaces of H invariant under A and B are {0} and H. Then provided that certain technical assumptions hold (the exponentiated commutation relations), we will conclude that A and B are unitarily equivalent to the usual position and momentum operators X and P. That is, there is a unitary operator ![
$$U : \\mathbf{H} \\rightarrow {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_14_Chapter_IEq2.gif) such that U AU − 1 = X and U BU − 1 = P. If H is not irreducible, then it decomposes as a direct sum of invariant subspaces V l for A and B, and the restrictions of A and B to each V l are unitarily equivalent to the usual X and P.

We begin this chapter with a heuristic argument for the Stone–von Neumann theorem, an argument that glosses over certain (essential but technical) domain issues. Then we introduce the exponentiated commutation relations, which should be thought of as a sort of mild strengthening of the ordinary canonical commutation relations. Finally, we give a precise statement of the theorem and provide a proof.

## 14.1 A Heuristic Argument

Suppose that A and B are any two (possibly unbounded) self-adjoint operators on a separable Hilbert space H satisfying ![
$$\[A,B\] = i\\hslash I.$$
](A272900_1_En_14_Chapter_IEq3.gif) What we would like to conclude is that H looks like a Hilbert space direct sum of closed subspaces V l that are invariant under A and B, and such that each V l is unitarily equivalent to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_14_Chapter_IEq4.gif) in a way that turns the operators A and B into the standard position and momentum operators X and ![
$$P.$$
](A272900_1_En_14_Chapter_IEq5.gif) That is to say, we hope to find unitary maps ![
$$U_{l} : V _{l} \\rightarrow {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_14_Chapter_IEq6.gif) such that

![
$$\\displaystyle\\begin{array}{rcl} U_{l}AU_{l}^{-1}& =& X {}\\\\ U_{l}BU_{l}^{-1}& =& P. {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ1.gif)

This conclusion is, however, not quite correct, for reasons having to do with the domains of the relevant operators. Nevertheless, let us consider a heuristic argument for this conclusion. We start by forming a lowering operator α and a raising operator α ∗ by analogy to the definitions of a and a ∗ in Chap.​ 11:

![
$$\\displaystyle{\\alpha = \\frac{m\\omega A + iB} {\\sqrt{2\\hslash m\\omega }} ;{\\quad \\alpha }^{{\\ast}} = \\frac{m\\omega A - iB} {\\sqrt{2\\hslash m\\omega }}.}$$
](A272900_1_En_14_Chapter_Equa.gif)

Then we look at the kernel W of the lowering operator α, which will be a closed subspace of H, provided that α is a closed operator. The elements of W may be thought of as "ground states" for the operator α ∗ α. Choose an orthonormal basis ![
$$\\left\\{\\phi _{0}^{l}\\right\\}$$
](A272900_1_En_14_Chapter_IEq7.gif) for W and define vectors

![
$$\\displaystyle{\\phi _{m}^{l} := {{\(\\alpha }^{{\\ast}}\)}^{m}\\phi _{ 0}^{l}.}$$
](A272900_1_En_14_Chapter_Equb.gif)

It is not hard to show that for ![
$$ l\\neq{l}^{\\prime},\\,\\phi_{m}^{l}\\text{ is orthogonal to }\\phi _{{m}^{{\\prime}}}^{{l}^{{\\prime}} }$$
](A272900_1_En_14_Chapter_IEq8.gif) for all m and m ′ . Let V l denote the closed span of the vectors ![
$$ \\psi_{m}^{l},\\,m=0,1,2,.\\,.\\,.. $$
](A272900_1_En_14_Chapter_IEq10102.gif).

Using the calculation in Sect.​ 11.​2, we can see that the way α and α ∗ act on each chain (the vectors ![
$$ \\psi_{m}^{l}\\text{ with } {l}$$
](A272900_1_En_14_Chapter_IEq10001.gif) fixed and m varying) is precisely the same as the way the standard lowering and raising operators a and a ∗ act on the chain of eigenvectors for a ∗ a. Thus, for each l, we can construct a unitary map U l from V l to ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_14_Chapter_IEq9.gif) by mapping the vectors ![
$$\\phi_{m}^{l}\\,\\text{in}\\,{V}_{j}\\text{ to the vectors }\\psi_{m}\\text{ in }{L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_14_Chapter_IEq10.gif) described in Theorems 11.3 and 11.4. (In particular, the vector ![
$$\\psi _{0} \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_14_Chapter_IEq11.gif) is the ground state for the harmonic oscillator, which is a Gaussian.) Since the formula for how α and α ∗ act is the same as the formula for how a and a ∗ act, U l will "intertwine" α with a and α ∗ with a and a ∗, meaning that U l α = aU l , and similarly for α ∗ and a ∗. It follows that U l also intertwines A with X and B with P.

It remains only to argue (heuristically) that the spaces V l fill up the whole Hilbert space H. Clearly, the span V of the V l 's is invariant under both α and α ∗. Thus, the orthogonal complement V ⊥ of V is invariant under the adjoints α ∗ and α. If V ⊥ is not zero, then arguing as in Chap.​ 11, there should be a ground state in V ⊥, that is a nonzero vector annihilated by α. This vector would be orthogonal to all the ![
$$\\phi_{0}^{l\\,,}$$
](A272900_1_En_14_Chapter_IEq10010.gif)s, contradicting the assumption that the ![
$$\\phi_{0}^{l\\,,}$$
](A272900_1_En_14_Chapter_IEq10011.gif)s form an orthonormal basis for the kernel of α.

The preceding heuristic argument cannot be completely rigorous, however, since the counterexample in Sect.​ 12.​2 gives a pair of operators A and B that satisfy the canonical commutation relations but are clearly not unitarily equivalent to the usual position and momentum operators. After all, the "position" operator A in that section is a bounded operator, which cannot be unitarily equivalent to the usual position operator.

What goes wrong is, as usual, a matter of domain considerations. Setting m, ![
$$\\hslash $$
](A272900_1_En_14_Chapter_IEq12.gif), and ω equal to 1, we can look for a vector ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10012.gif) that is annihilated by the operator

![
$$\\displaystyle{\\alpha = \\frac{1} {\\sqrt{2}}\(A + iB\) = \\frac{1} {\\sqrt{2}}\\left\(x + \\frac{d} {dx}\\right\).}$$
](A272900_1_En_14_Chapter_Equc.gif)

By the same argument as in Chap.​ 11, ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10013.gif) must be a constant multiple of the function ![
$${e}^{-{x}^{2}/2 }.$$
](A272900_1_En_14_Chapter_IEq13.gif) The function ![
$$\\phi _{1} :{=\\alpha }^{{\\ast}}\\phi _{0}$$
](A272900_1_En_14_Chapter_IEq14.gif) is then a multiple of ![
$$x{e}^{-{x}^{2}/2 }.$$
](A272900_1_En_14_Chapter_IEq15.gif) The problem is that ![
$$\\phi_{1}\\text{ is not in the domain of }\\alpha^{*}$$
](A272900_1_En_14_Chapter_IEq10014.gif). After all, ![
$$\\phi_{1}$$
](A272900_1_En_14_Chapter_IEq10015.gif) does not satisfy the periodic boundary condition ![
$$ \\psi\(-1\) = \\psi\(1\)$$
](A272900_1_En_14_Chapter_IEq1002.gif) that defines the domain of B. Thus, we cannot continue to apply α ∗ to obtain an orthogonal chain of vectors and the entire argument breaks down.

What we need, then, is some additional condition that will distinguish between the "good" cases of the canonical commutation relations and the "bad" cases. One possibility for this additional condition is the exponentiated form of the canonical commutation relations, which are discussed in the following section. Our rigorous proof (Sect. 14.3) of the Stone–von Neumann theorem will follow the same outline as the heuristic argument in this section, except that the unbounded operators α and α ∗ will be replaced by certain bounded operators, constructed by an analog of the Weyl quantization.

## 14.2 The Exponentiated Commutation Relations

If A is a bounded operator on a Hilbert space H, we may define the exponential of A, denoted either e A or exp(A), by the power series

![
$$\\displaystyle{{e}^{A} =\\sum _{ m=0}^{\\infty }\\frac{{A}^{m}} {m!},}$$
](A272900_1_En_14_Chapter_Equd.gif)

where A 0 = I. A standard power series argument shows that if ![
$$A,B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq16.gif) commute, then

![
$$\\displaystyle{ {e}^{A+B} = {e}^{A}{e}^{B},\\quad \[A,B\] = 0. }$$
](A272900_1_En_14_Chapter_Equ2.gif)

(14.1)

(See Exercise 6 in Chap.​ 16.) Even when A and B do not commute, there is a formula, called the Baker–Campbell–Hausdorff formula, that expresses e A e B , for sufficiently small A and B, in the form

![
$$\\displaystyle{{e}^{A}{e}^{B} =\\exp \\left\\{A + B + \\frac{1} {2}\[A,B\] + \\frac{1} {12}\[A,\[A,B\]\] + \\cdots \\,\\right\\},}$$
](A272900_1_En_14_Chapter_Eque.gif)

where the terms indicated by ⋯ are iterated commutators involving A and B. (See Chap.​ 3 of [21] for more information.) A very special case of this formula is obtained in the case where A and B commute with their commutator, so that all higher commutators are zero.

Theorem 14.1.

Suppose ![
$$A,B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq17.gif) commute with their commutator, that is,

![
$$\\displaystyle{\[A,\[A,B\]\] = \[B,\[A,B\]\] = 0.}$$
](A272900_1_En_14_Chapter_Equf.gif)

Then

![
$$\\displaystyle{{e}^{A}{e}^{B} = {e}^{A+B+\\frac{1} {2} \[A,B\]}.}$$
](A272900_1_En_14_Chapter_Equg.gif)

This relation may also be written as

![
$$\\displaystyle{{e}^{A+B} = {e}^{-\\frac{1} {2} \[A,B\]}{e}^{A}{e}^{B}.}$$
](A272900_1_En_14_Chapter_Equh.gif)

Note that in this special case of the Baker–Campbell–Hausdorff formula, no smallness assumption is imposed on A and B.

Proof.

We will prove that

![
$$\\displaystyle{ {e}^{tA}{e}^{tB} = {e}^{t\(A+B\)+\\frac{{t}^{2}} {2} \[A,B\]}, }$$
](A272900_1_En_14_Chapter_Equ3.gif)

(14.2)

which reduces to the desired result at t = 1. Since [A, B] commutes with everything in sight, we can use (14.1) to split the exponential on the right-hand side of (14.2) into two and then move the factor involving [A, B] to the other side. Thus, (14.2) is equivalent to the relation

![
$$\\displaystyle{ {e}^{tA}{e}^{tB}{e}^{-{t}^{2}\[A,B\]/2 } = {e}^{t\(A+B\)}. }$$
](A272900_1_En_14_Chapter_Equ4.gif)

(14.3)

Let α(t) denote the left-hand side of (14.3). We will show that α(t) satisfies a simple differential equation, which may be solved explicitly to obtain α(t) = e t(A \+ B).

Using term-by-term differentiation, it is easy to verify that

![
$$\\displaystyle{ \\frac{d} {dt}{e}^{tC} = C{e}^{tC} = {e}^{tC}C}$$
](A272900_1_En_14_Chapter_Equi.gif)

for any ![
$$C \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_14_Chapter_IEq18.gif) and that

![
$$\\displaystyle{ \\frac{d} {dt}{e}^{-{t}^{2}\[A,B\]/2 } = {e}^{-{t}^{2}\[A,B\]/2 }\(-t\[A,B\]\).}$$
](A272900_1_En_14_Chapter_Equj.gif)

We may then differentiate α(t) using the product rule, which is proved the same way as in the scalar case, giving

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d\\alpha } {dt}& =& {e}^{tA}A{e}^{tB}{e}^{-{t}^{2}\[A,B\]/2 } + {e}^{tA}{e}^{tB}B{e}^{-{t}^{2}\[A,B\]/2 } {}\\\\ & +& {e}^{tA}{e}^{tB}{e}^{-{t}^{2}\[A,B\]/2 }\(-t\[A,B\]\). {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ5.gif)

To simplify our expression for d α ∕ dt, we need an intermediate result. By the product rule

![
$$\\displaystyle{ \\frac{d} {dt}{e}^{-tB}A{e}^{tB} = {e}^{-tB}\[A,B\]{e}^{tB} = \[A,B\], }$$
](A272900_1_En_14_Chapter_Equ6.gif)

(14.4)

because B—and, thus, e B —commutes with [A, B]. Noting that e − tB Ae tB = A when t = 0, we may integrate (14.4) to get

![
$$\\displaystyle{ {e}^{-tB}A{e}^{tB} = A + t\[A,B\]. }$$
](A272900_1_En_14_Chapter_Equ7.gif)

(14.5)

(The difference of the two sides of (14.5) has derivative zero, so by Part (a) of Exercise 2, the two sides are equal up to a constant, which is seen to be zero by evaluating at t = 0.)

Using (14.5), we obtain

![
$$\\displaystyle{{e}^{tA}A{e}^{tB} = {e}^{tA}{e}^{tB}\({e}^{-tB}A{e}^{tB}\) = {e}^{tA}{e}^{tB}\(A + t\[A,B\]\).}$$
](A272900_1_En_14_Chapter_Equk.gif)

Moreover, since everything commutes with [A, B], we may commute anything we want past ![
$${e}^{-{t}^{2}\[A,B\]/2 }.$$
](A272900_1_En_14_Chapter_IEq19.gif) Thus,

![
$$\\displaystyle\\begin{array}{rcl} \\frac{d\\alpha } {dt}& =& \\alpha \(t\)\(A + t\[A,B\] + B - t\[A,B\]\) {}\\\\ & =& \\alpha \(t\)\(A + B\). {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ8.gif)

Now, according to Exercise 2, the unique solution to the differential equation d α ∕ dt = α(t)(A \+ B) is α(t) = α(0)e t(A \+ B). Since α(0) = I, we obtain the desired result (14.3). ■

Suppose, now, that A and B are unbounded self-adjoint operators satisfying

![
$$\\displaystyle{ \[A,B\] = i\\hslash I, }$$
](A272900_1_En_14_Chapter_Equ9.gif)

(14.6)

where the exponentials e isA and e itB are defined by means of the spectral theorem. If we formally apply Theorem 14.1 to isA and itB (even these operators are unbounded), we obtain

![
$$\\displaystyle{{e}^{i\(sA+tB\)} = {e}^{ist\\hslash /2}{e}^{isA}{e}^{itB} = {e}^{-ist\\hslash /2}{e}^{itB}{e}^{isA}}$$
](A272900_1_En_14_Chapter_Equl.gif)

so that

![
$$\\displaystyle{ {e}^{isA}{e}^{itB} = {e}^{-ist\\hslash }{e}^{itB}{e}^{isA}. }$$
](A272900_1_En_14_Chapter_Equ10.gif)

(14.7)

It is essential to emphasize that the conclusion (14.7) is only formal, since it assumes that results for bounded operators carry over to unbounded operators, which is false in general. Nevertheless, we may hope that in "good" cases, self-adjoint operators satisfying (14.6) will also satisfy (14.7).

Extending the preceding discussion to the case of several degrees of freedom in an obvious way, we are led to the following definition.

Definition 14.2.

If A 1 ,...,A n and B 1 ,...,B n are possibly unbounded selfadjoint operators on H, the A's and B's satisfy the exponentiated commutation relations if the following relations hold for all 1 ≤ j,k ≤ n and ![
$$s,t \\in \\mathbb{R}$$
](A272900_1_En_14_Chapter_IEq20.gif) :

![
$$\\displaystyle\\begin{array}{rcl} {e}^{isA_{j} }{e}^{itA_{k} }& =& {e}^{itA_{k} }{e}^{isA_{j} } {}\\\\ {e}^{isB_{j} }{e}^{itB_{k} }& =& {e}^{itB_{k} }{e}^{isB_{j} } {}\\\\ {e}^{isA_{j} }{e}^{itB_{k} }& =& {e}^{-ist\\hslash \\delta _{jk} }{e}^{itB_{k} }{e}^{isA_{j} }. {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ11.gif)

The operators ![
$${e}^{isA_{j}}$$
](A272900_1_En_14_Chapter_IEq21.gif) and ![
$${e}^{itB_{k}}$$
](A272900_1_En_14_Chapter_IEq22.gif) are defined by the spectral theorem for unbounded self-adjoint operators, and they are unitary operators, defined on all of H. Thus, when we say that the exponentiated commutation relations hold, we mean that they hold on the entire Hilbert space H.

Notation 14.3

Suppose operators A 1 ,...,A n and B 1 ,...,B n satisfy the exponentiated commutation relations. Then for all a and b in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_14_Chapter_IEq23.gif) let e i(a⋅A + b⋅B) denote the unitary operator given by

![
$$\\displaystyle{ {e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)} = {e}^{i\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2}{e}^{ia_{1}A_{1} }\\cdots {e}^{ia_{n}A_{n} }{e}^{ib_{1}B_{1} }\\cdots {e}^{ib_{n}B_{n} }. }$$
](A272900_1_En_14_Chapter_Equ12.gif)

(14.8)

Equation (14.8) is nothing but what we obtain by formally applying Theorem 14.1 to the operators i a ⋅A and i b ⋅B and then further splitting the exponentials by formally applying (14.1). The notation may be further justified by checking (Exercise 4) that the operators

![
$$\\displaystyle{ U_{\\mathbf{a},\\mathbf{b}}\(t\) := {e}^{i{t}^{2}\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2 }{e}^{ita_{1}A_{1} }\\cdots {e}^{ita_{n}A_{n} }{e}^{itb_{1}B_{1} }\\cdots {e}^{itb_{n}B_{n} } }$$
](A272900_1_En_14_Chapter_Equ13.gif)

(14.9)

form a strongly continuous one-parameter unitary group. If we then define a ⋅A \+ b ⋅B as the infinitesimal generator (Sect.​ 10.​2) of U a, b , the relation (14.8) will indeed hold. Using the definition of e i(a ⋅A \+ b ⋅B) and the exponentiated commutation relations, a simple calculation shows that

![
$$\\displaystyle{ {e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{A}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{B}\) } = {e}^{-i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }{e}^{i\(\(\\mathbf{a}+{\\mathbf{a}}^{{\\prime}}\)\\cdot \\mathbf{A}+\(\\mathbf{b}+{\\mathbf{b}}^{{\\prime}}\)\\cdot \\mathbf{B}\) }. }$$
](A272900_1_En_14_Chapter_Equ14.gif)

(14.10)

In particular, e − i(a ⋅A \+ b ⋅B) is the inverse of e i(a ⋅A \+ b ⋅B), as the notation suggests.

The following examples show that in the good case (the usual position and momentum operators on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq24.gif)), the exponentiated commutation relations do hold, where as in the bad case (the counterexample in Sect.​ 12.​2), they do not.

Example 14.4.

Let A j be the usual position operator X j acting on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq25.gif) and let B j be the usual momentum operator P j . Then the A's and B's satisfy the exponentiated commutation relations.

Proof.

Since X j is just multiplication by x j , it is easily verified that ![
$${e}^{isX_{j}}$$
](A272900_1_En_14_Chapter_IEq26.gif) is just multiplication by ![
$${e}^{isx_{j}}.$$
](A272900_1_En_14_Chapter_IEq27.gif) Meanwhile, the exponentiated momentum operators satisfy (Example 10.16)

![
$$\\displaystyle{\({e}^{itP_{j} }\\psi\)\(\\mathbf{x}\) =\\psi \(\\mathbf{x} + t\\hslash \\mathbf{e}_{j}\).}$$
](A272900_1_En_14_Chapter_Equm.gif)

It is then evident that ![
$${e}^{isX_{j}}$$
](A272900_1_En_14_Chapter_IEq28.gif) commutes with ![
$${e}^{itX_{k}}$$
](A272900_1_En_14_Chapter_IEq29.gif) and that ![
$${e}^{isP_{j}}$$
](A272900_1_En_14_Chapter_IEq30.gif) commutes with ![
$${e}^{itP_{k}}.$$
](A272900_1_En_14_Chapter_IEq31.gif) We may also compute that

![
$$\\displaystyle\\begin{array}{rcl} \({e}^{itP_{k} }{e}^{isX_{j} }\\psi\)\(\\mathbf{x}\)& =& {e}^{is\(\\mathbf{x}+t\\hslash \\mathbf{e}_{k}\)_{j} }\\psi \(\\mathbf{x} + t\\hslash \\mathbf{e}_{k}\) {}\\\\ & =& {e}^{ist\\hslash \\delta _{jk} }\({e}^{isX_{j} }{e}^{itP_{k} }\\psi\)\(\\mathbf{x}\), {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ15.gif)

which is what we wanted to prove. ■

Example 14.5.

Let A be the operator in Sect.​ 12.​2 and let B be the (unique self-adjoint extension of) the operator in that section. Then A and B do not satisfy the exponentiated commutation relations.

Proof.

The operator A is multiplication by x, and so the operator e isA is just multiplication by e isx . Meanwhile, the operator B is ![
$$-i\\hslash \\ d/dx,$$
](A272900_1_En_14_Chapter_IEq32.gif) with periodic boundary conditions. We will now demonstrate that e itB consists of "translation with wraparound." Specifically, for any ![
$$a \\in \\mathbb{R}$$
](A272900_1_En_14_Chapter_IEq33.gif) and ![
$$\\psi\\,\\in\\,{L}^{2}\(\[-1, 1\]\)$$
](A272900_1_En_14_Chapter_IEq1003.gif), let us define ![
$$S_{a}\\psi \\in {L}^{2}\(\[-1,1\]\)$$
](A272900_1_En_14_Chapter_IEq34.gif) by

![
$$\\displaystyle{\(S_{a}\\psi\)\(x\) =\\psi \(x + a - 2m_{x,a}\),}$$
](A272900_1_En_14_Chapter_Equn.gif)

where m x is the unique integer such that

![
$$\\displaystyle{-1 \\leq x + a - 2m_{x,a} < 1.}$$
](A272900_1_En_14_Chapter_Equo.gif)

It is easy to check that S a is a unitary map of L 2([0, 1]) for each ![
$$a \\in \\mathbb{R}.$$
](A272900_1_En_14_Chapter_IEq35.gif)

We then claim that

![
$$\\displaystyle{ {e}^{itB} = S_{ \\hslash t}. }$$
](A272900_1_En_14_Chapter_Equ16.gif)

(14.11)

To verify the correctness of (14.11), observe that B has an orthonormal basis of eigenvectors, namely the functions ![
$$ \\psi_{n}\(x\)\\,:={e}^{\\pi inx},\\,n \\in \\mathbb{Z},$$
](A272900_1_En_14_Chapter_IEq36.gif) with the corresponding eigenvalues being ![
$$\\pi n\\hslash.$$
](A272900_1_En_14_Chapter_IEq37.gif) Thus, if we compute e itB by means of the spectral theorem, we have

![
$$\\displaystyle{{e}^{itB}\\psi _{ n} = {e}^{\\pi int\\hslash }\\psi _{ n}.}$$
](A272900_1_En_14_Chapter_Equp.gif)

On the other hand,

![
$$\\displaystyle\\begin{array}{rcl} \(S_{a}\\psi _{n}\)\(x\)\({e}^{\\pi inx}\)& =& {e}^{\\pi in\(x+a-2m_{x,a}\)} {}\\\\ & =& {e}^{-2\\pi inm_{x,a} }{e}^{\\pi ina}{e}^{\\pi inx} {}\\\\ & =& {e}^{\\pi ina}\\psi _{ n}\(x\), {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ17.gif)

showing that e itB and ![
$$S_{\\hslash t}$$
](A272900_1_En_14_Chapter_IEq38.gif) agree on each of the functions ![
$$\\psi_{n},\\,n\\,\\in\\,\\mathbb{Z},$$
](A272900_1_En_14_Chapter_IEq39.gif) and thus on all of L 2([ − 1, 1]).

Having computed both e isA and e itB , we may now easily see that these operators do not satisfy the exponentiated commutation relations. We have, for example, that

![
$$\\displaystyle{{e}^{isA}{e}^{itB}\\mathbf{1} = {e}^{isx},}$$
](A272900_1_En_14_Chapter_Equq.gif)

whereas

![
$$\\displaystyle{{e}^{itB}{e}^{isA}\\mathbf{1} = {e}^{is\(x+t\\hslash -2m_{x,a}\)}.}$$
](A272900_1_En_14_Chapter_Equr.gif)

The function ![
$${e}^{is\(x+t\\hslash -2m_{x,a}\)}$$
](A272900_1_En_14_Chapter_IEq40.gif) is not equal to ![
$${e}^{ist\\hslash }{e}^{isx}$$
](A272900_1_En_14_Chapter_IEq41.gif) but rather to

![
$$\\displaystyle{{e}^{ist\\hslash }{e}^{isx}{e}^{-2ism_{x,a} },}$$
](A272900_1_En_14_Chapter_Equs.gif)

where ![
$${e}^{-2ism_{x,a}}$$
](A272900_1_En_14_Chapter_IEq42.gif) is not always equal to 1. ■

## 14.3 The Theorem

We give two versions of the Stone–von Neumann theorem, one for general operators satisfying the exponentiated commutation relations and one for the special case where the operators act irreducibly.

Definition 14.6.

Operators A 1 ,...,A n and B 1 ,...,B n satisfying the exponentiated commutation relations are said to act irreducibly on H if the only closed subspaces of H that are invariant under every ![
$${e}^{itA_{j}}$$
](A272900_1_En_14_Chapter_IEq43.gif) and every ![
$${e}^{itB_{j}}$$
](A272900_1_En_14_Chapter_IEq44.gif) are {0} and H.

Proposition 14.7.

The usual position and momentum operators act irreducibly on ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_14_Chapter_IEq45.gif)

We delay the proof of this result until near the end of this section.

Theorem 14.8 (Stone–von Neumann Theorem).

Suppose A 1 ,...,A n and B 1 ,...,B n are self-adjoint operators on H satisfying the exponentiated commutation relations. Then H can be decomposed as an orthogonal direct sum of closed subspaces {V l} with the following properties. First, each V l is invariant under ![
$${e}^{itA_{j}}$$
](A272900_1_En_14_Chapter_IEq46.gif) and ![
$${e}^{itB_{j}}$$
](A272900_1_En_14_Chapter_IEq47.gif) for all j and t. Second, there exist unitary operators ![
$$U_{l} : V _{l} \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq48.gif) such that

![
$$\\displaystyle{U_{l}{e}^{itA_{j} }U_{l}^{-1} = {e}^{itX_{j} }}$$
](A272900_1_En_14_Chapter_Equt.gif)

and

![
$$\\displaystyle{U_{l}{e}^{itB_{j} }U_{l}^{-1} = {e}^{itP_{j} }}$$
](A272900_1_En_14_Chapter_Equu.gif)

for all j and t.

If, in addition, the A's and B's act irreducibly on H, then there exists a single unitary map ![
$$U : \\mathbf{H} \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq49.gif) such that

![
$$\\displaystyle{U{e}^{itA_{j} }{U}^{-1} = {e}^{itX_{j} }}$$
](A272900_1_En_14_Chapter_Equv.gif)

and

![
$$\\displaystyle{U{e}^{itB_{j} }{U}^{-1} = {e}^{itP_{j} },}$$
](A272900_1_En_14_Chapter_Equw.gif)

for all t. The map U is unique up to multiplication by a constant of absolute value 1.

The preceding results can be expressed in terms of the Heisenberg group; see Exercise 6.

Our strategy (as in von Neumann's 1931 paper [41]) in proving Theorem 14.8 is to follow the outline of the heuristic argument in Sect. 14.1, but replacing the unbounded raising and lowering operators by the bounded operators e i(a ⋅A \+ b ⋅B) in Notation 14.3. If we define ![
$$\\phi _{0} \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq50.gif) by

![
$$\\displaystyle{ \\phi _{0}\(\\mathbf{x}\) = {\(\\pi \\sigma\)}^{-n/4}{e}^{-{\\left\\vert \\mathbf{x}\\right\\vert }^{2}/\(2\\sigma\) }, }$$
](A272900_1_En_14_Chapter_Equ18.gif)

(14.12)

for some σ > 0, then ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10016.gif) is a unit vector, which we may think of as the ground state of an n-dimensional harmonic oscillator with frequency ![
$$\\omega = \\hslash /\(m\\sigma\).$$
](A272900_1_En_14_Chapter_IEq51.gif) We can easily compute the Weyl symbol of the projection ![
$$\\left\\vert \\phi _{0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert$$
](A272900_1_En_14_Chapter_IEq52.gif) onto ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10017.gif) as follows:

![
$$\\displaystyle{ f_{0}\(\\mathbf{x},\\mathbf{p}\) := Q_{\\mathrm{Weyl}}^{-1}\(\\left\\vert \\phi _{ 0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert\) = {2}^{n}{e}^{-{\\left\\vert \\mathbf{x}\\right\\vert }^{2}/\\sigma }{e}^{-\\sigma {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/{\\hslash }^{2} }. }$$
](A272900_1_En_14_Chapter_Equ19.gif)

(14.13)

(See Exercise 9 in Chap.​ 13).

We may define a generalized Weyl quantization Q for H by using the operators e i(a ⋅A \+ b ⋅B) in place of the operators e i(a ⋅X \+ b ⋅P) in (13.​17). We will show that the operator P : = Q(f 0) is an orthogonal projection, and we will take W : = Range(P) as our space of ground states in H. A crucial result will be that the projection P is nonzero and, indeed, that the restriction of P to any nonzero subspace invariant under the e i(a ⋅A \+ b ⋅B)'s is nonzero.

If ![
$$\\{\\psi^{l}\\}$$
](A272900_1_En_14_Chapter_IEq1004.gif) is an orthonormal basis for W, consider the vectors

![
$$\\displaystyle{\\psi _{\\mathbf{a},\\mathbf{b}}^{l} := {e{}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\psi }^{l}.}$$
](A272900_1_En_14_Chapter_Equx.gif)

We will show that these vectors are orthogonal for different values of l, and that for fixed l, the inner product of two such vectors is the same as in the ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq53.gif) case. Thus, if V l denotes the closed span of the ![
$$\\psi _{\\mathbf{a},\\mathbf{b}}^{l}$$
](A272900_1_En_14_Chapter_IEq54.gif)'s with l fixed and a and b varying, we can construct a unitary map from V l to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq55.gif) that intertwines the operators e i(a ⋅A \+ b ⋅B) with the operators e i(a ⋅X \+ b ⋅P). The sum of the V l 's must be all of H, for if not, the orthogonal complement Y of the span would be invariant under the e i(a ⋅A \+ b ⋅B)'s. Thus, the restriction of P to Y would be nonzero, implying that there are elements of W : = Range(P) orthogonal to every ![
$$\\psi^{l}$$
](A272900_1_En_14_Chapter_IEq105.gif), contradicting the assumption that the ![
$$ \\psi^{l,}\\text{s span }W $$
](A272900_1_En_14_Chapter_IEq1006.gif).

The rest of this section will flesh out the argument sketched in the preceding paragraphs.

Definition 14.9.

Suppose self-adjoint operators A 1 ,...,A n and B 1 ,...,B n satisfy the exponentiated commutation relations on H . For any ![
$$f \\in \\mathcal{S}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_14_Chapter_IEq56.gif) define ![
$$Q\(f\) \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq57.gif) by the formula

![
$$\\displaystyle{Q\(f\) = {\(2\\pi\)}^{-n}\\int _{{ \\mathbb{R}}^{2n}}\\hat{f}\(\\mathbf{a},\\mathbf{b}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\ d\\mathbf{a}\\ d\\mathbf{b,}}$$
](A272900_1_En_14_Chapter_Equy.gif)

where ![
$$\\hat{f}$$
](A272900_1_En_14_Chapter_IEq58.gif) is the Fourier transform of f and where e i(a⋅A + b⋅B) is as in Notation 14.3. The integral is a Bochner integral with values in the Banach space ![
$$\\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_14_Chapter_IEq59.gif)

We will assume the following standard properties of the Bochner integral (Sect. V.5 of [46]). First, any continuous function ![
$$f : {\\mathbb{R}}^{2n} \\rightarrow \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq60.gif) for which ![
$$\\int \\left\\Vert f\(x\)\\right\\Vert \\ dx < \\infty $$
](A272900_1_En_14_Chapter_IEq61.gif) has a well-defined Bochner integral. Second, the Bochner integral commutes with applying bounded linear transformations. Third, a version of Fubini's theorem holds.

Proposition 14.10.

For any operators satisfying the exponentiated commutation relations, the associated map Q in Definition 14.9 has the following properties.

1.

If ![
$$f \\in \\mathcal{S}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_14_Chapter_IEq62.gif) is real valued, Q(f) is self-adjoint.

2.

For all a and b in ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_14_Chapter_IEq63.gif) and ![
$$f \\in \\mathcal{S}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_14_Chapter_IEq64.gif) we have

![
$$\\displaystyle\\begin{array}{rcl}{ e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}Q\(f\)& =& Q\({f}^{{\\prime}}\) {}\\\\ Q\(f\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}& =& Q\({f}^{{\\prime\\prime}}\), {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ20.gif)

where f ′ and f ″ are the functions with Fourier transforms given by

![
$$\\displaystyle\\begin{array}{rcl} \\widehat{{f}^{{\\prime}}}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)& =& {e}^{i\\hslash \({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{b}-\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}\)/2 }\\ \\hat{f}\({\\mathbf{a}}^{{\\prime}}-\\mathbf{a},{\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\) {}\\\\ \\widehat{{f}^{{\\prime\\prime}}}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)& =& {e}^{-i\\hslash \({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{b}-\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}\)/2 }\\hat{f}\({\\mathbf{a}}^{{\\prime}}-\\mathbf{a},{\\mathbf{b}}^{{\\prime}}-\\mathbf{b\)} {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ21.gif)

3.

For all f and g in ![
$$\\mathcal{S}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_14_Chapter_IEq65.gif) we have

![
$$\\displaystyle{Q\(f\)Q\(g\) = Q\(f \\star g\),}$$
](A272900_1_En_14_Chapter_Equz.gif)

where ⋆ is the Moyal product described in Proposition 13.9 .

4.

For all ![
$$f \\in \\mathcal{S}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_14_Chapter_IEq66.gif) if Q(f) = 0 then f = 0.

Using both parts of Point 14.10 of the theorem, we can see that for all ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_14_Chapter_IEq67.gif) we have

![
$$\\displaystyle{{e}^{-i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}Q\(f\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)} = Q\(g\),}$$
](A272900_1_En_14_Chapter_Equaa.gif)

where

![
$$\\displaystyle{ \\hat{g}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\) = {e}^{i\\hslash \({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{b}-\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}\) }\\hat{f}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\). }$$
](A272900_1_En_14_Chapter_Equ22.gif)

(14.14)

Proof.

For Point 14.10, we can re-express Q(f) as

![
$$\\displaystyle{{\(2\\pi\)}^{-n}\\int _{{ \\mathbb{R}}^{2n}}\\frac{1} {2}\\left\[\\hat{f}\(\\mathbf{a},\\mathbf{b}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)} +\\hat{ f}\(-\\mathbf{a},-\\mathbf{b}\){e}^{-i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\right\]\\ d\\mathbf{a}\\ d\\mathbf{b,}}$$
](A272900_1_En_14_Chapter_Equab.gif)

since the change of variable a ′ = − a, b ′ = − b brings the second term equal to the first term. If f is real valued, then ![
$$\\hat{f}\(-\\mathbf{a},-\\mathbf{b}\)$$
](A272900_1_En_14_Chapter_IEq68.gif) is the conjugate of ![
$$\\hat{f}\(\\mathbf{a},\\mathbf{b}\),$$
](A272900_1_En_14_Chapter_IEq69.gif) so that the expression in square brackets in the integral is self-adjoint for each (a, b).

For the first part of Point 14.10, we use (14.10) to obtain

![
$$\\displaystyle\\begin{array}{rcl} & & {e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}Q\(f\) {}\\\\ & =& {\(2\\pi\)}^{-n}\\int _{{ \\mathbb{R}}^{2n}}{e}^{-i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }\\hat{f}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\){e}^{i\(\(\\mathbf{a}+{\\mathbf{a}}^{{\\prime}}\)\\cdot \\mathbf{A}+\(\\mathbf{b}+{\\mathbf{b}}^{{\\prime}}\)\\cdot \\mathbf{B}\) }\\ d{\\mathbf{a}}^{{\\prime}}\\ d{\\mathbf{b}}^{{\\prime}}\\mathbf{.} {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ23.gif)

Making the change of variables a ′ ′ = a ′ \+ a and b ′ ′ = b ′ \+ b and simplifying gives the desired result. The proof of the second part of Point 2 is similar.

The proof of Point 3 is precisely the same as the proof of Proposition 13.9, which relies only on the exponentiated commutation relations.

For Point 4, suppose that Q(f) = 0 for some ![
$$f \\in \\mathcal{S}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_14_Chapter_IEq70.gif) Then for all ![
$$\\phi,\\psi\\,\\in\\,\\bf{H}\\text{ and all }\\mathbf{a},\\mathbf{b} \\in \\mathbb{R}^\\textit{n},$$
](A272900_1_En_14_Chapter_IEq71.gif) we have

![
$$\\displaystyle\\begin{array}{rcl} 0& =& \\left\\langle {e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\phi,Q\(f\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\psi \\right\\rangle {}\\\\ & =& \\left\\langle \\phi,{e}^{-i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}Q\(f\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\psi \\right\\rangle {}\\\\ & =& \\left\\langle \\phi,Q\(g\)\\psi \\right\\rangle {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ24.gif)

where g is as in (14.14). Thus,

![
$$\\displaystyle{ 0 =\\int {e}^{i\\hslash \({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{b}-\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}\) }\\hat{f}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)\\left\\langle \\phi,{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{A}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{B}\) }\\psi \\right\\rangle \\ d{\\mathbf{a}}^{{\\prime}}\\ d{\\mathbf{b}}^{{\\prime}} }$$
](A272900_1_En_14_Chapter_Equ25.gif)

(14.15)

for all ![
$$ \\phi,\\psi\\text{ and }\\bf{a, b}$$
](A272900_1_En_14_Chapter_IEq10006.gif). But (14.15) is just computing the inverse Fourier transform of the function ![
$$\\hat{f}\({\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}\)\\langle \\phi,{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{A}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{B}\) }\\psi \\rangle,$$
](A272900_1_En_14_Chapter_IEq72.gif) evaluated at the point (− a,b). By the Fourier inversion formula, then, this function must be zero for almost every pair (a ′ , b ′ ). Now, the function ![
$$\\langle \\phi,{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{A}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{B}\) }\\psi \\rangle$$
](A272900_1_En_14_Chapter_IEq73.gif) is a continuous function of (a, b) and by taking ![
$$\\phi = {e}^{i\(\\mathbf{a}_{0}\\cdot \\mathbf{A}+\\mathbf{b}_{0}\\cdot \\mathbf{B}\)}\\psi,$$
](A272900_1_En_14_Chapter_IEq74.gif) it can be made to be nonzero at any given point (a 0, b 0) in ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_14_Chapter_IEq75.gif) and thus also in a neighborhood of that point. Thus, actually, ![
$$\\hat{f}$$
](A272900_1_En_14_Chapter_IEq76.gif) is identically zero and so also is f. ■

Lemma 14.11.

Let f 0 be the function on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_14_Chapter_IEq77.gif) given by

![
$$\\displaystyle{f_{0}\(\\mathbf{x},\\mathbf{p}\) = {2}^{n}{e}^{-{\\left\\vert \\mathbf{x}\\right\\vert }^{2}/\\sigma }{e}^{-\\sigma {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/{\\hslash }^{2} },}$$
](A272900_1_En_14_Chapter_Equac.gif)

where σ is a fixed positive number. Then for all ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_14_Chapter_IEq78.gif) we have

![
$$\\displaystyle{ Q\(f_{0}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}Q\(f_{ 0}\) = {e}^{-\\sigma {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/4 }{e}^{-{\\hslash }^{2}{\\left\\vert \\mathbf{b}\\right\\vert }^{2}/\(4\\sigma\) }Q\(f_{0}\). }$$
](A272900_1_En_14_Chapter_Equ26.gif)

(14.16)

In particular,

![
$$\\displaystyle{Q{\(f_{0}\)}^{2} = Q\(f_{ 0}\).}$$
](A272900_1_En_14_Chapter_Equad.gif)

Proof.

By Proposition 14.10, (14.16) is equivalent to the assertion that

![
$$\\displaystyle{ f_{0} \\star f_{0}^{{\\prime}} = {e}^{-\\sigma {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/4 }{e}^{-{\\hslash }^{2}{\\left\\vert \\mathbf{b}\\right\\vert }^{2}/\(4\\sigma\) }f_{0}. }$$
](A272900_1_En_14_Chapter_Equ27.gif)

(14.17)

Now, it is certainly possible to establish (14.17) by direct computation from the definitions of f 0 ′ and ⋆ ; all the integrals involved will be Gaussian integrals, which can be evaluated by means of Proposition A.22. This approach, however, is both painful and unilluminating. A more sensible approach is to observe that is suffices to verify (14.16) for the ordinary Weyl quantization on ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_14_Chapter_IEq79.gif) After all, (14.16) is equivalent to (14.17), which in turn is equivalent to the identity

![
$$\\displaystyle\\begin{array}{rcl} & & Q_{\\mathrm{Weyl}}\(f_{0}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}Q_{\\mathrm{ Weyl}}\(f_{0}\) \\\\ & =& {e}^{-\\sigma {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/4 }{e}^{-{\\hslash }^{2}{\\left\\vert \\mathbf{b}\\right\\vert }^{2}/\(4\\sigma\) }Q_{\\mathrm{Weyl}}\(f_{0}\),{}\\end{array}$$
](A272900_1_En_14_Chapter_Equ28.gif)

(14.18)

by applying Proposition 14.10 in the case Q = Q Weyl.

Now, by Exercise 9 in Chap.​ 13, Q Weyl(f 0) is the one-dimensional projection ![
$$\\left\\vert \\phi _{0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert,$$
](A272900_1_En_14_Chapter_IEq80.gif) where ![
$$\\phi _{0}\(\\mathbf{x}\) = {\(\\pi \\alpha\)}^{-n/4}{e}^{-{\\left\\vert \\mathbf{x}\\right\\vert }^{2}/\(2\\sigma\) }$$
](A272900_1_En_14_Chapter_IEq81.gif). Thus,

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{Weyl}}\(f_{0}\){e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}Q_{\\mathrm{ Weyl}}\(f_{0}\)& =& \\left\\vert \\phi _{0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert {e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}\\left\\vert \\phi _{ 0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert \\\\ & =& c\\left\\vert \\phi _{0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert, {}\\end{array}$$
](A272900_1_En_14_Chapter_Equ29.gif)

(14.19)

where

![
$$\\displaystyle{c = \\left\\langle \\phi _{0}\\right\\vert {e}^{i\(\\mathbf{a}\\cdot \\mathbf{X}+\\mathbf{b}\\cdot \\mathbf{P}\)}\\left\\vert \\phi _{ 0}\\right\\rangle.}$$
](A272900_1_En_14_Chapter_Equae.gif)

To compute c, we use (13.​20), which gives

![
$$\\displaystyle{ c = {\(\\pi \\alpha\)}^{-n/2}{e}^{i\\hslash \(\\mathbf{a}\\cdot \\mathbf{b}\)/2}\\int _{{ \\mathbb{R}}^{n}}{e}^{-{\\left\\vert \\mathbf{x}\\right\\vert }^{2}/\(2\\sigma\) }{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}{e}^{-{\\left\\vert \\mathbf{x}+\\hslash \\mathbf{b}\\right\\vert }^{2}/\(2\\sigma\) }\\ d\\mathbf{x.} }$$
](A272900_1_En_14_Chapter_Equ30.gif)

(14.20)

The integral in (14.20) can be computed by expanding ![
$${\\left\\vert \\mathbf{x} + \\hslash \\mathbf{b}\\right\\vert }^{2},$$
](A272900_1_En_14_Chapter_IEq82.gif) collecting terms in the exponent, and applying Proposition A.22. The result, after a bit of algebra, is

![
$$\\displaystyle{c = {e}^{-\\sigma {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/4 }{e}^{-\\hslash {\\left\\vert \\mathbf{b}\\right\\vert }^{2}/\(4\\sigma\) },}$$
](A272900_1_En_14_Chapter_Equaf.gif)

which gives (14.18). ■

We now prove the claimed irreducibility of the usual position and momentum operators.

Proof of Proposition 14.7.

Given operators A 1,..., A n and B 1,..., B n satisfying the exponentiated commutation relations, consider the operator Q(f 0), where f 0 is as in (14.13). According to Lemma 14.11, ![
$$Q{\(f_{0}\)}^{2} = Q\(f_{0}\).$$
](A272900_1_En_14_Chapter_IEq83.gif) Since also f 0 is real valued, Q(f 0) is self-adjoint and thus an orthogonal projection. Suppose that the range of the orthogonal projection Q(f 0) is one-dimensional. We then claim that the A 's and B's act irreducibly. If not, there would exist a nontrivial closed subspace V that is invariant under each of the operators e i(a ⋅A \+ b ⋅B). Then the nonzero subspace V ⊥ would also be invariant under each of the operators ![
$${\({e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\)}^{{\\ast}} = {e}^{-i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}.$$
](A272900_1_En_14_Chapter_IEq84.gif) Thus, the exponentiated commutation relations are satisfied in both V and V ⊥, with the A's and B's being the infinitesimal generators of the restrictions of ![
$${e}^{itA_{j}}$$
](A272900_1_En_14_Chapter_IEq85.gif) and ![
$${e}^{itB_{j}}$$
](A272900_1_En_14_Chapter_IEq86.gif) to each subspace.

It follows that the restriction of Q(f 0) to each of these subspaces may be thought of as the generalized Weyl quantizations for V and V ⊥ of the function f 0. Applying Point 14.10 of Proposition 14.10 to V and to V ⊥, we conclude that the restrictions of Q(f 0) to V and to V ⊥ are nonzero. Thus, both V and V ⊥ will contain nonzero elements of Range(Q(f 0)), contradicting our assumption that Range(Q(f 0)) is one dimensional.

In case of ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_14_Chapter_IEq87.gif) we have ![
$$Q_{\\mathrm{Weyl}}\(f_{0}\) = \\left\\vert \\phi _{0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert$$
](A272900_1_En_14_Chapter_IEq88.gif), where ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq100107.gif) is given by (14.12), which clearly has a one-dimensional range. Thus, the usual position and momentum operators act irreducibly on ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_14_Chapter_IEq89.gif) ■

We are finally ready for the proof of the Stone–von Neumann theorem.

Proof of Theorem 14.8.

Let W = Range(Q(f 0)), where f 0 is given by (14.13) for some fixed σ > 0. For ![
$$ \\phi,\\psi\\,\\in\\,\\textit{W}$$
](A272900_1_En_14_Chapter_IEq1007.gif), we can use (14.10), Lemma 14.11, and the fact that Q(f 0) is the identity on W to obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\left\\langle {e}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\phi,{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{A}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{B}\) }\\psi \\right\\rangle \\\\ & =& \\left\\langle Q\(f_{0}\)\\phi,{e}^{-i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}{e}^{i\({\\mathbf{a}}^{{\\prime}}\\cdot \\mathbf{A}+{\\mathbf{b}}^{{\\prime}}\\cdot \\mathbf{B}\) }Q\(f_{0}\)\\psi \\right\\rangle \\\\ & =& {e}^{i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }\\left\\langle \\phi,Q\(f_{0}\){e}^{i\(\({\\mathbf{a}}^{{\\prime}}-\\mathbf{a}\)\\cdot \\mathbf{A}+\({\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\)\\cdot \\mathbf{B}\) }Q\(f_{0}\)\\psi \\right\\rangle \\\\ & =& {e}^{i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }{e}^{-\\sigma {\\left\\vert {\\mathbf{a}}^{{\\prime}}-\\mathbf{a}\\right\\vert }^{2}/4 }{e}^{-{\\hslash }^{2}{\\left\\vert {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\right\\vert }^{2}/\(4\\sigma\) }\\left\\langle \\phi,\\psi \\right\\rangle. {}\\end{array}$$
](A272900_1_En_14_Chapter_Equ31.gif)

(14.21)

Now let ![
$$\\{\\psi^{l}\\}$$
](A272900_1_En_14_Chapter_IEq01.gif) be an orthonormal basis for W and define vectors ![
$$\\psi_{\\rm a,b^{,}}^{l}\\,\\mathbf{a},\\mathbf{b} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_14_Chapter_IEq90.gif) by

![
$$\\displaystyle{\\psi _{\\mathbf{a},\\mathbf{b}}^{l} = {e{}^{i\(\\mathbf{a}\\cdot \\mathbf{A}+\\mathbf{b}\\cdot \\mathbf{B}\)}\\psi }^{l}.}$$
](A272900_1_En_14_Chapter_Equag.gif)

By (14.21), ![
$$\\psi_{\\rm{a,b^{,}}}^{l} \\textrm{ is orthogonal to }\\psi _{{\\mathbf{a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}}^{{l}^{{\\prime}} }$$
](A272900_1_En_14_Chapter_IEq91.gif) whenever l≠l ′ . Furthermore,

![
$$\\displaystyle{ \\left\\langle \\psi _{\\mathbf{a},\\mathbf{b}}^{l},\\psi _{{\\mathbf{ a}}^{{\\prime}},{\\mathbf{b}}^{{\\prime}}}^{l}\\right\\rangle = {e}^{i\\hslash \(\\mathbf{a}\\cdot {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\cdot {\\mathbf{a}}^{{\\prime}}\)/2 }{e}^{-\\sigma {\\left\\vert {\\mathbf{a}}^{{\\prime}}-\\mathbf{a}\\right\\vert }^{2}/4 }{e}^{-{\\hslash }^{2}{\\left\\vert {\\mathbf{b}}^{{\\prime}}-\\mathbf{b}\\right\\vert }^{2}/\(4\\sigma\) }, }$$
](A272900_1_En_14_Chapter_Equ32.gif)

(14.22)

where the right-hand side of (14.22) is "universal," that is, independent of l and independent of the particular Hilbert space in which we are working.

Let V l be the closed span of the vectors ![
$$\\psi_{\\rm{a,b}}^{l}$$
](A272900_1_En_14_Chapter_IEq02.gif) with l fixed and a, b varying. We may define a map ![
$$U_{l} : V _{l} \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq92.gif) by requiring that

![
$$\\displaystyle{U_{l}\\left\(\\sum _{j=1}^{N}\\alpha _{ j}\\psi _{\\mathbf{a}_{j},\\mathbf{b}_{j}}^{l}\\right\) =\\sum _{ j=1}^{N}\\alpha _{ j}\\phi _{\\mathbf{a}_{j},\\mathbf{b}_{j}},}$$
](A272900_1_En_14_Chapter_Equah.gif)

for every sequence a 1,..., a N and b 1,..., b N of vectors, where

![
$$\\displaystyle{\\phi _{\\mathbf{a},\\mathbf{b}} = {e}^{i\(\\mathbf{a\\cdot X}+\\mathbf{b}\\cdot \\mathbf{P}\)}\\phi _{ 0}.}$$
](A272900_1_En_14_Chapter_Equai.gif)

This map is isometric by (14.22) on linear combinations of the ![
$$\\psi_{\\rm{a,b}}^{l}$$
](A272900_1_En_14_Chapter_IEq03.gif) 's and thus extends uniquely to an isometric map of V l into ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_14_Chapter_IEq93.gif) [In particular, U l is well defined: If some linear combination of ![
$$\\psi_{\\rm{a,b}}^{l}$$
](A272900_1_En_14_Chapter_IEq04.gif)'s is zero, then this linear combination has norm zero and so its image under U l also has norm zero and is thus zero in ![
$${L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_14_Chapter_IEq94.gif)]

Now, V l is invariant under the operators e i(a ⋅A \+ b ⋅B) by (14.10), and, similarly, the image of V l under U l is invariant under the operators e i(a ⋅X \+ b ⋅P). By the irreducibility of ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq95.gif) (Proposition 14.7), we conclude that V l maps onto ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq96.gif) and is, therefore, unitary. Furthermore, using (14.10) and the analogous expression (13.​31) for the position and momentum operators, it is easy to check that each U l intertwines e i(a ⋅A \+ b ⋅B) with e i(a ⋅A \+ b ⋅B), for all ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{R}}^{n}.$$
](A272900_1_En_14_Chapter_IEq97.gif) In particular, taking either a = t e j and b = 0 or a = 0 and b = t e j we see that U l intertwines ![
$${e}^{itA_{j}}$$
](A272900_1_En_14_Chapter_IEq98.gif) with ![
$${e}^{itX_{j}}.$$
](A272900_1_En_14_Chapter_IEq99.gif) Similarly, U l intertwines ![
$${e}^{itB_{j}}$$
](A272900_1_En_14_Chapter_IEq100.gif) with ![
$${e}^{itP_{j}}.$$
](A272900_1_En_14_Chapter_IEq101.gif)

We now argue that the Hilbert space direct sum of the orthogonal subspaces V l is all of H. If not, then as in the proof of Proposition 14.7, the orthogonal complement Y of this sum would be invariant under the operators e i(a ⋅A \+ b ⋅B) and thus also under the operator Q(f 0). Furthermore, as in the proof of Proposition 14.7, the restriction of Q(f 0) to Y would be nonzero. Thus, there would exist elements of W = Range(Q(f 0)) orthogonal to each ![
$$\\psi^{l}$$
](A272900_1_En_14_Chapter_IEq05.gif), contradicting the assumption that the ![
$$\\psi^{l}$$
](A272900_1_En_14_Chapter_IEq06.gif)'s span W.

It remains only to address the irreducible case. If the A's and B's act irreducibly, then there can be only one subspace, V 1 = H, which means that W must be one dimensional. Any unitary map ![
$$U : \\mathbf{H} \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq102.gif) that intertwines each operator e i(a ⋅A \+ b ⋅B) with e i(a ⋅X \+ b ⋅P) must also intertwine each operator of the form Q(f) with Q Weyl(f). It follows that U must map the one-dimensional subspace W unitarily onto the one-dimensional range of ![
$$Q_{\\mathrm{Weyl}}\(f_{0}\) = \\left\\vert \\phi _{0}\\right\\rangle \\left\\langle \\phi _{0}\\right\\vert.$$
](A272900_1_En_14_Chapter_IEq103.gif) Thus, the restriction of U to W is unique up to a constant of absolute value 1. But the reasoning leading to the existence of U shows that U is determined by its action on W, so the entire map U is unique up to a constant. ■

## 14.4 The Segal–Bargmann Space

A simple example of the Stone–von Neumann theorem is provided by the Hilbert space ![
$$\\mathbf{H} := {L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_14_Chapter_IEq104.gif) together with the operators A j : = P j , and B j : = − X j . In that case (Exercise 3), the unitary map U in the Stone–von Neumann theorem will simply be a scaled version of the Fourier transform, as in Definition 6.1. To obtain a more interesting example, we construct a Hilbert space consisting of holomorphic functions on ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_14_Chapter_IEq1005.gif)

### 14.4.1 The Raising and Lowering Operators

A smooth function on ![
$$F : {\\mathbb{C}}^{n} \\rightarrow \\mathbb{C}$$
](A272900_1_En_14_Chapter_IEq106.gif) is said to be holomorphic if it is holomorphic as a function of z j with the other z k 's fixed. Equivalently, F is holomorphic if ![
$$\\partial F/\\partial \\bar{z}_{j} = 0,$$
](A272900_1_En_14_Chapter_IEq107.gif) where

![
$$\\displaystyle{ \\frac{\\partial } {\\partial \\bar{z}_{j}} = \\frac{1} {2}\\left\(\\frac{\\partial } {\\partial x_{j}} + i \\frac{\\partial } {\\partial y_{j}}\\right\).}$$
](A272900_1_En_14_Chapter_Equaj.gif)

The operator

![
$$\\displaystyle{ \\frac{\\partial } {\\partial z_{j}} := \\frac{1} {2}\\left\(\\frac{\\partial } {\\partial x_{j}} - i \\frac{\\partial } {\\partial y_{j}}\\right\)}$$
](A272900_1_En_14_Chapter_Equak.gif)

preserves the space of holomorphic functions on ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_14_Chapter_IEq108.gif)

Considered the operators z j (i.e., multiplication by z j ) and ![
$$\\hslash \\ \\partial /\\partial z_{j},$$
](A272900_1_En_14_Chapter_IEq109.gif) acting on the space of holomorphic functions on ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_14_Chapter_IEq110.gif) Fock [9] observed that these operators satisfy the following commutation relations:

![
$$\\displaystyle\\begin{array}{rcl} \[z_{j},z_{k}\]& =& \\left\[\\hslash \\frac{\\partial } {\\partial z_{j}}, \\hslash \\frac{\\partial } {\\partial z_{k}}\\right\] = 0 \\\\ \\left\[\\hslash \\frac{\\partial } {\\partial z_{j}},z_{k}\\right\]& =& \\hslash \\delta _{jk}I. {}\\end{array}$$
](A272900_1_En_14_Chapter_Equ33.gif)

(14.23)

These are essentially the same commutation relations as the raising and lowering operators considered in Sect.​ 11.​2. Specifically, (14.23) are the relations that would be satisfied by the natural higher-dimensional analogs of the operators a and a ∗ in that section if we omitted the factor of ![
$$\\sqrt{\\hslash }$$
](A272900_1_En_14_Chapter_IEq111.gif) in the denominator in (11.​4) and (11.​5).

Now, if we wish to interpret the operators z j and ![
$$\\hslash \\ \\partial /\\partial z_{j}$$
](A272900_1_En_14_Chapter_IEq112.gif) as raising and lowering operators, then we should look for an inner product on the space of holomorphic functions that would make these two operators adjoints of each other. After all, the analysis in Chap.​ 11 strongly depends on the assumption that a and a ∗ are adjoints of each other. In the early 1960s, Segal [36] and Bargmann [2] identified such an inner product. Once we have described this Segal–Bargmann inner product, we will construct self-adjoint "position" and "momentum" operators as appropriate linear combinations of z j and ![
$$\\hslash \\ \\partial /\\partial z_{j}.$$
](A272900_1_En_14_Chapter_IEq113.gif) We will then verify the exponentiated commutation relations and irreducibility, allowing us to apply the Stone–von Neumann theorem.

We look for an L 2 inner product with respect to a measure having a positive density with respect to the Lebesgue measure on ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_14_Chapter_IEq114.gif)

Lemma 14.12.

Suppose that μ is a smooth, strictly positive density on ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_14_Chapter_IEq115.gif) and that F and G are sufficiently nice (but not necessarily holomorphic) functions on ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_14_Chapter_IEq116.gif) . Then

![
$$\\displaystyle\\begin{array}{rcl} & & \\int _{{\\mathbb{C}}^{n}}\\overline{F\(\\mathbf{z}\)} \\frac{\\partial G} {\\partial z_{j}}\\mu \(\\mathbf{z}\)\\ d\\mathbf{z} \\\\ & =& -\\int _{{\\mathbb{C}}^{n}}\\overline{ \\frac{\\partial F} {\\partial \\bar{z}_{j}}}G\(\\mathbf{z}\)\\mu \(\\mathbf{z}\)\\ d\\mathbf{z} -\\int _{{\\mathbb{C}}^{n}}\\overline{ \\frac{\\partial \\log \\mu } {\\partial \\bar{z}_{j}}F\(\\mathbf{z}\)}\\ G\(\\mathbf{z}\)\\ d\\mathbf{z},{}\\end{array}$$
](A272900_1_En_14_Chapter_Equ34.gif)

(14.24)

where d z denotes the 2n-dimensional Lebesgue measure on ![
$${\\mathbb{C}}^{n}\\mathop{\\cong}{\\mathbb{R}}^{2n}.$$
](A272900_1_En_14_Chapter_IEq117.gif)

Equation (14.24) tells us that

![
$$\\displaystyle{{\\left\(\\frac{\\partial } {\\partial z_{j}}\\right\)}^{{\\ast}} = - \\frac{\\partial } {\\partial \\bar{z}_{j}} - \\frac{\\partial \\log \\mu } {\\partial \\bar{z}_{j}},}$$
](A272900_1_En_14_Chapter_Equal.gif)

where the adjoint is computed with respect to the inner product for the Hilbert space ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu\).$$
](A272900_1_En_14_Chapter_IEq118.gif) If we restrict the adjoint operator (∂ ∕ ∂ z j )∗ to the space of holomorphic functions, then the ![
$$\\partial /\\partial \\bar{z}_{j}$$
](A272900_1_En_14_Chapter_IEq119.gif) term is zero, by the definition of a holomorphic function.

Proof.

Let us approximate the integral over ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_14_Chapter_IEq120.gif) on the left-hand side of (14.24) by an integral over a large cube. By performing either the x j -integral or the y j -integral first, we can integrate by parts to push the derivatives with respect to x j or y j off of G and onto the product of ![
$$\\bar{F}$$
](A272900_1_En_14_Chapter_IEq121.gif) and μ (with a minus sign). The boundary term in the integration by parts will involve the function ![
$$\\overline{F\(\\mathbf{z}\)}G\(\\mathbf{z}\)\\mu \(\\mathbf{z\)}$$
](A272900_1_En_14_Chapter_IEq122.gif) integrated over two opposite faces of the cube. If this function tends to zero sufficiently rapidly at infinity, the boundary terms will vanish in the limit. In that case, we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\int _{{\\mathbb{C}}^{n}}\\overline{F\(\\mathbf{z}\)} \\frac{\\partial G} {\\partial z_{j}}\\mu \(\\mathbf{z}\)\\ d\\mathbf{z} {}\\\\ & =& -\\int _{{\\mathbb{C}}^{n}}\\left\(\\frac{\\partial } {\\partial z_{j}}\\overline{F\(\\mathbf{z}\)}\\right\)G\(\\mathbf{z}\)\\mu \(\\mathbf{z}\)\\ d\\mathbf{z} -\\int _{{\\mathbb{C}}^{n}}\\overline{F\(\\mathbf{z}\)}G\(\\mathbf{z}\) \\frac{\\partial \\mu } {\\partial z_{j}}\\ d\\mathbf{z}, {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ35.gif)

provided that all three of the above integrals are absolutely convergent. Since ![
$$\\partial \\bar{F}/\\partial z_{j} = \\overline{\\partial F/\\partial \\bar{z}_{j}}$$
](A272900_1_En_14_Chapter_IEq123.gif) and

![
$$\\displaystyle{ \\frac{\\partial \\mu } {\\partial z_{j}} = \\frac{\\partial \\log \\mu } {\\partial z_{j}}\\mu = \\overline{ \\frac{\\partial \\log \\mu } {\\partial \\bar{z}_{j}}}\\mu,}$$
](A272900_1_En_14_Chapter_Equam.gif)

we obtain (14.24). ■

We now look for a density ![
$$\\mu _{\\hslash }$$
](A272900_1_En_14_Chapter_IEq124.gif) for which ![
$$\\partial \\log \\mu /\\partial \\bar{z}_{j} = -z_{j}/\\hslash.$$
](A272900_1_En_14_Chapter_IEq125.gif) In that case, the adjoint operator (∂ ∕ ∂ z j )∗ preserves the holomorphic subspace of ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq126.gif) and is given on this subspace by multiplication by ![
$$z_{j}/\\hslash $$
](A272900_1_En_14_Chapter_IEq127.gif).

Lemma 14.13.

Specialize Lemma 14.12 to the case in which F and G are holomorphic polynomials and μ is the density ![
$$\\mu _{\\hslash }$$
](A272900_1_En_14_Chapter_IEq128.gif) given by

![
$$\\displaystyle{ \\mu _{\\hslash }\(\\mathbf{z}\) = \\frac{1} {{\(\\pi \\hslash\)}^{n}}{e}^{-{\\left\\vert \\mathbf{z}\\right\\vert }^{2}/\\hslash }. }$$
](A272900_1_En_14_Chapter_Equ36.gif)

(14.25)

Then we have

![
$$\\displaystyle{ \\int _{{\\mathbb{C}}^{n}}\\overline{F\(\\mathbf{z}\)} \\frac{\\partial G} {\\partial z_{j}}\\mu _{\\hslash }\(\\mathbf{z}\)\\ d\\mathbf{z} = \\frac{1} {\\hslash }\\int _{{\\mathbb{C}}^{n}}\\overline{z_{j}F\(\\mathbf{z}\)}G\(\\mathbf{z}\)\\mu _{\\hslash }\(\\mathbf{z}\)\\ d\\mathbf{z}. }$$
](A272900_1_En_14_Chapter_Equ37.gif)

(14.26)

Proof.

In the case that F and G are holomorphic polynomials, ![
$$\\partial F/\\partial \\bar{z}_{j} = 0,$$
](A272900_1_En_14_Chapter_IEq129.gif) so the first term on the right-hand side of (14.24) is zero. Furthermore, ![
$$\\bar{F}G\\mu$$
](A272900_1_En_14_Chapter_IEq130.gif) decreases rapidly at infinity and so the boundary terms vanish in this case. Finally, we may compute ![
$$\\partial \\log \\mu _{h}/\\partial \\bar{z}_{j}$$
](A272900_1_En_14_Chapter_IEq131.gif) as ![
$$-z_{j}/\\hslash,$$
](A272900_1_En_14_Chapter_IEq132.gif) giving (14.26). ■

Definition 14.14.

The Segal–Bargmann space, denoted ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq133.gif) is the space of holomorphic functions F on ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_14_Chapter_IEq134.gif) for which

![
$$\\displaystyle{\\left\\Vert F\\right\\Vert _{\\hslash } :={ \\left\(\\int _{{\\mathbb{C}}^{n}}{\\left\\vert F\(\\mathbf{z}\)\\right\\vert }^{2}\\mu _{ \\hslash }\(\\mathbf{z}\)\\ d\\mathbf{z}\\right\)}^{1/2} < \\infty,}$$
](A272900_1_En_14_Chapter_Equan.gif)

where ![
$$\\mu _{\\hslash }$$
](A272900_1_En_14_Chapter_IEq135.gif) is as in (14.25). Define raising and lowering operators a j ∗ and a j on ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq136.gif) by

![
$$\\displaystyle\\begin{array}{rcl} a_{j}^{{\\ast}}& =& z_{ j} {}\\\\ a_{j}& =& \\hslash \\frac{\\partial } {\\partial z_{j}}, {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ38.gif)

with the domain of a j and a j ∗ consisting of the space of holomorphic polynomials.

In light of Lemma 14.13, the operators a j and a j ∗ satisfy

![
$$\\displaystyle{\\left\\langle F,a_{j}G\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)} = \\left\\langle a_{j}^{{\\ast}}F,G\\right\\rangle _{ \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}}$$
](A272900_1_En_14_Chapter_Equao.gif)

for all holomorphic polynomials F and G, thus justifying the notation a j ∗ for the raising operator. The space ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq137.gif) is also sometimes called the Fock space. It should be noted, however, that in quantum field theory, the term Fock space also refers to a different (but related) space—the completion of the tensor algebra over a fixed Hilbert space.

Proposition 14.15.

The Segal–Bargmann space is complete with respect to the norm ![
$$\\left\\Vert \\cdot \\right\\Vert _{\\hslash }$$
](A272900_1_En_14_Chapter_IEq138.gif) and forms a Hilbert space with respect to the associated inner product,

![
$$\\displaystyle{\\left\\langle F,G\\right\\rangle _{\\hslash } :=\\int _{{\\mathbb{C}}^{n}}\\overline{F\(\\mathbf{z}\)}G\(\\mathbf{z}\)\\mu _{\\hslash }\(\\mathbf{z}\)\\ d\\mathbf{z}.}$$
](A272900_1_En_14_Chapter_Equap.gif)

Furthermore, the space of holomorphic polynomials forms a dense subspace of the Segal–Bargmann space.

Note that elements of ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq139.gif) are actual functions on ![
$${\\mathbb{C}}^{n},$$
](A272900_1_En_14_Chapter_IEq140.gif) not equivalence classes of functions. Nevertheless, we can regard ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq141.gif) as a subspace of ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq142.gif) since each equivalence class of almost-everywhere equal functions contains at most one holomorphic representative.

Proof.

Given any ![
$$\\mathbf{z}_{0} \\in {\\mathbb{C}}^{n}$$
](A272900_1_En_14_Chapter_IEq143.gif) and R > 0, let ![
$$P_{\\mathbf{z}_{0},R}$$
](A272900_1_En_14_Chapter_IEq144.gif) denote the polydisk given by

![
$$\\displaystyle{P_{\\mathbf{z}_{0}} = \\left\\{\\left.\\mathbf{z} \\in {\\mathbb{C}}^{n}\\right\\vert \\left\\vert z_{ j} - \(\\mathbf{z}_{0}\)_{j}\\right\\vert < R,\\ j = 1,\\ldots,n\\right\\}.}$$
](A272900_1_En_14_Chapter_Equaq.gif)

Using a power-series argument, it is easy to show that the value of a holomorphic function F at z 0 is equal to the average of F over ![
$$P_{\\mathbf{z}_{0},R}.$$
](A272900_1_En_14_Chapter_IEq145.gif) We can then multiply and divide by ![
$$\\mu _{\\hslash }$$
](A272900_1_En_14_Chapter_IEq146.gif) to obtain

![
$$\\displaystyle{F\(\\mathbf{z}_{0}\) = \\frac{1} {{\(\\pi {R}^{2}\)}^{n}}\\int _{P_{\\mathbf{z}_{ 0},R}} \\frac{1} {\\mu _{\\hslash }\(\\mathbf{z}\)}F\(\\mathbf{z}\)\\ \\mu _{\\hslash }\(\\mathbf{z}\)\\ d\\mathbf{z}.}$$
](A272900_1_En_14_Chapter_Equar.gif)

The Cauchy–Schwarz inequality then tells us that

![
$$\\displaystyle\\begin{array}{rcl} & & \\left\\vert F\(\\mathbf{z}_{0}\)\\right\\vert \\\\ & \\leq & \\frac{1} {{\(\\pi {R}^{2}\)}^{n}}\\left\(\\sup _{\\mathbf{z}\\in P_{\\mathbf{z}_{ 0},R}} \\frac{1} {\\mu _{\\hslash }\(\\mathbf{z}\)}\\right\)\\left\\Vert \\mathbf{1}_{P_{\\mathbf{z}_{ 0}},R}\\right\\Vert _{{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}\\left\\Vert F\\right\\Vert _{{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}.{}\\end{array}$$
](A272900_1_En_14_Chapter_Equ39.gif)

(14.27)

This inequality tells us that pointwise evaluation [the map F↦F(z 0)] is a bounded linear functional on the Segal–Bargmann space.

Suppose now that F n is a sequence of holomorphic functions such that F n converges in ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq147.gif) to some F. Using (14.27), we can easily show that F n converges to F uniformly on compact sets, which implies that F is also holomorphic. This shows that the holomorphic subspace of ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq148.gif) is closed and hence is a Hilbert space.

To show the denseness of polynomials, consider some ![
$$F \\in \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq149.gif) and let

![
$$\\displaystyle{ F\(\\mathbf{z}\) =\\sum _{\\mathbf{n}}a_{\\mathbf{n}}{\\mathbf{z}}^{\\mathbf{n}} }$$
](A272900_1_En_14_Chapter_Equ40.gif)

(14.28)

be the Taylor expansion of F, where n ranges over all multi-indices. This series converges to F uniformly on compact subsets of ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_14_Chapter_IEq1500.gif) We claim that the terms in (14.28) are orthogonal. To see this, use Fubini's theorem to perform the integration of ![
$$\\overline{{\\mathbf{z}}^{\\mathbf{n}}}$$
](A272900_1_En_14_Chapter_IEq151.gif) against z m one variable at a time. Using polar coordinates in each copy of ![
$$\\mathbb{C},$$
](A272900_1_En_14_Chapter_IEq152.gif) we can see that we will get zero if the power of z j in z n is not the same as the power of z j in z m .

Since it is orthogonal, the series in (14.28) will converge in ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq153.gif) provided that the sum of the squares of the norms of the terms is finite. If P 0, R is a sequence of polydisks of increasing radius centered at the origin, the argument in the preceding paragraph shows that the terms in (14.28) are orthogonal in ![
$${L}^{2}\(P_{0,R},\\mu _{\\hslash }\).$$
](A272900_1_En_14_Chapter_IEq154.gif) Since the series converges uniformly on P 0, R , we can then interchange sum and integral to obtain

![
$$\\displaystyle{\\sum _{\\mathbf{n}}{\\left\\vert a_{\\mathbf{n}}\\right\\vert }^{2}\\left\\Vert {\\mathbf{z}}^{\\mathbf{n}}\\right\\Vert _{{ L}^{2}\(P_{0,R},\\mu _{\\hslash }\)}^{2} = \\left\\Vert F\\right\\Vert _{{ L}^{2}\(P_{0,R},\\mu _{\\hslash }\)}^{2}.}$$
](A272900_1_En_14_Chapter_Equas.gif)

By applying monotone convergence to both the sum over n and the integrals over P 0, R , we may let R tend to infinity to obtain

![
$$\\displaystyle{\\sum _{\\mathbf{n}}{\\left\\vert a_{\\mathbf{n}}\\right\\vert }^{2}\\left\\Vert {\\mathbf{z}}^{\\mathbf{n}}\\right\\Vert _{{ L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}^{2} = \\left\\Vert F\\right\\Vert _{{ L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}^{2} < \\infty.}$$
](A272900_1_En_14_Chapter_Equat.gif)

Thus, the series in (14.28) converges in ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq155.gif) and this L 2 limit must coincide with the pointwise limit, namely F itself. ■

### 14.4.2 The Exponentiated Commutation Relations

To apply the Stone–von Neumann theorem to the Segal–Bargmann space, we define self-adjoint "position" and "momentum" operators as follows:

![
$$\\displaystyle\\begin{array}{rcl} A_{j}& =& \\frac{1} {\\sqrt{2}}\\left\(z_{j} + \\hslash \\frac{\\partial } {\\partial z_{j}}\\right\) {}\\\\ B_{j}& =& \\frac{i} {\\sqrt{2}}\\left\(z_{j} - \\hslash \\frac{\\partial } {\\partial z_{j}}\\right\). {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ41.gif)

We will identify one-parameter unitary groups having (extensions of) these operators as their infinitesimal generators, which will show (by Stone's theorem) that the generators are indeed self-adjoint on suitable domains. We will then verify the exponentiated commutation relations and check irreducibility.

Let us compute heuristically and then check that our results are correct. If we formally apply Theorem 14.1 to the (unbounded) operators ![
$$\\sum \\bar{a}_{j}z_{j}$$
](A272900_1_En_14_Chapter_IEq156.gif) and ![
$$-\\hslash \\sum a_{j}\\partial /\\partial z_{j},$$
](A272900_1_En_14_Chapter_IEq157.gif) we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\exp \\left\\{\\sum _{j=1}^{n}\\left\(-\\bar{a}_{ j}z_{j} + \\hslash a_{j} \\frac{\\partial } {\\partial z_{j}}\\right\)\\right\\} \\\\ & & =\\exp \\left\\{-\\frac{1} {2}\\hslash {\\left\\vert \\mathbf{a}\\right\\vert }^{2}\\right\\}\\exp \\left\\{-\\sum _{ j=1}^{n}\\bar{a}_{ j}z_{j}\\right\\}\\exp \\left\\{\\hslash \\sum _{j=1}^{n}a_{ j} \\frac{\\partial } {\\partial z_{j}}\\right\\}.{}\\end{array}$$
](A272900_1_En_14_Chapter_Equ42.gif)

(14.29)

This calculation suggests that we define operators T a by the formula

![
$$\\displaystyle{ \(T_{\\mathbf{a}}F\)\(\\mathbf{z}\) = {e}^{-\\hslash {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/2 }{e}^{-\\mathbf{\\bar{a}}\\cdot \\mathbf{z}}F\(\\mathbf{z} + \\hslash \\mathbf{a}\),\\quad \\mathbf{a} \\in {\\mathbb{C}}^{n}, }$$
](A272900_1_En_14_Chapter_Equ43.gif)

(14.30)

where for any ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{C}}^{n},$$
](A272900_1_En_14_Chapter_IEq158.gif) we define ![
$$\\mathbf{a} \\cdot \\mathbf{b} =\\sum _{j}a_{j}b_{j}$$
](A272900_1_En_14_Chapter_IEq159.gif) (no complex conjugates). Since the exponent on the left-hand side of (14.29) is skew-self-adjoint (the difference of an operator and its adjoint), we expect the operators T a to be unitary. For suitable choices of a, the operator on the left-hand side of (14.29) will become the one-parameter group generated by A j or B j .

Theorem 14.16.

For each ![
$$\\mathbf{a} \\in {\\mathbb{C}}^{n},$$
](A272900_1_En_14_Chapter_IEq160.gif) the operator T a defined by ( 14.30 ) is a unitary operator on the Segal–Bargmann space, and the map a ↦T a is strongly continuous. These operators satisfy

![
$$\\displaystyle{ T_{\\mathbf{a}}T_{\\mathbf{b}} = {e}^{i\\hslash \\mathrm{Im}\(\\mathbf{\\bar{a}}\\cdot \\mathbf{b}\)}T_{\\mathbf{ a}+\\mathbf{b}}. }$$
](A272900_1_En_14_Chapter_Equ44.gif)

(14.31)

In particular, for each j, the maps

![
$$\\displaystyle{U_{j}\(t\) := T_{it\\mathbf{e}_{ j}/\\sqrt{2}};\\quad V _{j}\(t\) := T_{t\\mathbf{e}_{ j}/\\sqrt{2}}}$$
](A272900_1_En_14_Chapter_Equau.gif)

are strongly continuous one-parameter unitary groups. The infinitesimal generators A j and B j of these groups satisfy the exponentiated commutation relations.

For any F ∈ Dom (A j ), we have

![
$$\\displaystyle{\(A_{j}F\)\(\\mathbf{z}\) = \\frac{1} {\\sqrt{2}}\\left\(z_{j}F\(\\mathbf{z}\) + \\hslash \\frac{\\partial F} {\\partial z_{j}}\\right\)}$$
](A272900_1_En_14_Chapter_Equav.gif)

and for any F ∈ Dom (B j ), we have

![
$$\\displaystyle{\(B_{j}F\)\(\\mathbf{z}\) = \\frac{i} {\\sqrt{2}}\\left\(z_{j}F\(\\mathbf{z}\) - \\hslash \\frac{\\partial F} {\\partial z_{j}}\\right\).}$$
](A272900_1_En_14_Chapter_Equaw.gif)

Furthermore, the domains of A j and B j contain all holomorphic polynomials.

Finally, the operators A j and B j act irreducibly on the Segal–Bargmann space, in the sense of Definition 14.6.

Proof.

It is evident that T a F(z) is holomorphic as a function of z for each fixed a. Meanwhile, for any ![
$$F \\in \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq161.gif) we have

![
$$\\displaystyle\\begin{array}{rcl} \\left\\Vert T_{\\mathbf{a}}F\\right\\Vert _{{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}^{2}& =& {\(\\pi \\hslash\)}^{-n}\\int _{{ \\mathbb{C}}^{n}}{e}^{-\\hslash {\\left\\vert \\mathbf{a}\\right\\vert }^{2} }{e}^{-2\\mathrm{Re}\(\\mathbf{\\bar{a}}\\cdot \\mathbf{z}\)}{\\left\\vert F\(\\mathbf{z} + \\hslash \\mathbf{a}\)\\right\\vert }^{2}{e}^{-{\\left\\vert \\mathbf{z}\\right\\vert }^{2}/\\hslash }\\ d\\mathbf{z} {}\\\\ & =& {\(\\pi \\hslash\)}^{-n}\\int _{{ \\mathbb{C}}^{n}}{e}^{-{\\left\\vert \\mathbf{z}+\\hslash \\mathbf{a}\\right\\vert }^{2}/\\hslash }{\\left\\vert F\(\\mathbf{z} + \\hslash \\mathbf{a}\)\\right\\vert }^{2}\\ d\\mathbf{z} {}\\\\ & =& \\left\\Vert F\\right\\Vert _{{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}^{2}, {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ45.gif)

showing that T a is isometric. The formula for T a T b follows from direct computation (Exercise 7), and from this formula we see that T a T − a = I, which shows that T a is surjective and thus unitary. The strong continuity of T a is easily verified on polynomials (Exercise 8), which are dense in the ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\).$$
](A272900_1_En_14_Chapter_IEq162.gif)

It easily follows from (14.31) that U j (⋅) and V j (⋅) are one-parameter unitary groups, and also that (the infinitesimal generators of) these unitary groups satisfy the exponentiated commutation relations. If F is in the domain of the infinitesimal generator of U j (⋅), the limit

![
$$\\displaystyle{ \(A_{j}F\)\(\\mathbf{z}\) := \\frac{1} {i} \\lim _{t\\rightarrow 0}\\frac{1} {t}\\left\[{e}^{-\\hslash {t}^{2}/4 }{e}^{itz_{j}/\\sqrt{2}}F\(\\mathbf{z} + it\\hslash \\mathbf{e}_{ j}/\\sqrt{2}\) - F\(\\mathbf{z}\)\\right\] }$$
](A272900_1_En_14_Chapter_Equ46.gif)

(14.32)

must exist in ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq163.gif). The L 2 limit coincides with the easily computed pointwise limit, giving

![
$$\\displaystyle{A_{j}F\(\\mathbf{z}\) = \\frac{1} {i} \\left\(\\frac{i} {\\sqrt{2}}z_{j}F\(\\mathbf{z}\) + \\frac{i\\hslash } {\\sqrt{2}} \\frac{\\partial F} {\\partial z_{j}}\\right\),}$$
](A272900_1_En_14_Chapter_Equax.gif)

as claimed. If F is a polynomial, it is easily shown, using dominated convergence, that the limit in (14.32) exists in ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\).$$
](A272900_1_En_14_Chapter_IEq164.gif) The analysis of B j is similar.

Finally, we address irreducibility. If the A j 's and B j 's did not act irreducibly, then in the application of the Stone–von Neumann theorem to ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq165.gif) there would exist at least two subspaces V l . Thus, there would exist at least two linearly independent vectors F l such that for all j, we have that F l is in the domain of A j and B j and

![
$$\\displaystyle{0 = \(A_{j} + iB_{j}\)F_{l} = \\frac{2\\hslash } {\\sqrt{2}} \\frac{\\partial F_{l}} {\\partial z_{j}}.}$$
](A272900_1_En_14_Chapter_Equay.gif)

(Take F l to be the preimage under U l of the function ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10019.gif) in (14.12), with ![
$$\\sigma = \\hslash.$$
](A272900_1_En_14_Chapter_IEq166.gif)) This would mean that each F l is constant, contradicting the assumption that the F l 's are linearly independent. ■

### 14.4.3 The Reproducing Kernel

According to (14.27), evaluation of ![
$$F \\in \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq167.gif) at a fixed point z is a continuous linear functional. Thus, this linear functional can be written as the inner product with a unique element χ z of ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq168.gif) which we now compute. The vector χ z is called the coherent state with parameter z.

Proposition 14.17.

For all ![
$$F \\in \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq169.gif) we have

![
$$\\displaystyle{ F\(\\mathbf{z}\) =\\int _{{\\mathbb{C}}^{n}}{e}^{\\mathbf{z}\\cdot \\mathbf{\\bar{w}}/\\hslash }F\(\\mathbf{w}\)\\mu _{ \\hslash }\(\\mathbf{w}\)\\ d\\mathbf{w}. }$$
](A272900_1_En_14_Chapter_Equ47.gif)

(14.33)

The function ![
$${e}^{\\mathbf{z}\\cdot \\mathbf{\\bar{w}}/\\hslash }$$
](A272900_1_En_14_Chapter_IEq170.gif) is called the reproducing kernel for ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq171.gif) since integration against this kernel simply gives back (or "reproduces") the function F. Of course, the relation (14.33) holds only for holomorphic functions in ![
$${L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\).$$
](A272900_1_En_14_Chapter_IEq172.gif) Equation (14.33) can be rewritten as

![
$$\\displaystyle{F\(\\mathbf{z}\) = \\left\\langle \\chi _{\\mathbf{z}},F\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)},}$$
](A272900_1_En_14_Chapter_Equaz.gif)

where

![
$$\\displaystyle{\\chi _{\\mathbf{z}}\(\\mathbf{w}\) = {e}^{\\mathbf{\\bar{z}}\\cdot \\mathbf{w}/\\hslash }.}$$
](A272900_1_En_14_Chapter_Equba.gif)

Proof.

We begin by establishing the result in the case z = 0. We have already established, in the proof of Proposition 14.15, that the Taylor series of F converges to F in ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq173.gif) and the distinct monomials in this series are orthogonal. Thus, when computing ![
$$\\left\\langle \\mathbf{1},F\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)},$$
](A272900_1_En_14_Chapter_IEq174.gif) only the constant term in the expansion of F survives, giving

![
$$\\displaystyle{ \\left\\langle \\mathbf{1},F\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)} = F\(0\)\\left\\langle \\mathbf{1},\\mathbf{1}\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)} = F\(0\), }$$
](A272900_1_En_14_Chapter_Equ48.gif)

(14.34)

since ![
$$\\mu _{\\hslash }$$
](A272900_1_En_14_Chapter_IEq175.gif) is a probability measure. But this relation is precisely the z = 0 case of (14.33).

Let us now apply (14.34) to T a F, where T a is the unitary operator in (14.30). According to Theorem 14.16, T a is unitary with inverse equal to T −a , giving

![
$$\\displaystyle{\(T_{\\mathbf{a}}F\)\(0\) = \\left\\langle \\mathbf{1},T_{\\mathbf{a}}F\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)} = \\left\\langle T_{-\\mathbf{a}}\\mathbf{1},F\\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}.}$$
](A272900_1_En_14_Chapter_Equbb.gif)

Writing this relation out using w as our variable of integration gives

![
$$\\displaystyle{{e}^{-\\hslash {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/2 }F\(\\hslash \\mathbf{a}\) =\\int \\overline{{e}^{-\\hslash {\\left\\vert \\mathbf{a}\\right\\vert }^{2}/2 }{e}^{\\mathbf{\\bar{a}}\\cdot \\mathbf{w}}}F\(\\mathbf{w}\)\\mu _{\\hslash }\(\\mathbf{w}\)\\ dw\\mathbf{.}}$$
](A272900_1_En_14_Chapter_Equbc.gif)

Setting a = z ∕ ℏ and simplifying gives the desired result. ■

### 14.4.4 The Segal–Bargmann Transform

Since the operators A j and B j in Theorem 14.16 satisfy the exponentiated commutation relations and act irreducibly on ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\),$$
](A272900_1_En_14_Chapter_IEq176.gif) the second part of the Stone–von Neumann theorem tells us that there is a unitary map ![
$$U : \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq177.gif), unique up to a constant, that intertwines these operator with the usual position and momentum operators. The inverse map ![
$$V : {L}^{2}\({\\mathbb{R}}^{n}\) \\rightarrow \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)$$
](A272900_1_En_14_Chapter_IEq178.gif) is called the Segal–Bargmann transform.

Theorem 14.18.

Let V be the inverse of the map ![
$$U : \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq179.gif) given by the Stone–von Neumann theorem, normalized so that V takes the function ![
$$\\phi _{0} \\in {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq180.gif) in ( 14.12 ) (with ![
$$\\sigma = \\hslash $$
](A272900_1_En_14_Chapter_IEq181.gif) ) to the constant function ![
$$\\mathbf{1} \\in \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\).$$
](A272900_1_En_14_Chapter_IEq182.gif) Then V may be computed as follows:

![
$$\\displaystyle{\(V \\psi\)\(\\mathbf{z}\) = {\(\\pi \\hslash\)}^{-n/4}\\int _{{ \\mathbb{R}}^{n}}\\exp \\left\\{- \\frac{1} {2\\hslash }\\left\(\\mathbf{z} \\cdot \\mathbf{z} - 2\\sqrt{2}\\mathbf{z} \\cdot \\mathbf{x} + \\mathbf{x} \\cdot \\mathbf{x}\\right\)\\right\\}\\psi \(\\mathbf{x}\)\\ d\\mathbf{x}.}$$
](A272900_1_En_14_Chapter_Equbd.gif)

Recall that we define ![
$$\\mathbf{a} \\cdot \\mathbf{b} =\\sum _{j}a_{j}b_{j}$$
](A272900_1_En_14_Chapter_IEq183.gif) for all ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{C}}^{n},$$
](A272900_1_En_14_Chapter_IEq184.gif) with no complex conjugates in the definition. In particular, the integrand in the formula for ![
$${V} \\psi$$
](A272900_1_En_14_Chapter_IEq07.gif) is a holomorphic function of z, for each fixed x.

Note that the value of (![
$${V} \\psi$$
](A272900_1_En_14_Chapter_IEq08.gif))(z) at z = 0 is simply the inner product of ![
$$\\psi\\text{ with the ground state function }\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10020.gif), with ![
$$\\sigma = \\hslash.$$
](A272900_1_En_14_Chapter_IEq185.gif) The proof of Theorem 14.18 will show that the value of (![
$${V} \\psi$$
](A272900_1_En_14_Chapter_IEq09.gif))(z) at an arbitrary z is a certain constant c z times the inner product of ![
$$\\psi$$
](A272900_1_En_14_Chapter_IEq010.gif) with a phase space translate of ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10021.gif), that is, a vector of the form ![
$${e}^{i\\mathbf{a}\\cdot \\mathbf{X}}{e}^{i\\mathbf{b}\\cdot \\mathbf{P}}\\phi _{0}.$$
](A272900_1_En_14_Chapter_IEq186.gif) [See (14.36).] According to (the obvious higher-dimensional counterpart to) Proposition 12.11, ![
$$\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10022.gif) is a minimum uncertainty state, meaning that equality is achieved in Corollary 12.9 for each j. Thus, by (the obvious higher-dimensional counterpart to) Exercise 3 in Chap.​ 12, each state of the form ![
$${e}^{i\\mathbf{a}\\cdot \\mathbf{X}}{e}^{i\\mathbf{b}\\cdot \\mathbf{P}}\\phi _{0}$$
](A272900_1_En_14_Chapter_IEq187.gif) is also a minimum uncertainty state.

Proof.

By the unitarity of V and the z = 0 case of Proposition 14.17, we have

![
$$\\displaystyle{\\left\\langle \\phi _{0},\\psi \\right\\rangle _{{L}^{2}\({\\mathbb{R}}^{n}\)} = \\left\\langle V \\phi _{0},V \\psi \\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)} = \\left\\langle \\mathbf{1},V \\psi \\right\\rangle _{\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)} = \(V \\psi\)\(0\).}$$
](A272900_1_En_14_Chapter_Eqube.gif)

Thus, the value of ![
$${V}\\psi$$
](A272900_1_En_14_Chapter_IEq011.gif) at 0 is just the inner product of ![
$$\\psi\\text{ with }\\phi_{0}$$
](A272900_1_En_14_Chapter_IEq10023.gif). More generally,

![
$$\\displaystyle\\begin{array}{rcl} \\left\\langle {e}^{-i\\mathbf{a}\\cdot \\mathbf{X}}{e}^{-i\\mathbf{b}\\cdot \\mathbf{P}}\\phi _{ 0},\\psi \\right\\rangle & =& \\left\\langle \\phi _{0},{e}^{i\\mathbf{b}\\cdot \\mathbf{P}}{e}^{i\\mathbf{a}\\cdot \\mathbf{X}}\\psi \\right\\rangle \\\\ & =& \\left\\langle V \\phi _{0},V {e}^{i\\mathbf{b}\\cdot \\mathbf{P}}{e}^{i\\mathbf{a}\\cdot \\mathbf{X}}\\psi \\right\\rangle \\\\ & =& \\left\\langle \\mathbf{1},{e}^{i\\mathbf{b}\\cdot \\mathbf{B}}{e}^{i\\mathbf{a}\\cdot \\mathbf{A}}V \\psi \\right\\rangle \\\\ & =& \({e}^{i\\mathbf{b}\\cdot \\mathbf{B}}{e}^{i\\mathbf{a}\\cdot \\mathbf{A}}V \\psi\)\(0\),{}\\end{array}$$
](A272900_1_En_14_Chapter_Equ49.gif)

(14.35)

where e i a ⋅A means the product (in any order) of the operators ![
$${e}^{ia_{j}A_{j}},$$
](A272900_1_En_14_Chapter_IEq188.gif) and similarly for e i b ⋅B .

Recall that A j 's and B j 's are defined as the infinitesimal generators of the groups U j and V j in Theorem 14.16, which in turn are defined in terms of the operators T a . If we use (14.31) to compute the right-hand side of (14.35), we obtain

![
$$\\displaystyle\\begin{array}{rcl} \({e}^{i\\mathbf{b}\\cdot \\mathbf{B}}{e}^{i\\mathbf{a}\\cdot \\mathbf{A}}V \\psi\)\(0\)& =& \(T_{\\mathbf{ b}/\\sqrt{2}}T_{i\\mathbf{a}/\\sqrt{2}}V \\psi\)\(0\) {}\\\\ & =& {e}^{i\\hslash \\mathbf{a}\\cdot \\mathbf{b}/2}\(T_{ \(\\mathbf{b}+i\\mathbf{a}\)/\\sqrt{2}}V \\psi\)\(0\) {}\\\\ & =& {e}^{i\\hslash \\mathbf{a}\\cdot \\mathbf{b}/2}{e}^{-\\hslash \({\\left\\vert \\mathbf{a}\\right\\vert }^{2}+{\\left\\vert \\mathbf{b}\\right\\vert }^{2}\)/4 }\(V \\psi\)\(\\hslash \(\\mathbf{b} + i\\mathbf{a}\)/\\sqrt{2}\). {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ50.gif)

Thus, if we apply (14.35) with ![
$$\\mathbf{a} = \\sqrt{2}\\mathbf{y}_{0}/\\hslash $$
](A272900_1_En_14_Chapter_IEq189.gif) and ![
$$\\mathbf{b} = \\sqrt{2}\\mathbf{x}_{0}/\\hslash $$
](A272900_1_En_14_Chapter_IEq190.gif), we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\left\\langle {e}^{-i\\sqrt{2}\\mathbf{y}_{0}\\cdot \\mathbf{X}/\\hslash }{e}^{-i\\sqrt{2}\\mathbf{x}_{0}\\cdot \\mathbf{P}/\\hslash }\\phi _{ 0},\\psi \\right\\rangle \\\\ & =& {e}^{i\\mathbf{x}_{0}\\cdot \\mathbf{y}_{0}/\\hslash }{e}^{-\({\\left\\vert \\mathbf{x}_{0}\\right\\vert }^{2}+{\\left\\vert \\mathbf{y}_{ 0}\\right\\vert }^{2}\)/\(2\\hslash\) }\(V \\psi\)\(\\mathbf{x}_{0} + i\\mathbf{y}_{0}\).{}\\end{array}$$
](A272900_1_En_14_Chapter_Equ51.gif)

(14.36)

Solving (14.36) for (![
$${V}\\psi$$
](A272900_1_En_14_Chapter_IEq012.gif))(x 0 \+ i y 0) gives

![
$$\\displaystyle\\begin{array}{rcl} \(V \\psi\)\(\\mathbf{x}_{0} + i\\mathbf{y}_{0}\)& =& {\(\\pi \\hslash\)}^{-n/4}{e}^{-i\\mathbf{x}_{0}\\cdot \\mathbf{y}_{0}/\\hslash }{e}^{\({\\left\\vert \\mathbf{x}_{0}\\right\\vert }^{2}+{\\left\\vert \\mathbf{y}_{ 0}\\right\\vert }^{2}\)/\(2\\hslash\) } {}\\\\ & \\times & \\int _{{\\mathbb{R}}^{n}}{e}^{i\\sqrt{2}\\mathbf{y}_{0}\\cdot \\mathbf{x}/\\hslash }{e}^{-{\\left\\vert \\mathbf{x-}\\sqrt{2}\\mathbf{x}_{0}\\right\\vert }^{2}/\(2\\hslash\) }\\psi \(\\mathbf{x}\)\\ d\\mathbf{x}, {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ52.gif)

which simplifies to the claimed formula for ![
$${V}\\psi$$
](A272900_1_En_14_Chapter_IEq013.gif). ■

## 14.5 Exercises

1.

Show that if operators A and B satisfy the exponentiated commutation relations of Sect. 14.2, they satisfy the "semi-exponentiated" commutation relations, that is, the hypotheses of Theorem 12.8.

Hint: For any ![
$$a,s \\in \\mathbb{R}$$
](A272900_1_En_14_Chapter_IEq191.gif) and ![
$$\\psi$$
](A272900_1_En_14_Chapter_IEq014.gif) ∈ Dom(A), rearrange the expression

![
$$\\displaystyle{\\frac{{e}^{isA}\({e}^{iaB}\\psi\) - \({e}^{iaB}\\psi\)} {s} }$$
](A272900_1_En_14_Chapter_Equbf.gif)

using the exponentiated commutation relations. Then let s tend to zero and apply Stone's theorem.

2.

(a)

Suppose ![
$$\\alpha : \\mathbb{R} \\rightarrow \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq192.gif) is a differentiable map, meaning that

![
$$\\displaystyle{\\lim _{h\\rightarrow 0}\\frac{\\alpha \(t + h\) -\\alpha \(t\)} {h} }$$
](A272900_1_En_14_Chapter_Equbg.gif)

exists in the norm topology of ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq193.gif) for each t. Show that if d α ∕ dt = 0 for all t, then α is constant.

(b)

Suppose ![
$$\\alpha : \\mathbb{R} \\rightarrow \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_14_Chapter_IEq194.gif) is a differentiable map such that

![
$$\\displaystyle{ \\frac{d\\alpha } {dt} =\\alpha \(t\)A}$$
](A272900_1_En_14_Chapter_Equbh.gif)

for some fixed ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_14_Chapter_IEq195.gif) Show that α(t) = α(0)e tA for all t.

3.

Show that the operators A j : = P j and B j : = − X j on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq196.gif) satisfy the exponentiated commutation relations. Determine the unitary operator ![
$$U : {L}^{2}\({\\mathbb{R}}^{n}\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq197.gif) (unique up to a constant) such that

![
$$\\displaystyle\\begin{array}{rcl} U{e}^{itA_{j} }{U}^{-1}& =& {e}^{itX_{j} } {}\\\\ U{e}^{itB_{j} }{U}^{-1}& =& {e}^{itP_{j} }. {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ53.gif)

4.

Verify that the operators U a, b (t) in (14.9) form a strongly continuous one-parameter unitary group.

5.

In this exercise, we develop a discrete version of (the n = 1 case of) the Stone–von Neumann theorem. Let p be a prime number, let ![
$$\\mathbb{Z}/p$$
](A272900_1_En_14_Chapter_IEq198.gif) denote the field of integers modulo p, and let h be a nonzero element of ![
$$\\mathbb{Z}/p.$$
](A272900_1_En_14_Chapter_IEq199.gif) Consider the finite-dimensional Hilbert space ![
$${L}^{2}\(\\mathbb{Z}/p\),$$
](A272900_1_En_14_Chapter_IEq200.gif) taken with respect to the counting measure on ![
$$\\mathbb{Z}/p.$$
](A272900_1_En_14_Chapter_IEq201.gif) Let U denote the "modulation" operator

![
$$\\displaystyle{\(Uf\)\(n\) = {e}^{2\\pi in/p}f\(n\)}$$
](A272900_1_En_14_Chapter_Equbi.gif)

and let V denote the "translation" operator on ![
$${L}^{2}\(\\mathbb{Z}/p\),$$
](A272900_1_En_14_Chapter_IEq202.gif) given by

![
$$\\displaystyle{\(V f\)\(n\) = f\(n + h\).}$$
](A272900_1_En_14_Chapter_Equbj.gif)

In the case of the modulation operator, note that the expression e 2π i n ∕ p descends unambiguously from ![
$$n \\in \\mathbb{Z}$$
](A272900_1_En_14_Chapter_IEq203.gif) to ![
$$n \\in \\mathbb{Z}/p.$$
](A272900_1_En_14_Chapter_IEq204.gif)

(a)

Verify that U p = V p = I and that, for all l and m in ![
$$\\mathbb{Z},$$
](A272900_1_En_14_Chapter_IEq205.gif)

![
$$\\displaystyle{{U}^{l}{V }^{m} = {e}^{-2\\pi ilm/p}{V }^{m}{U}^{l}.}$$
](A272900_1_En_14_Chapter_Equbk.gif)

(b)

Suppose now that A and B are unitary operators on a finite-dimensional Hilbert space H satisfying A p = B p = I and

![
$$\\displaystyle{{A}^{l}{B}^{m} = {e}^{-2\\pi ilm/p}{B}^{m}{V }^{l}.}$$
](A272900_1_En_14_Chapter_Equbl.gif)

Suppose also that the only subspaces of H invariant under both A and B are {0} and H. Show that there is a unitary map W from H to ![
$${L}^{2}\(\\mathbb{Z}/p\)$$
](A272900_1_En_14_Chapter_IEq206.gif) such that

![
$$\\displaystyle\\begin{array}{rcl} WA{W}^{-1}& =& U {}\\\\ WB{W}^{-1}& =& V. {}\\\\ \\end{array}$$
](A272900_1_En_14_Chapter_Equ54.gif)

Hint: Show that if v ∈ H is an eigenvector for A, then so is B l v for any l. Show that each eigenspace for A has dimension 1 and identify the associated eigenvectors with the "δ-functions" in ![
$${L}^{2}\(\\mathbb{Z}/p\).$$
](A272900_1_En_14_Chapter_IEq207.gif)

6.

Given a constant ![
$$u \\in \\mathbb{C}$$
](A272900_1_En_14_Chapter_IEq208.gif) with ![
$$\\left\\vert u\\right\\vert = 1$$
](A272900_1_En_14_Chapter_IEq209.gif) and a pair of vectors ![
$$\\mathbf{a},\\mathbf{b} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_14_Chapter_IEq210.gif) let U u, a, b be the unitary operator on ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_14_Chapter_IEq211.gif) given by

![
$$\\displaystyle{\(U_{u,\\mathbf{a},\\mathbf{b}}\\psi\)\(\\mathbf{x}\) = u{e}^{i\\mathbf{a}\\cdot \\mathbf{x}}\\psi \(\\mathbf{x} + \\hslash \\mathbf{b}\).}$$
](A272900_1_En_14_Chapter_Equbm.gif)

(a)

Verify that the set of operators of this form a group under the operation of composition, and denote this group by H n .

(b)

Let ![
$$\\tilde{H}_{n}$$
](A272900_1_En_14_Chapter_IEq212.gif) denote the set of (n \+ 2) ×(n \+ 2) matrices of the form

![
$$\\displaystyle{A = \\left\(\\begin{array}{ccccc} 1&a_{1} & \\cdots &a_{n}& c \\\\ & 1 & & & b_{1}\\\\ & & \\ddots & & \\vdots \\\\ & & & 1 &b_{n} \\\\ & & & & 1\\end{array} \\right\),}$$
](A272900_1_En_14_Chapter_Equbn.gif)

with a 1,..., a n and b 1,..., b n in ![
$$\\mathbb{R}.$$
](A272900_1_En_14_Chapter_IEq213.gif) (The only nonzero entries in A are on the main diagonal, in the first row, and in the last column.) Verify that ![
$$\\tilde{H}_{n}$$
](A272900_1_En_14_Chapter_IEq214.gif) forms a group under matrix multiplication. Show that there is a surjective group homomorphism ![
$$\\Phi :\\tilde{ H}_{n} \\rightarrow H_{n}$$
](A272900_1_En_14_Chapter_IEq215.gif) with discrete kernel.

Hint: Compare the formulas for group multiplication in H n and ![
$$\\tilde{H}_{n}.$$
](A272900_1_En_14_Chapter_IEq216.gif)

Note: In the language of Chap.​ 16, ![
$$\\tilde{H}_{n}$$
](A272900_1_En_14_Chapter_IEq217.gif) is the universal covering group of H n . The group ![
$$\\tilde{H}_{n}$$
](A272900_1_En_14_Chapter_IEq218.gif) is called the Heisenberg group.

7.

Show by direct computation that the operators T a in (14.30) satisfy the relations (14.31).

8.

Using dominated convergence, show that for every holomorphic polynomial F on ![
$${\\mathbb{C}}^{n},$$
](A272900_1_En_14_Chapter_IEq219.gif) we have

![
$$\\displaystyle{\\lim _{\\mathbf{a}\\rightarrow \\mathbf{b}}\\left\\Vert T_{\\mathbf{a}}F - T_{\\mathbf{b}}F\\right\\Vert _{{L}^{2}\({\\mathbb{C}}^{n},\\mu _{\\hslash }\)}^{2} = 0,}$$
](A272900_1_En_14_Chapter_Equbo.gif)

where T a is as in (14.30).

References

[2].

V. Bargmann, On a Hilbert space of analytic functions and an associated integral transform Part I. Comm. Pure Appl. Math. 14, 187–214 (1961)CrossRefMATHMathSciNet

[9].

V. Fock, Verallgemeinerung und Lösung der Diracschen statistischen Gleichung. Zeit. Phys. 49, 339–350 (1928)CrossRefMATH

[21].

B.C. Hall, Lie Groups, Lie Algebras, and Representations: An Elementary Introduction. Graduate Texts in Mathematics, vol. 222 (Springer, New York, 2003)

[36].

I.E. Segal, Mathematical problems of relativistic physics. In Proceedings of the Summer Seminar, Boulder, Colorado, 1960, ed. by M. Kac (American Mathematical Society, Providence, RI, 1963)

[41].

J. von Neumann, Die Eindeutigkeit der Schrödingerschen operatoren. Math. Ann. 105, 570–578 (1931)CrossRef

[46].

K. Yosida, Functional Analysis, 4th edn. (Springer, New York, 1980)CrossRefMATH
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_15

© Springer Science+Business Media New York 2013

# 15. The WKB Approximation

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

The WKB method, named for Gregor Wentzel, Hendrik Kramers, and Léon Brillouin, gives an approximation to the eigenfunctions and eigenvalues of the Hamiltonian operator ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq01.gif) in one dimension.

## 15.1 Introduction

The WKB method, named for Gregor Wentzel, Hendrik Kramers, and Léon Brillouin, gives an approximation to the eigenfunctions and eigenvalues of the Hamiltonian operator ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq1.gif) in one dimension. The approximation is best understood as applying to a fixed range of energies as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq2.gif) tends to zero. (It is also reasonable in many cases to think of the approximation as applying to a fixed value of ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq3.gif) as the energy tends to infinity.)

The idea of the WKB approximation is that the potential function V (x) can be thought of as being "slowly varying," with the result that solutions to the time-independent Schrödinger equation will look locally like the solutions in the case of a constant potential. In the classically allowed region, this line of thinking will yield an approximation consisting of a rapidly oscillating complex exponential multiplied by a slowly varying amplitude. We make the "local frequency" of the exponential equal to what it would be if V were constant. Having made this choice, there is a unique choice for the amplitude that yields an error that is of order ![
$${\\hslash }^{2}.$$
](A272900_1_En_15_Chapter_IEq4.gif) This amplitude, however, tends to infinity as we approach the "turning points," that is, the points where the classical particle changes directions. Similarly, in the classically forbidden region, we obtain approximate solutions that are rapidly growing or decaying exponentials, multiplied by a slowly varying factor. Again, there is a unique choice for the slowly varying factor that gives errors of order ![
$${\\hslash }^{2},$$
](A272900_1_En_15_Chapter_IEq5.gif) and again, this factor blows up at the turning points.

The difficulty near the turning points means that we cannot directly "match" the approximate solutions in different regimes the way we did in Chap.​ 5. Instead, we will use the Airy function to approximate the solution to the Schrödinger equation near the turning points. Asymptotics of the Airy function will then yield the appropriate matching condition, which turns out to be a corrected form of the Bohr–Sommerfeld rule that appears in the "old" quantum theory.

## 15.2 The Old Quantum Theory and the Bohr–Sommerfeld Condition

The old quantum theory, developed by Bohr, Sommerfeld, and de Broglie, among others, may be pictured as follows. Consider, for simplicity, a particle with one degree of freedom, and let C be a level set in phase space of the Hamiltonian,

![
$$\\displaystyle{ C = \\left \\{\\left.\(x,p\) \\in {\\mathbb{R}}^{2}\\right\\vert H\(x,p\) = E\\right\\}, }$$
](A272900_1_En_15_Chapter_Equ1.gif)

(15.1)

which we assume to be a closed curve. We now imagine drawing a "wave" on C, that is, some oscillatory function defined over C. Following the de Broglie hypothesis (Sect.​ 1.​2.​2), we postulate that the local frequency k of the wave as a function of x is ![
$$p/\\hslash.$$
](A272900_1_En_15_Chapter_IEq6.gif) This means that the phase of our wave should be obtained by integrating the 1-form

![
$$\\displaystyle{ \\frac{1} {\\hslash }p\\ dx }$$
](A272900_1_En_15_Chapter_Equ2.gif)

(15.2)

along the curve. Thus, the wave itself can be pictured as a function on C of the form

![
$$\\displaystyle{ \\cos \\left \(\\frac{1} {\\hslash }\\int _{x_{0}}^{x}p\\ dx-\\delta \\right\), }$$
](A272900_1_En_15_Chapter_Equ3.gif)

(15.3)

where x 0 is some arbitrary starting point on the curve C and where δ is an arbitrary phase. Note that the old quantum theory did not offer a physical interpretation of this wave; it was simply a crude attempt to introduce waves into the picture.

The Bohr–Sommerfeld condition is simply the requirement that the function in (15.3) should match up with itself when we go all the way around the curve. This will happen precisely if

![
$$\\displaystyle{ \\frac{1} {\\hslash }\\int _{C}p\\ dx = 2\\pi n, }$$
](A272900_1_En_15_Chapter_Equ4.gif)

(15.4)

for some integer n. The energy levels in the old quantum theory were taken to be those numbers E for which the corresponding level curve C satisfies the Bohr–Sommerfeld condition (15.4). Although Bohr–Sommerfeld quantization had some successes, notably explaining the energy levels of the hydrogen atom, it ultimately failed to correctly predict the energies of complex systems.

For systems with one degree of freedom, a vestige of the Bohr–Sommerfeld approach survives in modern quantum theory, with two modifications. First, the condition (15.4) has to be corrected by replacing the n by ![
$$n + 1/2$$
](A272900_1_En_15_Chapter_IEq7.gif) on the right-hand side of (15.4). (The replacement of n by ![
$$n + 1/2$$
](A272900_1_En_15_Chapter_IEq8.gif) is known as the Maslov correction.) Second, this condition does not (in most cases) give the exact energy levels, but only the leading-order semiclassical approximation to the energy levels. The preceding discussion leads to the following definition.

Condition 15.1

A number E is said to satisfy the Maslov-corrected Bohr–Sommerfeld condition if

![
$$\\displaystyle{ \\frac{1} {\\hslash }\\int _{C}p\\ dx = 2\\pi \(n + 1/2\) }$$
](A272900_1_En_15_Chapter_Equ5.gif)

(15.5)

for some integer n, where C is the classical energy curve in ( 15.1 ). In light of Green's theorem, this condition may be rewritten as

![
$$\\displaystyle{ \\frac{1} {2\\pi \\hslash }\({Area\\,enclosed\\,by }\\,C\) = n + \\frac{1} {2}.}$$
](A272900_1_En_15_Chapter_Equa.gif)

When the Maslov correction is included, the Bohr–Sommerfeld condition can be stated as saying that the wave with phase given by integrating the 1-form in (15.2) should be 180∘ out of phase with itself after one trip around the energy curve. Figure 15.1 shows an example, which should be contrasted with Fig.​ 1.​3. (Note also that Fig.​ 1.​3 is drawn in the configuration space, whereas Fig. 15.1 is in the phase space.)

Figure 15.1

A trajectory satisfying the corrected Bohr–Sommerfeld condition with n = 10.

In our analysis in the subsequent sections, we will see that the Maslov correction—that is, the extra 1 ∕ 2 in (15.5), as compared to (15.4)—actually consists of a contribution of 1 ∕ 4 from each of the two "turning points" of the classical particle. (The turning points are the points where the classical particle changes directions.) Specifically, in the WKB approximation, the phase of the wave function will be computed as the integral of ![
$$\(p\\ dx\)/\\hslash $$
](A272900_1_En_15_Chapter_IEq9.gif) along one "branch" of the classical energy curve C. Using the Airy function to approximate the wave function near the turning points, we will obtain an "extra" π ∕ 4 of phase between each turning point and the last local maximum or minimum of the wave function. Because of the two branches of C, the extra π ∕ 4 of phase near each of the two turning points actually contributes an extra π to the integral on the left-hand side of (15.5).

The reader may wonder why there is no comparable correction term in our discussion of the Bohr–de Broglie model of the hydrogen atom in Sect.​ 1.​2.​2. One way to answer this question is as follows. As we will see in Sect.​ 18.​1, the Schrödinger operator for the hydrogen atom can be reduced to a one-dimensional Schrödinger operator with an effective potential of the form

![
$$\\displaystyle{V _{\\mathrm{eff}}\(r\) = -\\frac{{Q}^{2}} {r} + \\frac{{\\hslash }^{2}l\(l + 1\)} {2m{r}^{2}}.}$$
](A272900_1_En_15_Chapter_Equb.gif)

Here l is a non-negative integer that labels the "total angular momentum" of the wave function. At least when l > 0, one can analyze this Schrödinger operator using a WKB-type analysis very similar to the one in the current chapter, with one important modification: The radial wave function the quantity h(r) in ([18.​5)] must be zero at r = 0 in order for the wave function to be in the domain of the Hamiltonian.

If one analyzes the situation carefully, it turns out that the zero boundary condition at r = 0 introduces another correction into the Bohr–Sommerfeld condition in the amount of 1 ∕ 2. There is still also a correction of 1 ∕ 4 for each of the two turning points, leading to the condition

![
$$\\displaystyle{\\frac{1} {\\hslash }\\int _{C}p\\ dx = 2\\pi \\left \(n + \\frac{1} {4} + \\frac{1} {4} + \\frac{1} {2}\\right\) = 2\\pi \(n + 1\).}$$
](A272900_1_En_15_Chapter_Equc.gif)

Since n \+ 1 is again an integer, we are effectively back to the uncorrected Bohr–Sommerfeld condition. See Chap.​ 11 of [8] for a discussion of different approaches to the WKB approximation for radial potentials.

## 15.3 Classical and Semiclassical Approximations

We are interested in finding approximate solutions to the time-independent Schrödinger equation,

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi } {d{x}^{2}} + \(V \(x\) - E\)\\psi \(x\) = 0 }$$
](A272900_1_En_15_Chapter_Equ6.gif)

(15.6)

for small values of ![
$$\\hslash.$$
](A272900_1_En_15_Chapter_IEq10.gif) Ultimately, we will need to analyze the behavior of solutions in three different regions, the classically allowed region [points where V (x) < E], the classically forbidden region (points where V (x) > E), and the region near the "turning points," that is, the points where V (x) = E.

Let us consider at first the classically allowed region. Given a potential V and an energy level E, we can solve (up to a choice of sign) for the momentum of a classical particle as a function of position as

![
$$\\displaystyle{p\(x\) = \\sqrt{2m\(E - V \(x\)\)}.}$$
](A272900_1_En_15_Chapter_Equd.gif)

We look for approximate solutions ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq02.gif) to (15.6) of the form

![
$$\\displaystyle{ \\psi \(x\) = A\(x\){e}^{\\pm iS\(x\)/\\hslash }, }$$
](A272900_1_En_15_Chapter_Equ7.gif)

(15.7)

where S satisfies S ′ (x) = p(x). Note that we are taking the phase of our wave function to be

![
$$\\displaystyle{\\text{phase} = \\pm \\frac{1} {\\hslash }\\int p\(x\)\\ dx,}$$
](A272900_1_En_15_Chapter_Eque.gif)

as in the old quantum theory in Sect. 15.2. The "amplitude function" A(x) will be chosen to be independent of ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq11.gif) and thus "slowly varying" (for small ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq12.gif)) compared to the exponent ![
$$S\(x\)/\\hslash.$$
](A272900_1_En_15_Chapter_IEq13.gif)

Our first, elementary, result is that for any number E for which there is a classically allowed region and for any reasonable choice of the amplitude A(x) in (15.7), we obtain an approximate eigenvector solution to the time-independent Schrödinger equation, with an error term of order ![
$$\\hslash.$$
](A272900_1_En_15_Chapter_IEq14.gif)

Proposition 15.2.

For any two numbers E 1 and E 2 with ![
$$E_{1}>\\inf _{x\\in \\mathbb{R}}V \(x\),$$
](A272900_1_En_15_Chapter_IEq15.gif) there exists a constant C and a nonzero function ![
$$A \\in C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_15_Chapter_IEq16.gif) with the following property. For every ![
$$E \\in \[E_{1},E_{2}\],$$
](A272900_1_En_15_Chapter_IEq17.gif) the support of A is contained in the classically allowed region at energy E and the function ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq03.gif) given by

![
$$\\displaystyle{\\psi \(x\) = A\(x\)\\exp \\left \\{\\pm \\frac{i} {\\hslash }\\int p\(x\)\\ dx\\right\\}}$$
](A272900_1_En_15_Chapter_Equf.gif)

satisfies

![
$$\\displaystyle{ \\Vert \\hat{H}\\psi - E\\psi \\Vert \\leq C\\hslash \\left \\Vert \\psi \\right\\Vert. }$$
](A272900_1_En_15_Chapter_Equ8.gif)

(15.8)

Proof.

For any ![
$$E \\in \[E_{1},E_{2}\],$$
](A272900_1_En_15_Chapter_IEq18.gif) the classically allowed region for energy E contains the classically allowed region for energy E 1. We choose, then, A to be any nonzero element of ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_15_Chapter_IEq19.gif) with support in the classically allowed region for energy E 1. If we evaluate ![
$$\\hat{H}\\psi - E\\psi$$
](A272900_1_En_15_Chapter_IEq20.gif) by direct calculation, there will a term in which two derivatives fall on the exponential factor, bringing down a factor involving p(x)2. The definition of p(x) is such that the term involving p(x)2 will cancel the term involving V (x) − E, leaving us with

![
$$\\displaystyle\\begin{array}{rcl} \\hat{H}\\psi - E\\psi & & = -\\frac{{\\hslash }^{2}} {2m}\\left \({A}^{{\\prime\\prime}}\(x\) \\pm \\frac{i} {\\hslash }2{A}^{{\\prime}}\(x\)p\(x\) \\pm \\frac{i} {\\hslash }{p}^{{\\prime}}\(x\)A\(x\)\\right\) \\\\ & & \\times \\exp \\left \\{\\pm \\frac{i} {\\hslash }\\int p\(x\)\\ dx\\right\\}. {}\\end{array}$$
](A272900_1_En_15_Chapter_Equ9.gif)

(15.9)

(Here, each occurrence of the symbol ± has the same value, either all pluses or all minuses.) Thus,

![
$$\\displaystyle{ \\Vert \\hat{H}\\psi - E\\psi \\Vert \\leq \\frac{{\\hslash }^{2}} {2m}\\Vert {A}^{{\\prime\\prime}}\\Vert + \\frac{\\hslash } {2m}\\Vert 2{A}^{{\\prime}}p + A{p}^{{\\prime}}\\Vert. }$$
](A272900_1_En_15_Chapter_Equ10.gif)

(15.10)

Since ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq04.gif) is independent of ![
$$\\hslash,$$
](A272900_1_En_15_Chapter_IEq21.gif) the right-hand side of (15.10) is of order ![
$$\\hslash \\left \\Vert \\psi \\right\\Vert.$$
](A272900_1_En_15_Chapter_IEq22.gif) It is easy to check that ![
$$\\Vert 2{A}^{{\\prime}}p + A{p}^{{\\prime}}\\Vert$$
](A272900_1_En_15_Chapter_IEq23.gif) is bounded as a function of E for any E in the range ![
$$\[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq24.gif) and the result follows.

Proposition 15.2, along with elementary spectral theory, tells us that for any E larger than the minimum of V, there is a point ![
$$\\tilde{E}$$
](A272900_1_En_15_Chapter_IEq25.gif) in the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq26.gif) such that

![
$$\\displaystyle{ \\vert E -\\tilde{ E}\\vert \\leq c\\hslash. }$$
](A272900_1_En_15_Chapter_Equ11.gif)

(15.11)

(See Exercise 4 in Chap.​ 10) If we assume that V (x) tends to + ∞ as x → ± ∞, then ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq27.gif) will have discrete spectrum and we can say that ![
$$\\tilde{E}$$
](A272900_1_En_15_Chapter_IEq28.gif) is an eigenvalue for ![
$$\\hat{H}.$$
](A272900_1_En_15_Chapter_IEq29.gif) The conclusion, for such potentials, is this: Given any number ![
$$E \\in \[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq30.gif), there is an eigenvalue of ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq31.gif) within ![
$$C\\hslash $$
](A272900_1_En_15_Chapter_IEq32.gif) of ![
$$E.$$
](A272900_1_En_15_Chapter_IEq33.gif) Thus, as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq34.gif) tends to zero, the eigenvalues of ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq35.gif) "fill up" the entire range of values of the classical energy function.

Proposition 15.2 is one manifestation of the "classical limit" of quantum mechanics: the quantum energy spectrum is, in a certain sense, approximating the classical energy spectrum as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq36.gif) gets small. Notice, however, that this result tells us only that the eigenvalues are at most order ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq37.gif) apart and nothing further about the location of the individual eigenvalues.

In this chapter, we will show that if E satisfies the corrected Bohr–Sommerfeld condition, then there exists an eigenvalue ![
$$\\tilde{E}$$
](A272900_1_En_15_Chapter_IEq38.gif) of ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq39.gif) such that

![
$$\\displaystyle{ \\vert E -\\tilde{ E}\\vert \\leq C{\\hslash }^{9/8}. }$$
](A272900_1_En_15_Chapter_Equ12.gif)

(15.12)

An estimate of the form (15.12) locates eigenvalues with an error bound that is small compared to the expected average spacing between the eigenvalues, which is of order ![
$$\\hslash.$$
](A272900_1_En_15_Chapter_IEq40.gif) On the other hand, the approximate energy levels E are determined by Condition 15.1, which is a condition on the classical energy curve. Thus, (15.12) can be described as a semiclassical estimate: It is estimating quantum mechanical quantities (the individual energy levels) in classical terms (the level curves of the classical Hamiltonian).

## 15.4 The WKB Approximation Awayfrom the Turning Points

We consider only the simplest interesting case of the WKB approximation, in which the following assumption holds. See the book of Miller [30] for much about this sort of asymptotic analysis.

Assumption 15.3

Consider a smooth, real-valued potential V (x), with V (x) → +∞ as x →±∞. Assume that the functions V ′ (x)∕V (x) and V ″ (x)∕V (x) are bounded for x near ±∞.

Consider also a range of energies of the form ![
$$E_{1} \\leq E \\leq E_{2}.$$
](A272900_1_En_15_Chapter_IEq41.gif) Assume that for each E in this range, there are exactly two points, a(E) and b(E), with a(E) < b(E), for which V (x) = E. Further assume that the derivative of V is nonzero at a(E) and b(E), for all ![
$$E \\in \[E_{1},E_{2}\].$$
](A272900_1_En_15_Chapter_IEq42.gif)

See Fig. 15.2 for a typical example. Since V is locally bounded and tends to + ∞ at infinity, ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq43.gif) is essentially self-adjoint on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\)$$
](A272900_1_En_15_Chapter_IEq44.gif) (Theorem 9.39) and has purely discrete spectrum (Theorem XIII.16 in Volume IV of [34]). The assumption that V ′ ∕ V and V ′ ′ ∕ V be bounded near infinity is stronger than necessary, but still applies to most of the interesting cases.

Figure 15.2

A potential satisfying Assumption 15.3.

We refer to a(E) and b(E) as the turning points, since these are the points where a classical particle with energy E changes direction. When the energy E is understood as being fixed, we will write the turning points simply as a and b.

### 15.4.1 The Classically Allowed Region

As in Sect. 15.3, we seek approximate solutions to the time-independent Schrödinger equation having the following form in the classically allowed region:

![
$$\\displaystyle{ \\psi = A\(x\)\\exp \\left \\{\\pm \\frac{i} {\\hslash }\\int p\(x\)\\ dx\\right\\}, }$$
](A272900_1_En_15_Chapter_Equ13.gif)

(15.13)

where ![
$$p\(x\) = \\sqrt{2m\(E - V \(x\)\)}$$
](A272900_1_En_15_Chapter_IEq45.gif) is the momentum of a classical particle with energy E and position x. According to (15.9), this form for ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq05.gif) gives

![
$$\\displaystyle\\begin{array}{rcl} \\hat{H}\\psi - E\\psi & & = -\\frac{{\\hslash }^{2}} {2m}\\left \({A}^{{\\prime\\prime}}\(x\) \\pm \\frac{i} {\\hslash }2{A}^{{\\prime}}\(x\)p\(x\) \\pm \\frac{i} {\\hslash }{p}^{{\\prime}}\(x\)A\(x\)\\right\) \\\\ & & \\times \\exp \\left \\{\\pm \\frac{i} {\\hslash }\\int p\(x\)\\ dx\\right\\}. {}\\end{array}$$
](A272900_1_En_15_Chapter_Equ14.gif)

(15.14)

Since we want to obtain an approximate solution with an error smaller than ![
$$\\hslash,$$
](A272900_1_En_15_Chapter_IEq46.gif) we require that the second and third terms in parentheses in (15.14) cancel. This cancellation will occur if A satisfies

![
$$\\displaystyle{2{A}^{{\\prime}}\(x\)p\(x\) = -{p}^{{\\prime}}\(x\)A\(x\)}$$
](A272900_1_En_15_Chapter_Equg.gif)

or

![
$$\\displaystyle{ \\frac{{A}^{{\\prime}}\(x\)} {A\(x\)} = -\\frac{1} {2} \\frac{{p}^{{\\prime}}\(x\)} {p\(x\)}, }$$
](A272900_1_En_15_Chapter_Equ15.gif)

(15.15)

which we can easily solve (Exercise 3) as

![
$$\\displaystyle{ A\(x\) = C{\(p\(x\)\)}^{-1/2}. }$$
](A272900_1_En_15_Chapter_Equ16.gif)

(15.16)

If A is given by (15.16), we will have

![
$$\\displaystyle{ \\hat{H}\\psi - E\\psi = -\\frac{{\\hslash }^{2}} {2m} \\frac{{A}^{{\\prime\\prime}}\(x\)} {A\(x\)} \\psi \(x\), }$$
](A272900_1_En_15_Chapter_Equ17.gif)

(15.17)

indicating that our error is of order ![
$${\\hslash }^{2}.$$
](A272900_1_En_15_Chapter_IEq47.gif) This expression, however, is only local, in that it applies only in the classically allowed region. Furthermore, p(x) tends to zero at the turning points, which means that A(x) becomes unbounded at these points. This blow-up of the amplitude is a substantial complicating factor in the analysis.

We can get an approximate solution to the Schrödinger equation by taking a linear combination of the function in (15.13) with two different choices for the sign in the exponent, with constants c 1 and c 2. It is convenient to take the basepoint of our integration to be the left-hand turning point a = a(E). Furthermore, since the Schrödinger operator ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq48.gif) commutes with complex conjugation, the real and imaginary parts of any solution to the time-independent Schrödinger equation is again a solution. We will therefore consider only real-valued approximate solutions, i.e., those in which ![
$$c_{2} = \\overline{c_{1}}.$$
](A272900_1_En_15_Chapter_IEq49.gif) Using Exercise 1, we can then write our approximate solution as follows.

Summary 15.4

Suppose ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq06.gif) is a real-valued solution to the time-independent Schrödinger equation. Then in the classically allowed region but away from the turning points, we expect that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq07.gif) is well approximated by an expression of the form

![
$$\\displaystyle{ \\frac{R} {\\sqrt{p\(x\)}}\\cos \\left \\{\\frac{1} {\\hslash }\\int _{a}^{x}p\(y\)\\ dy-\\delta \\right\\}, }$$
](A272900_1_En_15_Chapter_Equ18.gif)

(15.18)

where ![
$$p\(x\) = \\sqrt{2m\(E - V \(x\)\)}$$
](A272900_1_En_15_Chapter_IEq50.gif) is the momentum of a classical particle with energy E and position x. Here R and δ are real constants, referred to as the amplitude and the phase of the approximate solution.

We refer to the function in (15.18) as the oscillatory WKB function. In integrating the square of the oscillatory WKB function over some interval, we may apply the identity ![
$${\\cos }^{2}\\theta = \(1 +\\cos \(2\\theta \)\)/2$$
](A272900_1_En_15_Chapter_IEq51.gif) to the cosine factor. The rapidly oscillating cos(2θ) term will be small for small ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq52.gif) because of cancellation between positive and negative values. Thus, the integral of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq08.gif) 2(x) over an interval will be, to leading order, just a constant times the integral of 1 ∕ p(x), or, equivalently, a constant times 1 ∕ v(x), where v is the velocity of the classical particle. But the integral of ![
$$1/v\(x\) = dt/dx$$
](A272900_1_En_15_Chapter_IEq53.gif) with respect to x is just the time t that the classical particle spends in the interval. We obtain, then, the following result.

Conclusion 15.5

If the amplitude R in (15.18) is chosen so that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq09.gif) has L 2 norm 1 over [a,b], then the probability of finding the quantum particle in an interval [c,d] ⊂ [a,b] is approximately the fraction of time the classical particle spends in [c,d] over one period of classical motion.

### 15.4.2 The Classically Forbidden Region

In the classically forbidden region, let us introduce the quantity

![
$$\\displaystyle{q\(x\) := \\sqrt{2m\(V \(x\) - E\)}.}$$
](A272900_1_En_15_Chapter_Equh.gif)

We look for approximate solutions to the Schrödinger equation (15.6) of the form

![
$$\\displaystyle{\\psi \(x\) = A\(x\)\\exp \\left \\{\\pm \\frac{1} {\\hslash }\\int _{x_{0}}^{x}q\(y\)\\ dy\\right\\}.}$$
](A272900_1_En_15_Chapter_Equi.gif)

If we analyze approximate solutions of this form precisely as in the classically allowed region, we again find that there is a unique choice for A (up to multiplication by a constant) that causes the order-![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq54.gif) terms in ![
$$\\hat{H}\\psi - E\\psi$$
](A272900_1_En_15_Chapter_IEq55.gif) to cancel, namely ![
$$A\(x\) = C{\(q\(x\)\)}^{-1/2}.$$
](A272900_1_En_15_Chapter_IEq56.gif) If we are hoping to approximate a square-integrable solution of the Schrödinger equation, we want to take a minus sign in the exponent on the interval (b, ∞), and it is convenient to the basepoint of our integration to be b. In the region (− ∞, a), we want to take a plus sign in the exponent; it is then convenient to take the basepoint of our integration to be a and to reverse the direction of integration, which changes the sign in the exponent back to being negative.

Summary 15.6

If ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq010.gif) 1 (x) is a solution to the time-independent Schrödinger equation that tends to zero as x approaches −∞, we expect that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq011.gif) 1 will be well approximated on (−∞,a), but away from the turning point, by the expression

![
$$\\displaystyle{ \\frac{c_{1}} {\\sqrt{q\(x\)}}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{x}^{a}q\(y\)\\ dy\\right\\}, }$$
](A272900_1_En_15_Chapter_Equ19.gif)

(15.19)

where ![
$$q\(x\) = \\sqrt{2m\(V \(x\) - E\)}$$
](A272900_1_En_15_Chapter_IEq57.gif) . Meanwhile, if ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq012.gif) 2 (x) is a solution to the time-independent Schrödinger equation that tends to zero as x approaches + ∞, we expect that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq013.gif) will be well approximated on (b,+∞), but away from the turning point, by the expression

![
$$\\displaystyle{ \\frac{c_{2}} {\\sqrt{q\(x\)}}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{b}^{x}q\(y\)\\ dy\\right\\}. }$$
](A272900_1_En_15_Chapter_Equ20.gif)

(15.20)

We refer to the functions in (15.19) and (15.20) as the exponential WKB functions. The general theory of ordinary differential equations tells us that any solution to the time-independent Schrödinger equation for a smooth potential is smooth. Thus, the singularity at the turning points is an artifact of our approximation method. Nevertheless, for small values of ![
$$\\hslash,$$
](A272900_1_En_15_Chapter_IEq58.gif) the true solution will "track" the WKB approximation until x gets very close to the turning point, with the result that the true solution will be large, but finite, near the turning points.

Figure 15.3 plots a potential function V (x), an energy level E, and the WKB functions in both the classically allowed and classically forbidden regions. In the figure, the WKB functions have been (improperly) used all the way up to the turning points.

Figure 15.3

The WKB functions, extended all the way to the turning points.

## 15.5 The Airy Function and the Connection Formulas

For any constant c 1 and any energy level E, we expect that there is a unique solution ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq014.gif) 1 of the Schrödinger equation (15.6) that is well approximated for x tending to − ∞ by a function of the form (15.19). We expect that this solution will be well approximated in the classically allowed region (but not too close to the turning points) by a function of the form (15.18) for a unique pair of constants R and δ. In this section, we will see that the correct choices for R and δ are

![
$$\\displaystyle{ R = 2c_{1},\\quad \\delta = \\frac{\\pi } {4}. }$$
](A272900_1_En_15_Chapter_Equ21.gif)

(15.21)

The formula (15.21) for R and δ is called a connection formula; there is a similar formula connecting an approximate solution that tends to zero as x tends to + ∞ to an approximate solution in the classically allowed region. By comparing the two connection formulas, we will obtain conditions on the energy E under which the two approximate solutions (one that decays near − ∞ and one that decays near + ∞) agree up to a constant in the classically allowed region. The condition on E will turn out to be precisely Condition 15.1.

The discussion in the previous paragraph should be compared to the analysis in Chap.​ 5, where we determined the constants for the solution inside the well in terms of the energy level and the constant in front of the exponentially decaying solution outside the well. Here, of course, the analysis is more complicated because neither of the approximations (15.19) or (15.18) is valid near the turning point. The connection formula will be obtained, then, by using the Airy equation to approximate the Schrödinger equation near the turning points.

To get a reasonable approximation of our wave function near the turning points, we approximate V locally by a linear function. (By contrast, in the WKB functions, we are essentially thinking of V as being locally constant.) Thus, for example, near the turning point a, we write V (x) ≈ (a − x)F 0, where ![
$$F_{0} = -{V }^{{\\prime}}\(a\),$$
](A272900_1_En_15_Chapter_IEq59.gif) yielding the approximate equation

![
$$\\displaystyle{-\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}\\psi } {d{x}^{2}} + \(a - x\)F_{0}\\psi = 0.}$$
](A272900_1_En_15_Chapter_Equj.gif)

By making the change of variable

![
$$\\displaystyle{ u ={ \\left \(\\frac{2mF_{0}} {{\\hslash }^{2}} \\right\)}^{1/3}\(a - x\) }$$
](A272900_1_En_15_Chapter_Equ22.gif)

(15.22)

we can reduce the equation to

![
$$\\displaystyle{ \\frac{{d}^{2}\\psi } {d{u}^{2}} - u\\psi \(u\) = 0, }$$
](A272900_1_En_15_Chapter_Equ23.gif)

(15.23)

which is the Airy equation.

Equation (15.23) has two linearly independent solutions, denoted Ai(u) and Bi(u). We are interested in the solution Ai(u), since this is the one that decays for u > 0, that is, for x < a. The function Ai(u) is defined by the following convergent improper integral

![
$$\\displaystyle{ \\mathrm{Ai}\(u\) = \\frac{1} {\\pi } \\int _{0}^{\\infty }\\cos \\left \(\\frac{{t}^{3}} {3} + ut\\right\)\\ dt. }$$
](A272900_1_En_15_Chapter_Equ24.gif)

(15.24)

Intuitively, convergence is due to the very rapid oscillation of the integrand for large t, which produces a cancellation between the positive and negative values of the cosine function. Rigorously, convergence can be proved using integration by parts, as in Exercise 6. By differentiating under the integral sign (Exercise 7), one can show that Ai indeed satisfies the Airy equation (15.23).

As | u | gets large, the integrand in (15.24) becomes more and more rapidly oscillating, producing more cancellation. The only exception to this behavior is when the derivative (with respect to t) of the function ![
$${t}^{3}/3 + ut$$
](A272900_1_En_15_Chapter_IEq60.gif) is zero. Near such a point, the argument of the cosine function is changing slowly and there is little oscillation. If u is negative, there is a unique critical point of ![
$${t}^{3}/3 + ut$$
](A272900_1_En_15_Chapter_IEq61.gif), at ![
$$t = \\sqrt{-u},$$
](A272900_1_En_15_Chapter_IEq62.gif) and we expect that the main contribution to the integral in (15.24) will come from ![
$$t \\approx \\sqrt{-u}.$$
](A272900_1_En_15_Chapter_IEq63.gif) If u is positive, ![
$${t}^{3}/3 + ut$$
](A272900_1_En_15_Chapter_IEq64.gif) has no critical points, and we expect that the integral in (15.24) will become quite small as u tends to + ∞. This sort of reasoning can be used to determine the precise asymptotics of the Airy function as u tends to + ∞ and as u tends to − ∞; see the discussion following (15.32) and (15.33).

We now state our main result, which will be derived in the remainder of this section. The result is not rigorous, because we have not estimated any of errors involved; such error estimates will be performed in Sect. 15.6.

Claim 15.7

If ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq015.gif) 1 is a solution of the Schrödinger equation ( 15.6 ) that tends to zero near −∞, then ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq016.gif) 1 can be normalized so that the following approximations hold

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{1}\(x\) \\approx \\frac{1} {2\\sqrt{q\(x\)}}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{x}^{a}q\(y\)\\ dy\\right\\}\\quad \\text{\(near } -\\infty \\text{\)}& &{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ25.gif)

(15.25)

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{1}\(x\) \\approx \\frac{\\sqrt{\\pi }} {{\(2mF_{0}\\hslash \)}^{1/6}}\\mathrm{Ai}\\left \({\\left \(\\frac{2mF_{0}} {{\\hslash }^{2}} \\right\)}^{1/3}\(a - x\)\\right\)\\quad \\text{\(near }x = a\\text{\)}& &{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ26.gif)

(15.26)

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{1}\(x\) \\approx \\frac{1} {\\sqrt{p\(x\)}}\\cos \\left \\{\\frac{1} {\\hslash }\\int _{a}^{x}p\(y\)\\ dy - \\frac{\\pi } {4}\\right\\}\\quad \\text{\(}a < x < b\\text{\).}& &{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ27.gif)

(15.27)

Here ![
$$F_{0} = -{V }^{{\\prime}}\(a\)$$
](A272900_1_En_15_Chapter_IEq65.gif) and in the case of (15.27), x should not be too close to a or to b.

Similarly, if ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq017.gif) 2 is a solution of the Schrödinger equation ( 15.6 ) that tends to zero near + ∞, then ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq018.gif) 2 can be normalized so that the following approximations hold

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{2}\(x\) \\approx \\frac{1} {\\sqrt{p\(x\)}}\\cos \\left \\{-\\frac{1} {\\hslash }\\int _{x}^{b}p\(y\)\\ dy + \\frac{\\pi } {4}\\right\\}\\quad \\text{\(}a < x < b\\text{\)}& &{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ28.gif)

(15.28)

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{2}\(x\) \\approx \\frac{\\sqrt{\\pi }} {{\(2mF_{1}\\hslash \)}^{1/6}}\\mathrm{Ai}\\left \({\\left \(\\frac{2F_{1}m} {{\\hslash }^{2}} \\right\)}^{1/3}\(x - b\)\\right\)\\quad \\text{\(near }x = b\\text{\)}& &{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ29.gif)

(15.29)

![
$$\\displaystyle\\begin{array}{rcl} \\psi _{2}\(x\) \\approx \\frac{1} {2\\sqrt{q\(x\)}}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{b}^{x}q\(y\)\\ dy\\right\\}\\quad \\text{\(near } + \\infty \\text{\).}& &{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ30.gif)

(15.30)

Here ![
$$F_{1} = {V }^{{\\prime}}\(b\)$$
](A272900_1_En_15_Chapter_IEq66.gif) and in the case of ( 15.28 ), x should not be too close to a or to b.

The approximate formulas for ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq0018.gif) 1 and ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq019.gif) 2 will agree, up to multiplication by a constant, in the classically allowed region if and only if we have

![
$$\\displaystyle{ \\frac{1} {\\hslash }\\int _{a}^{b}p\(x\)\\ dx = \\left \(n + \\frac{1} {2}\\right\)\\pi }$$
](A272900_1_En_15_Chapter_Equ31.gif)

(15.31)

for some non-negative integer n.

More specifically, (15.27) and (15.28) are equal when the integer n in (15.31) is even and they are negatives of each other when n is odd. Note that there is a factor of 2 in the denominator in (15.25) but not in (15.27); this factor accounts for the expression R = 2c 1 in (15.21).

Since the classical energy curve consists of two "branches," of the form (x, p(x)) and (x, − p(x)), the compatibility condition (15.31) is equivalent to Condition 15.1. Since the phase of the approximate wave function in the classically allowed region is given by ![
$$1/\\hslash $$
](A272900_1_En_15_Chapter_IEq67.gif) times the integral of p dx, the condition (15.31) says that the wave function goes through a little more than n half-cycles between the two turning points, where a half-cycle corresponds to a change in the phase in the amount of π, or the interval between two critical points of the wave function. In particular, the wave function has exactly n \+ 1 critical points inside the classically allowed region. The first and last critical points occur slightly inside the turning points, leaving a change in phase of roughly π ∕ 4 between the extreme critical point and the turning point.

Figure 15.4 considers the same potential as in Fig. 15.3. The figure shows the WKB functions (15.25) and (15.27), together with the scaled Airy function (15.26), near the turning point x = a. Note that there is a good match between the WKB functions and the scaled Airy function when x is close to, but not too close to, the turning point. Meanwhile, Fig. 15.5 then shows the full approximate wave function with ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq68.gif) chosen so that (15.31) holds with n = 39, obtained by using the WKB functions away from the turning points and the scaled Airy functions near the turning points. Finally, Fig. 15.6 shows the probability distribution associated to the approximate wave function, plotted together with the function 1 ∕ p(x). (Compare the discussion preceding Conclusion 15.5.)

Figure 15.4

Plots of the scaled Airy function (thick curve) and the WKB functions, near the turning point x = a.

Figure 15.5

The approximate wave function with n = 39.

Figure 15.6

The probability distribution of the approximate wave function, plotted against the function 1 ∕ p(x).

We now derive the results in Claim 15.7. The Airy function Ai(u) is known to have the following asymptotic behavior:

![
$$\\displaystyle{ \\mathrm{Ai}\(u\) \\approx \\frac{1} {2\\sqrt{\\pi }{u}^{1/4}}\\exp \\left \\{-\\frac{2} {3}{u}^{3/2}\\right\\},\\quad u \\rightarrow +\\infty, }$$
](A272900_1_En_15_Chapter_Equ32.gif)

(15.32)

and

![
$$\\displaystyle{ \\mathrm{Ai}\(u\) \\approx \\frac{1} {\\sqrt{\\pi }{\(-u\)}^{1/4}}\\cos \\left \(\\frac{2} {3}{\(-u\)}^{3/2} - \\frac{\\pi } {4}\\right\),\\quad u \\rightarrow -\\infty. }$$
](A272900_1_En_15_Chapter_Equ33.gif)

(15.33)

For u tending to − ∞, the asymptotics in (15.33) can be obtained by a straightforward application of the "method of stationary phase," as explained in Exercise 9. For u tending to + ∞, repeated integrations by parts (Exercise 8) show that Ai(u) decays faster than any power of u, which is all that is strictly required for the main theorem of Sect. 15.6. To obtain the precise asymptotics in (15.32), one should deform the contour of integration to obtain a different integral representation of Ai(u), and then apply some variant of the method of stationary phase, such as Laplace's method or the method of steepest descent. See Sect. 4.7 of [30] for one approach to this analysis.

We will use the Airy function on an interval around the turning points with a length that goes to zero as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq69.gif) tends to zero (so that the linear approximation to the potential gets better and better) but with a length that is large compared to ![
$${\\hslash }^{2/3}$$
](A272900_1_En_15_Chapter_IEq70.gif) (so that the value of u at the ends of the interval will be large, putting us into the asymptotic region of the Airy function). See Sect. 15.6 for more information.

We use the linear approximation V (x) ≈ (a − x)F 0 to the potential near x = a, where ![
$$F_{0} = -{V }^{{\\prime}}\(a\),$$
](A272900_1_En_15_Chapter_IEq71.gif) which turns the Schrödinger equation (15.6) into the Airy equation, as previously noted. Now, the linear approximation to V yields

![
$$\\displaystyle{ p \\approx \\sqrt{2mF_{0}}\\sqrt{x - a} }$$
](A272900_1_En_15_Chapter_Equ34.gif)

(15.34)

and

![
$$\\displaystyle{ \\frac{1} {\\hslash }\\int _{a}^{x}p\(y\)\\ dy \\approx \\frac{\\sqrt{2mF_{0}}} {\\hslash } \\frac{{\(x - a\)}^{3/2}} {3/2} = \\frac{2} {3}{\(-u\)}^{3/2}. }$$
](A272900_1_En_15_Chapter_Equ35.gif)

(15.35)

From here it is a simple matter to check, using (15.33), that

![
$$\\displaystyle{ \\frac{\\sqrt{\\pi }} {{\(2mF_{0}\\hslash \)}^{1/6}}\\mathrm{Ai}\(u\) \\approx \\frac{1} {\\sqrt{p\(x\)}}\\cos \\left \(\\frac{1} {\\hslash }\\int _{a}^{x}p\(y\)\\ dy - \\frac{\\pi } {4}\\right\)}$$
](A272900_1_En_15_Chapter_Equk.gif)

for x > a, where the approximation holds in an intermediate region where x is close to a but not too close to a. Thus, if we scale our solution ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq020.gif) 1 to the Schrödinger equation so that it is approximated by ![
$${\\pi }^{1/2}{\(2mF_{0}\\hslash \)}^{-1/6}$$
](A272900_1_En_15_Chapter_IEq72.gif) times Ai(u) near x = a, it should satisfy (15.27) in the classically allowed region (but away from the turning points). It is then straightforward to verify, using (15.32), that this multiple of Ai(u) satisfies (15.25) for x near − ∞. The analysis of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq021.gif) 2 is entirely similar.

Finally, to compare the approximations (15.27) and (15.28), we note that

![
$$\\displaystyle{-\\frac{1} {\\hslash }\\int _{x}^{b}p\(y\)\\ dy + \\frac{\\pi } {4} = \\left \(\\int _{a}^{x}p\(y\)\\ dy - \\frac{\\pi } {4}\\right\)-\\phi,}$$
](A272900_1_En_15_Chapter_Equl.gif)

where

![
$$\\displaystyle{\\phi = \\frac{1} {\\hslash }\\int _{a}^{b}p\(y\)\\ dy -\\pi /2.}$$
](A272900_1_En_15_Chapter_Equm.gif)

Now, if   is an odd multiple of π, then ![
$$\\cos \(\\theta -\\phi \) = -\\cos \\theta$$
](A272900_1_En_15_Chapter_IEq73.gif) and if   is an even multiple of π, then ![
$$\\cos \(\\theta -\\phi \) =\\cos \\theta.$$
](A272900_1_En_15_Chapter_IEq74.gif) For all other values of   (Exercise 4), cos(θ −  ) is not a constant multiple of cos θ. Thus, (15.31) is a necessary and sufficient condition for the two approximate solutions to agree up to a constant in the classically allowed region.

## 15.6 A Rigorous Error Estimate

The preceding sections give a treatment of the WKB approximation that is typical of many books in the literature. This treatment gives the idea that energies E satisfying the corrected Bohr–Sommerfeld Condition (Condition 15.1) should be approximate eigenvalues for the Hamiltonian operator ![
$$\\hat{H},$$
](A272900_1_En_15_Chapter_IEq75.gif) without specifying the sense in which this approximation holds. In this section, we prove a rigorous estimate, as follows.

Theorem 15.8.

For any potential V and range ![
$$\[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq76.gif) of energies satisfying Assumption 15.3, there is a constant C such that the following holds. For any energy ![
$$E \\in \[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq77.gif) satisfying Condition 15.1, there exists a nonzero function ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq0021.gif) belonging to ![
$$\\mathrm{Dom}\(\\hat{H}\)$$
](A272900_1_En_15_Chapter_IEq78.gif) such that

![
$$\\displaystyle{ \\Vert \\hat{H}\\psi - E\\psi \\Vert < C{\\hslash }^{9/8}\\left \\Vert \\psi \\right\\Vert. }$$
](A272900_1_En_15_Chapter_Equ36.gif)

(15.36)

As noted already in Sect. 15.3, an estimate of the form ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert <\\varepsilon \\left \\Vert \\psi \\right\\Vert$$
](A272900_1_En_15_Chapter_IEq79.gif) implies that there is a point ![
$$\\tilde{E}$$
](A272900_1_En_15_Chapter_IEq80.gif) in the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq81.gif) with ![
$$\\vert E -\\tilde{ E}\\vert <\\varepsilon.$$
](A272900_1_En_15_Chapter_IEq82.gif) (See Exercise 4 in Chap.​ 10) Since, under our assumptions on V, the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq83.gif) is purely discrete, we conclude that for each number ![
$$E \\in \[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq84.gif) satisfying Condition 15.1, there is an actual eigenvalue ![
$$\\tilde{E}$$
](A272900_1_En_15_Chapter_IEq85.gif) for ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq86.gif) with

![
$$\\displaystyle{ \\vert E -\\tilde{ E}\\vert < C{\\hslash }^{9/8}. }$$
](A272900_1_En_15_Chapter_Equ37.gif)

(15.37)

If E satisfies Condition 15.1, then the estimate (15.37) actually holds with ![
$${\\hslash }^{9/8}$$
](A272900_1_En_15_Chapter_IEq87.gif) replaced by ![
$${\\hslash }^{2}$$
](A272900_1_En_15_Chapter_IEq88.gif) on the right-hand side. It is not, however, possible to obtain such an optimal estimate by the methods we are using in this chapter. Specifically, the approximate eigenvector ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq022.gif) constructed in the proof of Theorem 15.8 does not satisfy an estimate of the form ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert < C{\\hslash }^{2}.$$
](A272900_1_En_15_Chapter_IEq89.gif) One can, however, construct an approximate eigenvector by different methods—for example, the method in [31]—that satisfies an order-![
$${\\hslash }^{2}$$
](A272900_1_En_15_Chapter_IEq90.gif) error estimate, for any E satisfying the corrected Condition 15.1. Nevertheless, the error bound in (15.37) is small compared to the typical spacing between the energy levels, which is of order ![
$$\\hslash.$$
](A272900_1_En_15_Chapter_IEq91.gif)

Recall, as we noted at the beginning of Sect. 15.4, that a Schrödinger operator with potential V that is smooth and tends to + ∞ at ± ∞ is essentially self-adjoint on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\).$$
](A272900_1_En_15_Chapter_IEq92.gif) The operator ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq93.gif) in Theorem 15.8 is, more precisely, the unique self-adjoint extension of the Schrödinger operator defined on ![
$$C_{c}^{\\infty }\(\\mathbb{R}\).$$
](A272900_1_En_15_Chapter_IEq94.gif)

### 15.6.1 Preliminaries

Our construction of the approximate eigenfunction ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq023.gif) will be essentially by the WKB approximation as outlined in Claim 15.7. That is to say, we will define ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq024.gif) using scaled Airy functions near the turning points and by the standard WKB functions in the classically allowed and classically forbidden regions. There is, however, a difficulty with this approach, which is that at the boundary between different regions, the scaled Airy function does not exactly match the WKB functions, but only approximately. What this means is that if we define ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq025.gif) by the WKB formula in, say, an interval of the form ![
$$\(-\\infty,a-\\varepsilon \)$$
](A272900_1_En_15_Chapter_IEq95.gif) and we define ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq026.gif) by a scaled Airy function on ![
$$\(a-\\varepsilon,a+\\varepsilon \),$$
](A272900_1_En_15_Chapter_IEq96.gif) then ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq027.gif) may be discontinuous at ![
$$a -\\varepsilon.$$
](A272900_1_En_15_Chapter_IEq97.gif) Even if we scale ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq028.gif) by a constant on one of these intervals to eliminate the discontinuity in ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq029.gif) itself, the derivative of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq030.gif) will still probably be discontinuous. But if the derivative of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq031.gif) is discontinuous, ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq032.gif) is not actually in the domain of ![
$$\\hat{H},$$
](A272900_1_En_15_Chapter_IEq98.gif) and the left-hand side of (15.36) does not make sense. (Compare Sect.​ 5.​2).

The condition that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq033.gif) ′ be continuous is not just a technicality: If we did not worry about continuity of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq034.gif) ′ , then we could always match the scaled Airy function to the WKB functions, just by multiplying the various functions by constants, regardless of whether or not the energy satisfies the corrected Bohr–Sommerfeld Condition. In that case, we would be claiming that any number ![
$$E \\in \[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq99.gif) is within ![
$$C{\\hslash }^{9/8}$$
](A272900_1_En_15_Chapter_IEq100.gif) of an eigenvalue of ![
$$\\hat{H},$$
](A272900_1_En_15_Chapter_IEq101.gif) which is false already for the harmonic oscillator.

To work around the difficulty described in the previous paragraphs, we must put in a transition region over which we smoothly pass from one function to the other, using the "join" construction described in Sect. 15.6.4. Thus, we define the function ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq035.gif) in Theorem 15.8 as follows. We use the formulas in Claim 15.7 in the indicated intervals, except that multiply the functions (15.28), (15.29), and (15.30) by − 1 when n is odd. We use the scaled Airy functions (15.26) and (15.29) on intervals of the form ![
$$\(a-\\varepsilon,a+\\varepsilon \)$$
](A272900_1_En_15_Chapter_IEq102.gif) and ![
$$\(b-\\varepsilon,b+\\varepsilon \),$$
](A272900_1_En_15_Chapter_IEq103.gif) respectively, for some ![
$$\\varepsilon$$
](A272900_1_En_15_Chapter_IEq104.gif) depending on ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq105.gif) in a manner to be determined later. We then put in four transition regions, each having length δ, where δ also depends on ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq106.gif) in a manner to be determined later. The first transition region, for example, is the interval ![
$$\(a -\\varepsilon -\\delta,a-\\varepsilon \)$$
](A272900_1_En_15_Chapter_IEq107.gif) between the first classically forbidden region and the first turning point. In each transition region, we change over smoothly from one function to another. See Fig. 15.7 for an illustration of the transition regions around the turning point x = a.

Figure 15.7

The approximate eigenfunction ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq036.gif), with the transition regions shaded.

Suppose ![
$$\\hat{H}_{0}$$
](A272900_1_En_15_Chapter_IEq108.gif) denotes the Schrödinger operator with potential V, with domain equal to ![
$$C_{c}^{\\infty }\(\\mathbb{R}\).$$
](A272900_1_En_15_Chapter_IEq109.gif) Then, as we have noted, ![
$$\\hat{H}_{0}$$
](A272900_1_En_15_Chapter_IEq110.gif) is essentially self-adjoint, and we are letting ![
$$\\hat{H},$$
](A272900_1_En_15_Chapter_IEq111.gif) which coincides with the adjoint operator ![
$$\\hat{H}_{0}^{{\\ast}},$$
](A272900_1_En_15_Chapter_IEq112.gif) denote the unique self-adjoint extension of ![
$$\\hat{H}_{0}.$$
](A272900_1_En_15_Chapter_IEq113.gif) Now, the domain of ![
$$\\hat{H}_{0}^{{\\ast}}$$
](A272900_1_En_15_Chapter_IEq114.gif) consists of all functions ![
$$\\psi \\in {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_15_Chapter_IEq115.gif) such that the Schrödinger operator, computed in the distributional sense, again belongs to ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_15_Chapter_IEq116.gif) In particular, if ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq037.gif) is smooth, then ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq038.gif) belongs to the domain of ![
$$\\hat{H} =\\hat{ H}_{0}^{{\\ast}}$$
](A272900_1_En_15_Chapter_IEq117.gif) if and only if ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq039.gif) is in ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_15_Chapter_IEq118.gif) and ![
$$-{\({\\hslash }^{2}/2m\)\\psi }^{{\\prime\\prime}} + V \\psi$$
](A272900_1_En_15_Chapter_IEq119.gif) is also in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_15_Chapter_IEq120.gif)

Because of the joins, our approximate eigenfunction is ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq040.gif) actually infinitely differentiable on all of ![
$$\\mathbb{R}.$$
](A272900_1_En_15_Chapter_IEq121.gif) And since V (x) tends to + ∞ at ± ∞, the exponential WKB functions (15.25) and (15.30) have rapid decay at infinity, which shows that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq041.gif) is in ![
$${L}^{2}\(\\mathbb{R}\).$$
](A272900_1_En_15_Chapter_IEq122.gif) Furthermore, for x near ± ∞, the calculation (15.17) applies, with ![
$$A\(x\) = Cq{\(x\)}^{-1/2}.$$
](A272900_1_En_15_Chapter_IEq123.gif) We obtain, after a short calculation,

![
$$\\displaystyle\\begin{array}{rcl} & & -{\\frac{{\\hslash }^{2}} {2m}{\\psi} ^{{\\prime\\prime}}}\(x\) + V \(x\)\\psi \(x\) \\\\ & & = -\\frac{{\\hslash }^{2}} {2m}\\left \( \\frac{5} {16}{\\left \( \\frac{{V }^{{\\prime}}\(x\)} {V \(x\) - E}\\right\)}^{2} -\\frac{1} {4} \\frac{{V }^{{\\prime\\prime}}\(x\)} {V \(x\) - E}\\right\)\\psi \(x\).{}\\end{array}$$ 
](A272900_1_En_15_Chapter_Equ38.gif)

(15.38)

Since V ′ ∕ V and V ′ ′ ∕ V are assumed to be bounded near infinity and ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq042.gif)(x) tends to + ∞ at ± ∞, we see that the Schrödinger operator applied to ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq043.gif) is bounded by a constant times ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq044.gif) near infinity and is thus square integrable. This shows that ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq045.gif) is in the domain ![
$$\\hat{H}.$$
](A272900_1_En_15_Chapter_IEq124.gif)

In Sect. 15.6.2, we will take the width ![
$$2\\varepsilon$$
](A272900_1_En_15_Chapter_IEq125.gif) of the region around the turning points to be of order ![
$${\\hslash }^{1/2}.$$
](A272900_1_En_15_Chapter_IEq126.gif) In that case, the L 2 norm of our approximate wave function is of order 1 (bounded and bounded away from zero) as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq127.gif) tends to zero, despite the blow-up of order ![
$${\\hslash }^{-1/6}$$
](A272900_1_En_15_Chapter_IEq128.gif) very near the turning points. Although this result is not hard to verify (Exercise 10), if anything, the norm would be blowing up as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq129.gif) tends to zero, which would only help us in showing that ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq130.gif) is small compared to ![
$$\\left \\Vert \\psi \\right\\Vert.$$
](A272900_1_En_15_Chapter_IEq131.gif)

To prove Theorem 15.8, we must estimate the contributions to the quantity ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq132.gif) from four different types of regions: the classically allowed region, the classically forbidden regions, the regions near the turning points, and the transition regions. These estimates will occupy the remainder of this section, with the analysis in the transition regions being the most involved. In particular, it is essential that the derivative of scaled Airy function almost match the derivative of the WKB function in the transition region, as in the second part of Lemma 15.9.

### 15.6.2 The Regions Near the Turning Points

We use a scaled Airy function in an interval around each turning point. [We use (15.26) near x = a and either (15.29) or the negative thereof near x = b, depending on whether n is even or odd.] We now verify that taking these intervals to have length of order ![
$${\\hslash }^{1/2}$$
](A272900_1_En_15_Chapter_IEq133.gif) will give satisfactory estimates. If ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq134.gif) denotes one of the scaled Airy functions, then ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq046.gif) satisfies a Schrödinger equation in which the potential V is replaced by a linear approximation ![
$$\\tilde{V }$$
](A272900_1_En_15_Chapter_IEq135.gif) near one of the turning points, which means that

![
$$\\displaystyle{ \\hat{H}\\psi - E\\psi = \(V \(x\) -\\tilde{ V }\(x\)\)\\psi. }$$
](A272900_1_En_15_Chapter_Equ39.gif)

(15.39)

The difference between V (x) and its linear approximation ![
$$\\tilde{V }\(x\)$$
](A272900_1_En_15_Chapter_IEq136.gif) grows at most quadratically with the distance from the turning point. Meanwhile, the asymptotics of the Airy function tell us that it can be bounded as ![
$$\\left \\vert \\mathrm{Ai}\(u\)\\right\\vert \\leq C{u}^{-1/4}.$$
](A272900_1_En_15_Chapter_IEq137.gif) (This is terrible estimate for small u, but still true.) Now u, as defined in (15.22), is of order ![
$${\\hslash }^{-2/3}$$
](A272900_1_En_15_Chapter_IEq138.gif) times the distance to the turning point. Since, also, there is factor of ![
$${\\hslash }^{-1/6}$$
](A272900_1_En_15_Chapter_IEq139.gif) in (15.26) and the distance from the turning point is at most of order ![
$${\\hslash }^{1/2},$$
](A272900_1_En_15_Chapter_IEq140.gif) we find that

![
$$\\displaystyle{\\vert \\hat{H}\\psi - E\\psi \\vert \\leq C{\({\\hslash }^{1/2}\)}^{2}{\\hslash }^{-1/6}{\({\\hslash }^{-2/3}{\\hslash }^{1/2}\)}^{-1/4} = C{\\hslash }^{7/8}}$$
](A272900_1_En_15_Chapter_Equn.gif)

over the interval around each turning point. Finally, if a function f satisfies f ≤ D on an interval of length L, then the L 2 norm of f over that interval will be at most ![
$$D\\sqrt{L}.$$
](A272900_1_En_15_Chapter_IEq141.gif) Thus, over the interval around the turning points,

![
$$\\displaystyle{\\vert \\vert \\hat{H}\\psi - E\\psi \\vert \\vert \\ = O\({\\hslash }^{7/8}{\\hslash }^{1/4}\) = O\({\\hslash }^{9/8}\).}$$
](A272900_1_En_15_Chapter_Equo.gif)

### 15.6.3 The Classically Allowed and Classically Forbidden Regions

The expression (15.38) for ![
$$\\hat{H}\\psi - E\\psi,$$
](A272900_1_En_15_Chapter_IEq142.gif) derived from (15.17), applies both in the classically allowed region and in the classically forbidden regions. Let us consider first the classically allowed region. Although (15.38) is nominally of order ![
$${\\hslash }^{2},$$
](A272900_1_En_15_Chapter_IEq143.gif) we use this expression on an interval whose ends get closer and closer to the turning point as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq144.gif) tends to zero. Since, also, the expression in (15.38) is blowing up at the turning points, the contribution to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq145.gif) from this interval is of order larger than ![
$${\\hslash }^{2}$$
](A272900_1_En_15_Chapter_IEq146.gif).

We have taken the interval around the turning point to have length ![
$$2\\varepsilon$$
](A272900_1_En_15_Chapter_IEq147.gif) that is of order ![
$${\\hslash }^{1/2},$$
](A272900_1_En_15_Chapter_IEq148.gif) and we will also take (Sect. 15.6.4) the transition regions to have length δ that is of order ![
$${\\hslash }^{1/2}.$$
](A272900_1_En_15_Chapter_IEq149.gif) Thus, we use the oscillatory WKB function on an interval of the form ![
$$\(a+\\gamma,b-\\gamma \),$$
](A272900_1_En_15_Chapter_IEq150.gif) where ![
$$\\gamma =\\varepsilon +\\delta$$
](A272900_1_En_15_Chapter_IEq151.gif) is of order ![
$${\\hslash }^{1/2}.$$
](A272900_1_En_15_Chapter_IEq152.gif) Now, the formula for ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq047.gif) in the classically allowed regions has a factor of ![
$$1/\\sqrt{p\(x\)}$$
](A272900_1_En_15_Chapter_IEq153.gif) times a bounded quantity (the cosine factor). Since V ′ (a) is assumed to be nonzero, V (x) − E behaves like a constant times (x − a) and so ![
$$1/\\sqrt{p\(x\)}$$
](A272900_1_En_15_Chapter_IEq154.gif) behaves like a constant time ![
$${\(x - a\)}^{-1/4}$$
](A272900_1_En_15_Chapter_IEq155.gif) for x approaching a, with similar behavior near the other turning point.

Meanwhile, the more problematic term in (15.38) is the term having (V (x) − E)2 in the denominator. Keeping in mind the ![
$$1/\\sqrt{p}$$
](A272900_1_En_15_Chapter_IEq156.gif) blowup of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq048.gif) itself, this term behaves like ![
$${\(x - a\)}^{-9/4}$$
](A272900_1_En_15_Chapter_IEq157.gif) as x approaches a. Thus, we may estimate the norm of ![
$$\\hat{H}\\psi - E\\psi$$
](A272900_1_En_15_Chapter_IEq158.gif) over the left half of the classically allowed region as

![
$$\\displaystyle\\begin{array}{rcl} \\vert \\vert \\hat{H}\\psi - E\\psi \\Vert \\ & & \\leq C{\\hslash }^{2}{\\left \(\\int _{ \(a+b\)/2}^{a+\\gamma }{\(x - a\)}^{-9/2}\\ dx\\right\)}^{1/2} {}\\\\ & & = {C}^{{\\prime}}{\\hslash }^{2}{{\(\\gamma }^{-7/2} - {\(\(a + b\)/2\)}^{7/2}\)}^{1/2}. {}\\\\ \\end{array}$$
](A272900_1_En_15_Chapter_Equ40.gif)

Since γ is of order ![
$${\\hslash }^{1/2}$$
](A272900_1_En_15_Chapter_IEq159.gif), the contribution to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq160.gif) from the interval ![
$$\(a+\\gamma,\(a + b\)/2\)$$
](A272900_1_En_15_Chapter_IEq161.gif) will consist of a term of order ![
$${\\hslash }^{2}{\\hslash }^{-7/8} = {\\hslash }^{9/8},$$
](A272900_1_En_15_Chapter_IEq162.gif) plus lower-order terms. The estimate over the other half of the classically allowed region is similar.

Meanwhile, in the first classically forbidden region, we also apply (15.38). By Assumption 15.3, V ′ ∕ V and V ′ ′ ∕ V are bounded near infinity. Thus, ![
$${V }^{{\\prime}}/\(V - E\)$$
](A272900_1_En_15_Chapter_IEq163.gif) and ![
$${V }^{{\\prime\\prime}}/\(V - E\)$$
](A272900_1_En_15_Chapter_IEq164.gif) will also be bounded near infinity, and thus also bounded on ![
$$\(-\\infty,a - 1\)$$
](A272900_1_En_15_Chapter_IEq165.gif), since V − E is strictly positive on this interval and tends to + ∞ as x tends to − ∞. We see, then, that the norm of ![
$$\\hat{H}\\psi - E\\psi$$
](A272900_1_En_15_Chapter_IEq166.gif) over ![
$$\(-\\infty,a - 1\)$$
](A272900_1_En_15_Chapter_IEq167.gif) is bounded by a constant times ![
$${\\hslash }^{2}\\left \\Vert \\psi \\right\\Vert.$$
](A272900_1_En_15_Chapter_IEq168.gif)

The norm of ![
$$\\hat{H}\\psi - E\\psi$$
](A272900_1_En_15_Chapter_IEq169.gif) over an interval of the form ![
$$\(a - 1,a-\\gamma \)$$
](A272900_1_En_15_Chapter_IEq170.gif) can be analyzed similarly to the classically allowed region. The estimates from this region are better, however, because of the exponentially decaying factor in the definition of the WKB function. Thus, the contribution to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq171.gif) from the classically forbidden region ![
$$\(-\\infty,a-\\gamma \)$$
](A272900_1_En_15_Chapter_IEq172.gif) is certainly no larger than order ![
$${\\hslash }^{9/8},$$
](A272900_1_En_15_Chapter_IEq173.gif) and similarly for the other classically forbidden region.

### 15.6.4 The Transition Regions

Given two smooth functions ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq049.gif) 1 and ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq050.gif) 2 and some interval of the form [α, α \+ δ], we now define a "join" ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq051.gif) 1 ⊔ ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq0051.gif) 2 of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq052.gif) 1 and ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq053.gif) 2, where ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq054.gif) 1 ⊔ ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq055.gif) 2(x) is equal to ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq056.gif) 1(x) for x < α and equal to ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq057.gif) 2(x) for x > α \+ δ, and where ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq058.gif) 1 ⊔ ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq059.gif) 2 is smooth everywhere. Let χ be a smooth function on [0, 1] that is identically equal to 0 in a neighborhood of 0 and identically equal to 1 in a neighborhood of 1. Then define ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq060.gif) 1 ⊔ ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq061.gif) 2 by

![
$$\\displaystyle{\(\\psi _{1} \\sqcup \\psi _{2}\)\(x\) =\\psi _{1}\(x\) + \(\\psi _{2}\(x\) -\\psi _{1}\(x\)\)\\chi \(\(x-\\alpha \)/\\delta \).}$$
](A272900_1_En_15_Chapter_Equp.gif)

(See Fig. 15.8.) By direct calculation, we have

![
$$\\displaystyle\\begin{array}{rcl} \(\\hat{H} - EI\)\(\\psi _{1} \\sqcup \\psi _{2}\)& & = \(\\hat{H}\\psi _{1} - E\\psi _{1}\) \\sqcup \(\\hat{H}\\psi _{2} - E\\psi _{2}\) \\\\ & & -\\frac{1} {\\delta } \\frac{{\\hslash }^{2}} {m} {\(\\psi _{2}^{{\\prime}}\(x\) -\\psi _{ 1}^{{\\prime}}\(x\)\)\\chi }^{{\\prime}}\(\(x - a\)/\\delta \) \\\\ & & -{\\frac{1} {\\delta }^{2}} \\frac{{\\hslash }^{2}} {2m}{\(\\psi _{2}\(x\) -\\psi _{1}\(x\)\)\\chi }^{{\\prime\\prime}}\(\(x - a\)/\\delta \).{}\\end{array}$$
](A272900_1_En_15_Chapter_Equ41.gif)

(15.40)

Figure 15.8

The join of two functions over the interval [α, α \+ δ], as indicated by the (thick curve).

In our constructing our approximate eigenfunction, we use five different formulas in five different regions: the two classically forbidden regions, the classically allowed region, and the regions near the two turning points. Since none of these functions exactly matches the function in the next interval, we put in a total of four joins in order to produce a function that is in the domain of ![
$$\\hat{H}.$$
](A272900_1_En_15_Chapter_IEq174.gif) We choose the width δ of the interval on which the join takes place to be of the same size as the intervals around the turning points, namely, order ![
$${\\hslash }^{1/2}.$$
](A272900_1_En_15_Chapter_IEq175.gif)

The most critical case is the transition from the region near the turning points to the classically allowed region. Consider, for example, the scaled Airy function ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq062.gif) 1 in (15.26) and the oscillatory WKB function ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq063.gif) 2 in (15.27). There are two contributions to the mismatch between these two functions. First, there is a discrepancy between the Airy function and its leading-order asymptotics. Second, there is an error in the approximations (15.34) and (15.35), which come from the discrepancy between the potential V (x) and its linear approximation ![
$$\\tilde{V }\(x\)$$
](A272900_1_En_15_Chapter_IEq176.gif) near x = a. We need to consider both contributions to the mismatch in our estimation of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq064.gif) 1 − ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq065.gif) 2 and of ![
$$\\psi _{1}^{{\\prime}}-\\psi _{2}^{{\\prime}}.$$
](A272900_1_En_15_Chapter_IEq177.gif)

Lemma 15.9.

Let ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq066.gif) 1 denote the scaled Airy function in ( 15.26 ), let ![
$$\\tilde{\\psi }_{1}$$
](A272900_1_En_15_Chapter_IEq178.gif) denote the same function with the Airy function replaced by the right-hand side of ( 15.33 ), and let ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq067.gif) 2 denote the oscillatory WKB function in ( 15.27 ). If x − a is positive and of order ![
$${\\hslash }^{1/2},$$
](A272900_1_En_15_Chapter_IEq179.gif) we have

![
$$\\displaystyle\\begin{array}{rcl} \\vert \\psi _{1}\(x\) -\\tilde{\\psi }_{1}\(x\)\\vert & & = O\({\\hslash }^{1/8}\) {}\\\\ \\vert \\tilde{\\psi }_{1}\(x\) -\\psi _{2}\(x\)\\vert & & = O\({\\hslash }^{1/8}\) {}\\\\ \\end{array}$$
](A272900_1_En_15_Chapter_Equ42.gif)

and

![
$$\\displaystyle\\begin{array}{rcl} \\vert \\psi _{1}^{{\\prime}}\(x\) -\\tilde{\\psi }_{ 1}^{{\\prime}}\(x\)\\vert & & = O\({\\hslash }^{-5/8}\) {}\\\\ \\vert \\tilde{\\psi }_{1}^{{\\prime}}\(x\) -\\psi _{ 2}\(x\)\\vert & & = O\({\\hslash }^{-5/8}\). {}\\\\ \\end{array}$$
](A272900_1_En_15_Chapter_Equ43.gif)

Before giving the proof of this lemma, let us verify that these estimates are sufficient to control the contribution to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq180.gif) from the transition region ![
$$\(a+\\varepsilon,a +\\varepsilon +\\delta \)$$
](A272900_1_En_15_Chapter_IEq181.gif) between the first turning point and the classically allowed region, where both ![
$$\\varepsilon$$
](A272900_1_En_15_Chapter_IEq182.gif) and δ are taken to be of order ![
$${\\hslash }^{1/2}.$$
](A272900_1_En_15_Chapter_IEq183.gif) We must consider each of the three lines in (15.40). The L 2 norm of the first line is of order at most ![
$${\\hslash }^{9/8},$$
](A272900_1_En_15_Chapter_IEq184.gif) by precisely the same argument as in Sect. 15.6.3.

For the second and third lines, we recall that if a function f is bounded by C, then the L 2 norm of f over an interval of length L is at most ![
$$C\\sqrt{L}.$$
](A272900_1_En_15_Chapter_IEq185.gif) Since we are taking the length δ of our transition interval to be of order ![
$${\\hslash }^{1/2},$$
](A272900_1_En_15_Chapter_IEq186.gif) the L 2 norm of the second line of (15.40) is of order

![
$$\\displaystyle{ \\frac{1} {{\\hslash }^{1/2}}{\\hslash }^{2}{\\hslash }^{-5/8}{\\hslash }^{1/4} = {\\hslash }^{9/8}.}$$
](A272900_1_En_15_Chapter_Equq.gif)

Meanwhile, the contribution from the third line of (15.40) is of order

![
$$\\displaystyle{\\frac{1} {\\hslash }{\\hslash }^{2}{\\hslash }^{1/8}{\\hslash }^{1/4} = {\\hslash }^{11/8}.}$$
](A272900_1_En_15_Chapter_Equr.gif)

Thus, the contribution to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq187.gif) from the transition region ![
$$\(a+\\varepsilon,a +\\varepsilon +\\delta \)$$
](A272900_1_En_15_Chapter_IEq188.gif) is of order at most ![
$${\\hslash }^{9/8}.$$
](A272900_1_En_15_Chapter_IEq189.gif)

The analysis of the transition between the classically allowed region and the region around x = b is entirely similar. The analysis of the transitions between the regions near the turning points and the classically forbidden regions is also similar, but much less delicate, because all of the functions involved are very small in the transition region. When (a − x) is positive and of order ![
$${\\hslash }^{1/2},$$
](A272900_1_En_15_Chapter_IEq190.gif) for example, u, as defined in (15.22) will be of order ![
$${\\hslash }^{-1/6}$$
](A272900_1_En_15_Chapter_IEq191.gif) and so u 3 ∕ 2 is of order ![
$${\\hslash }^{-1/4}.$$
](A272900_1_En_15_Chapter_IEq192.gif) Thus, the exponential factor in leading-order asymptotics of the Airy function for u > 0 will behave like ![
$$\\exp \(-C{\\hslash }^{-1/4}\),$$
](A272900_1_En_15_Chapter_IEq193.gif) which is very small for small ![
$$\\hslash,$$
](A272900_1_En_15_Chapter_IEq194.gif) certainly smaller than any power of ![
$$\\hslash.$$
](A272900_1_En_15_Chapter_IEq195.gif) Since all the factors in front of the exponential will behave like ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq196.gif) to a power, the overall contribution to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq197.gif) from the transition between the region near the turning points and the classically forbidden region is smaller than any power of ![
$$\\hslash.$$
](A272900_1_En_15_Chapter_IEq198.gif) Thus, none of the transition regions contributes an error worse that ![
$$O\({\\hslash }^{9/8}\).$$
](A272900_1_En_15_Chapter_IEq199.gif)

Proof of Lemma 15.9.

We consider only the estimates for the derivatives of the functions involved. The analysis of the functions themselves is similar (but easier) and is left as an exercise to the reader (Exercise 11).

We begin by considering ![
$$\\psi _{1}^{{\\prime}}-\\tilde{\\psi }_{1}^{{\\prime}}.$$
](A272900_1_En_15_Chapter_IEq200.gif) With a little algebra, we compute that

![
$$\\displaystyle{ \\frac{d\\psi _{1}} {dx} -\\frac{d\\tilde{\\psi }_{1}^{{\\prime}}} {dx} = -\\sqrt{\\pi }{\(2mF_{0}\)}^{1/6}{\\hslash }^{-5/6}\(\\mathrm{{Ai}}^{{\\prime}}\\left \(u\\right\) -\\widetilde{\\mathrm{{ Ai}}}^{{\\prime}}\(u\)\) }$$
](A272900_1_En_15_Chapter_Equ44.gif)

(15.41)

where u is as in (15.22) and where ![
$$\\widetilde{\\mathrm{Ai}}$$
](A272900_1_En_15_Chapter_IEq201.gif) is the function on the right-hand side of (15.33).

Now, Ai(u) has an asymptotic expansion for u → − ∞ given by

![
$$\\displaystyle{\\mathrm{Ai}\(u\) =\\widetilde{\\mathrm{ Ai}}\(u\)\(1 + C{u}^{-3/2} + \\cdots \\,\),}$$
](A272900_1_En_15_Chapter_Equs.gif)

and Ai ′ (u) has the asymptotic expansion obtained by formally differentiating this with respect to u. [See Eq. (7.64) in [30].] From this, we obtain

![
$$\\displaystyle{ \\mathrm{{Ai}}^{{\\prime}}\(u\) -\\widetilde{\\mathrm{{ Ai}}}^{{\\prime}}\(u\) =\\widetilde{\\mathrm{{ Ai}}}^{{\\prime}}\(u\)O\({\(-u\)}^{-3/2}\) +\\widetilde{\\mathrm{ Ai}}\(u\)O\({\(-u\)}^{-5/2}\). }$$
](A272900_1_En_15_Chapter_Equ45.gif)

(15.42)

From the explicit formula for ![
$$\\widetilde{\\mathrm{Ai}},$$
](A272900_1_En_15_Chapter_IEq202.gif) we see that ![
$$\\widetilde{\\mathrm{Ai}}\(u\)$$
](A272900_1_En_15_Chapter_IEq203.gif) is of order ![
$${\(-u\)}^{-1/4}.$$
](A272900_1_En_15_Chapter_IEq204.gif) Meanwhile, the formula ![
$$\\widetilde{\\mathrm{{Ai}}}^{{\\prime}}\(u\)$$
](A272900_1_En_15_Chapter_IEq205.gif) will contain two terms, the larger of which will be of order u 1 ∕ 4. Thus, the slower-decaying term on the right-hand side of (15.42) is the first one, which is of order ![
$${\(-u\)}^{-5/4}.$$
](A272900_1_En_15_Chapter_IEq206.gif) Now, in the transition regions, u behaves like ![
$${\\hslash }^{-2/3}{\\hslash }^{1/2} = {\\hslash }^{-1/6}.$$
](A272900_1_En_15_Chapter_IEq207.gif) Thus, (15.42) goes like ![
$${\\hslash }^{5/24}$$
](A272900_1_En_15_Chapter_IEq208.gif) and so (15.41) goes like ![
$${\\hslash }^{-5/6+5/24} = {\\hslash }^{-5/8},$$
](A272900_1_En_15_Chapter_IEq209.gif) as claimed.

We now consider ![
$$\\tilde{\\psi }_{1}^{{\\prime}}-\\psi _{2}^{{\\prime}}.$$
](A272900_1_En_15_Chapter_IEq210.gif) By direct calculation, the derivatives of ![
$$\\tilde{\\psi }_{1}$$
](A272900_1_En_15_Chapter_IEq211.gif) and ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq068.gif) 2 each consist of two terms, a "dominant" obtained by differentiating the cosine factor and a "subdominant" term obtained by differentiating the coefficient of the cosine factor. In the case of ![
$$\\tilde{\\psi }_{1}^{{\\prime}},$$
](A272900_1_En_15_Chapter_IEq212.gif) the dominant term in the derivative may be simplified to

![
$$\\displaystyle{ -\\frac{1} {\\hslash }{\(\(2mF_{0}\)\(x - a\)\)}^{1/4}\\sin \\left \(\\frac{2} {3}{\(-u\)}^{3/2} - \\frac{\\pi } {4}\\right\). }$$
](A272900_1_En_15_Chapter_Equ46.gif)

(15.43)

According to Exercise 12, we have, when x − a is of order ![
$${\\hslash }^{1/2}$$
](A272900_1_En_15_Chapter_IEq213.gif), the estimates

![
$$\\displaystyle{ {\(\(2mF_{0}\)\(a - x\)\)}^{1/4} = \\sqrt{p} + \\sqrt{p}O\({\\hslash }^{1/2}\) }$$
](A272900_1_En_15_Chapter_Equ47.gif)

(15.44)

and

![
$$\\displaystyle{ \\frac{2} {3}{\(-u\)}^{3/2} = \\frac{1} {\\hslash }\\int _{a}^{x}p\(y\)\\ dy + O\({\\hslash }^{1/4}\). }$$
](A272900_1_En_15_Chapter_Equ48.gif)

(15.45)

Since the derivative of sin θ is bounded, a change of order ![
$${\\hslash }^{1/4}$$
](A272900_1_En_15_Chapter_IEq214.gif) in the argument of a sine function produces a change of order ![
$${\\hslash }^{1/4}$$
](A272900_1_En_15_Chapter_IEq215.gif) in the value of the sine. Thus, if we substitute (15.44) and (15.45) into (15.43), we find that the difference between the dominant term in ![
$$\\tilde{\\psi }_{1}^{{\\prime}}$$
](A272900_1_En_15_Chapter_IEq216.gif) and the dominant term in ![
$$\\psi _{1}^{{\\prime}}$$
](A272900_1_En_15_Chapter_IEq217.gif) is

![
$$\\displaystyle{\\frac{1} {\\hslash }\\sqrt{p}O\({\\hslash }^{1/4}\) + \\text{lower-order terms.}}$$
](A272900_1_En_15_Chapter_Equt.gif)

Since ![
$$\\sqrt{p}$$
](A272900_1_En_15_Chapter_IEq218.gif) is of order ![
$${\(x - a\)}^{1/4}$$
](A272900_1_En_15_Chapter_IEq219.gif) or ![
$${\\hslash }^{1/8},$$
](A272900_1_En_15_Chapter_IEq220.gif) we get an error of order ![
$${\\hslash }^{-5/8},$$
](A272900_1_En_15_Chapter_IEq221.gif) as claimed.

Finally, the subdominant terms in the derivatives of ![
$$\\tilde{\\psi }_{1}$$
](A272900_1_En_15_Chapter_IEq222.gif) and ![
$$\\psi _{2}$$
](A272900_1_En_15_Chapter_IEq223.gif) are easily seen to be separately of order ![
$${\\hslash }^{-5/8}.$$
](A272900_1_En_15_Chapter_IEq224.gif) Thus, even without taking into account the cancellation between these terms, they do not change the order of the estimate.

### 15.6.5 Proof of the Main Theorem

We have estimated the contributions to ![
$$\\Vert \\hat{H}\\psi - E\\psi \\Vert$$
](A272900_1_En_15_Chapter_IEq225.gif) from each type of region: classically allowed and classically forbidden regions, the regions around the turning points, and the transition regions. In each case, we have found a contribution that is of order at most ![
$${\\hslash }^{9/8}\\left \\Vert \\psi \\right\\Vert.$$
](A272900_1_En_15_Chapter_IEq226.gif) Thus, it remains only to verify that the constants in all estimates are bounded uniformly over the given range E 1 ≤ E ≤ E 2 of energies.

This verification is straightforward. Near the turning point x = a, for example, we need to estimate the difference between the potential V (x) and its linear approximation ![
$$\\tilde{V }\(x\)$$
](A272900_1_En_15_Chapter_IEq227.gif) near x = a. As a consequence of the Taylor remainder formula, ![
$$\\vert V \(x\) -\\tilde{ V }\(x\)\\vert $$
](A272900_1_En_15_Chapter_IEq228.gif) will be bounded by ![
$$C{\\left \\vert x - a\\right\\vert }^{2}/2,$$
](A272900_1_En_15_Chapter_IEq229.gif) where C is the maximum of | V ′ ′ (x) | over the interval from a to x. As E varies over ![
$$\[E_{1},E_{2}\]$$
](A272900_1_En_15_Chapter_IEq230.gif), the set of points where we have to evaluate | V ′ ′ (x) | will be bounded, meaning that C can be taken to be independent of E, for E in such a range.

Similarly, in the classically allowed region, the blow-up of ![
$$1/{\(V \(x\) - E\)}^{2}$$
](A272900_1_En_15_Chapter_IEq231.gif) near x = a(E) can be controlled by the minimum of | V ′ (y) | for y between a and x. By assumption, ![
$$\\left \\vert {V }^{{\\prime}}\(x\)\\right\\vert > 0$$
](A272900_1_En_15_Chapter_IEq232.gif) at all the turning points a(E) and b(E) with E 1 ≤ E ≤ E 2, and thus, by continuity, in some neighborhood of that set of turning points. Thus, blow-up of ![
$$1/{\(V \(x\) - E\)}^{2}$$
](A272900_1_En_15_Chapter_IEq233.gif) will be controlled by the minimum of ![
$$\\left \\vert {V }^{{\\prime}}\(x\)\\right\\vert$$
](A272900_1_En_15_Chapter_IEq234.gif) on an interval of the form ![
$$\[a\(E_{2}\)+\\alpha,a\(E_{1}\)+\\alpha \]$$
](A272900_1_En_15_Chapter_IEq235.gif) for some small α > 0. The remaining details of this verification are left to the reader.

## 15.7 Other Approaches

The main complicating factor in the WKB approximation is the singular behavior near the turning points. The turning points, meanwhile, are only problematic because we are working in the position representation. The turning points, after all, are the points on the classical trajectory where the position of the particle achieves a maximum or a minimum. If we were to work in the momentum representation, the points where the momentum achieves a maximum or a minimum would instead be the problematic points. A. Voros 42] has proposed working in the Segal–Bargmann representation ([Sect.​ 14.​4). In Voros's analysis, there are no turning points and, thus, the analysis is much simpler. The problem with Voros's approach is that he only gives an approximation to the wave function on the classical energy curve. Even in simple cases, Voros's expression does not admit a holomorphic extension to the whole plane, but has branching behavior inside the classical energy curve. Thus, Voros's formula does not define an element of the quantum Hilbert space (which is a space of entire holomorphic functions), let alone an element of the domain of the Hamiltonian.

Nevertheless, it is possible to build approximate eigenfunctions as superpositions of coherent states, using formulas similar to those in Voros. This approach avoids dealing with turning points but still yields a rigorous eigenvalue estimate, with the same corrected Bohr–Sommerfeld condition as in Condition 15.1. See [7, 23, 31], or (in greater generality) [26].

## 15.8 Exercises

1.

Show that if c 1 is any complex number, then we have an identity of the form

![
$$\\displaystyle{c_{1}{e}^{i\\theta } + \\overline{c_{ 1}}{e}^{-i\\theta } = R\\cos \(\\theta -\\delta \)}$$
](A272900_1_En_15_Chapter_Equu.gif)

for some real numbers R and δ.

2.

Let ![
$$H\(x,p\) = {p}^{2}/2m + {m\\omega }^{2}{x}^{2}/2$$
](A272900_1_En_15_Chapter_IEq236.gif) be the Hamiltonian for a harmonic oscillator having mass m and classical frequency ω. Show that a positive number E satisfies the corrected Bohr–Sommerfeld condition (Condition 15.1) if and only if E is of the form ![
$$\(n + 1/2\)\\hslash \\omega,$$
](A272900_1_En_15_Chapter_IEq237.gif) where n is a non-negative integer.

Note: In light of the results of Chap.​ 11, this calculation means that, in this very special case, the corrected Bohr–Sommerfeld condition gives the exact eigenvalues of the quantum Hamiltonian ![
$$\\hat{H}.$$
](A272900_1_En_15_Chapter_IEq238.gif)

3.

Suppose A and p are two nonzero, smooth functions satisfying (15.15). Show that ![
$$A\(x\) = C{\(p\(x\)\)}^{-1/2}$$
](A272900_1_En_15_Chapter_IEq239.gif) for some constant C.

Hint: Think in terms of the logarithms of the functions involved.

4.

Show that cos(θ − δ), viewed as a function of θ, agrees, up to multiplication by a constant, with cos(θ − δ ′ ) if and only if δ − δ ′ is an integer multiple of π.

5.

If ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq069.gif) is an eigenvector for ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq240.gif) that is approximated by (15.25) near − ∞, one might hope to find an approximate expression for ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq070.gif) in the classically allowed region by analytically continuing around the turning point in the complex plane. Even assuming V is analytic, however, it is fairly evident that analytic continuation in the upper half-plane does not give the same answer as in the lower half-planes. Nevertheless, one could use the average of the upper and lower half-plane results as a (totally nonrigorous) guess for the behavior of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq071.gif) in the classically allowed region.

Show that the above approach gives the correct phase δ in the connection formula (15.21) but is off by a factor of 2 in the amplitude R.

6.

Using integration by parts, show that the limit

![
$$\\displaystyle{\\lim _{A\\rightarrow +\\infty }\\int _{0}^{A}\\cos \\left \(\\frac{{t}^{3}} {3} + ut\\right\)\\ dt}$$
](A272900_1_En_15_Chapter_Equv.gif)

exists.

Hint: Multiply and divide by t 2 \+ u (avoiding points where ![
$${t}^{2} + u = 0$$
](A272900_1_En_15_Chapter_IEq241.gif) in the case u < 0).

7.

In this exercise, we sketch an argument that the Airy function in (15.24) satisfies the differential equation ![
$${\\psi }^{{\\prime\\prime}}\(u\) - u\\psi \(u\) = 0.$$
](A272900_1_En_15_Chapter_IEq242.gif) For the purposes of this exercise, let us say that ![
$$\\int _{0}^{\\infty }f\(t\)\\ dt = C$$
](A272900_1_En_15_Chapter_IEq243.gif) if ![
$$\\int _{0}^{A}f\(t\)\\ dt = C + g\(A\),$$
](A272900_1_En_15_Chapter_IEq244.gif) where the function g is bounded and oscillates around an average value of zero.

Assuming that it is legal to differentiate under the integral sign, verify that Ai(u) satisfies the stated equation.

Hint: After differentiating under the integral, look for a term that can be integrated explicitly.

Note: A more rigorous approach to this verification would be to integrate by parts as in Exercise 6 and then differentiate under the integral. This approach is, however, a bit messier.

8.

By integrating by parts repeatedly in (15.24), show that Ai(u) decays faster than any power of u as u tends to + ∞.

Hint: A key point is to show that the boundary terms in the integration by parts vanish at every stage. After performing the integrations by parts, estimate the resulting integral by using the inequality

![
$$\\displaystyle{ \\frac{1} {{\({t}^{2} + u\)}^{n}} < \\frac{1} {{\({t}^{2} + 1\)}^{k}} \\frac{1} {{u}^{n-k}},\\quad u > 1,}$$
](A272900_1_En_15_Chapter_Equw.gif)

for some appropriate choice of k.

9.

(a)

For u < 0, make the change-of-variable ![
$$\\tau = t/\\sqrt{-u}$$
](A272900_1_En_15_Chapter_IEq245.gif) in the integral formula for the Airy function, to obtain the expression

![
$$\\displaystyle{ \\mathrm{Ai}\(u\) = \\frac{\\sqrt{-u}} {\\pi } \\int _{0}^{\\infty }\\cos \\left \(\\alpha \\left \(\\frac{{\\tau }^{3}} {3}-\\tau \\right\)\\right\)\\ d\\tau, }$$
](A272900_1_En_15_Chapter_Equ49.gif)

(15.46)

where ![
$$\\alpha = {\(-u\)}^{3/2}.$$
](A272900_1_En_15_Chapter_IEq246.gif)

(b)

Suppose f is a smooth function on [a, b] having a unique critical point x 0. Assuming that x 0 is in the interior of [a, b] and that ![
$${f}^{{\\prime\\prime}}\(x_{0}\)\\neq 0,$$
](A272900_1_En_15_Chapter_IEq247.gif) the method of stationary phase asserts that

![
$$\\displaystyle{\\int _{a}^{b}g\(x\){e}^{i\\alpha f\(x\)}\\ dx = g\(x_{ 0}\){e}^{i\\alpha f\(x_{0}\)}{e}^{\\pm i\\pi /4}\\sqrt{ \\frac{2\\pi } {\\alpha \\left \\vert {f}^{{\\prime\\prime}}\(x_{0}\)\\right\\vert }} + O\\left \(\\frac{1} {\\alpha } \\right\)}$$
](A272900_1_En_15_Chapter_Equx.gif)

for α tending to + ∞, where the plus sign in the exponent is taken when ![
$${f}^{{\\prime\\prime}}\(x_{0}\) > 0$$
](A272900_1_En_15_Chapter_IEq248.gif) and the minus sign is taken when ![
$${f}^{{\\prime\\prime}}\(x_{0}\) < 0.$$
](A272900_1_En_15_Chapter_IEq249.gif) (See, e.g., Eq. (5.12) in [30].)

Using this result, obtain the asymptotic formula (15.33).

Hint: Divide the integral in (15.46) into an integral over [0, 2] and an integral over [2, ∞). Use stationary phase for the first interval and integration by parts (as in Exercise 6) for the second interval.

10.

Let ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq072.gif) be the approximate eigenfunction for ![
$$\\hat{H}$$
](A272900_1_En_15_Chapter_IEq250.gif) defined in the beginning of Sect. 15.6. Show that the norm of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq073.gif) is bounded and bounded away from zero as ![
$$\\hslash $$
](A272900_1_En_15_Chapter_IEq251.gif) tends to zero.

Hint: First show that the L 2 norm of ![
$$\\psi$$
](A272900_1_En_15_Chapter_IEq074.gif) over the intervals around the turning points goes like ![
$${\\hslash }^{-1/6}{\\hslash }^{1/4}.$$
](A272900_1_En_15_Chapter_IEq252.gif) Then check that the functions ![
$$p{\(x\)}^{-1/2}$$
](A272900_1_En_15_Chapter_IEq253.gif) and ![
$$q{\(x\)}^{-1/2}$$
](A272900_1_En_15_Chapter_IEq254.gif) are square integrable near the turning points.

11.

By imitating the arguments in the proof of Lemma 15.9, prove the estimates for ![
$$\\psi _{1} -\\tilde{\\psi }_{1}$$
](A272900_1_En_15_Chapter_IEq255.gif) and ![
$$\\tilde{\\psi }_{1} -\\psi _{2}$$
](A272900_1_En_15_Chapter_IEq256.gif) in the lemma.

12.

By writing V (x) as F 0(a − x) plus an error term of order (x − a)2, verify that the estimates (15.44) and (15.45) in the proof of Lemma 15.9 hold in the transition region. (Assume that x − a is of order ![
$${\\hslash }^{1/2}$$
](A272900_1_En_15_Chapter_IEq257.gif) in the transition region.)

Hint: The leading-order Taylor expansion of (1 + z) a is ![
$$1 + az + O\({z}^{2}\),$$
](A272900_1_En_15_Chapter_IEq258.gif) for any real number a.

References

[7].

S. De Bièvre, J.-C. Houard, M. Irac-Astaud, Wave packets localized on closed classical trajectories. In Differential Equations with Applications to Mathematical Physics. Mathematics in Science and Engineering, vol. 192 (Academic, Boston, 1993), pp. 25–32

[8].

S. Dong, Wave Equations in Higher Dimensions (Springer, New York, 2011)CrossRefMATH

[23].

G. Hagedorn, S. Robinson, Bohr–Sommerfeld quantization rules in the semiclassical limit. J. Phys. A 31, 10113–10130 (1998)CrossRefMATHMathSciNet

[26].

M.V. Karasëv, Connections on Lagrangian submanifolds and some problems in quasiclassical approximation. I. (Russian); translation in J. Soviet Math. 59, 1053–1062 (1992)

[30].

P. Miller, Applied Asymptotic Analysis (American Mathematical Society, Providence, RI, 2006)MATH

[31].

T. Paul, A. Uribe, A construction of quasi-modes using coherent states. Ann. Inst. H. Poincaré Phys. Théor 59, 357–381 (1993)MATHMathSciNet

[34].

M. Reed, B. Simon, Methods of Modern Mathematical Physics. Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)

[42].

A. Voros, Wentzel–Kramers–Brillouin method in the Bargmann representation. Phys. Rev. A 40(3), 6814–6825 (1989)CrossRefMathSciNet
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_16

© Springer Science+Business Media New York 2013

# 16. Lie Groups, Lie Algebras, and Representations

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

An important concept in physics is that of symmetry, whether it be rotational symmetry for many physical systems or Lorentz symmetry in relativistic systems. In many cases, the group of symmetries of a system is a continuous group, that is, a group that is parameterized by one or more real parameters. More precisely, the symmetry group is often a Lie group, that is, a smooth manifold endowed with a group structure in such a way that operations of inversion and group multiplication are smooth. The tangent space at the identity in a Lie group has a natural "bracket" operation that makes the tangent space into a Lie algebra. The Lie algebra of a Lie group encodes many of the properties of the Lie group, and yet the Lie algebra is easier to work with because it is a linear space.

An important concept in physics is that of symmetry, whether it be rotational symmetry for many physical systems or Lorentz symmetry in relativistic systems. In many cases, the group of symmetries of a system is a continuous group, that is, a group that is parameterized by one or more real parameters. More precisely, the symmetry group is often a Lie group, that is, a smooth manifold endowed with a group structure in such a way that operations of inversion and group multiplication are smooth. The tangent space at the identity in a Lie group has a natural "bracket" operation that makes the tangent space into a Lie algebra. The Lie algebra of a Lie group encodes many of the properties of the Lie group, and yet the Lie algebra is easier to work with because it is a linear space.

In quantum mechanics, the way symmetry is encoded is usually through a unitary action of the group on the relevant Hilbert space. That is, we assume we are given a unitary representation of the relevant symmetry group G, that is, a continuous homomorphism of G into U(H), the group of unitary operators on the quantum Hilbert space H. Actually, since two unit vectors in H that differ only by a constant represent the same physical state, we should more properly consider projective unitary representations. A projective representation is a homomorphism of a group G into U(H) ∕ U(1), where U(1) is the group of complex numbers of magnitude 1, thought of multiples of I in U(H). An ordinary or projective representation of a Lie group gives rise to an ordinary or projective representation of its Lie algebra. The angular momentum operators, for example, form a representation of the Lie algebra of the rotation group.

Saying that, for example, the Hamiltonian operator of a quantum system is invariant under rotations means that ![
$$\\hat{H}$$
](A272900_1_En_16_Chapter_IEq1.gif) commutes with the relevant representation of the rotation group and thus also with the associated Lie algebra operators. This commutativity, in turn, implies that the eigenspaces for ![
$$\\hat{H}$$
](A272900_1_En_16_Chapter_IEq2.gif) are invariant under rotations. We will use this commutativity in Chap.​ 18 to help us in determining the energy eigenvectors for the hydrogen atom.

In this chapter, we will make a brief survey of Lie groups, Lie algebras, and their representations. For our purposes, it suffices to consider matrix Lie groups, those that can be realized as closed subgroups of the group of n ×n invertible matrices. Inevitably, I have had to present some of the deeper results without proof. Proofs of all results stated here can be found in 21]. The results of this chapter will be put to use in [Chap.​ 17, in our study of angular momentum, and in Chap.​ 18, in our study of the hydrogen atom.

## 16.1 Summary

In this chapter, we will consider a matrix Lie group G, which is, by definition, a (topologically) closed subgroup of some ![
$$\\mathsf{GL}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq3.gif) where ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq4.gif) is the group of n ×n invertible matrices with complex entries. To each such G, we will associate the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq5.gif) of G, where ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq6.gif) is a real subspace of ![
$$M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq7.gif) the space of all n ×n matrices. We will see that G is automatically an embedded real submanifold of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq8.gif) and that ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq9.gif) is the tangent space of G at the identity matrix.

Now, ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq10.gif) is not just a real vector space, but comes with a "bracket" operation mapping ![
$$\\mathfrak{g} \\times \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq11.gif) into ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq12.gif) Specifically, we will show that for all X and Y in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq13.gif) the matrix XY − YX belongs again to ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq14.gif) Thus, we define our bracket by setting [X, Y ] equal to XY − YX. As it turns out, the Lie algebra ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq15.gif) as a vector space with the bracket operation, encodes a lot of information about the group G. On the other hand, computing at the level of the Lie algebra is generally easier than computing at the group level, simply because ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq16.gif) is a linear space.

We will be interested in unitary representations of our group G, that is, continuous homomorphisms of G into U(H), the group of unitary operators on a Hilbert space. If we restrict attention, at first, to the case in which H is finite dimensional, then each representation Π of G gives rise to a representation π of the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq17.gif) of G. That is to say, π is a linear map of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq18.gif) into the space of linear maps of V to V, satisfying π([X, Y ]) = [π(X), π(Y)]. A deeper question is whether every representation π of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq19.gif) comes from a representation Π of G. As it turns out, the answer in general is no, but the answer is yes if G is simply connected.

We may consider, for example, the case G = SO(3). This group is not simply connected. On the other hand, the Lie algebra so(3) of SO(3) is isomorphic to the Lie algebra su(2) of SU(2), and SU(2) is simply connected. [That is, SU(2) is the "universal cover" of SO(3). ] Thus, given a representation π of so(3), there may or may not be an associated representation Π of SO(3). Even if there is not, however, there is always a representation Π ′ of the group SU(2).

In quantum mechanics, the vector e iθ   represents the same physical state as  . Thus, it is natural to consider "projective" unitary representations, that is, homomorphisms of G into the quotient group ![
$$\\mathsf{U}\(\\mathbf{H}\)/\\{{e}^{i\\theta }I\\}.$$
](A272900_1_En_16_Chapter_IEq20.gif) In the finite-dimensional case, each projective representation can be "de-projectivized" at the level of the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq21.gif) of G. We can then pass from the Lie algebra to the universal cover of G, that is, the simply connected group with Lie algebra ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq22.gif) In particular, in the finite dimensional case, the irreducible projective unitary representations of SO(3) are in one-to-one correspondence with irreducible ordinary unitary representations of the universal cover SU(2) of SO(3). Although the Hilbert spaces of physical systems are usually infinite dimensional, for compact groups such as SO(3), general unitary representations can be decomposed as direct sums of finite-dimensional ones. (See, e.g., Proposition 17.19 and the discussion following it.)

## 16.2 Matrix Lie Groups

Let ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq23.gif) denote the space of n ×n matrices with complex entries. We identify ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq24.gif) with ![
$${\\mathbb{C}}^{{n}^{2} },$$
](A272900_1_En_16_Chapter_IEq25.gif) equipped with the usual topology. Thus, a sequence A m in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq26.gif) converges to a matrix ![
$$A \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq27.gif) if (A m ) jk converges to A jk as m tends to infinity, for all 1 ≤ j, k ≤ n. Let ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq28.gif) denote the general linear group, consisting of all invertible n ×n matrices with complex entries. Then ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq29.gif) forms a group under the operation of matrix multiplication. Furthermore, ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq30.gif)—that is, the set of ![
$$A \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq31.gif) with det A≠0—is an open subset of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq32.gif). Since ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq33.gif) is a complex vector space of dimension n 2, it may be identified with ![
$${\\mathbb{C}}^{{n}^{2} }\\mathop{\\cong}{\\mathbb{R}}^{2{n}^{2} }.$$
](A272900_1_En_16_Chapter_IEq34.gif) Since ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq35.gif) is an open subset of ![
$$M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq36.gif) it looks locally like ![
$${\\mathbb{R}}^{2{n}^{2} }$$
](A272900_1_En_16_Chapter_IEq37.gif) and is therefore a real manifold of dimension 2n 2.

Definition 16.1

A subgroup G of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq38.gif) is closed if for each sequence A m in G that converges to a matrix A, either A is again in G or A is not invertible. A matrix Lie group is a closed subgroup of some ![
$$\\mathsf{GL}\(n; \\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq39.gif)

A subgroup ![
$$G$$
](A272900_1_En_16_Chapter_IEq40.gif) of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq41.gif) is closed if it is topologically closed as a subset of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq42.gif)—but not necessarily as a subset of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq43.gif). We will see that each matrix Lie group is a real embedded submanifold of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq44.gif) and thus is a Lie group.

Definition 16.2

If G 1 and G 2 are matrix Lie groups, then a Lie group homomorphism of G 1 to G 2 is a continuous group homomorphism of G 1 into G 2. A Lie group homomorphism is called a Lie group isomorphism if it is one-to-one and onto with continuous inverse. Two matrix Lie groups are called isomorphic if there exists a Lie group isomorphism between them.

Example 16.3

The real general linear group, denoted ![
$$\\mathsf{GL}\(n, \\mathbb{R}\),$$
](A272900_1_En_16_Chapter_IEq45.gif) is the group of invertible n ×n matrices with real entries. The groups ![
$$\\mathsf{SL}\(n, \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq46.gif) and ![
$$\\mathsf{SL}\(n, \\mathbb{R}\)$$
](A272900_1_En_16_Chapter_IEq47.gif) are, respectively, the groups of complex and real matrices with determinant 1. They are called the special linear groups.

Example 16.4

An n ×n matrix ![
$$U \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq48.gif) is said to be unitary if ![
$${U}^{{\\ast}}U = U{U}^{{\\ast}} = I.$$
](A272900_1_En_16_Chapter_IEq49.gif) A matrix U is unitary if and only if

![
$$\\displaystyle{\\left \\langle Uv,Uw\\right\\rangle = \\left \\langle v,w\\right\\rangle }$$
](A272900_1_En_16_Chapter_Equa.gif)

for all ![
$$v,w \\in {\\mathbb{C}}^{n}.$$
](A272900_1_En_16_Chapter_IEq50.gif) The group of unitary matrices is denoted U(n) and called the (n ×n) unitary group. The special unitary group, denoted SU(2), is the subgroup of U(n) consisting of unitary matrices with determinant 1.

The condition ![
$$\({U}^{{\\ast}}U\)_{jk} =\\delta _{jk}$$
](A272900_1_En_16_Chapter_IEq51.gif) is equivalent to the condition that the columns of U form an orthonormal set in ![
$${\\mathbb{C}}^{n},$$
](A272900_1_En_16_Chapter_IEq52.gif) as can be seen by direct computation. Geometrically, the condition U ∗ U = I is equivalent to the condition that ![
$$\\left \\langle Uv_{1},Uv_{2}\\right\\rangle = \\left \\langle v_{1},v_{2}\\right\\rangle$$
](A272900_1_En_16_Chapter_IEq53.gif) for all ![
$$v_{1},v_{2} \\in {\\mathbb{C}}^{n},$$
](A272900_1_En_16_Chapter_IEq54.gif) i.e., that U preserves the inner product on ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_16_Chapter_IEq55.gif) By taking the determinant of the condition U ∗ U = I, we see that ![
$$\\left \\vert \\det U\\right\\vert = 1$$
](A272900_1_En_16_Chapter_IEq56.gif) for all U ∈ U(n).

In this, the finite-dimensional case, the condition U ∗ U = I implies that U ∗ is the inverse of U and thus that UU ∗ = I. This result does not hold in the infinite-dimensional case.

Example 16.5

An n ×n real matrix ![
$$R \\in M_{n}\(\\mathbb{R}\)$$
](A272900_1_En_16_Chapter_IEq57.gif) is said to be orthogonal if ![
$${R}^{tr}R = R{R}^{tr} = I$$
](A272900_1_En_16_Chapter_IEq58.gif). A matrix R is orthogonal if and only if

![
$$\\displaystyle{\\left \\langle Rv,Rw\\right\\rangle = \\left \\langle v,w\\right\\rangle }$$
](A272900_1_En_16_Chapter_Equb.gif)

for all ![
$$v,w \\in {\\mathbb{R}}^{n}.$$
](A272900_1_En_16_Chapter_IEq59.gif) The group of orthogonal matrices is denoted O(n) and is called the (n ×n) orthogonal group. The special orthogonal group, denoted SO(n), is the subgroup of O(n) consisting of orthogonal matrices with determinant 1.

As in the unitary case, the condition R tr R = I implies that RR tr = I and that the columns of R form an orthonormal set in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_16_Chapter_IEq60.gif) Geometrically, a real matrix R is in O(n) if and only if ![
$$\\left \\langle Rv_{1},Rv_{2}\\right\\rangle = \\left \\langle v_{1},v_{2}\\right\\rangle$$
](A272900_1_En_16_Chapter_IEq61.gif) for all ![
$$v_{1},v_{2} \\in {\\mathbb{R}}^{n},$$
](A272900_1_En_16_Chapter_IEq62.gif) i.e., if and only if R preserves the inner product on ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_16_Chapter_IEq63.gif) By taking the determinant of the condition R tr R = I we see that det R = ± 1 for all R ∈ O(n).

It is easy to verify that all the groups in Examples 16.3, 16.4, and 16.5 are, indeed, subgroups of ![
$$\\mathsf{GL}\(n, \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq64.gif) and that they are closed.

Definition 16.6

A matrix Lie group G is connected if for all A, B ∈ G there is a continuous path ![
$$A : \[0,1\] \\rightarrow M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq65.gif) such that A(0) = A and A(1) = B and such that A(t) lies in G for all t. A matrix Lie group G is simply connected if it is connected and every continuous loop in G can be shrunk continuously to a point in G. A matrix Lie group G is compact if it is compact as a subset of ![
$$M_{n}\(\\mathbb{C}\)\\mathop{\\cong}{\\mathbb{R}}^{2{n}^{2} }.$$
](A272900_1_En_16_Chapter_IEq66.gif)

By the Heine–Borel theorem (e.g., Proposition 0.26 of [12]), a matrix Lie group G is compact if and only if it is a closed and bounded subset of ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq67.gif) The condition we are calling "connected" is, more properly, the condition of being path connected. We will see, however, that each matrix Lie group is an embedded real submanifold of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq68.gif) and is, therefore, locally path connected. For matrix Lie groups, then, connectedness and path connectedness are equivalent.

To prove that a matrix Lie group G is connected, it suffices to prove that for all A ∈ G, there is a continuous path in G connecting A to I. After all, if both A and B can be connected to I, then they can be connected to each other.

Example 16.7

The groups O(n), SO(n), U(n), and SU(n) are compact.

Proof.

The conditions defining these groups are obtained by setting certain continuous functions equal to a constant. The group SU(n), for example, is defined by setting ![
$$\({U}^{{\\ast}}U\)_{jk} =\\delta _{jk}$$
](A272900_1_En_16_Chapter_IEq69.gif) for each j and k and by setting det U = 1. These groups are thus closed not just as subsets of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq70.gif) but also as subsets of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq71.gif). Furthermore, each of these groups has the property that each column of any matrix in the group is a unit vector. Thus, each group is a bounded subset of ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq72.gif)

Example 16.8

The group U(n) is connected.

Proof.

If ![
$$U \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq73.gif) is unitary, then U has an orthonormal basis of eigenvectors with eigenvalues of absolute value 1. Thus, there is another unitary matrix V (the change of basis matrix) such that

![
$$\\displaystyle{U = V \\left \(\\begin{array}{cccc} {e}^{i\\theta _{1}} & & & \\\\ & {e}^{i\\theta _{2}} & & \\\\ & & \\ddots & \\\\ & & & {e}^{i\\theta _{n}} \\end{array} \\right\){V }^{-1},}$$
](A272900_1_En_16_Chapter_Equc.gif)

for some real numbers ![
$$\\theta _{1},\\theta _{2},\\ldots,\\theta _{n}.$$
](A272900_1_En_16_Chapter_IEq74.gif) Thus, we can define a family U(t) of unitary matrices by setting

![
$$\\displaystyle{U\(t\) = V \\left \(\\begin{array}{cccc} {e}^{it\\theta _{1}} & & & \\\\ & {e}^{it\\theta _{2}} & & \\\\ & & \\ddots & \\\\ & & & {e}^{it\\theta _{n}} \\end{array} \\right\){V }^{-1}.}$$
](A272900_1_En_16_Chapter_Equd.gif)

Then U(⋅) is a continuous path lying in U(n) with U(0) = I and U(1) = U

Example 16.9

The group SU(2) is simply connected.

Proof.

We claim that

![
$$\\displaystyle{\\mathsf{SU}\(2\) = \\left \\{\\left.\\left \(\\begin{array}{cc} \\alpha &-\\bar{\\beta }\\\\ \\beta & \\bar{\\alpha } \\end{array} \\right\)\\right\\vert \\alpha,\\beta \\in \\mathbb{C},\\ {\\left \\vert \\alpha \\right\\vert }^{2} +{ \\left \\vert \\beta \\right\\vert }^{2} = 1\\right\\}.}$$
](A272900_1_En_16_Chapter_Eque.gif)

It is easy to see that each matrix of the indicated form is indeed unitary and has determinant 1. On the other hand, if U is any element of ![
$$\\mathsf{SU}\(2\),$$
](A272900_1_En_16_Chapter_IEq75.gif) then the first column of U is a unit vector ![
$$\(\\alpha,\\beta \) \\in {\\mathbb{C}}^{2}.$$
](A272900_1_En_16_Chapter_IEq76.gif) The second column of U must then be orthogonal to (α, β). Since ![
$$\(-\\bar{\\beta },\\bar{\\alpha }\)$$
](A272900_1_En_16_Chapter_IEq77.gif) is orthogonal to (α, β) and ![
$${\\mathbb{C}}^{2}$$
](A272900_1_En_16_Chapter_IEq78.gif) is 2-dimensional, the second column of U must be a multiple of ![
$$\(-\\bar{\\beta },\\bar{\\alpha }\).$$
](A272900_1_En_16_Chapter_IEq79.gif) But the only multiple that produces a matrix with determinant 1 is 1.

We see, then, that SU(2) is, topologically, the unit sphere S 3 inside ![
$${\\mathbb{C}}^{2}\\mathop{\\cong}{\\mathbb{R}}^{4}$$
](A272900_1_En_16_Chapter_IEq80.gif) and is, therefore, simply connected.

## 16.3 Lie Algebras

We now introduce the general algebraic concept of a Lie algebra. Once this is done, we will show how to associate a real Lie algebra with an arbitrary matrix Lie group.

Definition 16.10

A Lie algebra over a field ![
$$\\mathbb{F}$$
](A272900_1_En_16_Chapter_IEq81.gif) is a vector space ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq82.gif) over ![
$$\\mathbb{F},$$
](A272900_1_En_16_Chapter_IEq83.gif) together with a "bracket" map ![
$$\\left \[\\cdot,\\cdot \\right\] : \\mathfrak{g} \\times \\mathfrak{g} \\rightarrow \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq84.gif) having the following properties:

1.

[⋅, ⋅] is bilinear

2.

Y, X = − X, Y for all ![
$$X,Y \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq85.gif)

3.

[X, X] = 0 for all ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq86.gif)

4.

For all ![
$$X,Y,Z \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq87.gif) we have the Jacobi identity

![
$$\\displaystyle{\[X,\[Y,Z\]\] + \[Y,\[Z,X\]\] + \[Z,\[X,Y\]\] = 0.}$$
](A272900_1_En_16_Chapter_Equf.gif)

If the characteristic of ![
$$\\mathbb{F}$$
](A272900_1_En_16_Chapter_IEq88.gif) is not equal to 2, then Property 3 is a consequence of Property 2. If ![
$$\\mathbb{F} = \\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq89.gif) then we say that ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq90.gif) is a real Lie algebra. An example of a real Lie algebra is the vector space ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_16_Chapter_IEq91.gif) with the bracket equal to the cross product. Properties 1, 2, and 3 are evident from the definition of the cross product, while the Jacobi identity is a known property of the cross product that can be verified by direct calculation.

A large class of Lie algebras may be obtained by the following procedure.

Example 16.11

Let ![
$$\\mathcal{A}$$
](A272900_1_En_16_Chapter_IEq92.gif) be an associative algebra and let ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq93.gif) be a subspace of ![
$$\\mathcal{A}$$
](A272900_1_En_16_Chapter_IEq94.gif) with the property that for all x, y in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq95.gif) XY − yx is again in ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq96.gif) Then the bracket

![
$$\\displaystyle{\[x,y\] := xy - yx}$$
](A272900_1_En_16_Chapter_Equg.gif)

makes ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq97.gif) into a Lie algebra.

In Example 16.11, we may take, for example, ![
$$\\mathfrak{g} = \\mathcal{A}.$$
](A272900_1_En_16_Chapter_IEq98.gif) It is evident that this bracket satisfies Properties 1, 2, and 3 of a Lie algebra, and the Jacobi identity is easily verified by direct calculation. As it turns out, every Lie algebra is isomorphic to a Lie algebra of this type. (This claim is a consequence of the Poincaré–Birkhoff–Witt theorem, which is proved, for example, in Sect.​ 5.​2 of [25]. The algebra ![
$$\\mathcal{A}$$
](A272900_1_En_16_Chapter_IEq99.gif) in the Poincaré–Birkhoff–Witt theorem is the so-called universal enveloping algebra of ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq100.gif))

Definition 16.12

If ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq101.gif) and ![
$$\\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq102.gif) are Lie algebras, a map ![
$$\\phi : \\mathfrak{g}_{1} \\rightarrow \\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq103.gif) is called a Lie algebra homomorphism if   is linear and   satisfies

![
$$\\displaystyle{\\phi \(\[X,Y\]\) = \[\\phi \(X\),\\phi \(Y \)\]}$$
](A272900_1_En_16_Chapter_Equh.gif)

for all ![
$$X,Y \\in \\mathfrak{g}_{1}.$$
](A272900_1_En_16_Chapter_IEq104.gif) A Lie algebra homomorphism is called a Lie algebra isomorphism if it is one-to-one and onto.

Definition 16.13

If ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq105.gif) is a Lie algebra, a subalgebra of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq106.gif) is a subspace ![
$$\\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq107.gif) of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq108.gif) with the property that ![
$$\[X,Y\] \\in \\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq109.gif) for all X and Y in ![
$$\\mathfrak{h}.$$
](A272900_1_En_16_Chapter_IEq110.gif) An ideal in ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq111.gif) is a subalgebra ![
$$\\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq112.gif) of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq113.gif) with the stronger property that ![
$$\[X,Y\] \\in \\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq114.gif) for all X in ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq115.gif) and Y in ![
$$\\mathfrak{h}.$$
](A272900_1_En_16_Chapter_IEq116.gif)

The notion of a subalgebra of a Lie algebra is analogous to the notion of a subgroup of a group, while the notion of an ideal in a Lie algebra is analogous to the notion of a normal subgroup of a group. In particular, the kernel of any Lie algebra homomorphism is an ideal, just as the kernel of a group homomorphism is a normal subgroup.

Definition 16.14

The direct sum of Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq117.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq118.gif) denoted ![
$$\\mathfrak{g}_{1} \\oplus \\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq119.gif) is the direct sum of ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq120.gif) and ![
$$\\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq121.gif) as a vector space, equipped with the bracket given by

![
$$\\displaystyle{\[\(X_{1},Y _{1}\),\(X_{2},Y _{2}\)\] = \(\[X_{1},X_{2}\],\[Y _{1},Y _{2}\]\)}$$
](A272900_1_En_16_Chapter_Equi.gif)

for all ![
$$X_{1},X_{2} \\in \\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq122.gif) and ![
$$Y _{1},Y _{2} \\in \\mathfrak{g}_{2}.$$
](A272900_1_En_16_Chapter_IEq123.gif)

## 16.4 The Matrix Exponential

In the next section, we will associate a Lie algebra with each matrix Lie group. To describe this association, we need the notion of the exponential of a matrix. Given a matrix ![
$$X \\in M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq124.gif) we define the matrix exponential of X, denoted by e X or exp(X), by the usual power series,

![
$$\\displaystyle{{e}^{X} =\\sum _{ m=0}^{\\infty }\\frac{{X}^{m}} {m!},}$$
](A272900_1_En_16_Chapter_Equj.gif)

where X 0 = I (the identity matrix). This series converges absolutely for all ![
$$X \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq125.gif), as can easily be seen using the inequality ![
$$\\left \\Vert {X}^{m}\\right\\Vert \\leq {\\left \\Vert X\\right\\Vert }^{m},$$
](A272900_1_En_16_Chapter_IEq126.gif) where X is the operator norm of X; see Definition A.35. (In this, the finite-dimensional case, we could just as well use the Hilbert–Schmidt norm, which amounts to using the usual Euclidean norm on ![
$$M_{n}\(\\mathbb{C}\)\\mathop{\\cong}{\\mathbb{C}}^{{n}^{2} }.$$
](A272900_1_En_16_Chapter_IEq127.gif) See Exercise 3.) The matrix exponential shares some but not all of the properties of the exponential of a number.

Theorem 16.15

The matrix exponential has the following properties for all ![
$$X,Y \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq128.gif).

1.

e 0 = I

2.

![
$${e}^{{X}^{tr} } = {\({e}^{X}\)}^{tr}$$
](A272900_1_En_16_Chapter_IEq129.gif) and ![
$${e}^{{X}^{{\\ast}} } = {\({e}^{X}\)}^{{\\ast}}$$
](A272900_1_En_16_Chapter_IEq130.gif)

3.

If A is an invertible n × n matrix, then

![
$$\\displaystyle{{e}^{AX{A}^{-1} } = A{e}^{X}{A}^{-1}.}$$
](A272900_1_En_16_Chapter_Equk.gif)

4.

![
$$\\det \({e}^{X}\) = {e}^{\\mathrm{trace}\(X\)}$$
](A272900_1_En_16_Chapter_IEq131.gif)

5.

If XY = YX then ![
$${e}^{X+Y } = {e}^{X}{e}^{Y }$$
](A272900_1_En_16_Chapter_IEq132.gif)

6.

e X is invertible and ![
$${\({e}^{X}\)}^{-1} = {e}^{-X}$$
](A272900_1_En_16_Chapter_IEq133.gif)

7.

Even if XY ≠YX, we have

![
$$\\displaystyle{{e}^{X+Y } =\\lim _{ m\\rightarrow \\infty }{\\left \({e}^{X/m}{e}^{Y/m}\\right\)}^{m}.}$$
](A272900_1_En_16_Chapter_Equl.gif)

Here X tr and X ∗ denote the transpose and adjoint (conjugate transpose) of X, respectively. Property 16.15 is known as the Lie Product Formula and is a special case of the Trotter Product formula (Theorem 20.1). Properties 1, 2, and 16.15 are easily verified using term-by-term computation. Property 16.15 follows from Property 16.15 by taking Y = − X and applying Property 1. The proofs of Properties 16.15, 16.15, and 16.15 are outlined in Exercises 5, 6, and 7.

Suppose a matrix X is diagonalizable, meaning that

![
$$\\displaystyle{X = A\\left \(\\begin{array}{ccc} \\lambda _{1} & & 0\\\\ &\\ddots & \\\\ 0&&\\lambda _{n} \\end{array} \\right\){A}^{-1},}$$
](A272900_1_En_16_Chapter_Equm.gif)

for some invertible matrix A and complex numbers ![
$$\\lambda _{1},\\lambda _{2},\\ldots,\\lambda _{n}.$$
](A272900_1_En_16_Chapter_IEq134.gif) Then using Property 16.15 of Theorem 16.15, it is easy to see that

![
$$\\displaystyle{{e}^{X} = A\\left \(\\begin{array}{ccc} {e}^{\\lambda _{1}} & & 0\\\\ &\\ddots & \\\\ 0 &&{e}^{\\lambda _{n}} \\end{array} \\right\){A}^{-1}.}$$
](A272900_1_En_16_Chapter_Equn.gif)

If X is not diagonalizable, e X can be computed in terms of the SN decomposition of X. See Sect.​ 2.​2 of [21] for details.

Example 16.16

If

![
$$\\displaystyle{X = \\left \(\\begin{array}{cc} 0 &a\\\\ - a & 0 \\end{array} \\right\)}$$
](A272900_1_En_16_Chapter_Equo.gif)

then

![
$$\\displaystyle{{e}^{X} = \\left \(\\begin{array}{rr} \\cos a&\\sin a\\\\ -\\sin a &\\cos a \\end{array} \\right\).}$$
](A272900_1_En_16_Chapter_Equp.gif)

Proof.

The eigenvalues of X are ± ia and the corresponding eigenvectors are (1, ± i). Thus, we may calculate that

![
$$\\displaystyle\\begin{array}{rcl}{ e}^{X}& = \\left \(\\begin{array}{rr} 1& 1 \\\\ i& - i \\end{array} \\right\)\\left \(\\begin{array}{cc} {e}^{ia}& 0 \\\\ 0 &{e}^{-ia} \\end{array} \\right\) \\frac{1} {\(-2i\)}\\left \(\\begin{array}{rr} - i& - 1 \\\\ - i& 1 \\end{array} \\right\)& {}\\\\ & = -\\frac{1} {2i}\\left \(\\begin{array}{cc} - i\({e}^{ia} + {e}^{-ia}\)& - {e}^{ia} + {e}^{-ia} \\\\ {e}^{ia} - {e}^{-ia} & - i\({e}^{ia} + {e}^{-ia}\) \\end{array} \\right\), & {}\\\\ \\end{array}$$
](A272900_1_En_16_Chapter_Equ1.gif)

which simplifies to the desired result.

The relation ![
$${e}^{X+Y } = {e}^{X}{e}^{Y }$$
](A272900_1_En_16_Chapter_IEq135.gif) certainly does not hold for general (noncommuting) matrices X and Y. Nevertheless, for any ![
$$X \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq136.gif) we have

![
$$\\displaystyle{{e}^{\(s+t\)X} = {e}^{sX}{e}^{tX}}$$
](A272900_1_En_16_Chapter_Equq.gif)

for all s and t in ![
$$\\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq137.gif) since sX commutes with tX. Thus, for each X, the set of matrices of the form e tX , ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq138.gif) forms a subgroup of ![
$$GL\(n; \\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq139.gif) It is not hard to show (Exercise 4), using term-by-term differentiation, that

![
$$\\displaystyle{ \\left. \\frac{d} {dt}{e}^{tX}\\right\\vert _{ t=0} = X. }$$
](A272900_1_En_16_Chapter_Equ2.gif)

(16.1)

Here, the derivative of a matrix-valued function is defined as being entrywise. [That is, if f(t) is a matrix-valued function, df ∕ dt is the matrix-valued function whose (j, k) entry is d(f(t) jk ) ∕ dt. ]

Definition 16.17

A one-parameter subgroup of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq140.gif) is a continuous homomorphism of ![
$$\\mathbb{R}$$
](A272900_1_En_16_Chapter_IEq141.gif) into ![
$$\\mathsf{GL}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq142.gif) that is, a continuous map ![
$$A : \\mathbb{R} \\rightarrow \\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq143.gif) such that A(0) = i and A(s \+ t) = A(s)A(t) for all ![
$$s,t \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq144.gif)

Theorem 16.18

If A(⋅) is a one-parameter subgroup of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq145.gif) there exists a unique ![
$$X \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq146.gif) such that

![
$$\\displaystyle{A\(t\) = {e}^{tX}}$$
](A272900_1_En_16_Chapter_Equr.gif)

for all ![
$$t \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq147.gif)

This is Theorem 2.13 in [21].

## 16.5 The Lie Algebra of a Matrix Lie Group

We now associate a Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq148.gif) to each matrix Lie group G.

Definition 16.19

If ![
$$G \\subset \\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq149.gif) is a matrix Lie group, then the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq150.gif) of G is defined as follows:

![
$$\\displaystyle{\\mathfrak{g} = \\left \\{X \\in M_{n}\(\\mathbb{C}\)\\left \\vert {e}^{tX} \\in G\\text{ for all }t \\in \\mathbb{R}\\right.\\right\\}.}$$
](A272900_1_En_16_Chapter_Equs.gif)

That is to say, X belongs to ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq151.gif) if and only if the one-parameter subgroup generated by X lies entirely in G. Note that to have X belong to ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq152.gif) we need only have e tX belong to G for all real numbers t.

Proposition 16.20

For any matrix Lie group G, the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq153.gif) of G has the following properties.

1.

The zero matrix 0 belongs to ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq154.gif)

2.

For all X in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq155.gif) tX belongs to ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq156.gif) for all real numbers t.

3.

For all X and Y in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq157.gif) X + Y belongs to ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq158.gif)

4.

For all A ∈ G and ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq159.gif) we have ![
$$AX{A}^{-1} \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq160.gif)

5.

For all X and Y in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq161.gif) the commutator [X,Y] := XY − YX belongs to ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq162.gif)

The first three properties of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq163.gif) say that ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq164.gif) is a real vector space. Since ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq165.gif) is an associative algebra under the operation of matrix multiplication, the last property of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq166.gif) shows that ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq167.gif) is a real Lie algebra (Example 16.11).

Proof.

Points 1 and 2 are elementary, and Point 3 follows from the Lie product formula, using the assumption that G is closed. Point 4 follows from Property 3 in Theorem 16.15. To verify Point 5, we observe that the commutator [X, Y ] may be computed as

![
$$\\displaystyle{\[X,Y\] = \\left. \\frac{d} {dt}{e}^{tX}Y {e}^{-tX}\\right\\vert _{ t=0},}$$
](A272900_1_En_16_Chapter_Equt.gif)

using (4) and an easily verified product rule for differentiation of matrix-valued functions. For ![
$$X,Y \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq168.gif) ![
$${e}^{tX}Y {e}^{-tX}$$
](A272900_1_En_16_Chapter_IEq169.gif) belongs to ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq170.gif) for all ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq171.gif) by Point 4. Furthermore, we have already shown that ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq172.gif) is a real subspace of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq173.gif) and therefore a closed subset of ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq174.gif) Thus,

![
$$\\displaystyle{\[X,Y\] =\\lim _{h\\rightarrow 0}\\frac{{e}^{hX}Y {e}^{-hX} - Y } {h} }$$
](A272900_1_En_16_Chapter_Equu.gif)

belongs to ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq175.gif)

Example 16.21

Let ![
$$\\mathsf{gl}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq176.gif) ![
$$\\mathsf{gl}\(n; \\mathbb{R}\),$$
](A272900_1_En_16_Chapter_IEq177.gif) ![
$$\\mathsf{sl}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq178.gif) and ![
$$\\mathsf{sl}\(n; \\mathbb{R}\)$$
](A272900_1_En_16_Chapter_IEq179.gif) denote the Lie algebras of ![
$$\\mathsf{GL}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq180.gif) ![
$$\\mathsf{GL}\(n; \\mathbb{R}\),$$
](A272900_1_En_16_Chapter_IEq181.gif) ![
$$\\mathsf{SL}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq182.gif) and ![
$$\\mathsf{SL}\(n; \\mathbb{R}\),$$
](A272900_1_En_16_Chapter_IEq183.gif) respectively. Then we have

![
$$\\displaystyle\\begin{array}{rcl} \\mathsf{gl}\(n; \\mathbb{C}\)& & = M_{n}\(\\mathbb{C}\) {}\\\\ \\mathsf{gl}\(n; \\mathbb{R}\)& & = M_{n}\(\\mathbb{R}\) {}\\\\ \\mathsf{sl}\(n; \\mathbb{C}\)& & = \\left \\{X \\in M_{n}\(\\mathbb{C}\)\\left \\vert \\mathrm{trace}\(X\) = 0\\right.\\right\\} {}\\\\ \\mathsf{sl}\(n; \\mathbb{R}\)& & = \\left \\{X \\in M_{n}\(\\mathbb{R}\)\\left \\vert \\mathrm{trace}\(X\) = 0\\right.\\right\\}. {}\\\\ \\end{array}$$
](A272900_1_En_16_Chapter_Equ3.gif)

Proof.

Let us consider, for example, the case of ![
$$\\mathsf{sl}\(n; \\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq184.gif) By Property 16.15 of Theorem 16.15, if trace(X) = 0, then

![
$$\\displaystyle{\\det \({e}^{tX}\) = {e}^{t\\mathrm{trace}\(X\)} = {e}^{0} = 1,}$$
](A272900_1_En_16_Chapter_Equv.gif)

so that ![
$${e}^{tX} \\in \\mathsf{SL}\(n; \\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq185.gif) In the other direction, if ![
$$X \\in \\mathsf{sl}\(n; \\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq186.gif) then by the above calculation, we must have e ttrace(X) = 0 for all ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq187.gif) which is possible only if trace(X) = 0. The proofs of the other cases are similar and are omitted.

Example 16.22

The Lie algebras u(n) and su(n) of U(n) and SU(n) are given by

![
$$\\displaystyle\\begin{array}{rcl} \\mathsf{u}\(n\)& & = \\left \\{X \\in M_{n}\(\\mathbb{C}\)\\left \\vert {X}^{{\\ast}} = -X\\right.\\right\\} {}\\\\ \\mathsf{su}\(n\)& & = \\left \\{X \\in u\(n\)\\left \\vert \\mathrm{trace}\(X\) = 0\\right.\\right\\}. {}\\\\ \\end{array}$$
](A272900_1_En_16_Chapter_Equ4.gif)

The Lie algebra so(n) of SO(n) is given by

![
$$\\displaystyle{\\mathsf{so}\(n\) = \\left \\{X \\in M_{n}\(\\mathbb{R}\)\\left \\vert {X}^{tr} = -X\\right.\\right\\}.}$$
](A272900_1_En_16_Chapter_Equw.gif)

Finally, the Lie algebra of O(n) is equal to so(n).

Proof.

If X ∗ = − X, then by Property 2 of Theorem 16.15,

![
$$\\displaystyle{{\({e}^{tX}\)}^{{\\ast}} = {e}^{t{X}^{{\\ast}} } = {e}^{-tX} = {\({e}^{tX}\)}^{-1},}$$
](A272900_1_En_16_Chapter_Equx.gif)

showing that e tX is unitary. In the other direction, if e tX is unitary for all ![
$$t \\in \\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq188.gif) then ![
$${\({e}^{tX}\)}^{{\\ast}} = {\({e}^{tX}\)}^{-1} = {e}^{-tX}.$$
](A272900_1_En_16_Chapter_IEq189.gif) Thus, ![
$${e}^{t{X}^{{\\ast}} } = {e}^{-tX}.$$
](A272900_1_En_16_Chapter_IEq190.gif) Differentiating this relation at t = 0, using (16.1), gives X ∗ = − X. Thus, the Lie algebra of U(n) consists exactly of the matrices with the property that X ∗ = − X. For the Lie algebra of SU(n), we add the trace-zero condition, as in the proof of Example 16.21. The calculations for SO(n) are similar and are omitted. Note that if ![
$$X \\in M_{n}\(\\mathbb{R}\)$$
](A272900_1_En_16_Chapter_IEq191.gif) satisfies X tr = − X, then the diagonal entries of X are zero and, thus, trace(X) is automatically 0. This observation explains why the Lie algebras of O(n) and SO(n) are the same.

Specializing Proposition 16.22 the case n = 3 gives

![
$$\\displaystyle{\\mathsf{so}\(3\) = \\left \\{\\left.\\left \(\\begin{array}{rrr} 0& a& b\\\\ - a & 0 & c \\\\ - b& - c&0 \\end{array} \\right\)\\right\\vert a,b,c \\in \\mathbb{R}\\right\\}.}$$
](A272900_1_En_16_Chapter_Equy.gif)

We can use the following basis for so(3):

![
$$\\displaystyle\\begin{array}{rcl} F_{1} := \\left \(\\begin{array}{rrr} 0&0& 0\\\\ 0 &0 & - 1 \\\\ 0&1& 0 \\end{array} \\right\);\\ F_{2} := \\left \(\\begin{array}{rrr} 0&0&1\\\\ 0 &0 &0 \\\\ - 1&0&0 \\end{array} \\right\);\\ F_{3} := \\left \(\\begin{array}{rrr} 0& - 1&0\\\\ 1 & 0 &0 \\\\ 0& 0&0 \\end{array} \\right\).& & \\\\ & &{}\\end{array}$$
](A272900_1_En_16_Chapter_Equ5.gif)

(16.2)

Direct calculation establishes the following commutation relations for the F j 's:

![
$$\\displaystyle\\begin{array}{rcl} \[F_{1},F_{2}\]& = F_{3} & \\\\ {}\[F_{2},F_{3}\]& = F_{1} & \\\\ {}\[F_{3},F_{1}\]& = F_{2}.&{}\\end{array}$$
](A272900_1_En_16_Chapter_Equ6.gif)

(16.3)

More concisely, we have ![
$$\[F_{1},F_{2}\] = F_{3},$$
](A272900_1_En_16_Chapter_IEq192.gif) together with relations obtained from this one by cyclic permutation of the indices. Note that all remaining commutation relations follow from (16.3) by means of the skew-symmetry of the bracket; we have, for example, ![
$$\[F_{2},F_{1}\] = -F_{3}$$
](A272900_1_En_16_Chapter_IEq193.gif) and ![
$$\[F_{1},F_{1}\] = 0.$$
](A272900_1_En_16_Chapter_IEq194.gif)

## 16.6 Relationships Between Lie Groups and Lie Algebras

In this section, we explore the relationships between matrix Lie groups and their Lie algebras. In particular, we investigate the question of the extent to which a matrix Lie group is determined (up to isomorphism) by its Lie algebra. We begin by showing that every Lie group homomorphism gives rise to a Lie algebra homomorphism in a natural way.

Theorem 16.23

Suppose G 1 and G 2 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq195.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq196.gif) respectively, and suppose Φ : G 1 → G 2 is a Lie group homomorphism. Then there exists a unique linear map ![
$$\\phi : \\mathfrak{g}_{1} \\rightarrow \\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq197.gif) such that

![
$$\\displaystyle{\\Phi \({e}^{tX}\) = {e}^{t\\phi \(X\)}}$$
](A272900_1_En_16_Chapter_Equz.gif)

for all ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_16_Chapter_IEq198.gif) and ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq199.gif) This linear map has the following additional properties:

1.

  ([X,Y]) = [   (X),  (Y )] for all ![
$$X,Y \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq200.gif)

2.

![
$$\\phi \(AX{A}^{-1}\) = \\Phi \(A\)\\phi \(X\)\\Phi {\(A\)}^{-1}$$
](A272900_1_En_16_Chapter_IEq201.gif) for all A ∈ G and ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq202.gif)

3.

  (X) may be computed as

![
$$\\displaystyle{\\phi \(X\) = \\left. \\frac{d} {dt}\\Phi \\left \({e}^{tX}\\right\)\\right\\vert _{ t=0}.}$$
](A272900_1_En_16_Chapter_Equaa.gif)

Point 1 shows that   is a Lie algebra homomorphism. Part of the assertion of Point 3 of the theorem is that Φ(e tX ) is a smooth function of t for each X.

To construct  , note that since Φ is a continuous homomorphism, the map t ↦ Φ(e tX ) is a one-parameter subgroup. By Theorem 16.18, there exists a unique Y such that ![
$$\\Phi \({e}^{tX}\) = {e}^{tY }$$
](A272900_1_En_16_Chapter_IEq203.gif) for all ![
$$t \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq204.gif) We then set  (X) = Y. An argument similar to the proof of Proposition 16.20 then establishes the desired properties of  . See the proof of Theorem 2.21 in [21] for the details.

Corollary 16.24

Suppose that G 1 and G 2 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq205.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq206.gif) respectively. If G 1 is isomorphic to G 2, then ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq207.gif) is isomorphic to ![
$$\\mathfrak{g}_{2}.$$
](A272900_1_En_16_Chapter_IEq208.gif)

Proof.

See Exercise 11.

Our next task is to show that for any matrix Lie group G, the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq209.gif) of G is large enough to capture what is happening in a neighborhood of the identity in G. This will show, for example, that for connected matrix Lie groups, a Lie group homomorphism is determined by the corresponding Lie algebra homomorphism.

Theorem 16.25

Let G be a matrix Lie group with Lie algebra ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq210.gif) Then there exists a neighborhood U of 0 in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq211.gif) and a neighborhood V of I in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq212.gif) such that the matrix exponential maps U diffeomorphically onto V and such that for all X ∈ U, we have that X belongs to ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq213.gif) if and only if e X belongs to G.

See Theorem 2.27 in [21]. This result has a number of important consequences.

Corollary 16.26

Every matrix Lie group ![
$$G \\subset \\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq214.gif) is a real embedded submanifold of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq215.gif) with the dimension of G equal to the dimension of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq216.gif) as a real vector space.

The claim means, more precisely, that for each A ∈ G, there exists a neighborhood U of A and a diffeomorphism Φ of U with a neighborhood V of 0 in ![
$${\\mathbb{R}}^{2{n}^{2} }$$
](A272900_1_En_16_Chapter_IEq217.gif) such that ![
$$\\Phi \(U {\\cap} G\) = V {\\cap} {\\mathbb{R}}^{d},$$
](A272900_1_En_16_Chapter_IEq218.gif) where ![
$$d =\\dim \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq219.gif) That is to say, after a change of coordinates, G "looks" locally like a little piece of ![
$${\\mathbb{R}}^{d}$$
](A272900_1_En_16_Chapter_IEq220.gif) sitting inside ![
$$M_{n}\(\\mathbb{C}\)\\mathop{\\cong}{\\mathbb{R}}^{2{n}^{2} }.$$
](A272900_1_En_16_Chapter_IEq221.gif)

Proof.

We use exponential coordinates in the neighborhood V of I in ![
$$M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq222.gif) meaning that we write each element A of V as A = e X , with X ∈ U. Theorem 16.25 says that near the identity, in these coordinates, G "looks like" the real vector space ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq223.gif) inside ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq224.gif) Given any other point A ∈ G, we can use left multiplication by A − 1 to move the action to the identity (Exercise 17), with the result that G looks like ![
$$\\mathfrak{g} \\subset M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq225.gif) near A. Thus, G is a real embedded submanifold of dimension ![
$$d =\\dim \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq226.gif)

Corollary 16.27

The Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq227.gif) of a matrix Lie group G is the tangent space to G at I. That is to say, ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq228.gif) coincides with the set of those X in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq229.gif) for which there exists a smooth curve ![
$$\\gamma : \\mathbb{R} \\rightarrow M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq230.gif) lying entirely in G and such that γ(0) = i and γ ′(0) = X.

Proof.

If ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq231.gif) then X is the derivative of e tX at t = 0, so ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq232.gif) is contained in the tangent space at ![
$$I.$$
](A272900_1_En_16_Chapter_IEq233.gif) In the other direction, if γ is any smooth curve in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq234.gif) that lies entirely in G and passes through I at t = 0, then by Theorem 16.25, we can express γ as γ(t) = e δ(t) (at least for small t), where δ is a smooth curve in ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq235.gif) with δ(0) = 0. It is then easy to see (Exercise 8) that ![
$${\\gamma }^{{\\prime}}\(0\) {=\\delta }^{{\\prime}}\(0\).$$
](A272900_1_En_16_Chapter_IEq236.gif) But if δ lies in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq237.gif) then δ ′ (0), which equals γ ′ (0), also lies in ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq238.gif) as in the proof of Proposition 16.20. Thus, the tangent space at I is contained in ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq239.gif)

Corollary 16.28

If a matrix Lie group G is connected, then for all A ∈ G there exists a finite sequence ![
$$X_{1},X_{2},\\ldots,X_{N}$$
](A272900_1_En_16_Chapter_IEq240.gif) of elements of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq241.gif) such that

![
$$\\displaystyle{A = {e}^{X_{1} }{e}^{X_{2} }\\cdots {e}^{X_{N} }.}$$
](A272900_1_En_16_Chapter_Equab.gif)

Proof.

If G is connected in the sense of Definition 16.6 (which really means that G is path connected), then G is certainly connected in the usual topological sense of having no nontrivial sets that are both open and closed. Let U denote the set of points in G that can be expressed as a product of exponentials of elements of ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq242.gif) This set is open in G because if A ∈ U and B ∈ G is close to A, then A − 1 B is close to I in G, and therefore ![
$${A}^{-1}B = {e}^{X}$$
](A272900_1_En_16_Chapter_IEq243.gif) for some ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq244.gif) Thus, B = Ae X , which means that B is also a product of exponentials. In the other direction, if B ∈ G is in the closure of U, then there is some element A of U that is close to B. We then have, again, that B = Ae X for some ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq245.gif) which, again, means that B ∈ U. Now, G is connected and U is both open and closed. Since U is nonempty (I ∈ U), we have U = G.

Corollary 16.29

Suppose that G 1 and G 2 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq246.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq247.gif) respectively. Suppose that ![
$$\\Phi _{1} : G_{1} \\rightarrow G_{2}$$
](A272900_1_En_16_Chapter_IEq248.gif) and ![
$$\\Phi _{2} : G_{1} \\rightarrow G_{2}$$
](A272900_1_En_16_Chapter_IEq249.gif) are Lie group homomorphisms, with associated Lie algebra homomorphisms ![
$$\\phi _{1}$$
](A272900_1_En_16_Chapter_IEq250.gif) and   2, respectively. If G 1 is connected and   1 =   2, then Φ1 = Φ2.

Proof.

The result follows from Corollary 16.28 and the condition ![
$$\\Phi _{j}\({e}^{X}\) = {e}^{\\phi _{j}\(X\)},$$
](A272900_1_En_16_Chapter_IEq251.gif) j = 1, 2.

We have seen that a homomorphism of matrix Lie groups gives rise to a homomorphism of the associated Lie algebra, and (Corollary 16.29) that if the domain group is connected, the Lie algebra homomorphism determines the Lie group homomorphism. A more difficult question is whether we can go in the opposite direction, from a Lie algebra homomorphism to a Lie group homomorphism. That is to say, given a Lie algebra homomorphism between the Lie algebras of two matrix Lie groups, does there exist a Lie group homomorphism related in the usual way to the Lie algebra homomorphism? The answer turns out to be yes, provided that the domain group G 1 is connected and simply connected (i.e., that every continuous loop in G 1 can be shrunk continuously in G 1 to a point).

Theorem 16.30

Suppose that G 1 and G 2 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq252.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq253.gif) respectively, and suppose that ![
$$\\phi : \\mathfrak{g}_{1} \\rightarrow \\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq254.gif) is a Lie algebra homomorphism. If G 1 is connected and simply connected, then there exists a unique Lie group homomorphism Φ : G 1 → G 2 such that Φ and   are related as in Theorem 16.23.

One way to prove this deep result is to make use of the Baker–Campbell–Hausdorff formula. (See, e.g., Chap.​ 3 of [21].) This formula states that for all sufficiently small X and Y in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq255.gif) we have

![
$$\\displaystyle{{e}^{X}{e}^{Y } = {e}^{X+Y +\\frac{1} {2} \[X,Y\]+ \\frac{1} {12} \[X,\[X,Y\]\]-\\frac{1} {12} \[Y,\[X,Y\]\]+\\cdots }.}$$
](A272900_1_En_16_Chapter_Equac.gif)

Here ⋯ denotes terms that are expressible in terms of repeated commutators involving X and Y, with coefficients that are "universal," that is, independent of n (the size of the matrices) and of the choice of X and Y in ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq256.gif) Given a Lie algebra homomorphism ![
$$\\phi : \\mathfrak{g}_{1} \\rightarrow \\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq257.gif) one can use the Baker–Campbell–Hausdorff formula to construct a "local homomorphism," mapping a neighborhood of the identity in G 1 into G 2. If G 1 is connected and simply connected, it is possible to extend this local representation to a global representation. See Sect.​ 3.​6 of [21] for the details of this construction.

Corollary 16.31

Suppose that G 1 and G 2 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq258.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq259.gif) respectively. If G 1 and G 2 are connected and simply connected and ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq260.gif) is isomorphic to ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq261.gif) then G 1 is isomorphic to G 2.

Proof.

Suppose ![
$$\\phi : \\mathfrak{g}_{1} \\rightarrow \\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq262.gif) is a Lie algebra isomorphism. Since G 1 is connected and simply connected, there exists a Lie group homomorphism Φ : G 1 → G 2 related in the usual way to  . Since G 2 is connected and simply connected, there exists a Lie group homomorphism Ψ : G 2 → G 1 related in the usual way to   − 1. Consider now the homomorphism Ψ ∘ Φ : G 1 → G 1.

By the composition property of Lie algebra homomorphisms (Exercise 10), the Lie algebra homomorphism associated with Ψ ∘ Φ is   − 1 ∘   = I. It then follows from Corollary 16.29 that Ψ ∘ Φ = I. A similar argument shows that Φ ∘ Ψ = I, which means that Φ is a Lie group isomorphism.

Corollary 16.31 does not hold without the assumption that both groups are simply connected, as the following important example shows.

Example 16.32

The Lie algebras su(2) and so(3) are isomorphic, but the groups SU(2) and SO(3) are not isomorphic.

Since SU(2) is simply connected (Example 16.9), SO(3) must fail to be simply connected. Indeed, ![
$$\\pi _{1}\(\\mathsf{SO}\(3\)\)\\mathop{\\cong}\\mathbb{Z}/2,$$
](A272900_1_En_16_Chapter_IEq263.gif) as can be seen from Example 16.34.

Proof.

The Lie algebra su(2) of SU(2) is the space of 2 ×2 skew-self-adjoint matrices with trace zero. Explicitly,

![
$$\\displaystyle{\\mathsf{su}\(2\) = \\left \\{\\left.\\left \(\\begin{array}{cc} ia &b + ic\\\\ - b + ic & - ia \\end{array} \\right\)\\right\\vert a,b,c \\in \\mathbb{R}\\right\\}.}$$
](A272900_1_En_16_Chapter_Equad.gif)

We may consider the following basis for su(2):

![
$$\\displaystyle{ E_{1} = \\frac{1} {2}\\left \(\\begin{array}{rr} i& 0\\\\ 0 & - i \\end{array} \\right\);\\quad E_{2} = \\frac{1} {2}\\left \(\\begin{array}{rr} 0&1\\\\ - 1 &0 \\end{array} \\right\);\\quad E_{3} = \\frac{1} {2}\\left \(\\begin{array}{cc} 0& i\\\\ i &0 \\end{array} \\right\). }$$
](A272900_1_En_16_Chapter_Equ7.gif)

(16.4)

Direct calculation shows that ![
$$\[E_{1},E_{2}\] = E_{3}$$
](A272900_1_En_16_Chapter_IEq264.gif) and relations obtained from this by cyclic permutation of the indices. These are the same relations as those satisfied by the basis elements F j , j = 1, 2, 3, for so(3) in (16.2) and (16.3). Thus, there is a Lie algebra isomorphism   : su(2) → so(3) such that ![
$$\\phi \(E_{j}\) = F_{j},$$
](A272900_1_En_16_Chapter_IEq265.gif) j = 1, 2, 3.

On the other hand, there can be no isomorphism between SU(2) and SO(3), since SU(2) has a nontrivial center (containing at least I and − I), whereas the center of SO(3) is trivial (Exercise 14).

Definition 16.33

Suppose G is a connected matrix Lie group with Lie algebra ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq266.gif) A universal cover of G is an ordered pair ![
$$\(\\tilde{G},\\Phi \)$$
](A272900_1_En_16_Chapter_IEq267.gif) consisting of a simply connected matrix Lie group ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq268.gif) and a Lie group homomorphism ![
$$\\Phi :\\tilde{ G} \\rightarrow G$$
](A272900_1_En_16_Chapter_IEq269.gif) such that the associated Lie algebra homomorphism ![
$$\\phi : \\tilde{\\mathfrak{g}} \\rightarrow \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq270.gif) is an isomorphism of the Lie algebra ![
$$\\tilde{\\mathfrak{g}}$$
](A272900_1_En_16_Chapter_IEq271.gif) of ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq272.gif) with ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq273.gif) The map Φ is called the covering map for ![
$$\\tilde{G}.$$
](A272900_1_En_16_Chapter_IEq274.gif)

Although each Lie group has a universal cover that is again a Lie group, the universal cover of a matrix Lie group may not be isomorphic to any matrix Lie group. [The universal cover of ![
$$\\mathsf{SL}\(2; \\mathbb{R}\)$$
](A272900_1_En_16_Chapter_IEq275.gif), e.g., is not a matrix Lie group.] It can be shown, however, that if a matrix Lie group G is compact, then the universal cover of G is again a matrix Lie group (not necessarily compact).

Suppose ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq276.gif) is any simply connected Lie group with a Lie algebra ![
$$\\tilde{\\mathfrak{g}}$$
](A272900_1_En_16_Chapter_IEq277.gif) that is isomorphic to ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq278.gif) The choice of a particular isomorphism ![
$$\\phi : \\tilde{\\mathfrak{g}} \\rightarrow \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq279.gif) gives rise, by Theorem 16.30, to a Lie group homomorphism ![
$$\\Phi :\\tilde{ G} \\rightarrow G,$$
](A272900_1_En_16_Chapter_IEq280.gif) so that ![
$$\(\\tilde{G},\\Phi \)$$
](A272900_1_En_16_Chapter_IEq281.gif) is a universal cover of G.

If ![
$$\(\\tilde{G},\\Phi \)$$
](A272900_1_En_16_Chapter_IEq282.gif) is a universal cover of G, it is often convenient to use the isomorphism   to identify ![
$$\\tilde{\\mathfrak{g}}$$
](A272900_1_En_16_Chapter_IEq283.gif) with ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq284.gif) If we follow this convention, we may say that a universal cover of G is a simply connected group ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq285.gif) having "the same" Lie algebra as G.

If ![
$$\(\\tilde{G}_{1},\\Phi _{1}\)$$
](A272900_1_En_16_Chapter_IEq286.gif) and ![
$$\(\\tilde{G}_{2},\\Phi _{2}\)$$
](A272900_1_En_16_Chapter_IEq287.gif) are two universal covers of a given matrix Lie group G, then there is a unique Lie group isomorphism ![
$$\\Psi :\\tilde{ G}_{1} \\rightarrow \\tilde{ G}_{2}$$
](A272900_1_En_16_Chapter_IEq288.gif) such that Φ2(Ψ(A)) = Φ1(A) for all ![
$$A \\in \\tilde{ G}_{1}.$$
](A272900_1_En_16_Chapter_IEq289.gif) (This result follows easily from Corollary 16.31.) In light of this uniqueness result, we will often speak of "the" universal cover of G.

Example 16.34

Let Φ : SU(2) → SO(3) be the unique Lie group homomorphism for which the associated Lie algebra homomorphism   satisfies  (E j ) = F j , j = 1, 2, 3. Then ![
$$\\ker \\Phi =\\{ I,-I\\}$$
](A272900_1_En_16_Chapter_IEq290.gif) and (SU(2), Φ) is a universal cover of SO(3).

Proof.

Since E 1 is diagonal, it is easy to see that ![
$${e}^{2\\pi E_{1}} = -I$$
](A272900_1_En_16_Chapter_IEq291.gif) in SU(2). On the other hand, by a trivial extension of Example 16.16, we have

![
$$\\displaystyle{{e}^{aF_{1} } = \\left \(\\begin{array}{rrr} 1& 0& 0\\\\ 0 &\\cos a & -\\sin a \\\\ 0&\\sin a& \\cos a \\end{array} \\right\)}$$
](A272900_1_En_16_Chapter_Equae.gif)

for all ![
$$a \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq292.gif) In particular, ![
$${e}^{2\\pi F_{1}} = I.$$
](A272900_1_En_16_Chapter_IEq293.gif) Thus,

![
$$\\displaystyle{\\Phi \(-I\) = \\Phi \({e}^{2\\pi E_{1} }\) = {e}^{2\\pi F_{1} } = I.}$$
](A272900_1_En_16_Chapter_Equaf.gif)

This shows that − I belongs to the kernel of Φ.

Now, since   is injective, Φ is injective in a neighborhood of I. After all, given distinct elements A and B of SU(2) near I, Theorem 16.25 tells us that we can express A as e X and B as e Y , with X and Y being distinct small elements of SU(2). Then  (X) and  (Y) are distinct small elements of so(3). Applying Theorem 16.25 again tells us that Φ(A) = e   (X) and Φ(B) = e   (Y) are distinct.

We see, then, that ker Φ is a discrete normal subgroup of SU(2). But a standard exercise (Exercise 1) shows that a discrete normal subgroup of a connected group is automatically central. On the other hand, it is easily verified (Exercise 2) that the center of SU(2) is ![
$$\\{I,-I\\},$$
](A272900_1_En_16_Chapter_IEq294.gif) so ker Φ cannot be larger than ![
$$\\{I,-I\\}.$$
](A272900_1_En_16_Chapter_IEq295.gif)

To show that Φ maps onto SO(3), we first verify (Exercise 13) that each element R of SO(3) can be expressed as R = e X , with X ∈ so(3). Since   is surjective and ![
$$\\Phi \({e}^{X}\) = {e}^{\\phi \(X\)},$$
](A272900_1_En_16_Chapter_IEq296.gif) Φ maps onto SO(3).

## 16.7 Finite-Dimensional Representations of Lie Groups and Lie Algebras

A representation of a group G is a homomorphism Π of G into GL(V), the group of invertible linear transformations on some vector space. If Π is injective then G is isomorphic to its image under Π; thus, Π serves to "represent" G concretely as a group of invertible linear transformations. (We continue to use the term "representation" even if Π is not injective.) Similarly, a representation of a Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq297.gif) is a Lie algebra homomorphism of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq298.gif) into gl(V), the space of all linear transformations of V, where we equip gl(V) with the bracket [X, Y ] : = XY − YX.

Recall that an action of a group G on a set X is a map from G ×X to X, denoted (g, x) ↦ g⋅x satisfying e⋅x = x for all x ∈ X and g⋅(h⋅x) = (gh)⋅x for all g, h ∈ G and x ∈ X. A representation Π of G on some vector space V gives rise to a linear action of G on V, given by g⋅v = Π(g)v. (A linear action is an action for which the map v ↦ g⋅v is linear for each g.) Thus, we may use g⋅v as an alternative notation to Π(g)v, when convenient.

### 16.7.1 Finite-Dimensional Representations

If G is a matrix Lie group, then G is already represented as a group of matrices. Nevertheless, it is of interest as we will see in [Chap.​ 17 in the case G = SO(3)] to explore other representations of G. Since a matrix Lie group has a topological structure (inherited from ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq299.gif)), it is natural to require representations to be continuous. It is also simpler to deal at first with finite-dimensional representations, that is, those where the vector space in question is finite dimensional, although eventually we will need to consider infinite-dimensional representations as well. This discussion leads to the following definition.

Definition 16.35

Let ![
$$G \\subset \\mathsf{GL}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq300.gif) be a matrix Lie group. A finite-dimensional representation of G is a continuous homomorphism of G into GL(V), the group of invertible linear transformations of a finite-dimensional vector space V.

We will assume that all of our vector spaces are over the field ![
$$\\mathbb{C},$$
](A272900_1_En_16_Chapter_IEq301.gif) even though it is occasionally of interest to consider also representations over ![
$$\\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq302.gif) The topology on GL(V) is defined by picking a basis, and thereby identifying the space of linear maps of V to V with ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq303.gif) We then use the subset topology on ![
$$\\mathsf{GL}\(V\)\\mathop{\\cong}\\mathsf{GL}\(n; \\mathbb{C}\) \\subset M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq304.gif) This topology is easily seen to be independent of the choice of basis.

An important example of representations in quantum theory arises from the time-independent Schrödinger equation in ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_16_Chapter_IEq305.gif) namely the equation ![
$$\\hat{H}\\psi = E\\psi,$$
](A272900_1_En_16_Chapter_IEq306.gif) for a fixed constant ![
$$E \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq307.gif) If ![
$$\\hat{H}$$
](A272900_1_En_16_Chapter_IEq308.gif) is invariant under rotations, then the space of solutions to this equation is invariant under rotations. Note that an individual solution   to this equation may or may not be a rotationally invariant (i.e., radial) function. But if ![
$$\\hat{H}$$
](A272900_1_En_16_Chapter_IEq309.gif) is rotationally invariant, then rotating a solution to ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_16_Chapter_IEq310.gif) will give another solution of this equation. Even if the quantum Hilbert space is infinite dimensional, the solution spaces to ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_16_Chapter_IEq311.gif) are typically finite dimensional and constitute finite dimensional representations of the group SO(n) of rotations. If we can understand what all possible finite-dimensional representations of SO(n) look like, we will have made a lot of progress in understanding solutions to ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_16_Chapter_IEq312.gif) in the rotationally invariant case. This line of reasoning will be explored in detail in Chap.​ 18.

We may consider as well finite-dimensional representations of Lie algebras. Assuming our Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq313.gif) is finite dimensional (which is the only case we will consider in this chapter), there is no need to impose a requirement of continuity, since a linear map of one finite-dimensional real or complex vector space to another is automatically continuous.

Definition 16.36

A finite-dimensional representation of a Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq314.gif) is a Lie algebra homomorphism of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq315.gif) into gl(V), the space of all linear transformations of V. Here gl (V) is considered as a Lie algebra with bracket given by [X, Y ] = XY − YX.

We typically consider Lie algebras defined over the field ![
$$\\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq316.gif) since the Lie algebra of a matrix Lie group is in general only a real subspace of ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq317.gif) Nevertheless, it is convenient to consider vector spaces over ![
$$\\mathbb{C}.$$
](A272900_1_En_16_Chapter_IEq318.gif) If ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq319.gif) is a real Lie algebra and V, and therefore also gl(V), is a complex vector space, then we require only that ![
$$\\pi : \\mathfrak{g} \\rightarrow \\mathsf{gl}\(V\)$$
](A272900_1_En_16_Chapter_IEq320.gif) be real linear, which is the only requirement that makes sense.

In the interest of simplifying the terminology, we will sometimes speak of "a representation V," without making explicit mention of the homomorphism Π or π.

Definition 16.37

If Π : G → GL(V) is a representation of a matrix Lie group G, then a subspace W of V is called an invariant subspace if Π(g)w ∈ W for all g ∈ G and w ∈ W. Similarly, if ![
$$\\pi : \\mathfrak{g} \\rightarrow \\mathsf{gl}\(V\)$$
](A272900_1_En_16_Chapter_IEq321.gif) is a representation of a Lie algebra ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq322.gif) then a subspace W of V is called an invariant subspace if π(X)w ∈ W for all ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq323.gif) and w ∈ W. A representation of a group or Lie algebra is called irreducible if the only invariant subspaces are W = V and ![
$$W =\\{ 0\\}.$$
](A272900_1_En_16_Chapter_IEq324.gif)

Definition 16.38

If (Π, V 1) and (Σ, V 2) are representations of a matrix Lie group G, a map ![
$$\\Phi : V _{1} \\rightarrow V _{2}$$
](A272900_1_En_16_Chapter_IEq325.gif) is called an intertwining map (or morphism) if Φ(Π(g)v) = Σ(g)Φ(v) for all v ∈ V 1, with an analogous definition for intertwining maps of Lie algebra representations. If an intertwining map is an invertible linear map, it is called an isomorphism. Two representations are said to be isomorphic (or equivalent) if there exists an isomorphism between them.

In the "action" notation, the requirement on an intertwining map Φ is that Φ(g⋅v) = g⋅Φ(v), meaning that Φ commutes with the action of G. A typical goal of representation theory is to classify all finite-dimensional irreducible representations of G up to isomorphism.

Given a representation Π : G → GL(V) of a matrix Lie group G, we can identify GL(V) with ![
$$\\mathsf{GL}\(N; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq326.gif) and gl(V) with ![
$$\\mathsf{gl}\(n; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq327.gif) by picking a basis for V. We may then apply Theorem 16.23 to obtain a representation ![
$$\\pi : \\mathfrak{g} \\rightarrow \\mathsf{gl}\(V\)$$
](A272900_1_En_16_Chapter_IEq328.gif) such that

![
$$\\displaystyle{\\Pi \({e}^{X}\) = {e}^{\\pi \(X\)}}$$
](A272900_1_En_16_Chapter_Equag.gif)

for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq329.gif)

Proposition 16.39

Suppose G is a connected matrix Lie group with Lie algebra ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq330.gif) Suppose that Π : G → GL (V) is a finite-dimensional representation of G and ![
$$\\pi : \\mathfrak{g} \\rightarrow \\mathsf{gl}\(V\)$$
](A272900_1_En_16_Chapter_IEq331.gif) is the associated Lie algebra representation. Then a subspace W of V is invariant under the action of G if and only if it is invariant under the action of ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq332.gif) In particular, Π is irreducible if and only if π is irreducible. Furthermore, two representations of G are isomorphicIf and only if the associated Lie algebra representations are isomorphic.

In general, given an representation π of ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq333.gif) there may be no representation Π such that π and Π are related in the usual way. If, however, G is simply connected, Theorem 16.30 tells us that there is, in fact, a Π associated with every π.

Proof.

Suppose W ⊂ V is invariant under π(X) for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq334.gif) Then W is invariant under π(X) m for all m. Since V is finite-dimensional, any subspace of it is automatically a closed subset and thus W is invariant under

![
$$\\displaystyle{\\Pi \({e}^{X}\) = {e}^{\\pi \(X\)} =\\sum _{ m=0}^{\\infty }\\frac{\\pi {\(X\)}^{m}} {m!}.}$$
](A272900_1_En_16_Chapter_Equah.gif)

Since G is connected, every element of G is (Corollary 16.28) a product of exponentials of elements of ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq335.gif) and so W is invariant under Π(A) for all A ∈ G.

In the other direction, if W is invariant under Π(A) for all A ∈ G, then since W is closed, it is invariant under

![
$$\\displaystyle{\\pi \(X\) =\\lim _{h\\rightarrow 0}\\frac{{e}^{hX} - I} {h},}$$
](A272900_1_En_16_Chapter_Equai.gif)

for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq336.gif)

Now suppose Π 1 and Π 2 are two representations of G, acting on vector spaces V 1 and V 2, respectively. If Φ : V 1 → V 2 is an invertible linear map, then an argument similar to the above shows ΦΠ1(A) = Π 2(A)Φ for all A ∈ G if and only if ![
$$\\Phi \\pi _{1}\(X\) =\\pi _{2}\(X\)\\Phi$$
](A272900_1_En_16_Chapter_IEq337.gif) for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq338.gif) Thus, Φ is an isomorphism of group representations if and only if it is an isomorphism of Lie algebra representations.

Theorem 16.40 (Schur's Lemma).

If V 1 and V 2 are two irreducible representations of a group or Lie algebra, then the following hold.

1.

If Φ : V 1 → V 2 is an intertwining map, then either Φ = 0 or Φ is an isomorphism.

2.

If Φ : V 1 → V 2 and Ψ : V 1 → V 2 are nonzero intertwining maps, then there exists a nonzero constant ![
$$c \\in \\mathbb{C}$$
](A272900_1_En_16_Chapter_IEq339.gif) such that Φ = cΨ. In particular, if Φ is an intertwining map of V 1 to itself then Φ = cI.

Although the first part of Schur's lemma holds for representations over an arbitrary field, the second part holds only for representations over algebraically closed fields.

Proof.

It is easy to see that ker Φ is an invariant subspace of V 1. Since V 1 is irreducible, this means that either ker Φ = V 1, in which case Φ = 0, or ![
$$\\ker \\Phi =\\{ 0\\},$$
](A272900_1_En_16_Chapter_IEq340.gif) in which case Φ is injective. Similarly, the range of Φ is invariant, and thus equal to either ![
$$\\{0\\}$$
](A272900_1_En_16_Chapter_IEq341.gif) or V 2. If Φ is not zero, then the range of Φ is not zero, hence all of V 2. Thus, if Φ is not zero, it is both injective and surjective, establishing Point 1.

For Point 2, since Φ and Ψ are nonzero, they are isomorphisms, by Point 1. It suffices to prove that Γ : = Φ− 1 Ψ is a multiple of the identity, where Γ is an intertwining map of V 1 to itself. Since we are working over ![
$$\\mathbb{C},$$
](A272900_1_En_16_Chapter_IEq342.gif) Γ must have at least one eigenvalue λ. If W denotes the λ-eigenspace of Γ, then W is invariant under the action of the group or Lie algebra. After all, if Γ w = λ w, then (in the notation of the group case) Γ(Π(A)w) = Π(A)Γ w = λ Π(A)w. Since λ is an eigenvector of Γ, the invariant subspace W is nonzero and thus W = V 1, which means precisely that Γ = λ I.

### 16.7.2 Unitary Representations

In quantum mechanics, we are interested not only in vector spaces, but, more specifically, in Hilbert spaces, since expectation values are defined in terms of an inner product. We wish to consider, then, actions of a group that preserve the inner product as well as the linear structure. Although the Hilbert spaces in quantum mechanics are generally infinite-dimensional, we restrict our attention in this section to the finite-dimensional case.

Definition 16.41

Suppose V is a finite-dimensional Hilbert space over ![
$$\\mathbb{C}.$$
](A272900_1_En_16_Chapter_IEq343.gif) Denote by U(V) the group of invertible linear transformations of V that preserve the inner product. A (finite-dimensional) unitary representation of a matrix Lie group G is a continuous homomorphism of Π : G → U(V), for some finite-dimensional Hilbert space V.

Proposition 16.42

Let Π : G → GL (V) be a finite-dimensional representation of a connected matrix Lie group G, and let π be the associated representation of the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq344.gif) of G. Let⋅,⋅ be an inner product on V. Then Π is unitary with respect to⋅,⋅ if and only if π(X) is skew-self-adjoint with respect to⋅,⋅ for all ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq345.gif) that is, if and only if

![
$$\\displaystyle{\\pi {\(X\)}^{{\\ast}} = -\\pi \(X\)}$$
](A272900_1_En_16_Chapter_Equaj.gif)

for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq346.gif)

In a slight abuse of notation, we will refer to a representation π of a Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq347.gif) on a finite-dimensional inner product space as unitary if π(X)∗ = − π(X) for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq348.gif)

Proof.

Suppose first that Π(A) is unitary for all A ∈ G. Then for all ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq349.gif) and ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_16_Chapter_IEq350.gif) we have

![
$$\\displaystyle{\\Pi {\({e}^{tX}\)}^{{\\ast}} = \\Pi {\({e}^{tX}\)}^{-1} = \\Pi \({e}^{-tX}\) = {e}^{-t\\pi \(X\)}.}$$
](A272900_1_En_16_Chapter_Equak.gif)

On the other hand,

![
$$\\displaystyle{\\Pi {\({e}^{tX}\)}^{{\\ast}} = {\({e}^{t\\pi \(X\)}\)}^{{\\ast}} = {e}^{t\\pi {\(X\)}^{{\\ast}} }.}$$
](A272900_1_En_16_Chapter_Equal.gif)

Thus,

![
$$\\displaystyle{{e}^{t\\pi {\(X\)}^{{\\ast}} } = {e}^{-t\\pi \(X\)}}$$
](A272900_1_En_16_Chapter_Equam.gif)

for all t. Differentiating at t = 0 yields π(X)∗ = − π(X).

In the other direction, if π(X)∗ = − π(X) for all ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq351.gif) then

![
$$\\displaystyle{\\Pi {\({e}^{X}\)}^{{\\ast}} = {e}^{\\pi {\(X\)}^{{\\ast}} } = {e}^{-\\pi \(X\)} = \\Pi \({e}^{-X}\) = \\Pi {\({e}^{X}\)}^{-1},}$$
](A272900_1_En_16_Chapter_Equan.gif)

meaning that Π(e X ) is unitary. Since G is connected, Corollary 16.28 tells us that each element A of G is expressible as a product of exponentials, from which it follows that Π(A) is unitary.

### 16.7.3 Projective Unitary Representations

In quantum mechanics, two unit vectors in the quantum Hilbert space that differ by multiplication by a constant are considered to represent the same physical state. Thus, an operator of the form e iθ I, with ![
$$\\theta \\in \\mathbb{R},$$
](A272900_1_En_16_Chapter_IEq352.gif) will act as the identity at the level of the physical states. Suppose that V is a Hilbert space over ![
$$\\mathbb{C},$$
](A272900_1_En_16_Chapter_IEq353.gif) assumed for the moment to be finite-dimensional. Then it is natural to consider homomorphisms not into U(V) but rather into the quotient group ![
$$\\mathsf{U}\(V\)/\\{{e}^{i\\theta }I\\}.$$
](A272900_1_En_16_Chapter_IEq354.gif) Of course, given a homomorphism Π of G into U(V), we can always turn Π into a homomorphism of G into the quotient group, just by composing Π with the quotient map. Not every homomorphism into the quotient group, however, arises from a homomorphism into U(V).

Definition 16.43

Suppose V is a finite-dimensional Hilbert space over ![
$$\\mathbb{C}.$$
](A272900_1_En_16_Chapter_IEq355.gif) Then the projective unitary group over V, denoted PU(V), is the quotient group

![
$$\\displaystyle{\\mathsf{PU}\(V\) = \\mathsf{U}\(V\)/\\{{e}^{i\\theta }I\\},}$$
](A272900_1_En_16_Chapter_Equao.gif)

where ![
$$\\{{e}^{i\\theta }I\\}$$
](A272900_1_En_16_Chapter_IEq356.gif) denotes the group of matrices of the form e iθ I, ![
$$\\theta \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq357.gif)

Note that ![
$$\\{{e}^{i\\theta }I\\}$$
](A272900_1_En_16_Chapter_IEq358.gif) is a closed normal subgroup of U(V). Now, U(V) is (isomorphic to) a matrix Lie group, since we can identify it with U(n) by picking an orthonormal basis for V. In general, the quotient of a matrix Lie group by a closed normal subgroup may not be a matrix Lie group. In this case, however, it is not hard to realize the quotient ![
$$\\mathsf{U}\(n\)/\\{{e}^{i\\theta }I\\}$$
](A272900_1_En_16_Chapter_IEq359.gif) as a matrix Lie group.

Proposition 16.44

If V is a finite-dimensional Hilbert space over ![
$$\\mathbb{C},$$
](A272900_1_En_16_Chapter_IEq360.gif) then PU (V) is isomorphic to a matrix Lie group.

Let Q : U(V) →PU(V) be the quotient homomorphism and let q : u(V) →pu(V) be the associated Lie algebra homomorphism. Then q maps u(V) onto pu(V) and the kernel of q is the space of matrices of the form iaI with ![
$$a \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq361.gif) Thus, pu (V) is isomorphic to ![
$$\\mathsf{u}\(V\)/\\{iaI\\}.$$
](A272900_1_En_16_Chapter_IEq362.gif)

The Lie algebra u(V) of U(V) is the space of skew-self-adjoint operators on V. In Proposition 16.44, the space ![
$$\\{iaI\\}$$
](A272900_1_En_16_Chapter_IEq363.gif) is an ideal in u(V) and the quotient is in the sense of Lie algebras over ![
$$\\mathbb{R}$$
](A272900_1_En_16_Chapter_IEq364.gif); see Exercise 9. If dim V = N, then it is not hard to see that the Lie algebra ![
$$\\mathsf{pu}\(V\)\\mathop{\\cong}\\mathsf{u}\(V\)/\\{iaI\\}$$
](A272900_1_En_16_Chapter_IEq365.gif) is isomorphic to the Lie algebra su(N). The group PU(V) is not, however, isomorphic to the group SU(N). See Exercise 16.

Proof.

If dim V = N, then gl(V), the space of all linear maps of V to V, has dimension N 2. Given U ∈ U(V), we can define

![
$$\\displaystyle{C_{U} : \\mathsf{gl}\(V\) \\rightarrow \\mathsf{gl}\(V\)}$$
](A272900_1_En_16_Chapter_Equap.gif)

by

![
$$\\displaystyle{C_{U}\(X\) = UX{U}^{-1}.}$$
](A272900_1_En_16_Chapter_Equaq.gif)

(That is to say, C U is conjugation by U.) Note that ![
$${\(C_{U}\)}^{-1} = C_{{U}^{-1}}$$
](A272900_1_En_16_Chapter_IEq366.gif) and ![
$$C_{UV } = C_{U}C_{V }.$$
](A272900_1_En_16_Chapter_IEq367.gif) Thus, C (i.e., the map U ↦ C U ) is a homomorphism of U(V) into GL(gl(V)), and this homomorphism is clearly continuous. If U is a multiple of the identity, then C U is the identity operator on gl(V). Conversely, if C U is the identity, then UX = XU for all X ∈ gl(V), which implies (Exercise 18) that U is a multiple of the identity. Thus, the kernel of C consists precisely of those scalar multiples of the identity that are in U(V); that is, ![
$$\\ker C =\\{ {e}^{i\\theta }I\\}.$$
](A272900_1_En_16_Chapter_IEq368.gif)

We have constructed, then, a homomorphism of U(V) into ![
$$\\mathsf{GL}\(\\mathsf{gl}\(V\)\)\\mathop{\\cong}\\mathsf{GL}\({N}^{2}; \\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq369.gif) with a kernel that is precisely ![
$$\\{{e}^{i\\theta }I\\}.$$
](A272900_1_En_16_Chapter_IEq370.gif) The image of U(V) under this homomorphism is, therefore, isomorphic to the quotient group ![
$$\\mathsf{U}\(V\)/\\{{e}^{i\\theta }I\\}.$$
](A272900_1_En_16_Chapter_IEq371.gif) Furthermore, since U(V) is compact, the image of U(V) under C is compact and thus closed. This image is, then, a matrix Lie group isomorphic to PU(V).

Let c be the associated Lie algebra homomorphism associated with the homomorphism C. Using Point 3 of Theorem 16.23, we may calculate that

![
$$\\displaystyle\\begin{array}{rcl} c_{X}\(Y \)& & = \\left. \\frac{d} {dt}{e}^{tX}Y {e}^{-tX}\\right\\vert _{ t=0} {}\\\\ & & = XY - Y X {}\\\\ & & = \[X,Y\]. {}\\\\ \\end{array}$$
](A272900_1_En_16_Chapter_Equ8.gif)

Using Exercise 18 again, we see that c X = 0 if and only if X is a multiple of the identity. Thus, the kernel of c consists of all the scalar multiples of I in u(V), namely ![
$$\\{iaI\\}.$$
](A272900_1_En_16_Chapter_IEq372.gif)

Now, the image of U(V) under C is (isomorphic to) PU(V); in particular, C maps U(V) onto PU(V). It follows that c must map u(V) onto pu(V). (This claim follows from Theorem 3.15 in [21].) Thus, ![
$$\\mathsf{pu}\(V\)\\mathop{\\cong}\\mathsf{u}\(V\)/\\{iaI\\}.$$
](A272900_1_En_16_Chapter_IEq373.gif)

Definition 16.45

A finite-dimensional projective unitary representation of a matrix Lie group G is a continuous homomorphism Π of G into PU(V), where V is a finite-dimensional Hilbert space over ![
$$\\mathbb{C}.$$
](A272900_1_En_16_Chapter_IEq374.gif) A subspace W of V is said to be invariant under Π if for each A ∈ G, W is invariant under U for every U ∈ U(V) such that [U] = Π(A). A projective unitary representation (Π, V) is irreducible if the only invariant subspaces are ![
$$\\{0\\}$$
](A272900_1_En_16_Chapter_IEq375.gif) and V.

Given an ordinary unitary representation, Σ : G → U(V), we can always form a projective representation, Π : G → PU(V), simply by setting Π = Q ∘ Σ. Not every projective representation, however, arises in this fashion. Thus, considering projective representations gives us more flexibility than considering ordinary unitary representations.

Proposition 16.46

Let Π : G → PU(V) be a finite-dimensional projective unitary representation of a matrix Lie group G, and let ![
$$\\pi : \\mathfrak{g} \\rightarrow \\mathsf{pu}\(V\)$$
](A272900_1_En_16_Chapter_IEq376.gif) be the associated Lie algebra homomorphism. Then there exists a Lie algebra homomorphism ![
$$\\sigma : \\mathfrak{g} \\rightarrow \\mathsf{u}\(V\)$$
](A272900_1_En_16_Chapter_IEq377.gif) such that π(X) = q(σ(X)) for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq378.gif) It is possible to choose σ so that trace (σ(X)) = 0 for all ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq379.gif) and σ is unique if we require this condition.

That is to say, every finite-dimensional projective representation can be "de-projectivized" at the Lie algebra level. In general, σ is not unique, because there may be σ's for which trace(σ(X)) is nonzero for some X. On the other hand, if ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq380.gif) has the property that every ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq381.gif) is a linear combination of commutators—which is true if ![
$$\\mathfrak{g} = \\mathsf{so}\(3\)$$
](A272900_1_En_16_Chapter_IEq382.gif)—then σ is unique. See Exercise 15.

Proof.

Recall that ![
$$\\mathsf{pu}\(V\)\\mathop{\\cong}\\mathsf{u}\(V\)/\\{iaI\\}.$$
](A272900_1_En_16_Chapter_IEq383.gif) That is, for each ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq384.gif) π(X) denotes a whole family of operator that differ by adding iaI. If Y ∈ u(n) is any representative of π(X), then since Y ∗ = − Y, the trace of Y will be pure imaginary. Thus, there is a unique pure-imaginary constant c = − trace(Y) ∕ dim V such that the trace of Y \+ cI is zero. Let us then set σ(X) = Y \+ cI. Since π is a Lie algebra homomorphism, σ([X, Y ]) will equal [σ(X), σ(Y)] + iaI, for some ![
$$a \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq385.gif) Since trace(σ([X, Y ])) = 0 by construction and since the commutator of any two matrices has trace zero, we see that actually a = 0. Thus, a σ as in the proposition exists, and it is unique if we require that σ(X) have trace zero.

Theorem 16.47

Suppose G is a matrix Lie group and ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq386.gif) is a universal cover of G, with covering map Φ. Then the following hold.

1.

Let Π : G → PU(V) be a finite-dimensional projective unitary representation of G. Then there is an ordinary unitary representation ![
$$\\Sigma :\\tilde{ G} \\rightarrow \\mathsf{U}\(V\)$$
](A272900_1_En_16_Chapter_IEq387.gif) of ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq388.gif) such that Π ∘ Φ = Q ∘ Σ. Any such Σ is irreducible if and only if Π is irreducible. It is possible to choose Σ so that det (Σ(A)) = 1 for all ![
$$A \\in \\tilde{ G},$$
](A272900_1_En_16_Chapter_IEq389.gif) and Σ is unique if we require this condition.

2.

Let Σ be a finite-dimensional irreducible unitary representation of ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq390.gif) . Then the kernel of the associated projective unitary representation Q ∘ Σ contains the kernel of the covering map Φ. Thus, Q ∘ Σ factors through G and gives rise to a projective unitary representation of G.

In the finite-dimensional case, then, there is a one-to-one correspondence between irreducible projective unitary representations of G and irreducible, determinant-one ordinary unitary representations of ![
$$\\tilde{G}.$$
](A272900_1_En_16_Chapter_IEq391.gif) Point 1 of the theorem means that any finite-dimensional projective unitary representation of the group G can be "de-projectivized" at the expense of passing to the universal cover ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq392.gif) of G.

Note that Theorem 16.47 applies only to finite-dimensional projective unitary representations. Example 16.56 will provide an infinite-dimensional example in which Point 1 of the theorem fails.

Proof.

If ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq393.gif) is the Lie algebra of G, Proposition 16.46 tells us that we can find an ordinary representation ![
$$\\sigma : \\mathfrak{g} \\rightarrow \\mathsf{u}\(V\)$$
](A272900_1_En_16_Chapter_IEq394.gif) such that q ∘ σ = π. We then define a representation ![
$$\\tilde{\\sigma }: \\tilde{\\mathfrak{g}} \\rightarrow \\mathsf{u}\(V\)$$
](A272900_1_En_16_Chapter_IEq395.gif) of the Lie algebra ![
$$\\tilde{\\mathfrak{g}}$$
](A272900_1_En_16_Chapter_IEq396.gif) of ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq397.gif) by setting ![
$$\\tilde{\\sigma }\(X\) =\\sigma \(\\phi \(X\)\),$$
](A272900_1_En_16_Chapter_IEq398.gif) ![
$$X \\in \\tilde{\\mathfrak{g}}.$$
](A272900_1_En_16_Chapter_IEq399.gif) Since ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq400.gif) is simply connected, we can then find a unique representation ![
$$\\Sigma :\\tilde{ G} \\rightarrow \\mathsf{U}\(V\)$$
](A272900_1_En_16_Chapter_IEq401.gif) such that ![
$$\\Sigma \({e}^{X}\) = {e}^{\\tilde{\\sigma }\(X\)}$$
](A272900_1_En_16_Chapter_IEq402.gif) for all ![
$$X \\in \\tilde{\\mathfrak{g}}.$$
](A272900_1_En_16_Chapter_IEq403.gif) Since

![
$$\\displaystyle{q\\circ \\tilde{\\sigma } = q \\circ \\sigma \\circ \\phi =\\pi \\circ \\phi,}$$
](A272900_1_En_16_Chapter_Equar.gif)

it follows that Q ∘ Σ = Π ∘ Φ. Furthermore, if Σ maps into SU(V), ![
$$\\sigma =\\tilde{\\sigma } {\\circ \\phi }^{-1}$$
](A272900_1_En_16_Chapter_IEq404.gif) maps into su(n). This condition uniquely determines σ and thus also ![
$$\\tilde{\\sigma }$$
](A272900_1_En_16_Chapter_IEq405.gif) and Σ, establishing Point 1 of the theorem.

For Point 2, observe that ker Φ is a discrete normal subgroup of ![
$$\\tilde{G},$$
](A272900_1_En_16_Chapter_IEq406.gif) which is therefore central (Exercises 1 and 12). Thus, for all A ∈ ker Φ, we have

![
$$\\displaystyle{\\Sigma \(A\)\\Sigma \(B\) = \\Sigma \(AB\) = \\Sigma \(BA\) = \\Sigma \(B\)\\Sigma \(A\)}$$
](A272900_1_En_16_Chapter_Equas.gif)

for all ![
$$B \\in \\tilde{ G}.$$
](A272900_1_En_16_Chapter_IEq407.gif) That is to say, Σ(A) is an intertwining map of V to itself. Since V is also irreducible as a representation of ![
$$\\tilde{G},$$
](A272900_1_En_16_Chapter_IEq408.gif) Schur's lemma tells us that Σ(A) = cI, where ![
$$\\left \\vert c\\right\\vert = 1$$
](A272900_1_En_16_Chapter_IEq409.gif) because Σ(A) ∈ U(V). Thus, A is in the kernel of the associated projective representation Q ∘ Σ.

## 16.8 New Representations from Old

In this section, we consider three basic mechanisms for combining representations to produce new representations: direct sums, tensor products, and duals. This section assumes familiarity with these notions at the level of vector spaces; a brief review is provided in Appendix A.1.

Definition 16.48

Suppose ![
$$\\left \(\\Pi _{1},V _{1}\\right\)$$
](A272900_1_En_16_Chapter_IEq410.gif) and ![
$$\(\\Pi _{2},V _{2}\)$$
](A272900_1_En_16_Chapter_IEq411.gif) are representations of a matrix Lie group G. The direct sum of these two representations is the representation ![
$$\\Pi _{1} \\oplus \\Pi _{2} : G \\rightarrow \\mathsf{GL}\(V _{1} \\oplus V _{2}\)$$
](A272900_1_En_16_Chapter_IEq412.gif) given by

![
$$\\displaystyle{\(\\Pi _{1} \\oplus \\Pi _{2}\)\(A\) = \\Pi _{1}\(A\) \\oplus \\Pi _{2}\(A\).}$$
](A272900_1_En_16_Chapter_Equat.gif)

The tensor product of Π 1 and Π2 is the representation ![
$$\\Pi _{1} \\otimes \\Pi _{2} : G \\rightarrow \\mathsf{GL}\(V _{1} \\otimes V _{2}\)$$
](A272900_1_En_16_Chapter_IEq413.gif) given by

![
$$\\displaystyle{\(\\Pi _{1} \\otimes \\Pi _{2}\)\(A\) = \\Pi _{1}\(A\) \\otimes \\Pi _{2}\(A\).}$$
](A272900_1_En_16_Chapter_Equau.gif)

Finally, the dual of Π 1 is the representation ![
$$\\Pi _{1}^{tr} : G \\rightarrow \\mathsf{GL}\({V }^{{\\ast}}\)$$
](A272900_1_En_16_Chapter_IEq414.gif) given by

![
$$\\displaystyle{\\Pi _{1}^{tr}\(A\) = \\Pi _{ 1}{\({A}^{-1}\)}^{tr} ={ \\left \(\\Pi _{ 1}{\(A\)}^{tr}\\right\)}^{-1}.}$$
](A272900_1_En_16_Chapter_Equav.gif)

Similarly, the direct sum, tensor product, and dual of Lie algebra representations can be defined by

![
$$\\displaystyle\\begin{array}{rcl} \(\\pi _{1} \\oplus \\pi _{2}\)\(X\)& & =\\pi _{1}\(X\) \\oplus \\pi _{2}\(X\) {}\\\\ \(\\pi _{1} \\otimes \\pi _{2}\)\(X\)& & =\\pi _{1}\(X\) \\otimes I + I \\otimes \\pi _{2}\(X\) {}\\\\ \\pi _{1}^{tr}\(X\)& & = -\\pi _{ 1}{\(X\)}^{tr}. {}\\\\ \\end{array}$$
](A272900_1_En_16_Chapter_Equ9.gif)

It is important to note the differences in formulas between the group and the Lie algebra in the case of tensor products and dual representations. It is easy to motivate the definitions for the Lie algebra: If G acts on V 1 ⊗ V 2 by Π 1(A) ⊗ Π 2(A), then the associated Lie algebra action will be given by

![
$$\\displaystyle{\\left. \\frac{d} {dt}\\Pi _{1}\({e}^{tX}\) \\otimes \\Pi _{ 2}\({e}^{tX}\)\\right\\vert _{ t=0} =\\pi _{1}\(X\) \\otimes I + I \\otimes \\pi _{2}\(X\).}$$
](A272900_1_En_16_Chapter_Equaw.gif)

Of course, we continue to use this last formula for tensor products of Lie algebra representations, even if there is no associated group representations.

Remark 16.49

If (Π 1, V 1) and (Π 2, V 2) are representations of a group G, it is possible to view V 1 ⊗ V 2 as a representation of the direct product group G ×G, by setting

![
$$\\displaystyle{\(\\Pi _{1} \\otimes \\Pi _{2}\)\(A,B\) = \\Pi _{1}\(A\) \\otimes \\Pi _{2}\(B\).}$$
](A272900_1_En_16_Chapter_Equax.gif)

Similarly, if ![
$$\(\\pi _{1},V _{1}\)$$
](A272900_1_En_16_Chapter_IEq415.gif) and ![
$$\(\\pi _{2},V _{2}\)$$
](A272900_1_En_16_Chapter_IEq416.gif) are representations of a Lie algebra ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq417.gif) it is possible to view ![
$$V _{1} \\otimes V _{2}$$
](A272900_1_En_16_Chapter_IEq418.gif) as a representation of ![
$$\\mathfrak{g} \\oplus \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq419.gif) by setting

![
$$\\displaystyle{\(\\pi _{1} \\otimes \\pi _{2}\)\(X,Y \) =\\pi _{1}\(X\) \\otimes I + I \\otimes \\pi _{2}\(Y \).}$$
](A272900_1_En_16_Chapter_Equay.gif)

Nevertheless, it is, in most cases, more natural to view ![
$$V _{1} \\otimes V _{2}$$
](A272900_1_En_16_Chapter_IEq420.gif) as a representation of G itself, rather than of G ×G. Even if V 1 and V 2 are irreducible representations of G, the space ![
$$V _{1} \\otimes V _{2}$$
](A272900_1_En_16_Chapter_IEq421.gif) will in most cases fail to be irreducible as a representation of G. If, for example, we take ![
$$V _{1} = V _{2} = V,$$
](A272900_1_En_16_Chapter_IEq422.gif) then the space of symmetric tensors inside V ⊗ V will form a nontrivial invariant subspace, unless dim V = 1. An important problem in representation theory is to decompose V 1 ⊗ V 2 as a direct sum of irreducible representations, where V 1 and V 2 are irreducible representations of a fixed group or Lie algebra. In the case of the Lie algebra su(2), this decomposition is discussed in Sect.​ 17.​9.

Definition 16.50

A finite-dimensional representation of a group or Lie algebra is said to be completely reducible if it is isomorphic to a direct sum of irreducible representations.

Proposition 16.51

Every finite-dimensional unitary representation of a group or Lie algebra is completely reducible.

Proof.

Suppose (Π, V) is a unitary representation of a matrix Lie group G. If W is a subspace of V invariant under each Π(A), then W ⊥ is invariant under each Π(A)∗, as the reader may easily verify. But since Π is unitary,

![
$$\\displaystyle{\\Pi {\(A\)}^{{\\ast}} = \\Pi {\(A\)}^{-1} = \\Pi \({A}^{-1}\).}$$
](A272900_1_En_16_Chapter_Equaz.gif)

Thus, W ⊥ is invariant under Π(A − 1) for all A ∈ G, hence under Π(A) for all A ∈ G. We conclude that, in the unitary case, the orthogonal complement of an invariant subspace is always invariant.

If V is irreducible, there is nothing to prove. If not, we pick a nontrivial invariant subspace W and decompose V as W ⊕ W ⊥. The restriction of Π to W or to W ⊥ is again a unitary representation, so we can repeat this procedure for each of these subspaces. Since V is finite-dimensional, the process must eventually terminate, yielding an orthogonal decomposition of V as a direct sum of irreducible invariant subspaces.

If we consider a unitary representation π of a Lie algebra ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq423.gif) we have the same argument, but with the identity ![
$$\\Pi {\(A\)}^{{\\ast}} = \\Pi \({A}^{-1}\)$$
](A272900_1_En_16_Chapter_IEq424.gif) replaced by ![
$$\\pi {\(X\)}^{{\\ast}} = -\\pi \(X\).$$
](A272900_1_En_16_Chapter_IEq425.gif)

Proposition 16.52

Suppose K is a compact matrix Lie group. For any finite-dimensional representation (Π,V) of K, there exists an inner product on V such that Π(A) is unitary for all A ∈ G. In particular, every finite-dimensional representation of K is completely reducible.

See Proposition 4.36 in [21].

## 16.9 Infinite-Dimensional Unitary Representations

For the applications we have in mind, we need to consider representations that are infinite-dimensional. The theory of such representations is inevitably more complicated than that of finite-dimensional representations. For our purposes, it suffices to consider the nicest sort of infinite-dimensional representations—unitary representations in a Hilbert space.

### 16.9.1 Ordinary Unitary Representations

We begin by considering ordinary representations and then turn to projective representations.

Definition 16.53

Suppose G is a matrix Lie group. Then a unitary representation of G is a strongly continuous homomorphism Π : G → U(H), where H is a separable Hilbert space and U(H) is the group of unitary operators on H. Here, strong continuity of Π means that if a sequence A m in G converges to A ∈ G, then

![
$$\\displaystyle{\\lim _{m\\rightarrow \\infty }\\left \\Vert \\Pi \(A_{m}\)\\psi - \\Pi \(A\)\\psi \\right\\Vert = 0}$$
](A272900_1_En_16_Chapter_Equba.gif)

for all   ∈ H.

We can attempt to associate to a unitary representation Π of G some sort of representation π of the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq426.gif) of G, by imitating the construction in Theorem 16.23. For any ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq427.gif) the map t ↦ Π(e tX ) is a strongly continuous one-parameter unitary group. Thus, Stone's theorem (Theorem 10.15) tells us that there exists a unique self-adjoint operator A such that ![
$$\\Pi \({e}^{tX}\) = {e}^{itA}$$
](A272900_1_En_16_Chapter_IEq428.gif) for all ![
$$t \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq429.gif) If we let π(X) denote the skew-self-adjoint operator iA, we will have

![
$$\\displaystyle{ \\Pi \({e}^{tX}\) = {e}^{t\\pi \(X\)}. }$$
](A272900_1_En_16_Chapter_Equ10.gif)

(16.5)

The operators π(X), ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq430.gif) are in general unbounded and defined only on a dense subspace of ![
$$\\mathbf{H}.$$
](A272900_1_En_16_Chapter_IEq431.gif) Nevertheless, it can be shown (see, e.g., [43]) that there exists a dense subspace V of H contained in the domain of each π(X) and that is invariant under each π(X), and on which we have π([X, Y ]) = [π(X), π(Y)]. In the case of the particular representation that we will consider in the next chapter, we can avoid these difficulties by looking at finite-dimensional invariant subspaces.

Proposition 16.54

Suppose G is a matrix Lie group and Π : G → U( H ) is a unitary representation of G. For each ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq432.gif) let π(X) denote the operator in ( 16.5 ). Suppose V ⊂ H is a finite-dimensional subspace of H such that Π(A) maps V into V, for all A ∈ G. Then for all ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq433.gif) V ⊂ Dom (π(X)), π(X) maps V into V, and we have

![
$$\\displaystyle{ \\pi \(\[X,Y\]\)v = \[\\pi \(X\),\\pi \(Y \)\]v }$$
](A272900_1_En_16_Chapter_Equ11.gif)

(16.6)

for all v ∈ V.

In the other direction, suppose G is connected and suppose V is any finite-dimensional subspace of H such that for all ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq434.gif) V ⊂ Dom (π(X)) and π(X) maps V into V. Then Π(A) also maps V into V, for all A ∈ G.

Proof.

Since V is invariant under both Π(A) and ![
$$\\Pi {\(A\)}^{{\\ast}} = \\Pi \({A}^{-1}\),$$
](A272900_1_En_16_Chapter_IEq435.gif) the restriction to V of each Π(A) is unitary. The operators Π(A) V form a finite-dimensional unitary representation of G that is strongly continuous and thus continuous. (In the finite-dimensional case, all reasonable notions of continuity for representations coincide.) For each ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq436.gif) Theorem 16.18 tells us that there is an operator ![
$$\\tilde{X}$$
](A272900_1_En_16_Chapter_IEq437.gif) on V such that

![
$$\\displaystyle{\\left.\\Pi \({e}^{tX}\)\\right\\vert _{ V } = {e}^{t\\tilde{X}}.}$$
](A272900_1_En_16_Chapter_Equbb.gif)

Thus, for any v ∈ V, we have

![
$$\\displaystyle{\\lim _{t\\rightarrow 0}\\frac{\\Pi \({e}^{tX}\)v - v} {t} =\\lim _{t\\rightarrow 0}\\frac{{e}^{t\\tilde{X}}v - v} {t} =\\tilde{ X}v.}$$
](A272900_1_En_16_Chapter_Equbc.gif)

This calculation shows that v is in the domain of the infinitesimal generator π(X) of the unitary group Π(e tX ), and that ![
$$\\pi \(X\)v =\\tilde{ X}v.$$
](A272900_1_En_16_Chapter_IEq438.gif) Since the operators ![
$$\\tilde{X},$$
](A272900_1_En_16_Chapter_IEq439.gif) ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq440.gif) form a representation of ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq441.gif) we have the relation (16.6).

In the other direction, if V is invariant under π(X), the restriction of π(X) to V is automatically bounded. Thus, there is a constant C such that

![
$$\\displaystyle{ \\left \\Vert \\pi {\(X\)}^{m}v\\right\\Vert \\leq {C}^{m}\\left \\Vert v\\right\\Vert }$$
](A272900_1_En_16_Chapter_Equ12.gif)

(16.7)

for all v ∈ V. If we use the direct-integral form of the spectral theorem for the self-adjoint operator A : = − iπ(X), it is easy to see that (16.7) can only hold if v, viewed as an element of the direct integral, is supported on a bounded interval inside the spectrum of A. Since the power series of the function λ ↦ e t λ converges to e t λ uniformly on any finite interval, we will have

![
$$\\displaystyle{\\Pi \({e}^{tX}\)v = {e}^{itA}v =\\sum _{ m=0}^{\\infty }\\frac{{t}^{m}\\pi {\(X\)}^{m}} {m!} v.}$$
](A272900_1_En_16_Chapter_Equbd.gif)

Each term in the above power series belongs to V, which is finite dimensional and thus closed. We conclude that Π(e tX )v belongs to V for all ![
$$X \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq442.gif) Since G is connected, each element of G is a product of exponentials of Lie algebra elements, and we have the claim.

### 16.9.2 Projective Unitary Representations

Given a Hilbert space H, let S H denote the unit sphere in H, that is, the set of vectors with norm 1. Let P H be the quotient space (S H ) ∕ ∼ , where " ∼ " denotes the equivalence relation in which u ∼ v if and only if u = e iθ v for some ![
$$\\theta \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq443.gif) The quotient map q : S H → P H induces a topology on P H in which a set U ⊂ P H is open if and only if q − 1(U) is open as a subset of the metric space S H ⊂ H.

As in the finite-dimensional case, we can form the quotient group

![
$$\\displaystyle{\\mathsf{PU}\(\\mathbf{H}\) := \\mathsf{U}\(\\mathbf{H}\)/\\{{e}^{i\\theta }I\\}.}$$
](A272900_1_En_16_Chapter_Eqube.gif)

The action of U(H) on S H descends to a well-defined action of PU(H) on P H.

Definition 16.55

A projective unitary representation of a matrix Lie group G is a homomorphism Π : G → PU(H), for some Hilbert space H, with the property that if a sequence A m in G converges to A in G, then

![
$$\\displaystyle{\\Pi \(A_{m}\)x \\rightarrow \\Pi \(A\)x}$$
](A272900_1_En_16_Chapter_Equbf.gif)

for all x ∈ P H.

Recall that in the finite-dimensional case, every projective unitary representation of G can be "de-projectivized" at the expense of possibly having to pass to the universal cover ![
$$\\tilde{G}$$
](A272900_1_En_16_Chapter_IEq444.gif) of G (Theorem 16.47). The de-projectivization proceeds by passing to the Lie algebra, choosing the trace-zero representative of each equivalence class, and then exponentiating back to the universal cover of the original group. This approach does not work in the infinite-dimensional case. After all, even assuming we can construct a Lie algebra homomorphism π(X) for each ![
$$X \\in \\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq445.gif) the representatives of π(X) are typically unbounded operators on H, for which the notion of trace does not make sense. This difficulty is not just a technicality; the corresponding result in the infinite-dimensional case is false, as we will now see.

Example 16.56

For all ![
$$\(a,b\) \\in {\\mathbb{R}}^{2},$$
](A272900_1_En_16_Chapter_IEq446.gif) define an operator T (a, b) on ![
$${L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_16_Chapter_IEq447.gif) by

![
$$\\displaystyle{\(T_{\(a,b\)}\\psi \)\(x\) = {e}^{iax}\\psi \(x - b\).}$$
](A272900_1_En_16_Chapter_Equbg.gif)

Then T (a, b) is unitary for all ![
$$\(a,b\) \\in {\\mathbb{R}}^{2}$$
](A272900_1_En_16_Chapter_IEq448.gif) and we have

![
$$\\displaystyle\\begin{array}{rcl} \\left \(T_{\(a,b\)}T_{\({a}^{{\\prime}},{b}^{{\\prime}}\)}\\psi \\right\)\(x\)& & = {e}^{iax}{e}^{i{a}^{{\\prime}}\(x-b\) }\\psi \(x - \(b + {b}^{{\\prime}}\)\) \\\\ & & = {e}^{-i{a}^{{\\prime}}b }\\left \(T_{\(a+{a}^{{\\prime}},b+{b}^{{\\prime}}\)}\\psi \\right\)\(x\).{}\\end{array}$$
](A272900_1_En_16_Chapter_Equ13.gif)

(16.8)

The map (a, b) ↦ [T (a, b)] is a homomorphism of ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_16_Chapter_IEq449.gif) into ![
$$\\mathsf{PU}\({L}^{2}\(\\mathbb{R}\)\),$$
](A272900_1_En_16_Chapter_IEq450.gif) and this homomorphism is continuous in the sense of Definition 16.55. There does not, however, exist any homomorphism ![
$$S : {\\mathbb{R}}^{2} \\rightarrow \\mathsf{U}\({L}^{2}\(\\mathbb{R}\)\)$$
](A272900_1_En_16_Chapter_IEq451.gif) such that [S (a, b)] = [T (a, b)] for all ![
$$\(a,b\) \\in {\\mathbb{R}}^{2}.$$
](A272900_1_En_16_Chapter_IEq452.gif)

Thus, even though ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_16_Chapter_IEq453.gif) is simply connected (and thus its own universal cover), there is no way to de-projectivize the projective unitary representation (a, b) ↦ [T (a, b)] of ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_16_Chapter_IEq454.gif)

Proof.

The map (a, b) → T (a, b) is easily seen to be strongly continuous, and thus the map (a, b) ↦ [T (a, b)] is continuous in the sense of Definition 16.55. If a homomorphism S with the indicated properties existed, then there would be constants θ a, b such that ![
$$S_{\(a,b\)} = {e}^{i\\theta _{a,b}}T_{ \(a,b\)}$$
](A272900_1_En_16_Chapter_IEq455.gif). But then since S is a homomorphism from the commutative group ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_16_Chapter_IEq456.gif) into ![
$$\\mathsf{U}\({L}^{2}\(\\mathbb{R}\)\),$$
](A272900_1_En_16_Chapter_IEq457.gif) the operator S (a, b) would have to commute with ![
$$S_{\({a}^{{\\prime}},{b}^{{\\prime}}\)}$$
](A272900_1_En_16_Chapter_IEq458.gif) for all (a, b) and ![
$$\({a}^{{\\prime}},{b}^{{\\prime}}\).$$
](A272900_1_En_16_Chapter_IEq459.gif) But then the operators T (a, b) and ![
$$T_{\({a}^{{\\prime}},{b}^{{\\prime}}\)},$$
](A272900_1_En_16_Chapter_IEq460.gif) being constant multiples of commuting operators, would need to commute as well. But this is not the case; for example, T (a, 0) does not commute with ![
$$T_{\(0,{b}^{{\\prime}}\)},$$
](A272900_1_En_16_Chapter_IEq461.gif) as is easily verified using (16.8).

Despite the negative result in Example 16.56, there is a positive result in this direction: If G is connected and "semi-simple," every projective unitary representation of G can be de-projectivized after passing to the universal cover. Here, a Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq462.gif) is said to be simple if ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq463.gif) has no nontrivial ideals and ![
$$\\dim \\mathfrak{g} \\geq 2.$$
](A272900_1_En_16_Chapter_IEq464.gif) A Lie algebra is said to be semi-simple if it is a direct sum of simple algebras. Finally, a Lie group G is said to be semi-simple if the Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq465.gif) of G is semi-simple.

For any connected Lie group G, a projective unitary representation Π of G can be de-projectivized by passing to a one-dimensional central extension. A one-dimensional central extension of G is a Lie group G ′ together with a surjective homomorphism Φ : G ′ → G such that the kernel of Φ is one-dimensional and contained in the center of G ′ . See the article [1] of V. Bargmann for more information about these issues.

## 16.10 Exercises

1.

Suppose that G is a connected matrix Lie group and that N is a discrete normal subgroup of G, meaning that there is some neighborhood U of I in G such that ![
$$U {\\cap} N =\\{ I\\}.$$
](A272900_1_En_16_Chapter_IEq466.gif) Show that N is contained in the center of G.

Hint: Consider the quantity gng − 1 for g ∈ G and n ∈ N.

2.

(a)

Suppose two elements U and V of SU(2) commute. Show that each eigenspace for U is invariant under V and vice versa.

(b)

Show that if U is in the center of SU(2), then U = I or U = − I.

3.

Define the Hilbert–Schmidt norm of a matrix ![
$$X \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq467.gif) by the formula

![
$$\\displaystyle{\\left \\Vert X\\right\\Vert _{\\mathrm{HS}}^{2} =\\sum _{ j,k=1}^{n}{\\left \\vert X_{ jk}\\right\\vert }^{2}.}$$
](A272900_1_En_16_Chapter_Equbh.gif)

Using the Cauchy–Schwarz inequality, show that

![
$$\\displaystyle{ \\left \\Vert XY \\right\\Vert _{\\mathrm{HS}} \\leq \\left \\Vert X\\right\\Vert _{\\mathrm{HS}}\\left \\Vert Y \\right\\Vert _{\\mathrm{HS}} }$$
](A272900_1_En_16_Chapter_Equ14.gif)

(16.9)

for all ![
$$X,Y \\in M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq468.gif)

4.

Using term-by-term differentiation of power series, show that for all ![
$$X \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq469.gif) and all 1 ≤ j, k ≤ n, we have

![
$$\\displaystyle{ \\frac{d} {dt}\\left.\\left \[\\left \({e}^{tX}\\right\)_{ jk}\\right\]\\right\\vert _{t=0} = X_{jk}.}$$
](A272900_1_En_16_Chapter_Equbi.gif)

5.

Verify Property 16.15 of Theorem 16.15. This should be easy in the case that X is diagonalizable. In the general case, either use the Jordan canonical form or appeal to the fact that diagonalizable matrices are dense in ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq470.gif)

6.

Suppose X and Y are commuting n ×n matrices. Show that

![
$$\\displaystyle{{e}^{X}{e}^{Y } = {e}^{X+Y }.}$$
](A272900_1_En_16_Chapter_Equbj.gif)

This is Property 16.15 of Theorem 16.15.

Hint: Multiply together the power series for e X and e Y and then group terms where the total power of X and Y is n.

7.

For ![
$$A \\in M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq471.gif) define the logarithm of A by the power series

![
$$\\displaystyle{\\log A = A - I -\\frac{{\(A - I\)}^{2}} {2} + \\frac{{\(A - I\)}^{3}} {3} -\\cdots }$$
](A272900_1_En_16_Chapter_Equbk.gif)

whenever this series converges. Assume the following result: If A is sufficiently close to I, then log A is defined and exp(log A) = A. [This can be seen easily when A is diagonalizable, and the set of diagonalizable matrices is dense in ![
$$M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq472.gif)]

(a)

Show that there exists a constant C such that for all A with A − I < 1 ∕ 2 we have

![
$$\\displaystyle{\\left \\Vert \\log A - \(A - I\)\\right\\Vert \\leq C{\\left \\Vert A - I\\right\\Vert }^{2}.}$$
](A272900_1_En_16_Chapter_Equbl.gif)

(b)

Show that for all ![
$$X,Y \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq473.gif) we have

![
$$\\displaystyle{ \\log \\left \({e}^{X/m}{e}^{Y/m}\\right\) = \\frac{X} {m} + \\frac{Y } {m} + O\\left \( \\frac{1} {{m}^{2}}\\right\). }$$
](A272900_1_En_16_Chapter_Equ15.gif)

(16.10)

Note that ![
$${e}^{X/m}{e}^{Y/m}$$
](A272900_1_En_16_Chapter_IEq474.gif) tends to I as m tends to infinity, so that the left-hand side of (16.10) is defined for all sufficiently large m.

(c)

Prove the Lie Product Formula.

8.

(a)

Show that for all ![
$$X,Y \\in M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_16_Chapter_IEq475.gif)

![
$$\\displaystyle{\\left \\Vert \\left. \\frac{d} {dt}{\(X + tY \)}^{m}\\right\\vert _{ t=0}\\right\\Vert \\leq m{\\left \\Vert X\\right\\Vert }^{m-1}\\left \\Vert Y \\right\\Vert.}$$
](A272900_1_En_16_Chapter_Equbm.gif)

(b)

Show that the map X ↦ e tX is a continuously differentiable map of ![
$$M_{n}\(\\mathbb{C}\)\\mathop{\\cong}{\\mathbb{R}}^{2{n}^{2} }$$
](A272900_1_En_16_Chapter_IEq476.gif) to itself.

(c)

Using Exercise 4, show that the differential of the map X ↦ e X at X = 0 is the identity map of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq477.gif) to itself. (Recall that the differential of smooth map of ![
$${\\mathbb{R}}^{j}$$
](A272900_1_En_16_Chapter_IEq478.gif) to ![
$${\\mathbb{R}}^{k},$$
](A272900_1_En_16_Chapter_IEq479.gif) evaluated at a point in ![
$${\\mathbb{R}}^{j},$$
](A272900_1_En_16_Chapter_IEq480.gif) is a linear map of ![
$${\\mathbb{R}}^{j}$$
](A272900_1_En_16_Chapter_IEq481.gif) to ![
$${\\mathbb{R}}^{k}.$$
](A272900_1_En_16_Chapter_IEq482.gif))

9.

Suppose ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq483.gif) is a Lie algebra and ![
$$\\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq484.gif) is an ideal in ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq485.gif) Let ![
$$\\mathfrak{g}/\\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq486.gif) denote the vector space quotient of ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq487.gif) by ![
$$\\mathfrak{h}.$$
](A272900_1_En_16_Chapter_IEq488.gif) Show that the bracket on ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq489.gif) descends unambiguously to a bilinear map on ![
$$\\mathfrak{g}/\\mathfrak{h},$$
](A272900_1_En_16_Chapter_IEq490.gif) and that ![
$$\\mathfrak{g}/\\mathfrak{h}$$
](A272900_1_En_16_Chapter_IEq491.gif) forms a Lie algebra under this map.

10.

Suppose that G 1, G 2, and G 3 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1},$$
](A272900_1_En_16_Chapter_IEq492.gif) ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq493.gif) and ![
$$\\mathfrak{g}_{3},$$
](A272900_1_En_16_Chapter_IEq494.gif) respectively. Suppose that ![
$$\\Phi : G_{1} \\rightarrow G_{2}$$
](A272900_1_En_16_Chapter_IEq495.gif) and ![
$$\\Psi : G_{2} \\rightarrow G_{3}$$
](A272900_1_En_16_Chapter_IEq496.gif) are Lie group homomorphisms with associated Lie algebra homomorphisms   and  , respectively. Show that the Lie algebra homomorphism associated to ![
$$\\Psi \\circ \\Phi : G_{1} \\rightarrow G_{3}$$
](A272900_1_En_16_Chapter_IEq497.gif) is   ∘  .

11.

Show that isomorphic matrix Lie groups have isomorphic Lie algebras.

12.

Suppose G 1 and G 2 are matrix Lie groups with Lie algebras ![
$$\\mathfrak{g}_{1}$$
](A272900_1_En_16_Chapter_IEq498.gif) and ![
$$\\mathfrak{g}_{2},$$
](A272900_1_En_16_Chapter_IEq499.gif) respectively. Suppose Φ : G 1 → G 2 is a Lie group homomorphism with the property that the associated Lie algebra homomorphism ![
$$\\phi : \\mathfrak{g}_{1} \\rightarrow \\mathfrak{g}_{2}$$
](A272900_1_En_16_Chapter_IEq500.gif) is injective. Show that there exists a neighborhood U of the identity in G 1 such that ![
$$U {\\cap} \\ker \\Phi =\\{ I\\}.$$
](A272900_1_En_16_Chapter_IEq501.gif)

Hint: Use Theorem 16.25.

13.

(a)

Show that every R ∈ SO(3) has an eigenvalue of 1.

(b)

Show that every R ∈ SO(3) is conjugate in SO(3) to matrix of the form

![
$$\\displaystyle{\\left \(\\begin{array}{ccc} 1&0& 0\\\\ 0 & \\cos \\theta &-\\sin \\theta \\\\ 0& \\sin \\theta & \\cos \\theta \\end{array} \\right\)}$$
](A272900_1_En_16_Chapter_Equbn.gif)

for some ![
$$\\theta \\in \\mathbb{R}.$$
](A272900_1_En_16_Chapter_IEq502.gif)

(c)

Show that the exponential map from so(3) to SO(3) is surjective.

(d)

Show that SO(3) is connected.

14.

Show that the center of SO(3) is trivial.

Hint: Use Part (a) of Exercise 13.

15.

Given a Lie algebra ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq503.gif) let ![
$$\[\\mathfrak{g},\\mathfrak{g}\]$$
](A272900_1_En_16_Chapter_IEq504.gif) denote the space of linear combinations of commutators, that is, the space spanned by elements of the form [X, Y ] with ![
$$X,Y \\in \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq505.gif)

(a)

Show that ![
$$\[\\mathfrak{g},\\mathfrak{g}\]$$
](A272900_1_En_16_Chapter_IEq506.gif) is an ideal in ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq507.gif) and that the quotient ![
$$\\mathfrak{g}/\[\\mathfrak{g},\\mathfrak{g}\]$$
](A272900_1_En_16_Chapter_IEq508.gif) is commutative. (The ideal ![
$$\[\\mathfrak{g},\\mathfrak{g}\]$$
](A272900_1_En_16_Chapter_IEq509.gif) is called the commutator ideal of ![
$$\\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq510.gif))

(b)

If ![
$$\\mathfrak{g} = \\mathsf{so}\(3\),$$
](A272900_1_En_16_Chapter_IEq511.gif) show that ![
$$\[\\mathfrak{g},\\mathfrak{g}\] = \\mathfrak{g}.$$
](A272900_1_En_16_Chapter_IEq512.gif)

(c)

If ![
$$\\pi : \\mathfrak{g} \\rightarrow \\mathsf{gl}\(V\)$$
](A272900_1_En_16_Chapter_IEq513.gif) is any finite-dimensional representation of ![
$$\\mathfrak{g},$$
](A272900_1_En_16_Chapter_IEq514.gif) show that ![
$$\\pi \(\[\\mathfrak{g},\\mathfrak{g}\]\)$$
](A272900_1_En_16_Chapter_IEq515.gif) is contained in sl(V), the space of endomorphisms of V with trace zero.

16.

(a)

Show that the Lie algebra ![
$$\\mathsf{pu}\(n\)\\mathop{\\cong}\\mathsf{u}\(n\)/\\{ia\\mathbb{R}\\}$$
](A272900_1_En_16_Chapter_IEq516.gif) is isomorphic to the Lie algebra su(n).

(b)

Let ![
$$\\{{e}^{2\\pi ik/n}I\\}$$
](A272900_1_En_16_Chapter_IEq517.gif) denote the group of matrices that are of the form of an nth root of unity times the identity. Show that the group PU(n) is isomorphic to ![
$$\\mathsf{SU}\(n\)/\\{{e}^{2\\pi ik/n}I\\}.$$
](A272900_1_En_16_Chapter_IEq518.gif)

17.

Suppose that G is a matrix Lie group with Lie algebra ![
$$\\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq519.gif) and that A is an element of G. Show that the operation of left multiplication by A − 1 is a diffeomorphism of ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq520.gif). Now show that there exist neighborhoods U of 0 in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq521.gif) and V of A in ![
$$M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq522.gif) such that the map X ↦ Ae X maps U diffeomorphically onto V and such that for X ∈ U, we have ![
$$X \\in \\mathfrak{g}$$
](A272900_1_En_16_Chapter_IEq523.gif) if and only if Ae X ∈ V. (Use Theorem 16.25.)

18.

Suppose that ![
$$Z \\in M_{n}\(\\mathbb{C}\)$$
](A272900_1_En_16_Chapter_IEq524.gif) has the property that ZX = XZ for all ![
$$X \\in M_{n}\(\\mathbb{C}\).$$
](A272900_1_En_16_Chapter_IEq525.gif) Show that Z = cI for some ![
$$c \\in \\mathbb{C}.$$
](A272900_1_En_16_Chapter_IEq526.gif)

19.

Suppose (Π, H) is a unitary representation of a matrix Lie group G, and suppose V 1 and V 2 are finite-dimensional irreducible invariant subspaces of H. Show that if V 1 and V 2 are not isomorphic as representations of G, then V 1 is orthogonal to V 2 inside H.

Hint: Show that the orthogonal projection of H onto V 1 or V 2 is an intertwining map, and use Schur's lemma.

References

[1].

V. Bargmann, On unitary ray representations of continuous groups. Ann. Math. 59(2), 1–46 (1954)CrossRefMATHMathSciNet

[12].

G.B. Folland, Real Analysis: Modern Techniques and Their Applications, 2nd edn. (Wiley, New York, 1999)MATH

[21].

B.C. Hall, Lie Groups, Lie Algebras, and Representations: An Elementary Introduction. Graduate Texts in Mathematics, vol. 222 (Springer, New York, 2003)

[25].

N. Jacobson, Lie Algebras (Dover Publications, New York, 1979)

[43].

N.R. Wallach, Real Reductive Groups I (Academic, San Diego, 1988)MATH
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_17

© Springer Science+Business Media New York 2013

# 17. Angular Momentum and Spin

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

Classically, angular momentum may be thought of as the Hamiltonian generator of rotations (Proposition 2.30). Angular momentum is a particularly useful concept when a system has rotational symmetry, since in that case the angular momentum is a conserved quantity (Proposition 2.18). Quantum mechanically, angular momentum is still the "generator"of rotations, meaning that it is the infinitesimal generator of a one-parameter group of unitary rotation operators, in the sense of Stone's theorem (Theorem 10.15).

## 17.1 The Role of Angular Momentum in Quantum Mechanics

Classically, angular momentum may be thought of as the Hamiltonian generator of rotations (Proposition 2.30). Angular momentum is a particularly useful concept when a system has rotational symmetry, since in that case the angular momentum is a conserved quantity (Proposition 2.18). Quantum mechanically, angular momentum is still the "generator" of rotations, meaning that it is the infinitesimal generator of a one-parameter group of unitary rotation operators, in the sense of Stone's theorem (Theorem 10.15). The quantum angular momentum is again conserved in systems with rotational symmetry. This means that if the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_17_Chapter_IEq1.gif) is invariant under rotations, then ![
$$\\hat{H}$$
](A272900_1_En_17_Chapter_IEq2.gif) commutes with the angular momentum operators, in which case, the angular momentum operators are constants of motion in the quantum mechanical sense.

The various components of the classical angular momentum vector for a particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq3.gif) satisfy certain simple commutation relations under the Poisson bracket (Exercise 19 in Chap.​ 2). We will see that those relations are the commutation relations for the Lie algebra ![
$$\\mathsf{so}\(3\)$$
](A272900_1_En_17_Chapter_IEq4.gif) of the rotation group SO(3). If ![
$$\\hat{H}$$
](A272900_1_En_17_Chapter_IEq5.gif) commutes with each component of the angular momentum, each eigenspace for ![
$$\\hat{H}$$
](A272900_1_En_17_Chapter_IEq6.gif) (the solution space to ![
$$\\hat{H}\\psi =\\lambda \\psi$$
](A272900_1_En_17_Chapter_IEq7.gif) for a given λ) is invariant under the angular momentum operators. Thus, the eigenspace constitutes a representation of the Lie algebra so(3). By classifying the irreducible (finite-dimensional) representations of so(3), we can obtain a lot of information about the structure of the solution spaces to the equation ![
$$\\hat{H}\\psi =\\lambda \\psi,$$
](A272900_1_En_17_Chapter_IEq8.gif) in the case that ![
$$\\hat{H}$$
](A272900_1_En_17_Chapter_IEq9.gif) is invariant under rotations. Specifically, the representation theory of so(3) allows us to determine completely the angular dependence of a solution ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq01.gif)(x), leaving only the radial dependence of ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq02.gif) to be determined. This has the effect of reducing the number of independent variables from three to one (just the radius r in polar coordinates), thereby reducing the problem to solving an ordinary differential equation.

Understanding angular momentum from the point of view of representations of a Lie algebra also prepares us to understand the concept of spin. The Hilbert space for a particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq10.gif) with spin is the tensor product of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq11.gif) with a finite-dimensional vector space V, where V carries an irreducible action of the rotation group SO(3). In this setting, the proper notion of "action" is a projective representation of SO(3), meaning a family of operators satisfying the relations of SO(3) up to phase factors (constants of absolute value one). These phase factors are permitted because, physically, two vectors that differ only by a constant represent the same physical state. By Proposition 16.46, every projective representation of SO(3) can be de-projectivized at the level of the Lie algebra so(3). Conversely, every irreducible ordinary representation of the Lie algebra so(3) gives rise to a representation of the universal cover SU(2) of SO(3), which in turn gives rise (Theorem 16.47) to a projective representation of SO(3). Thus, the possibilities for the space V are in one-to-one correspondence with the irreducible representations of the Lie algebra so(3). In the case of "half-integer spin," the space V does not carry an ordinary representation of the group SO(3).

## 17.2 The Angular Momentum Operators in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq12.gif)

Recall from Sect.​ 2.​4 that the classical angular momentum for a particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq13.gif) is given by J = x ×p, so that, say, ![
$$J_{3} = x_{1}p_{2} - x_{2}p_{1}.$$
](A272900_1_En_17_Chapter_IEq14.gif) As in Sect.​ 3.​10, we introduce the quantum mechanical counterpart, a "vector" ![
$$\\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq15.gif) with components that are operators,

![
$$\\displaystyle{\\mathbf{\\hat{J}} = \\mathbf{X} \\times \\mathbf{P}.}$$
](A272900_1_En_17_Chapter_Equa.gif)

Thus, for example, ![
$$\\hat{J}_{1} = X_{2}P_{3} - X_{3}P_{2}.$$
](A272900_1_En_17_Chapter_IEq16.gif) Note that each component of the angular momentum involves products of distinct components of the position and momentum operators X and P, which commute. Thus, in the expression for, say, ![
$$\\hat{J}_{3},$$
](A272900_1_En_17_Chapter_IEq17.gif) it does not matter whether we write X 2 P 3 or P 3 X 2.

The angular momentum operators are unbounded operators and are defined only on a dense subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq18.gif) For the moment, we will not specify the domain of these operators, leaving that until the next section. We will see, however, that the domain of each angular momentum operator contains the Schwartz space ![
$$\\mathcal{S}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq19.gif) (Definition A.15).

As in Exercise 10 in Chap.​ 3, we can use the canonical commutation relations to obtain ![
$$\[\\hat{J}_{1},\\hat{J}_{2}\] = i\\hslash \\hat{J}_{3}.$$
](A272900_1_En_17_Chapter_IEq20.gif) We may similarly compute ![
$$\[\\hat{J}_{2},\\hat{J}_{3}\]$$
](A272900_1_En_17_Chapter_IEq21.gif) and ![
$$\[\\hat{J}_{1},\\hat{J}_{2}\]$$
](A272900_1_En_17_Chapter_IEq22.gif) to obtain the complete set of commutation relations among the ![
$$\\hat{J}$$
](A272900_1_En_17_Chapter_IEq23.gif)'s:

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[\\hat{J}_{1},\\hat{J}_{2}\] =\\hat{ J}_{3};\\quad \\frac{1} {i\\hslash }\[\\hat{J}_{2},\\hat{J}_{3}\] =\\hat{ J}_{1};\\quad \\frac{1} {i\\hslash }\[\\hat{J}_{3},\\hat{J}_{1}\] =\\hat{ J}_{2}.}$$
](A272900_1_En_17_Chapter_Equb.gif)

These relations compare well with the Poisson bracket relations among the various components of the classical angular momentum vector (Exercise 19 in Chap.​ 2).

Writing out ![
$$\\hat{J}_{3}$$
](A272900_1_En_17_Chapter_IEq24.gif) explicitly, we have

![
$$\\displaystyle\\begin{array}{rcl} \(\\hat{J}_{3}\\psi \)\(\\mathbf{x}\)& =& -i\\hslash \\left \(x_{1} \\frac{\\partial } {\\partial x_{2}} - x_{2} \\frac{\\partial } {\\partial x_{1}}\\right\)\\psi \(\\mathbf{x}\){}\\end{array}$$
](A272900_1_En_17_Chapter_Equ1.gif)

(17.1)

![
$$\\displaystyle\\begin{array}{rcl} & -& i\\hslash \\left.\\frac{d} {d\\theta }\\psi \(R_{\\theta }\\mathbf{x\)}\\right\\vert _{\\theta =0},{}\\end{array}$$
](A272900_1_En_17_Chapter_Equ2.gif)

(17.2)

where R θ denotes a counterclockwise rotation by angle θ in the (x 1, x 2) plane, with similar expression for ![
$$\\hat{J}_{1}$$
](A272900_1_En_17_Chapter_IEq25.gif) and ![
$$\\hat{J}_{2}.$$
](A272900_1_En_17_Chapter_IEq26.gif) This description of the angular momentum operators demonstrates that they—like the components of the classical angular momentum—are closely connected to rotations (recall Propositions 2.18 and 2.30). The connection between angular momentum and rotations will be made more explicit in the following sections by recognizing that they make up the Lie algebra action associated with the natural action of the rotation group on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq27.gif)

We may define a new version of the angular momentum operators ![
$$\\tilde{J}_{j}$$
](A272900_1_En_17_Chapter_IEq28.gif), given by

![
$$\\displaystyle{ \\tilde{J}_{j} = \\frac{1} {\\hslash }\\hat{J}_{j}. }$$
](A272900_1_En_17_Chapter_Equ3.gif)

(17.3)

Since Planck's constant and angular momentum have the same units, the ![
$$\\tilde{J}_{j}$$
](A272900_1_En_17_Chapter_IEq29.gif)'s do not depend on the choice of units; we refer to them as the dimensionless versions of the angular momentum operators.

## 17.3 Angular Momentum from the Lie Algebra Point of View

We begin this section by looking at the natural action of the rotation group SO(3) on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq30.gif)

Definition 17.1

For each R ∈ SO(3), define ![
$$\\Pi \(R\) : {L}^{2}\({\\mathbb{R}}^{3}\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq31.gif) by

![
$$\\displaystyle{ \(\\Pi \(R\)\\psi \)\(x\) =\\psi \({R}^{-1}x\). }$$
](A272900_1_En_17_Chapter_Equ4.gif)

(17.4)

Proposition 17.2

For each R ∈ SO(3), the map ![
$$\\Pi \(R\) : {L}^{2}\({\\mathbb{R}}^{3}\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq32.gif) is unitary. Furthermore, the map ![
$$\\Pi : \\mathsf{SO}\(3\) \\rightarrow \\mathsf{U}\({L}^{2}\({\\mathbb{R}}^{3}\)\)$$
](A272900_1_En_17_Chapter_IEq33.gif) is a strongly continuous homomorphism.

Proof.

Since the Lebesgue measure on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq34.gif) is invariant under rotations, Π(R) is unitary for all R ∈ SO(3). It is easily checked that ![
$$\\Pi \(R_{1}R_{2}\) = \\Pi \(R_{1}\)\\Pi \(R_{2}\)$$
](A272900_1_En_17_Chapter_IEq35.gif); for this to be true, we need to have ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq03.gif)(R − 1 x) rather than ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq04.gif)(Rx) in the definition of Π(R). Arguing as in the proof of Example 10.12, we can easily verify that Π is strongly continuous.

Recall the computation of the Lie algebra so(3) of SO(3) in Sect.​ 16.​5, and the basis ![
$$\\{F_{1},F_{2},F_{3}\\}$$
](A272900_1_En_17_Chapter_IEq36.gif) for so(3) in (16.​2) in that section.

Proposition 17.3

For each X ∈ so(3), let π(X) denote the skew-self-adjoint operator such that

![
$$\\displaystyle{ \\Pi \({e}^{tX}\) = {e}^{t\\pi \(X\)}. }$$
](A272900_1_En_17_Chapter_Equ5.gif)

(17.5)

Then the domain of each π(Fj) contains the Schwartz space ![
$$\\mathcal{S}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq37.gif) and on ![
$$\\mathcal{S}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq38.gif) we have the relation

![
$$\\displaystyle{\\hat{J}_{j} = i\\hslash \\pi \(F_{j}\).}$$
](A272900_1_En_17_Chapter_Equc.gif)

In the notation of Stone's theorem (Theorem 10.15), the operator π(X) in (17.5) is i times the infinitesimal generator of the one-parameter unitary group t↦Π(e tX ).

Proof.

In the case of ![
$$\\hat{J}_{3},$$
](A272900_1_En_17_Chapter_IEq39.gif) we compute as in Example 16.16 that ![
$${e}^{tF_{3}}$$
](A272900_1_En_17_Chapter_IEq40.gif) is a counterclockwise rotation in the (x 1, x 2)-plane. If ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq05.gif) belongs to ![
$$\\mathcal{S}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq41.gif) then the limit defining the derivative in (17.2) is easily seen to hold in the L 2 sense. Thus, recalling the inverse on the right-hand side of (17.4), we see that ![
$$\\hat{J}_{3}$$
](A272900_1_En_17_Chapter_IEq42.gif) coincides with ![
$$i\\hslash \\pi \(F_{3}\),$$
](A272900_1_En_17_Chapter_IEq43.gif) as claimed. Similar calculations apply to ![
$$\\hat{J}_{1}$$
](A272900_1_En_17_Chapter_IEq44.gif) and ![
$$\\hat{J}_{2}.$$
](A272900_1_En_17_Chapter_IEq45.gif)

Although it is not easy to determine the precise domain of each angular momentum operator, we can see from Proposition 16.54 that if ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq07.gif) belongs to a finite-dimensional subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq46.gif) that is invariant under rotations, then ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq08.gif) belongs to the domain of each ![
$$\\hat{J}_{j}.$$
](A272900_1_En_17_Chapter_IEq47.gif)

## 17.4 The Irreducible Representations of so(3)

In this section, we classify the irreducible finite-dimensional representations of the Lie algebra so(3), up to isomorphism. (See Sect.​ 16.​7 for the definitions and elementary properties of representations.) All representations are taken over the field of complex numbers and assumed to have dimension at least one. We continue to use the basis ![
$$\\{F_{1},F_{2},F_{3}\\}$$
](A272900_1_En_17_Chapter_IEq48.gif) for so(3) in (16.​2).

Theorem 17.4

Let π : so(3) →gl(V ) be a finite-dimensional irreducible representation of so(3). Define operators L +, L−, and L 3 on V by

![
$$\\displaystyle\\begin{array}{rcl} {L}^{+}& =& i\\pi \(F_{ 1}\) -\\pi \(F_{2}\) {}\\\\ {L}^{-}& =& i\\pi \(F_{ 1}\) +\\pi \(F_{2}\) {}\\\\ L_{3}& =& i\\pi \(F_{3}\). {}\\\\ \\end{array}$$
](A272900_1_En_17_Chapter_Equ6.gif)

Let ![
$$l = \\frac{1} {2}\(\\dim V - 1\),$$
](A272900_1_En_17_Chapter_IEq49.gif) so that ![
$$\\dim V = 2l + 1.$$
](A272900_1_En_17_Chapter_IEq50.gif) Then there exists a basis ![
$$v_{0},v_{1},\\ldots,v_{2l}$$
](A272900_1_En_17_Chapter_IEq51.gif) of V such that

![
$$\\displaystyle\\begin{array}{rcl} L_{3}v_{j}& =& \(l - j\)v_{j} \\\\ {L}^{-}v_{ j}& =& \\left \\{\\begin{array}{cl} v_{j+1} & \\text{if }j < 2l \\\\ 0 &\\text{if }j = 2l \\end{array} \\right. \\\\ {L}^{+}v_{ j}& =& \\left \\{\\begin{array}{cl} j\(2l + 1 - j\)v_{j-1} & \\text{if }j > 0 \\\\ 0 &\\text{if }j = 0 \\end{array} \\right..{}\\end{array}$$
](A272900_1_En_17_Chapter_Equ7.gif)

(17.6)

Thus, the quantity l completely determines the structure of an irreducible representation of so(3). Since dim V is a positive integer, l has to have one of the following values:

![
$$\\displaystyle{ l = 0, \\frac{1} {2},1, \\frac{3} {2},\\ldots. }$$
](A272900_1_En_17_Chapter_Equ8.gif)

(17.7)

The proof of Theorem 17.4 is given later in this section.

Definition 17.5

If (π,V) is an irreducible finite-dimensional representation of so(3), then the spin of (π,V) is the largest eigenvalue of the operator L 3 := iπ(F 3 ). Equivalently, l is the unique number such that ![
$$\\dim V = 2l + 1.$$
](A272900_1_En_17_Chapter_IEq52.gif)

Our next result says that all the values of l in (17.7) actually arise as spins of irreducible representations of so(3).

Theorem 17.6

For any ![
$$l = 0, \\frac{1} {2},1, \\frac{3} {2},\\ldots$$
](A272900_1_En_17_Chapter_IEq53.gif) there exists an irreducible representation of so(3) of dimension 2l + 1, and any two irreducible representations of so(3) of dimension 2l + 1 are isomorphic.

Note that the theorem is only asserting the existence, for each l, of a representation of the Lie algebra so(3). As we will see in the next section, an irreducible representation π of so(3) comes from a representation Π of SO(3) if and only if l is an integer. Nevertheless, the representations of so(3) with half-integer values of l—the ones where l is half of an integer but not an integer—still play an important role in quantum physics, as discussed in Sect. 17.8. (Although it would be clearer to refer to the case ![
$$l = 1/2,3/2,5/2,\\ldots$$
](A272900_1_En_17_Chapter_IEq54.gif) as "integer plus a half," the terminology "half-integer" is firmly established.)

By comparison to Proposition 17.3, we may think of L 3 as the analog of the third component of the dimensionless angular momentum operator on the space V. Indeed, we will eventually be interested in applying Theorem 17.4 to the case in which V is a subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq55.gif) that is invariant under the action of SO(3). In that case, L 3 will be precisely (the restriction to V of) the dimensionless angular momentum operator ![
$$\\tilde{J}_{3}.$$
](A272900_1_En_17_Chapter_IEq56.gif)

Observe that Theorem 17.4 bears a strong similarity to our analysis of the quantum harmonic oscillator. In both cases, we have a "chain" of eigenvectors for a certain operator, along with raising and lowering operators that raise and lower the eigenvalue of that operator. In the case of the harmonic oscillator, we have a chain that begins with a ground state and then extends infinitely in one direction. In the case of so(3) representations, we have a chain that is finite in both directions. The chain begins with an eigenvector v 0 for L 3 with maximal eigenvalue, so that v 0 is annihilated by the raising operator L +. A key step in the proof of Theorem 17.4 is to determine how the chain can terminate (in the direction of lower eigenvalues for L 3) without violating the commutation relations among L 3, L +, and L −.

Proof of Theorem 17.4.

Since π is a Lie algebra homomorphism, the π(F j )'s satisfy the same commutation relations as the F j 's themselves. From this we can easily verify the following relations among the operators L +, L −, and L 3:

![
$$\\displaystyle{ \[L_{3},{L}^{+}\] = {L}^{+} }$$
](A272900_1_En_17_Chapter_Equ9.gif)

(17.8)

![
$$\\displaystyle{ \[L_{3},{L}^{-}\] = -{L}^{-} }$$
](A272900_1_En_17_Chapter_Equ10.gif)

(17.9)

![
$$\\displaystyle{ \[{L}^{+},{L}^{-}\] = 2L_{ 3}. }$$
](A272900_1_En_17_Chapter_Equ11.gif)

(17.10)

Now, since we are working over the algebraically closed field ![
$$\\mathbb{C},$$
](A272900_1_En_17_Chapter_IEq57.gif) the operator L 3 has at least one eigenvector v with eigenvalue λ. Consider, then, L + v. Using (17.8), we compute that

![
$$\\displaystyle{ L_{3}{L}^{+}v = \({L}^{+}L_{ 3} + {L}^{+}\)v = {L}^{+}\(\\lambda v\) + {L}^{+}v = \(\\lambda +1\){L}^{+}v. }$$
](A272900_1_En_17_Chapter_Equ12.gif)

(17.11)

Thus, either ![
$${L}^{+}v = 0$$
](A272900_1_En_17_Chapter_IEq58.gif) or L + v is an eigenvector for L 3 with eigenvalue λ \+ 1. We call L + the "raising operator," since it has the effect of raising the eigenvalue of L 3 by 1.

If we apply L + repeatedly to v, we obtain eigenvectors for L 3 with eigenvalues increasing by 1 at each step, as long as we do not get the zero vector. Eventually, though, we must get 0, since the operator L 3 has only finitely many eigenvalues. Thus, there exists k ≥ 0 such that (L +) k v≠0 but ![
$${\({L}^{+}\)}^{k+1}v = 0.$$
](A272900_1_En_17_Chapter_IEq59.gif) By applying (17.11) repeatedly, we see that (L +) k v is an eigenvector for L 3 with eigenvalue λ \+ k.

Let us now introduce the notation ![
$$v_{0} := {\({L}^{+}\)}^{k}v$$
](A272900_1_En_17_Chapter_IEq60.gif) and ![
$$\\mu =\\lambda +k.$$
](A272900_1_En_17_Chapter_IEq61.gif) Then v 0 is a nonzero vector with ![
$${L}^{+}v_{0} = 0$$
](A272900_1_En_17_Chapter_IEq62.gif) and ![
$$L_{3}v_{0} =\\mu v_{0}.$$
](A272900_1_En_17_Chapter_IEq63.gif) We now forget about the original vector v and eigenvalue λ and consider only v 0 and μ. Define vectors v j by

![
$$\\displaystyle{v_{j} = {\({L}^{-}\)}^{j}v_{ 0},\\quad j = 0,1,2,\\ldots.}$$
](A272900_1_En_17_Chapter_Equd.gif)

Arguing as in (17.11), but using (17.9) in place of (17.8), we see that L − has the effect of either lowering the eigenvalue of L 3 by 1 or of giving the zero vector. Thus, ![
$$L_{3}v_{j} = \(\\mu -j\)v_{j}.$$
](A272900_1_En_17_Chapter_IEq64.gif)

Next, we claim that for j ≥ 1 we have

![
$$\\displaystyle{ {L}^{+}v_{ j} = j\(2\\mu + 1 - j\)v_{j},\\quad j = 1,2,3,\\ldots, }$$
](A272900_1_En_17_Chapter_Equ13.gif)

(17.12)

which is easily proved by induction on j, using (17.10) (Exercise 2). Since, again, L 3 has only finitely many eigenvectors, v j must eventually be zero. Thus, there exists some N ≥ 0 such that v N ≠0 but ![
$$v_{N+1} = 0.$$
](A272900_1_En_17_Chapter_IEq65.gif) Since ![
$$v_{N+1} = 0,$$
](A272900_1_En_17_Chapter_IEq66.gif) applying (17.12) with j = N gives

![
$$\\displaystyle{0 = {L}^{+}v_{ N+1} = \(N + 1\)\(2\\mu - N\)v_{N}.}$$
](A272900_1_En_17_Chapter_Eque.gif)

Since v N ≠0 and N \+ 1 > 0, we must have ![
$$\(2\\mu - N\) = 0.$$
](A272900_1_En_17_Chapter_IEq67.gif) This means that μ must equal N ∕ 2.

Letting ![
$$l = N/2$$
](A272900_1_En_17_Chapter_IEq68.gif) and putting ![
$$\\mu = N/2 = l,$$
](A272900_1_En_17_Chapter_IEq69.gif) we have the formulas recorded in (17.6). Meanwhile, since the v j 's are eigenvectors for L 3 with distinct eigenvalues, the v j 's are automatically linearly independent. Furthermore, the span of the v j 's is invariant under L +, L −, and L 3, hence under all of so(3). Since V is assumed to be irreducible, the span of the v j 's must be all of V. Thus, the v j 's form a basis for V. The dimension of V is therefore equal to the number of v j 's, which is ![
$$N + 1 = 2l + 1.$$
](A272900_1_En_17_Chapter_IEq70.gif)

Proof of Theorem 17.6.

We construct V simply by defining a space V with basis ![
$$v_{0},v_{1},\\ldots,v_{2l}$$
](A272900_1_En_17_Chapter_IEq71.gif) and defining the action of so(3) by (17.6). It is a simple matter (Exercise 4) to check that L +, L −, and L 3, defined in this way, have the correct commutation relations, so that V is indeed a representation of so(3).

It remains to show that V is irreducible. Suppose that W is an invariant subspace of V and that W≠{0}. We need to show that W = V. To this end, suppose that w is some nonzero element of W, which we can decompose as ![
$$w =\\sum _{ j=0}^{2l}a_{j}v_{j}.$$
](A272900_1_En_17_Chapter_IEq72.gif) Let j 0 be the largest index for which a j is nonzero. According to the formula for L + in (17.6), applying L + to any of the vectors v 1,..., v 2l gives a nonzero multiple of the previous element in our chain. Thus, ![
$${\({L}^{+}\)}^{j_{0}}w$$
](A272900_1_En_17_Chapter_IEq73.gif) will be a nonzero multiple of v 0. Since W is invariant, this means that v 0 belongs to W. But then by applying L − repeatedly, we see that v j belongs to W for each j, so that W = V.

Theorem 17.4 tells us that any irreducible representation of so(3) of dimension 2l \+ 1 has a basis as in (17.6). We can then construct an isomorphism between any two irreducible representations by mapping this basis in one space to the corresponding basis in the other space.

In the rest of this section, we look at some additional properties of representations of so(3).

Proposition 17.7

Let π : so(3) →gl(V ) be an irreducible representation of so(3). Then there exists an inner product on V, unique up to multiplication by a constant, such that π(X) is skew-self-adjoint for all X ∈ so(3).

Proof.

Recalling how the operators L 3, L +, and L − are defined, we can see that the assertion that each π(X), X ∈ so(3), is skew-self-adjoint is equivalent to the assertion that L 3 is self-adjoint and that L + and L − are adjoints of each other. Since the v j 's are eigenvectors for L 3 with distinct eigenvalues, if L 3 is to be self-adjoint, the v j 's must be orthogonal. Conversely, if we have any inner product for which the v j 's are orthogonal, then L 3 will be self-adjoint, as is easily verified.

It remains to investigate the consequences of the condition ![
$${\({L}^{+}\)}^{{\\ast}} = {L}^{-}.$$
](A272900_1_En_17_Chapter_IEq74.gif) Assuming this condition, we compute that

![
$$\\displaystyle{\\left \\langle v_{j},v_{j}\\right\\rangle = \\left \\langle {L}^{-}v_{ j-1},{L}^{-}v_{ j-1}\\right\\rangle = \\left \\langle v_{j-1},{L}^{+}{L}^{-}v_{ j-1}\\right\\rangle.}$$
](A272900_1_En_17_Chapter_Equf.gif)

But ![
$${L}^{+}{L}^{-} = {L}^{-}{L}^{+} + 2L_{3}.$$
](A272900_1_En_17_Chapter_IEq75.gif) Furthermore, ![
$$L_{3}v_{j-1} = \(l - j + 1\)v_{j-1}$$
](A272900_1_En_17_Chapter_IEq76.gif) and ![
$${L}^{+}v_{j-1} = \(j - 1\)\(2l - j + 2\)v_{j-1}$$
](A272900_1_En_17_Chapter_IEq77.gif) and, thus,

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle v_{j},v_{j}\\right\\rangle & =& \\left \\langle v_{j-1},{L}^{+}{L}^{-}v_{ j-1}\\right\\rangle {}\\\\ & =& \(j - 1\)\(2l - j + 2\)\\left \\langle v_{j-1},{L}^{-}v_{ j-2}\\right\\rangle + 2\(l - j + 1\)\\left \\langle v_{j-1},v_{j-1}\\right\\rangle. {}\\\\ \\end{array}$$
](A272900_1_En_17_Chapter_Equ14.gif)

Recalling that ![
$${L}^{-}v_{j-2} = v_{j-1}$$
](A272900_1_En_17_Chapter_IEq78.gif) and simplifying gives

![
$$\\displaystyle{ \\left \\langle v_{j},v_{j}\\right\\rangle = j\(2l - j + 1\)\\left \\langle v_{j-1},v_{j-1}\\right\\rangle. }$$
](A272900_1_En_17_Chapter_Equ15.gif)

(17.13)

It is easy to see that if the v j 's are orthogonal, then L + and L − are adjoints of each other if and only if the normalization condition (17.13) holds for j = 1, 2,..., 2l. Since ![
$$j\(2l - j + 1\)$$
](A272900_1_En_17_Chapter_IEq79.gif) is positive for each such j, there is no obstruction to normalizing the v j 's so that this condition holds, and so an inner product with the desired property exists. Since the only freedom of choice in defining the inner product is the normalization of v 0, the inner product is unique up to multiplication by a constant.

Proposition 17.8

Suppose (π,V) is an irreducible representation of so(3) of dimension 2l + 1. Define the Casimir operator C π ∈ End (V) by the formula

![
$$\\displaystyle{C_{\\pi } =\\pi {\(F_{1}\)}^{2} +\\pi {\(F_{ 2}\)}^{2} +\\pi {\(F_{ 3}\)}^{2}.}$$
](A272900_1_En_17_Chapter_Equg.gif)

Then for all v ∈ V, we have

![
$$\\displaystyle{C_{\\pi }v = -l\(l + 1\)v.}$$
](A272900_1_En_17_Chapter_Equh.gif)

Proof.

See Exercise 3.

If we look at the proof of Theorem 17.4, we see that the only place in which irreducibility was used is in showing that the span of ![
$$v_{0},v_{1},\\ldots,v_{2l}$$
](A272900_1_En_17_Chapter_IEq80.gif) is equal to V. We can therefore obtain the following result, which will be used in Sect. 17.9.

Proposition 17.9

Let (π,V) be any finite-dimensional representation of so(3), not necessarily irreducible. Suppose v 0 is a nonzero element of V such that ![
$${L}^{+}v_{0} = 0$$
](A272900_1_En_17_Chapter_IEq81.gif) and ![
$$L_{3}v_{0} =\\lambda v_{0}$$
](A272900_1_En_17_Chapter_IEq82.gif) for some ![
$$\\lambda \\in \\mathbb{C}.$$
](A272900_1_En_17_Chapter_IEq83.gif) Then λ is equal to a non-negative integer or half-integer l. Furthermore, the vectors ![
$$v_{0},v_{1},\\ldots,v_{2l}$$
](A272900_1_En_17_Chapter_IEq84.gif) defined by

![
$$\\displaystyle{v_{j} = {\({L}^{-}\)}^{j}v_{ 0},\\quad j = 0,1,\\ldots,2l,}$$
](A272900_1_En_17_Chapter_Equi.gif)

span an irreducible invariant subspace of V of dimension 2l + 1, and L +, L−, and L 3 act on these vectors according to the formulas in Theorem 17.4.

In general, given a finite-dimensional representation (π, V) of a Lie algebra and a nonzero vector v 0 ∈ V, we say that v 0 is a cyclic vector for V if the smallest invariant subspace of V containing v 0 is all of V. In Proposition 17.9, the vector v 0 is certainly a cyclic vector for W : = span(v 0,..., v 2l ). It should be noted, however, that a representation's having a cyclic vector does not, in general, mean that the representation is irreducible (Exercise 5). Thus, the irreducibility of W is not the result of some general result about cyclic vectors, but holds only because of the assumed special properties of the vector v 0.

## 17.5 The Irreducible Representations of SO(3)

Having classified the irreducible representations of the Lie algebra so(3), we now turn to the classification of the representations of the group SO(3). Since SO(3) is connected (Exercise 13 in Chap.​ 16), Proposition 16.39 tells us that a representation of SO(3) is irreducible if and only if the associated Lie algebra representation is irreducible, and that two representations of SO(3) are isomorphic if and only if the associated Lie algebra representations are isomorphic. Thus, to classify the irreducible representations of SO(3) up to isomorphism, we merely have to determine which irreducible representations of the Lie algebra so(3) come from a representation of the group SO(3).

Proposition 17.10

Let π l : so(3) →gl(V ) be an irreducible representation of so(3), with spin ![
$$l := \\frac{1} {2}\(\\dim V - 1\).$$
](A272900_1_En_17_Chapter_IEq85.gif) If l is an integer (i.e., if the dimension of V is odd), then there exists a representation Π l :SO(3) → GL (V) such that Π l and π l are related as in Theorem 16.23. If l is a half-integer (i.e., if the dimension of V is even) then no such representation Π l exists.

It follows from this result and Proposition 16.39 that the irreducible representations of the group SO(3) are precisely the Π l 's for which l is an integer.

Proof.

If l is a half-integer, then L 3 is diagonal in the basis {v j }, with eigenvalues being half-integers. Thus,

![
$$\\displaystyle{{e}^{2\\pi \\pi _{l}\(F_{3}\)} = {e}^{2\\pi iL_{3} } = -I.}$$
](A272900_1_En_17_Chapter_Equj.gif)

(Here the "π" in front of π l is the number π = 3. 14....) On the other hand, by a simple modification of Example 16.16, we can see that the matrix F 3 ∈ so(3) satisfies ![
$${e}^{2\\pi F_{3}} = I.$$
](A272900_1_En_17_Chapter_IEq86.gif) Thus, if a corresponding representation Π l of SO(3) existed, we would have

![
$$\\displaystyle{\\Pi _{l}\(I\) = \\Pi _{l}\\left \({e}^{2\\pi F_{3} }\\right\) = {e}^{2\\pi \\pi _{l}\(F_{3}\)} = -I,}$$
](A272900_1_En_17_Chapter_Equk.gif)

which is a contradiction.

If l is an integer, we make use of the isomorphism ![
$$\\phi$$
](A272900_1_En_17_Chapter_IEq09.gif) between su(2) and so(3) described in the proof of Example 16.32, which maps the basis ![
$$\\{E_{1},E_{2},E_{3}\\}$$
](A272900_1_En_17_Chapter_IEq87.gif) of su(2) to the basis ![
$$\\{F_{1},F_{2},F_{3}\\}$$
](A272900_1_En_17_Chapter_IEq88.gif) of so(3). We obtain a representation π l ′ of su(2) by setting ![
$$\\pi _{l}^{{\\prime}}\(X\) =\\pi _{l}\(\\phi \(X\)\).$$
](A272900_1_En_17_Chapter_IEq89.gif) Since SU(2) is simply connected, Theorem 16.30 tell us that there is a representation Π l ′ of SU(2) related to π l ′ in the usual way. We then compute that

![
$$\\displaystyle{\\Pi _{l}^{{\\prime}}\\left \(-I\\right\) = \\Pi _{ l}^{{\\prime}}\\left \({e}^{2\\pi E_{1} }\\right\) = {e}^{2\\pi \\pi _{l}^{{\\prime}}\(E_{ 1}\)} = {e}^{2\\pi \\pi _{l}\(F_{1}\)} = {e}^{2\\pi iL_{3}} = I,}$$
](A272900_1_En_17_Chapter_Equl.gif)

since the eigenvalues of L 3 are integers.

Now, by Example 16.34, there is a surjective homomorphism Φ from SU(2) onto SO(3) for which the associated Lie algebra homomorphism is ![
$$\\phi$$
](A272900_1_En_17_Chapter_IEq010.gif), and ![
$$\\ker \\Phi =\\{ I,-I\\}.$$
](A272900_1_En_17_Chapter_IEq90.gif) Since the kernel of Π l ′ contains {I, − I}, the map Π l ′ factors through SO(3), giving a representation Π l of SO(3) such that ![
$$\\Pi _{l}^{{\\prime}} = \\Pi _{l} \\circ \\Phi.$$
](A272900_1_En_17_Chapter_IEq91.gif) By Exercise 10 in Chap.​ 16, the associated Lie algebra representation σ l of so(3) satisfies ![
$$\\pi _{l}^{{\\prime}} =\\sigma _{l}\\circ \\phi,$$
](A272900_1_En_17_Chapter_IEq92.gif) so that ![
$$\\sigma _{l} =\\pi _{ l}^{{\\prime}}{\\circ \\phi }^{-1} =\\pi _{l}.$$
](A272900_1_En_17_Chapter_IEq93.gif) Thus, Π l is the desired representation of SO(3).

## 17.6 Realizing the Representations Inside L 2(S 2)

In this section, we deviate from the traditional treatment in the physics literature by thinking of the "spherical harmonics" as restrictions to the unit sphere of certain polynomials on ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_17_Chapter_IEq94.gif) rather than describing the spherical harmonics in angular coordinates on the sphere. Our approach avoids some messy computations in polar coordinates and it also generalizes readily to higher dimensions.

Recall from Sect. 17.3 that there is a natural unitary representation ![
$$\\Pi : \\mathsf{SO}\(3\) \\rightarrow {L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq95.gif) given by ![
$$\\Pi \(R\)\\psi \(x\) =\\psi \({R}^{-1}x\).$$
](A272900_1_En_17_Chapter_IEq96.gif) In solving rotationally invariant problems such as the quantum hydrogen atom, it will be useful to understand the structure of finite-dimensional subspaces V of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq97.gif) such that V is invariant under Π and such that the restriction of Π to V is irreducible.

If we write functions on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq98.gif) in polar coordinates, then SO(3) acts only on the angle variables. Thus, it is useful to consider also the action of SO(3) on L 2(S 2), given by the same formula as for ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_17_Chapter_IEq99.gif) namely

![
$$\\displaystyle{\(\\Pi \(R\)\\psi \)\(\\mathbf{x}\) =\\psi \({R}^{-1}\\mathbf{x}\),\\quad \\mathbf{x} \\in {S}^{\\mathsf{2}}.}$$
](A272900_1_En_17_Chapter_Equm.gif)

In computing the norm for L 2(S 2), we use the surface area measure on S 2, which is invariant under the action of SO(3). Once we have found invariant subspaces inside L 2(S 2), it is a simple matter to produce invariant subspaces inside ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq100.gif) as well, as we will see in the next section.

We will be interested in this section in harmonic polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq101.gif), that is, polynomials p satisfying Δ p = 0, where Δ is the Laplacian. Since we always consider representations over ![
$$\\mathbb{C},$$
](A272900_1_En_17_Chapter_IEq102.gif) we allow these polynomials to have complex coefficients.

Definition 17.11

Let l be a non-negative integer. Define a subspace V l of L 2 (S 2 ) by setting V l equal to the space of restrictions to S 2 of harmonic polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq103.gif) that are homogeneous of degree l. Then V l is called the space of spherical harmonics of degree l.

Note that if p is a homogeneous polynomial on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq104.gif) of some degree l, then the restriction of p to S 2 is identically zero only if p itself is identically zero. After all, if p is homogeneous of degree l and zero on S 2, then

![
$$\\displaystyle{p\(\\mathbf{x}\) ={ \\left \\vert \\mathbf{x}\\right\\vert }^{l}p\\left \(\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\) = 0}$$
](A272900_1_En_17_Chapter_Equn.gif)

for all x≠0, and hence, by continuity, for all ![
$$\\mathbf{x} \\in {\\mathbb{R}}^{3}.$$
](A272900_1_En_17_Chapter_IEq105.gif) (By contrast, the nonzero, nonhomogeneous polynomial ![
$$p\(\\mathbf{x}\) := x_{1}^{2} + x_{2}^{2} + x_{3}^{2} - 1$$
](A272900_1_En_17_Chapter_IEq106.gif) is identically zero on S 2.) We are therefore free to shift back and forth between thinking of the elements of V l as functions on S 2 or as functions on ![
$${\\mathbb{R}}^{3}.$$
](A272900_1_En_17_Chapter_IEq107.gif)

It is well known that the Laplacian Δ commutes with rotations. It follows that each V l is invariant under the action of the rotation group. We will eventually see that V l is irreducible under this action.

Every homogeneous polynomial of degree 0 or 1 is harmonic. Thus, V 0 consists of the constant functions on S 2 and V 1 is spanned by the restrictions to S 2 of the functions x 1, x 2, and x 3. Meanwhile, the space of homogeneous polynomials of degree 2 is 6-dimensional, and the space of harmonic polynomials that are homogeneous of degree 2 is spanned by the following five polynomials: x 1 x 2, x 2 x 3, x 3 x 1, ![
$$x_{1}^{2} - x_{2}^{2},$$
](A272900_1_En_17_Chapter_IEq108.gif) and ![
$$x_{2}^{2} - x_{3}^{2}.$$
](A272900_1_En_17_Chapter_IEq109.gif) (The polynomial ![
$$x_{1}^{2} - x_{3}^{2}$$
](A272900_1_En_17_Chapter_IEq110.gif) is also harmonic, but it is just the sum ![
$$x_{1}^{2} - x_{2}^{2},$$
](A272900_1_En_17_Chapter_IEq111.gif) and ![
$$x_{2}^{2} - x_{3}^{2}$$
](A272900_1_En_17_Chapter_IEq112.gif).)

Theorem 17.12

The spaces V l have the following properties.

1.

Each V l has dimension 2l + 1.

2.

Each V l is invariant under the action of the rotation group and irreducible under this action.

3.

For l≠m, the spaces V l and V m are orthogonal in L 2 (S 2 ).

4.

The Hilbert space L 2 (S 2 ) decomposes as the orthogonal direct sum of the V l 's, as l ranges over the non-negative integers.

The remainder of this section will be devoted to the proof of Theorem 17.12. We proceed in a series of lemmas, along with some corollaries of those lemmas.

Lemma 17.13

Let ![
$$\\mathcal{P}$$
](A272900_1_En_17_Chapter_IEq113.gif) denote the space of polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq114.gif) with complex coefficients. There exists an inner product ![
$$\\left \\langle \\cdot,\\cdot \\right\\rangle$$
](A272900_1_En_17_Chapter_IEq115.gif) on ![
$$\\mathcal{P}$$
](A272900_1_En_17_Chapter_IEq116.gif) with the property that

![
$$\\displaystyle{\\left \\langle p,\\Delta q\\right\\rangle _{\\mathcal{P}} = \\left \\langle {x}^{2}p,q\\right\\rangle _{ \\mathcal{P}},}$$
](A272900_1_En_17_Chapter_Equo.gif)

where

![
$$\\displaystyle{{x}^{2} = x_{ 1}^{2} + x_{ 2}^{2} + x_{ 3}^{2}.}$$
](A272900_1_En_17_Chapter_Equp.gif)

Proof.

Although it is possible to give a combinatorial construction of the desired inner product, we can also give an analytic construction. Every polynomial ![
$$p$$
](A272900_1_En_17_Chapter_IEq117.gif) on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq118.gif) certainly has a holomorphic extension to ![
$${\\mathbb{C}}^{3},$$
](A272900_1_En_17_Chapter_IEq119.gif) denoted ![
$$p_{\\mathbb{C}}.$$
](A272900_1_En_17_Chapter_IEq120.gif) We may define, then,

![
$$\\displaystyle{\\left \\langle p,q\\right\\rangle _{\\mathcal{P}} =\\int _{{\\mathbb{C}}^{3}}\\overline{p_{\\mathbb{C}}\(\\mathbf{z}\)}q_{\\mathbb{C}}\(\\mathbf{z}\){\\frac{{e}^{-{\\left \\vert z\\right\\vert }^{2}/2 }} {\\pi }^{3/2}} \\ {d}^{6}z,}$$
](A272900_1_En_17_Chapter_Equq.gif)

which is nothing but the inner product of ![
$$p_{\\mathbb{C}}$$
](A272900_1_En_17_Chapter_IEq121.gif) and ![
$$q_{\\mathbb{C}}$$
](A272900_1_En_17_Chapter_IEq122.gif) as elements of the Segal–Bargmann space ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{3},\\mu _{1}\).$$
](A272900_1_En_17_Chapter_IEq123.gif) According to Lemma 14.12, we have

![
$$\\displaystyle{\\int _{{\\mathbb{C}}^{3}}\\overline{p_{\\mathbb{C}}\(\\mathbf{z}\)}\\frac{\\partial q_{\\mathbb{C}}} {\\partial z_{j}} \(\\mathbf{z}\){\\frac{{e}^{-{\\left \\vert z\\right\\vert }^{2}/2 }} {\\pi }^{3/2}} \\ {d}^{6}z =\\int _{{ \\mathbb{C}}^{3}}\\overline{z_{j}p_{\\mathbb{C}}\(\\mathbf{z}\)}q_{\\mathbb{C}}\(\\mathbf{z}\){\\frac{{e}^{-{\\left \\vert z\\right\\vert }^{2}/2 }} {\\pi }^{3/2}} \\ {d}^{6}z}$$
](A272900_1_En_17_Chapter_Equr.gif)

for all ![
$$p,q \\in \\mathcal{P}$$
](A272900_1_En_17_Chapter_IEq124.gif) and all j = 1, 2, 3. This relation means that

![
$$\\displaystyle{\\left \\langle p, \\frac{\\partial q} {\\partial x_{j}}\\right\\rangle _{\\mathcal{P}} = \\left \\langle x_{j}p,q\\right\\rangle _{\\mathcal{P}},}$$
](A272900_1_En_17_Chapter_Equs.gif)

from which we readily obtain the desired property of our inner product.

A standard bit of elementary combinatorics shows that the number of ordered triples ![
$$\(l_{1},l_{2},l_{3}\)$$
](A272900_1_En_17_Chapter_IEq125.gif) with ![
$$l_{1} + l_{2} + l_{3} = l$$
](A272900_1_En_17_Chapter_IEq126.gif) is equal to ![
$$\(l + 2\)\(l + 1\)/2.$$
](A272900_1_En_17_Chapter_IEq127.gif) Since the monomials ![
$$x_{1}^{l_{1}}x_{2}^{l_{2}}x_{3}^{l_{3}}$$
](A272900_1_En_17_Chapter_IEq128.gif) with ![
$$l_{1} + l_{2} + l_{3} = l$$
](A272900_1_En_17_Chapter_IEq129.gif) form a basis for ![
$$\\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq130.gif), we have ![
$$\\dim \\mathcal{P}_{l} = \(l + 2\)\(l + 1\)/2.$$
](A272900_1_En_17_Chapter_IEq131.gif)

Corollary 17.14

If ![
$$\\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq132.gif) denotes the space of polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq133.gif) that are homogeneous of degree l, then the Laplacian Δ maps ![
$$\\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq134.gif) onto ![
$$\\mathcal{P}_{l-2}$$
](A272900_1_En_17_Chapter_IEq135.gif) for all l ≥ 2. Thus, for all l ≥ 2, we have

![
$$\\displaystyle\\begin{array}{rcl} \\dim V _{l}& =& \\dim \\mathcal{P}_{l} -\\dim \\mathcal{P}_{l-2} {}\\\\ & =& \\frac{\(l + 2\)\(l + 1\)} {2} -\\frac{l\(l - 1\)} {2} {}\\\\ & =& 2l + 1. {}\\\\ \\end{array}$$
](A272900_1_En_17_Chapter_Equ16.gif)

Proof.

Let us equip the finite-dimensional spaces ![
$$\\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq136.gif) and ![
$$\\mathcal{P}_{l-2}$$
](A272900_1_En_17_Chapter_IEq137.gif) with the inner product from Lemma 17.13. It is easy to see that the statement, "The orthogonal complement of the image is the kernel of the adjoint," applies to linear maps of one finite-dimensional inner product space to another. Applying this to ![
$$\\Delta : \\mathcal{P}_{l} \\rightarrow \\mathcal{P}_{l-2},$$
](A272900_1_En_17_Chapter_IEq138.gif) we note that the adjoint of Δ is multiplication by x 2, which is clearly injective, since ![
$$x_{1}^{2} + x_{2}^{2} + x_{3}^{2}$$
](A272900_1_En_17_Chapter_IEq139.gif) is zero only at the origin. Thus, the orthogonal complement of the image of Δ is {0}. Since the spaces are finite-dimensional, this means that Δ maps ![
$$\\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq140.gif) onto ![
$$\\mathcal{P}_{l-2}.$$
](A272900_1_En_17_Chapter_IEq141.gif)

Corollary 17.15

Let l be a non-negative integer and let ![
$$k = l/2$$
](A272900_1_En_17_Chapter_IEq142.gif) if l is even and let ![
$$k = \(l - 1\)/2$$
](A272900_1_En_17_Chapter_IEq143.gif) if l is odd. Then each ![
$$p \\in \\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq144.gif) can be decomposed in the form

![
$$\\displaystyle{p\(\\mathbf{x}\) = p_{0}\(\\mathbf{x}\) +{ \\left \\vert \\mathbf{x}\\right\\vert }^{2}p_{ 1}\(\\mathbf{x}\) +{ \\left \\vert \\mathbf{x}\\right\\vert }^{4}p_{ 2}\(\\mathbf{x}\) + \\cdots +{ \\left \\vert \\mathbf{x}\\right\\vert }^{2k}p_{ k}\(\\mathbf{x}\),}$$
](A272900_1_En_17_Chapter_Equt.gif)

where each ![
$$p_{j}\(\\mathbf{x}\)$$
](A272900_1_En_17_Chapter_IEq145.gif) is a harmonic polynomial that is homogeneous of degree l − 2j. In particular, the restriction of p to S 2 satisfies

![
$$\\displaystyle{\\left.p\\right\\vert _{{S}^{2}} = \\left.\\left \(p_{0} + p_{1} + \\cdots + p_{k}\\right\)\\right\\vert _{{S}^{2}},}$$
](A272900_1_En_17_Chapter_Equu.gif)

where ![
$$p_{0} + p_{1} + \\cdots + p_{k}$$
](A272900_1_En_17_Chapter_IEq146.gif) is a (nonhomogeneous) harmonic polynomial.

Given any polynomial p, not necessarily homogeneous, we can apply Corollary 17.15 to each homogeneous piece of p. We see, then, that given any polynomial p, there exists a harmonic polynomial ![
$$\\tilde{p}$$
](A272900_1_En_17_Chapter_IEq147.gif) such that p and ![
$$\\tilde{p}$$
](A272900_1_En_17_Chapter_IEq148.gif) have the same restriction to S 2.

Proof.

We proceed by induction on l. If l = 0 or l = 1, then all ![
$$p \\in \\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq149.gif) are harmonic and the desired decomposition is simply p = p 0. Consider, then, some l ≥ 2 and assume the result holds for all degrees less than l. Lemma 17.13 tells us that ![
$$\\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq150.gif) decomposes as an orthogonal direct sum of the kernel of Δ and the image of ![
$$\\mathcal{P}_{l-2}$$
](A272900_1_En_17_Chapter_IEq151.gif) under multiplication by ![
$${\\left \\vert \\mathbf{x}\\right\\vert }^{2}.$$
](A272900_1_En_17_Chapter_IEq152.gif) Thus, any ![
$$p \\in \\mathcal{P}_{l}$$
](A272900_1_En_17_Chapter_IEq153.gif) can be decomposed as ![
$$p = p_{0} +{ \\left \\vert \\mathbf{x}\\right\\vert }^{2}q_{0},$$
](A272900_1_En_17_Chapter_IEq154.gif) where p 0 is harmonic and q 0 belongs to ![
$$\\mathcal{P}_{l-2}.$$
](A272900_1_En_17_Chapter_IEq155.gif) By induction, q 0 has a decomposition of the desired form; substituting this in for q 0 in the decomposition ![
$$p = p_{0} +{ \\left \\vert \\mathbf{x}\\right\\vert }^{2}q_{0}$$
](A272900_1_En_17_Chapter_IEq156.gif) gives the desired decomposition of p.

To show that V l is irreducible under the action Π of SO(3), we pass to the Lie algebra. Since, as we have remarked, restriction to the sphere is injective on homogeneous polynomials, we may think of the elements of V j as polynomials on ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_17_Chapter_IEq157.gif) in which case, the Lie algebra action π associated with Π is given in terms of the usual angular momentum operators.

Lemma 17.16

As in Theorem 17.4 , let ![
$$L_{3} = i\\pi \(F_{3}\) =\\tilde{ J}_{3}$$
](A272900_1_En_17_Chapter_IEq158.gif) and let ![
$${L}^{+} = i\\pi \(F_{1}\) -\\pi \(F_{2}\) =\\tilde{ J}_{1} + i\\tilde{J}_{2}.$$
](A272900_1_En_17_Chapter_IEq159.gif) For any non-negative integer l, the polynomial ![
$$p\(x_{1},x_{2},x_{3}\) := {\(x_{1} + ix_{2}\)}^{l}$$
](A272900_1_En_17_Chapter_IEq160.gif) belongs to V l and satisfies

![
$$\\displaystyle{L_{3}p = lp}$$
](A272900_1_En_17_Chapter_Equv.gif)

and

![
$$\\displaystyle{{L}^{+}p = 0.}$$
](A272900_1_En_17_Chapter_Equw.gif)

Proof.

Since it is independent of x 3 and holomorphic as a function of ![
$$z := x_{1} + ix_{2},$$
](A272900_1_En_17_Chapter_IEq161.gif) the polynomial p is automatically harmonic, which can also be verified by direct calculation. Meanwhile, applying L 3 to p gives

![
$$\\displaystyle\\begin{array}{rcl} & -& i\\left \(x_{1} \\frac{\\partial } {\\partial x_{2}} - x_{2} \\frac{\\partial } {\\partial x_{1}}\\right\){\(x_{1} + ix_{2}\)}^{l} {}\\\\ & =& -i\\left \[x_{1}l{\(x_{1} + ix_{2}\)}^{l-1}\(i\) - x_{ 2}l{\(x_{1} + ix_{2}\)}^{l-1}\\right\] {}\\\\ & =& l{\(x_{1} + ix_{2}\)}^{l}. {}\\\\ \\end{array}$$
](A272900_1_En_17_Chapter_Equ17.gif)

Finally, applying ![
$${L}^{+} := i\\pi \(F_{1}\) -\\pi \(F_{2}\)$$
](A272900_1_En_17_Chapter_IEq162.gif) to p gives

![
$$\\displaystyle\\begin{array}{rcl} & -& i\\left \(x_{2} \\frac{\\partial } {\\partial x_{3}} - x_{3} \\frac{\\partial } {\\partial x_{2}}\\right\)p + \\left \(x_{3} \\frac{\\partial } {\\partial x_{1}} - x_{1} \\frac{\\partial } {\\partial x_{3}}\\right\)p {}\\\\ & =& -i\(-x_{3}l{\(x_{1} + ix_{2}\)}^{l-1}\(i\)\) + x_{ 3}l{\(x_{1} + ix_{2}\)}^{l-1}\(1\) {}\\\\ & =& 0, {}\\\\ \\end{array}$$
](A272900_1_En_17_Chapter_Equ18.gif)

as claimed.

Corollary 17.17

The space V l is irreducible under the action of SO(3).

Proof.

By Proposition 17.9, if we apply L − repeatedly to the polynomial p, we obtain a "chain" of eigenvectors of length 2l \+ 1. These eigenvectors span an irreducible invariant subspace of dimension 2l \+ 1. Since we have already established that ![
$$\\dim V _{l} = 2l + 1,$$
](A272900_1_En_17_Chapter_IEq163.gif) the elements of the chain must span V l , which implies that V l is irreducible.

We have now assembled all the pieces necessary for a proof of the main result of this section.

Proof of Theorem 17.12.

We have already proved Points 1 and 2 of the theorem in Corollaries 17.14 and 17.17, respectively. Now, each V l is an irreducible representation of SO(3), and no two of the V l 's can be isomorphic, because they all have different dimensions. Thus, by Exercise 19 in Chap.​ 16, V l and V m must be orthogonal inside L 2(S 2) for l≠m, which is Point 3.

Finally, by the Stone–Weierstrass theorem and the density results of Theorem A.10, the restrictions to S 2 of polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq164.gif) form a dense subspace of L 2(S 2). But Corollary 17.15 shows that the space of restrictions to S 2 of polynomials coincides with the space of restrictions to S 2 of harmonic polynomials. Thus, the span of the V j 's is dense in L 2(S 2), establishing Point 4.

## 17.7 Realizing the Representations Inside ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq165.gif)

Recall that for homogeneous polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq166.gif), the restriction map from ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq167.gif) to S 2 is injective. Thus, we may think of the space ![
$$V _{l}$$
](A272900_1_En_17_Chapter_IEq168.gif) equally well as a space of functions on S 2 (as in the previous section) or as a space of functions on ![
$${\\mathbb{R}}^{3}.$$
](A272900_1_En_17_Chapter_IEq169.gif) In this section, then, we will let V l denote the space of harmonic polynomials on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq170.gif) that are homogeneous of degree l.

Definition 17.18

Suppose l is a non-negative integer and f is a measurable function on (0, ∞) such that

![
$$\\displaystyle{ \\int _{0}^{\\infty }{\\left \\vert f\(r\)\\right\\vert }^{2}{r}^{2l+2}\\ dr < \\infty. }$$
](A272900_1_En_17_Chapter_Equ19.gif)

(17.14)

Let ![
$$V _{l,f} \\subset {L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq171.gif) denote the space of functions ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq011.gif) of the form

![
$$\\displaystyle{ \\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \), }$$
](A272900_1_En_17_Chapter_Equ20.gif)

(17.15)

where p ∈ V l.

The condition on f(r) is precisely what one needs to make ![
$$\\psi \(\\mathbf{x}\)$$
](A272900_1_En_17_Chapter_IEq172.gif) a square-integrable function on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq173.gif) (compute the L 2 norm in spherical coordinates).

Definition 17.18 is not the one that physicists typically use. In the physics literature, one sees a functions of the form

![
$$\\displaystyle{ \\psi \(\\mathbf{x}\) = Y _{lm}\(\\theta,\\phi \)g\(r\), }$$
](A272900_1_En_17_Chapter_Equ21.gif)

(17.16)

where r, θ, and ![
$$\\phi$$
](A272900_1_En_17_Chapter_IEq012.gif) are the usual spherical coordinates. Here Y lm is the restriction to the sphere of a particular harmonic polynomial that is homogeneous of degree l, written in spherical coordinates. (Up to a normalization factor, the Y lm 's are obtained by using the basis for V l in Theorem 17.4.) Thus, if we move along a ray from the origin in ![
$${\\mathbb{R}}^{3},$$
](A272900_1_En_17_Chapter_IEq174.gif) only the value of g(r) changes. By contrast, in (17.15), as we move along a ray, the p(x) factor contributes a factor of r l . We can write the physics expression in rectangular coordinates as

![
$$\\displaystyle\\begin{array}{rcl} \\psi \(\\mathbf{x}\)& =& Y _{lm}\\left \(\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\)g\(\\left \\vert \\mathbf{x}\\right\\vert \) \\\\ & =& Y _{lm}\(\\mathbf{x}\)\\frac{g\(\\left \\vert \\mathbf{x}\\right\\vert \)} {{\\left \\vert \\mathbf{x}\\right\\vert }^{l}}.{}\\end{array}$$
](A272900_1_En_17_Chapter_Equ22.gif)

(17.17)

For computational purposes, the expression (17.15) is more convenient than (17.17); in fact, in the analysis of the hydrogen atom, physicists multiply by r l at some later point in the calculation, just so that the relevant differential equation will take on a simpler form.

Proposition 17.19

Every space of the form ![
$$V _{l,f} \\subset {L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq175.gif) is invariant and irreducible under the action of SO(3). Conversely, every finite-dimensional, irreducible, SO(3)-invariant subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq176.gif) is of the form V l,f for some non-negative integer l and some f satisfying (17.14).

Proof.

Since the factor ![
$$f\(\\left \\vert \\mathbf{x}\\right\\vert \)$$
](A272900_1_En_17_Chapter_IEq177.gif) is invariant under rotations, the action of SO(3) only affects the function p. Thus, V l, f is isomorphic, as a representation of SO(3), to the space V l , which is irreducible by Theorem 17.12.

For the other direction, the Lebesgue measure on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq178.gif) decomposes as a product of the surface area measure on S 2 with the measure 4π r 2 dr on (0, ∞). Thus, by a standard measure-theoretic result (Proposition 19.12), ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq179.gif) decomposes canonically as the Hilbert tensor product of L 2(S 2) and L 2((0, ∞)), where a vector of the form f ⊗ g in the tensor product corresponds to the function f(θ, ![
$$\\phi$$
](A272900_1_En_17_Chapter_IEq013.gif))g(r) in ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_17_Chapter_IEq180.gif) as in (17.16). Since L 2(S 2) decomposes (Theorem 17.12) as the sum of the spaces V l , l = 0, 1, 2,..., we can decompose ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq181.gif) as sum of spaces of the form

![
$$\\displaystyle{V _{l,k} := V _{l} \\otimes g_{k},}$$
](A272900_1_En_17_Chapter_Equx.gif)

where the g k 's form an orthonormal basis for L 2((0, ∞)).

Now, let V be any finite-dimensional, irreducible, SO(3)-invariant subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq182.gif) Let ![
$$\\pi _{l,k} : {L}^{2}\({\\mathbb{R}}^{3}\) \\rightarrow V _{l,k}$$
](A272900_1_En_17_Chapter_IEq183.gif) be the orthogonal projection operator, and let ρ l, k be the restriction of π l, k to V. This map is easily seen to be an intertwining map for the action of SO(3). Thus, since both V and V l, k are irreducible, Schur's lemma tells us that each ρ l, k is either zero or an isomorphism. Furthermore, since the spaces V l, k are nonisomorphic for different values of l, we cannot have both ρ k, l and ![
$$\\rho _{{k}^{{\\prime}},{l}^{{\\prime}}}$$
](A272900_1_En_17_Chapter_IEq184.gif) being nonzero for l≠l ′ . On the other hand, ρ k, l cannot be zero for all k and l, since the V k, l 's span ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq185.gif) Thus, there must be some value l 0 of l such that ![
$$\\rho _{l_{0},k_{0}}$$
](A272900_1_En_17_Chapter_IEq186.gif) is nonzero for some k 0 but such that ρ l, k = 0 for all l≠l 0.

Applying Schur's lemma again, we see that ![
$$\\rho _{l_{0},k}{\(\\rho _{l_{0},k_{0}}\)}^{-1}$$
](A272900_1_En_17_Chapter_IEq187.gif) must be of the form c k I for each k. Given any ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq015.gif) ∈ V, let v be the unique element of V such that ![
$$\\rho _{l_{0},k_{0}}\(\\psi \) = v \\otimes g_{k_{0}}.$$
](A272900_1_En_17_Chapter_IEq188.gif) Then we have

![
$$\\displaystyle{\\rho _{l_{0},k}\(\\psi \) = c_{k}\(v \\otimes g_{k}\)}$$
](A272900_1_En_17_Chapter_Equy.gif)

for every k. Since also ρ l, k (![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq018.gif)) = 0 for l≠l 0, we conclude that ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq022.gif) must be of the form v ⊗ g, where

![
$$\\displaystyle{g =\\sum _{k}c_{k}g_{k}.}$$
](A272900_1_En_17_Chapter_Equz.gif)

Since this holds for each ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq020.gif) ∈ V (with the same set of constants c k ), we see that ![
$$V = V _{l_{0}} \\otimes g,$$
](A272900_1_En_17_Chapter_IEq189.gif) which is nothing but the form in (17.16). Then V is of the form claimed in the proposition, where ![
$$f\(r\) = g\(r\)/{r}^{l_{0}}.$$
](A272900_1_En_17_Chapter_IEq190.gif)

It can further be shown that each closed, SO(3)-invariant subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq191.gif) decomposes as an orthogonal direct sum of finite-dimensional, irreducible, SO(3)-invariant subspaces. This result is just a special case of a general result for strongly continuous unitary representations of compact topological groups. (See, e.g., Chap.​ 5 of [10].) Since we already know that ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq192.gif) is a direct sum of finite-dimensional, irreducible invariant subspaces, it is probably possible to give an elementary proof of this result, but we will not pursue that approach here.

## 17.8 Spin

We classified irreducible finite-dimensional representations of the Lie algebra so(3) by their "spin" l, where l is the largest eigenvalue for the operator L 3 = i π(F 3). The possible values for l are non-negative integers (0, 1, 2,...) and the positive half-integers (![
$$1/2,3/2,\\ldots$$
](A272900_1_En_17_Chapter_IEq193.gif)). Inside L 2(S 2) and ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_17_Chapter_IEq194.gif) however, we found only irreducible representations of so(3) with integer spin. It is easy to understand why the half-integer spin representations do not occur: They do not correspond to any representation of the group SO(3). Since L 2(S 2) and ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq195.gif) both carry a natural unitary action Π of the group SO(3), any finite-dimensional subspace that is invariant under the associated Lie algebra representation π will also be invariant under Π and thus constitute a representation of SO(3).

Although the half-integer representations π l of the Lie algebra so(3) cannot be exponentiated to representations of SO(3), they can be exponentiated to representations of the universal cover SU(2) of SO(3), as in the proof of Proposition 17.10. For a half-integer l, the associated representation Π l ′ of SU(2) satisfies ![
$$\\Pi _{l}^{{\\prime}}\(-I\) = -I,$$
](A272900_1_En_17_Chapter_IEq196.gif) which means that Π l ′ does not factor through ![
$$\\mathsf{SO}\(3\)\\mathop{\\cong}\\mathsf{SU}\(2\)/\\{I,-I\\}.$$
](A272900_1_En_17_Chapter_IEq197.gif) If, however, we think about projective representations, we see that [ − I] is the identity element in PU(V). Thus, even when l is a half-integer, we get a well-defined projective representation Π l of SO(3) that satisfies

![
$$\\displaystyle{\\Pi _{l}\({e}^{tX}\) = \[{e}^{t\\pi _{l}\(X\)}\]}$$
](A272900_1_En_17_Chapter_Equaa.gif)

for all X ∈ so(3), where [U] denotes the image of U ∈ U(V) in PU(V).

It is generally believed that the physics of the universe is invariant under the rotation group SO(3). This does not mean that one never considers models without rotational symmetry, because the local environment of, say, a hydrogen atom in a magnetic field breaks the rotational symmetry of the hydrogen atom. Nevertheless, if we were to rotation both the hydrogen atom and the magnetic field, the physics of the problem would not change. In quantum mechanics, rotational symmetry means that there should be a projective unitary representation of SO(3) on the Hilbert space of the universe that commutes with the Hamiltonian operator. Now, the Hilbert space of the universe (if there is such a thing) is built up out of Hilbert spaces for each type of particle. Thus, we expect that the Hilbert space for a single particle will also carry a projective unitary representation of SO(3).

The simplest possibility for the Hilbert space of a single particle is the Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_17_Chapter_IEq198.gif) which certainly carries an (ordinary) unitary action of SO(3), as we have been discussing in this chapter. Based on various experimental observations, however, physicists have proposed a modification to the Hilbert space for an individual particle that incorporates "internal degrees of freedom." The proposal is that for each type of particle, the quantum Hilbert space should be of the form ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V,$$
](A272900_1_En_17_Chapter_IEq199.gif) where V is a finite-dimensional Hilbert space that carries an irreducible projective unitary representation of SO(3). Here ![
$$\\hat{\\otimes }$$
](A272900_1_En_17_Chapter_IEq200.gif) is the Hilbert tensor product (Appendix A.4.5). The (projective) action of SO(3) on V describes the action of the rotation group on the internal degrees of freedom of the particle.

Now, according to Proposition 16.46, the space V carries a (trace-zero) ordinary representation π of the Lie algebra so(3). In customary physics terminology, the largest eigenvalue l of the operator L 3 : = i π(F 3) in V is then called the spin of the particle. We then denote the space V by V l to indicate the value of the spin. Electrons, for example, are "spin 1/2" particles, meaning that the Hilbert space for a single electron is ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{1/2},$$
](A272900_1_En_17_Chapter_IEq201.gif) where V 1 ∕ 2 is a two-dimensional projective representation of SO(3).

It is easy to see that the tensor product of two projective unitary representations of a given group is again a projective unitary representation of that group. (By contrast, the direct sum of two projective unitary representations is in general not again a projective unitary representation.) In the case at hand, we can think of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq202.gif) as carrying a unitary representation Π of SU(2) that factors through SO(3), that is, for which ![
$$\\Pi \(-I\) = I.$$
](A272900_1_En_17_Chapter_IEq203.gif) Meanwhile, we can think of V l as a carrying a unitary representation Π l of SU(2) in which ![
$$\\Pi _{l}\(-I\) = \\pm I,$$
](A272900_1_En_17_Chapter_IEq204.gif) with the plus sign if l is an integer and the minus sign if l is a half-integer. Thus, ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{l}$$
](A272900_1_En_17_Chapter_IEq205.gif) carries a unitary representation Π ⊗ Π l of SU(2) in which ![
$$\(\\Pi \\otimes \\Pi _{l}\)\(-I\) = \\pm I.$$
](A272900_1_En_17_Chapter_IEq206.gif) Thus, in the projective sense, Π ⊗ Π l factors through SO(3).

Summary 17.20 (Spin)

Each type of particle has a "spin" l, which is a non-negative integer or half-integer. The Hilbert space for such a particle is ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{l},$$
](A272900_1_En_17_Chapter_IEq207.gif) where V l is an irreducible projective representation of SO(3) of dimension 2l + 1.

Since V l is finite dimensional, the Hilbert tensor product ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{l}$$
](A272900_1_En_17_Chapter_IEq208.gif) coincides with the algebraic tensor product of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq209.gif) with V l .

Definition 17.21

A particle for which the spin is an integer is called a boson, and a particle for which the spin is a half-integer is called a fermion.

To see the significance of the distinction between integer and half-integer spin, one needs to look at the structure of the Hilbert space describing multiple particles of a given type, such as the Hilbert space for five electrons. This topic is discussed in Chap.​ 19.

## 17.9 Tensor Products of Representations: "Addition of Angular Momentum"

Let V l and V m be irreducible representations of so(3) with dimensions 2l \+ 1 and 2m \+ 1, respectively. As discussed in Sect.​ 16.​8, the tensor product space V l ⊗ V m can be viewed as another representation of so(3). Unless one of l and m is zero, V l ⊗ V m is not irreducible. It is of interest, then, to decompose V l ⊗ V m as a direct sum of irreducible invariant subspaces. This decomposition—in the case that V l is an irreducible SO(3)-invariant subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq210.gif) and V m is the space of internal degrees of freedom of a particle—will help us in decomposing the Hilbert space for a particle with spin into irreducible, SO(3)-invariant subspaces.

Proposition 17.22

Let V 1∕2 be an irreducible representation of so(3) of dimension 2, and let V l be an irreducible representation of so(3) of dimension 2l + 1, where l is a non-negative integer or half-integer. If l = 0, V l ⊗ V 1∕2 is irreducible. If l > 0, then we have

![
$$\\displaystyle{V _{l} \\otimes V _{1/2}\\mathop{\\cong}V _{l+1/2} \\oplus V _{l-1/2},}$$
](A272900_1_En_17_Chapter_Equab.gif)

where "≅" denotes an isomorphism of representations.

Proof.

If l = 0, then it is easy to see that V l ⊗ V 1 ∕ 2 is isomorphic to V 1 ∕ 2, which is irreducible. Assume, then, that l > 0.

Let L +, L −, and L 3 be the operators in Theorem 17.4, constructed using the representation π l , and let σ +, σ −, and σ 3 be the analogous operators constructed using the representation π 1 ∕ 2. As in Sect.​ 16.​8, we define operators J +, J −, and J 3 on V l ⊗ V 1 ∕ 2 by

![
$$\\displaystyle\\begin{array}{rcl} {J}^{+}& =& {L}^{+} \\otimes I + I {\\otimes \\sigma }^{+} \\\\ {J}^{-}& =& {L}^{-}\\otimes I + I {\\otimes \\sigma }^{-} \\\\ J_{3}& =& L_{3} \\otimes I + I \\otimes \\sigma _{3}.{}\\end{array}$$
](A272900_1_En_17_Chapter_Equ23.gif)

(17.18)

Let {v 0,..., v 2l } be a basis for V l as in Theorem 17.4, and let {e 0, e 1} be a similar basis for V 1 ∕ 2. Then the vectors of the form v j ⊗ e k form a basis for V l ⊗ V 1 ∕ 2. The eigenvalues of J 3 are the numbers of the form

![
$$\\displaystyle{\(l - j\) + \\left \(\\frac{1} {2} - k\\right\),}$$
](A272900_1_En_17_Chapter_Equac.gif)

j = 0, 1,..., 2l, k = 0, 1. Thus, the eigenvalues of J 3 range from ![
$$l + 1/2$$
](A272900_1_En_17_Chapter_IEq211.gif) to ![
$$-\(l + 1/2\).$$
](A272900_1_En_17_Chapter_IEq212.gif) The numbers ![
$$l + 1/2$$
](A272900_1_En_17_Chapter_IEq213.gif) and ![
$$-\(l + 1/2\)$$
](A272900_1_En_17_Chapter_IEq214.gif) occur as eigenvalues only once. All other eigenvalues λ occur twice, once as ![
$$\(\\lambda -1/2\) + 1/2$$
](A272900_1_En_17_Chapter_IEq215.gif) and once as ![
$$\(\\lambda +1/2\) - 1/2.$$
](A272900_1_En_17_Chapter_IEq216.gif)

The vector v 0 ⊗ e 0 is an eigenvector for J 3 with the largest possible eigenvalue ![
$$l + 1/2$$
](A272900_1_En_17_Chapter_IEq217.gif), so that ![
$${J}^{+}\(v_{0} \\otimes e_{0}\) = 0.$$
](A272900_1_En_17_Chapter_IEq218.gif) According to Proposition 17.9, if we apply J − repeatedly, we will obtain a "chain" of eigenvectors of length 2l \+ 2, and the span of these vectors forms an irreducible invariant subspace W 0 isomorphic to ![
$$V _{l+1/2}.$$
](A272900_1_En_17_Chapter_IEq219.gif)

Now, by Proposition 17.7, there exist inner products on V l and V 1 ∕ 2 that make π l and π 1 ∕ 2 "unitary," meaning that ![
$$\\pi {\(X\)}^{{\\ast}} = -\\pi \(X\)$$
](A272900_1_En_17_Chapter_IEq220.gif) for all X ∈ so(3). If we use on V l ⊗ V 1 ∕ 2 the natural inner product, obtained from the inner products on V l and V 1 ∕ 2 as in Appendix A.4.5, then π l ⊗ π 1 ∕ 2 is also unitary. Thus, the orthogonal complement of the invariant subspace W 0 is also invariant. Since all eigenvalues for J 3 except the largest and smallest have multiplicity 2, we see that the largest eigenvalue for J 3 in W 0 ⊥ is ![
$$l - 1/2.$$
](A272900_1_En_17_Chapter_IEq221.gif) Let ![
$$w_{0} \\in W_{0}^{\\perp }$$
](A272900_1_En_17_Chapter_IEq222.gif) be an eigenvector for J 3 with eigenvalue ![
$$l - 1/2.$$
](A272900_1_En_17_Chapter_IEq223.gif) If we repeatedly apply the lowering operator ![
$${J}^{-} : {L}^{-}\\otimes I + I {\\otimes \\sigma }^{-}$$
](A272900_1_En_17_Chapter_IEq224.gif) to w 0, we will obtain a chain of eigenvectors of length 2l. These eigenvectors span an irreducible invariant subspace W 1 of V l ⊗ V 1 ∕ 2 of dimension 2l. Since

![
$$\\displaystyle{\\dim W_{0} +\\dim W_{1} = 4l + 2 =\\dim \(V _{l} \\otimes V _{1/2}\),}$$
](A272900_1_En_17_Chapter_Equad.gif)

we must have ![
$$W_{1} = W_{0}^{\\perp },$$
](A272900_1_En_17_Chapter_IEq225.gif) completing the proof.

Since an electron is a "spin 1/2" particle, the Hilbert space for a single electron is, according to Sect. 17.8, ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{1/2},$$
](A272900_1_En_17_Chapter_IEq226.gif) where V 1 ∕ 2 is an irreducible projective unitary representation of SO(3) of dimension 2. Meanwhile, in Sect. 17.7, we saw how to find irreducible, SO(3)-invariant subspaces V l, f of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq227.gif) of dimension 2l \+ 1, for l = 0, 1, 2,..., where f is an arbitrary radial function. By applying Proposition 17.22 to the case V l = V l, f , we obtain irreducible SO(3)-invariant subspaces of the Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{1/2}.$$
](A272900_1_En_17_Chapter_IEq228.gif) Finding such subspaces is essential in, for example, analyzing the fine structure of the hydrogen atom.

In the case that V l is an SO(3)-invariant subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_17_Chapter_IEq229.gif) the formula for, say, the operator J 3 in (17.18) 17.22 is written in the physics literature as

![
$$\\displaystyle{ J_{3} = L_{3} +\\sigma _{3}, }$$
](A272900_1_En_17_Chapter_Equ24.gif)

(17.19)

where it is understood that L 3 acts on the first factor in the tensor product and σ 3 acts on the second factor. (That is to say, the tensor product with the identity operator is understood and thus not written.) Here L 3 is the ordinary angular momentum operator and σ 3 describes the action of the basis element F 3 ∈ so(3) on the space V 1 ∕ 2. Formulas such as (17.19) account for the physics terminology "addition of angular momentum" to describe the analysis of tensor products of representations of so(3). In this context, the operator L 3 ( = L 3 ⊗ I) is called an orbital angular momentum operator, and the operator σ 3 ( = I ⊗ σ 3) is called a spin angular momentum operator, and similarly for L ± and σ ±.

We now record the general result for tensor products of irreducible representations of so(3).

Proposition 17.23

For any ![
$$j = 0,1/2,1,\\ldots,$$
](A272900_1_En_17_Chapter_IEq230.gif) let V j denote the unique irreducible representation of so(3) of dimension 2j + 1. Then for any l and m with l ≥ m, we have

![
$$\\displaystyle{ V _{l} \\otimes V _{m}\\mathop{\\cong}V _{l+m} \\oplus V _{l+m-1} \\oplus \\cdots \\oplus V _{l-m+1} \\oplus V _{l-m}. }$$
](A272900_1_En_17_Chapter_Equ25.gif)

(17.20)

The proof of this result is similar to that of Proposition 17.22, and is omitted; see Theorem D.1 in Appendix D of [21]. An important property of this decomposition is that each irreducible representation that occurs on the right-hand side of (17.20) occurs only once. This property of the representations of so(3) is the key idea in the proof of the Wigner–Eckart theorem. See Appendix D of [21] for details.

## 17.10 Vectors and Vector Operators

Definition 17.24

A function ![
$$\\mathbf{c} : {\\mathbb{R}}^{3} \\times {\\mathbb{R}}^{3} \\rightarrow {\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq231.gif) is said to transform like a vector if

![
$$\\displaystyle{ \\mathbf{c}\(R\\mathbf{x},R\\mathbf{p}\) = R\(\\mathbf{c}\(\\mathbf{x},\\mathbf{p}\)\) }$$
](A272900_1_En_17_Chapter_Equ26.gif)

(17.21)

for all R ∈ SO(3).

In the physics literature, the expression "is a vector" is sometimes used in place of "transforms like a vector."

Note that in Definition 17.24, we only consider the transformation property of c under elements of SO(3) rather than under a general element of O(3). If c transforms like a vector, one says that c is an "true vector" if c satisfies (17.21) for all R in O(3) [not just in SO(3)] and one says that c is a "pseudovector" if c satisfies ![
$$\\mathbf{c}\(R\\mathbf{x},R\\mathbf{p}\) = -R\(\\mathbf{c}\(\\mathbf{x},\\mathbf{p}\)\)$$
](A272900_1_En_17_Chapter_IEq232.gif) for ![
$$R \\in \\mathsf{O}\(3\)\\setminus \\mathsf{SO}\(3\).$$
](A272900_1_En_17_Chapter_IEq233.gif) For our purposes, it is not necessary to distinguish between true vectors and pseudovectors.

The position function c 1(x, p) : = x, the momentum function c 2(x, p) : = p, and the angular momentum function c 3(x, p) : = x ×p are simple examples of functions that transform like vectors. (Transformation under rotations is one of the standard properties of the cross product.) A typical example of a function transforming like a vector is ![
$$\\mathbf{c}\(\\mathbf{x},\\mathbf{p}\) = \(\\mathbf{x} \\cdot \\mathbf{p}\)\\left \\vert \\mathbf{x}\\right\\vert \(\\mathbf{x \\times p}\).$$
](A272900_1_En_17_Chapter_IEq234.gif)

Proposition 17.25

Let j ( x, p ) = x × p denote the angular momentum function on ![
$${\\mathbb{R}}^{3} \\times {\\mathbb{R}}^{3.}$$
](A272900_1_En_17_Chapter_IEq235.gif) Suppose a smooth function ![
$$\\mathbf{c} : {\\mathbb{R}}^{3} \\times {\\mathbb{R}}^{3} \\rightarrow {\\mathbb{R}}^{3}$$
](A272900_1_En_17_Chapter_IEq236.gif) transforms like a vector. Then we have

![
$$\\displaystyle{ \\{c_{k},j_{k}\\} = 0 }$$
](A272900_1_En_17_Chapter_Equ27.gif)

(17.22)

for k = 1,2,3. Furthermore, we have

![
$$\\displaystyle{ \\{c_{1},j_{2}\\} =\\{ j_{1},c_{2}\\} = c_{3} }$$
](A272900_1_En_17_Chapter_Equ28.gif)

(17.23)

and other relations obtained from ( 17.23 ) by cyclically permuting the indices.

Proof.

Let R(θ) denote a counterclockwise rotation by angle θ in the (x 1, x 2)-plane. Applying (17.21) with R = R(θ) and looking only at the first component of the vectors, we have

![
$$\\displaystyle{ c_{1}\(R\(\\theta \)\\mathbf{x},R\(\\theta \)\\mathbf{p}\) = c_{1}\(\\mathbf{x},\\mathbf{p}\)\\cos \\theta - c_{2}\(\\mathbf{x},\\mathbf{p}\)\\sin \\theta. }$$
](A272900_1_En_17_Chapter_Equ29.gif)

(17.24)

Now, as in the proof of Proposition 2.30, the Poisson bracket {c 1, j 3} is precisely the derivative of the left-hand side of (17.24) with respect to θ, evaluated at θ = 0. Thus,

![
$$\\displaystyle{\\{c_{1},j_{3}\\} = -c_{2}}$$
](A272900_1_En_17_Chapter_Equae.gif)

and so ![
$$\\{j_{3},c_{1}\\} = c_{2},$$
](A272900_1_En_17_Chapter_IEq237.gif) which is one of the relations obtained from (17.23) by cyclically permuting the indices.

Meanwhile, if we again apply (17.21) with R = R(θ) but look now at the third component of the vectors, we have that

![
$$\\displaystyle{c_{3}\(R\(\\theta \)\\mathbf{x},R\(\\theta \)\\mathbf{p}\) = c_{3}\(\\mathbf{x},\\mathbf{p}\).}$$
](A272900_1_En_17_Chapter_Equaf.gif)

Differentiating this relation with respect to θ at θ = 0 gives {c 3, j 3} = 0. All other brackets are computed similarly.

We now turn to the quantum counterpart of a function that transforms like a vector.

Definition 17.26

For any ordered triple ![
$$\\mathbf{C} := \(C_{1},C_{2},C_{3}\)$$
](A272900_1_En_17_Chapter_IEq238.gif) of operators on ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq239.gif) and any vector ![
$$\\mathbf{v} \\in {\\mathbb{R}}^{3},$$
](A272900_1_En_17_Chapter_IEq240.gif) let v ⋅ C be the operator

![
$$\\displaystyle{ \\mathbf{v} \\cdot \\mathbf{C} =\\sum _{ j=1}^{3}v_{ j}C_{j}. }$$
](A272900_1_En_17_Chapter_Equ30.gif)

(17.25)

Then an ordered triple C of operators on ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq241.gif) is called a vector operator if

![
$$\\displaystyle{ \(R\\mathbf{v}\) \\cdot \\mathbf{C} = \\Pi \(R\)\(\\mathbf{v} \\cdot \\mathbf{C}\)\\Pi {\(R\)}^{-1} }$$
](A272900_1_En_17_Chapter_Equ31.gif)

(17.26)

for all R ∈ SO(3).

Here Π( ⋅) is the natural unitary action of SO(3) on ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq242.gif) in Definition 17.1. Let us try to understand what this definition is saying in the case of, say, the angular momentum, which is (as we shall see) a vector operator. The operators ![
$$\\hat{J}_{1},$$
](A272900_1_En_17_Chapter_IEq243.gif) ![
$$\\hat{J}_{2},$$
](A272900_1_En_17_Chapter_IEq244.gif) and ![
$$\\hat{J}_{3}$$
](A272900_1_En_17_Chapter_IEq245.gif) represent the components of ![
$$\\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq246.gif) in the directions of e 1, e 2, and e 3, respectively. More generally, we can consider the component of ![
$$\\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq247.gif) in the direction of any unit vector v, which will be nothing but ![
$$\\mathbf{v} \\cdot \\mathbf{\\hat{J}},$$
](A272900_1_En_17_Chapter_IEq248.gif) as defined in (17.25). Since there is no preferred direction in space, we expect that for any two unit vectors v 1 and v 2, the operators ![
$$\\mathbf{v}_{1} \\cdot \\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq249.gif) and ![
$$\\mathbf{v}_{2} \\cdot \\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq250.gif) should be "the same operator, up to rotation." Specifically, if R is some rotation with R v 1 = v 2, then ![
$$\\mathbf{v}_{1} \\cdot \\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq251.gif) and ![
$$\\mathbf{v}_{2} \\cdot \\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq252.gif) should differ only by the action of R on the Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq253.gif) But this is precisely what (17.26) says, with v = v 1 and ![
$$\\mathbf{C} = \\mathbf{\\hat{J}}$$
](A272900_1_En_17_Chapter_IEq254.gif):

![
$$\\displaystyle{\\mathbf{v}_{2} \\cdot \\mathbf{\\hat{J}} = \\Pi \(R\)\(\\mathbf{v}_{1} \\cdot \\mathbf{\\hat{J}}\)\\Pi {\(R\)}^{-1}}$$
](A272900_1_En_17_Chapter_Equag.gif)

We will not concern ourselves with the question of whether (17.26) continues to hold for ![
$$R \\in \\mathsf{O}\(3\)\\setminus \\mathsf{SO}\(3\).$$
](A272900_1_En_17_Chapter_IEq255.gif) The position and momentum operators X and P are easily seen to be vector operators. As in the classical case, the cross product of two vector operators is again a vector operator. (See Exercise 7 in Chap.​ 18.) In particular, the angular momentum, ![
$$\\mathbf{\\hat{J}} = \\mathbf{X \\times P}$$
](A272900_1_En_17_Chapter_IEq256.gif) is a vector operator.

If the operators C 1, C 2, and C 3 are unbounded, we should say something in Definition 17.26 about the domains of the operators in question. The simplest approach is to find some dense subspace V of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_17_Chapter_IEq257.gif) that is contained in the domain of each C j and such that V is invariant under rotations. In that case, the equality in (17.26) is understood to hold when applied to a vector in V. In many cases, we can take V to be the Schwartz space ![
$$\\mathcal{S}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_17_Chapter_IEq258.gif) In the following proposition, the space V should satisfy certain technical domain conditions that permit differentiation of (17.29) when applied to a vector ![
$$\\psi$$
](A272900_1_En_17_Chapter_IEq021.gif) in V. We will not pursue the details of such conditions here.

Proposition 17.27

If C is a vector operator, then the components of C satisfy

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[C_{j},\\hat{J}_{j}\] = 0 }$$
](A272900_1_En_17_Chapter_Equ32.gif)

(17.27)

for j = 1,2,3. Furthermore, we have

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[C_{1},\\hat{J}_{2}\] = \\frac{1} {i\\hslash }\[\\hat{J}_{1},C_{2}\] = C_{3}, }$$
](A272900_1_En_17_Chapter_Equ33.gif)

(17.28)

and other relations obtained from ( 17.28 ) by cyclically permuting the indices.

Proof.

As in the proof of Proposition 17.25, R(θ) denote a rotation in the (x 1, x 2)-plane, and let e 1 = (1, 0, 0). Applying (17.26) with R = R(θ) and v = e 1, we have

![
$$\\displaystyle{ \\Pi \(R\(\\theta \)\)C_{1}\\Pi {\(R\(\\theta \)\)}^{-1} = C_{ 1}\\cos \\theta + C_{2}\\sin \\theta. }$$
](A272900_1_En_17_Chapter_Equ34.gif)

(17.29)

But ![
$$R\(\\theta \) = {e}^{\\theta F_{3}},$$
](A272900_1_En_17_Chapter_IEq259.gif) where {F j } is the basis for so(3) described in Sect.​ 16.​5. Thus, differentiating (17.29) with respect to θ at θ = 0 gives

![
$$\\displaystyle{\\pi \(F_{3}\)C_{1} - C_{1}\\pi \(F_{3}\) = C_{2}.}$$
](A272900_1_En_17_Chapter_Equah.gif)

Since ![
$$\\hat{J}_{3} = i\\hslash \\pi \(F_{3}\)$$
](A272900_1_En_17_Chapter_IEq260.gif) (Proposition 17.3), we obtain ![
$$\(1/\(i\\hslash \)\)\[\\hat{J}_{3},C_{1}\] = C_{2},$$
](A272900_1_En_17_Chapter_IEq261.gif) which is one of the relations obtained from (17.28) by cyclically permuting the variables.

Meanwhile, applying (17.26) with R = R(θ) and v = e 3 gives

![
$$\\displaystyle{\\Pi \(R\(\\theta \)\)C_{3}\\Pi {\(R\(\\theta \)\)}^{-1} = C_{ 3}.}$$
](A272900_1_En_17_Chapter_Equai.gif)

Differentiating this relation with respect to θ at θ = 0 gives [π(F 3), C 3] = 0. All other relations are obtained similarly.

For more information about vector operators, including the Wigner–Eckart theorem, see Appendix D of [21]. See also Exercise 7.

## 17.11 Exercises

1.

Verify the expression (17.2) for the vector field ![
$$x_{1}\\partial /\\partial x_{2} - x_{2}\\partial /\\partial x_{1}.$$
](A272900_1_En_17_Chapter_IEq262.gif)

2.

Verify the relation (17.12) in the proof of Theorem 17.4, using induction on j and the commutation relation (17.10).

3.

This exercise provides a proof of Proposition 17.8. Let (π, V l ) denote an irreducible representation of so(3) of dimension 2l \+ 1 and let C π denote the Casimir operator as defined in the proposition.

(a)

Show that [π(F j ), C π ] = 0 for all j = 1, 2, 3.

(b)

Using Schur's lemma, show that there is some ![
$$\\lambda \\in \\mathbb{C}$$
](A272900_1_En_17_Chapter_IEq263.gif) such that C π v = λ v for all v ∈ V.

(c)

Show that

![
$$\\displaystyle{C_{\\pi } = -\\left \(L_{3}^{2} + {L}^{-}{L}^{+} + L_{ 3}\\right\),}$$
](A272900_1_En_17_Chapter_Equaj.gif)

where L +, L −, and L 3 are as in Theorem 17.4.

(d)

By computing C π on some suitably chosen vector in V, show that the constant λ in Part (b) has the value ![
$$-l\(l + 1\).$$
](A272900_1_En_17_Chapter_IEq264.gif)

4.

Let l be any non-negative integer or half-integer. Construct a vector space V by decreeing that vectors ![
$$\\{v_{0},v_{1},\\ldots,v_{2l}\\}$$
](A272900_1_En_17_Chapter_IEq265.gif) form a basis for V. Define operators L +, L −, and L 3 on V by the expressions in (17.6). Show that these operators satisfy the commutation relations (17.8), (17.9), and (17.10).

Hint: In the case of L −, treat the vector v 2l separately from the other basis vectors. In the case of the L +, treat the vector v 0 separately from the other basis vectors.

5.

Let (π, V) be an irreducible representation of so(3) of dimension 2, with basis {v 0, v 1} as in (17.6). Consider V ⊕ V as a representation of so(3) as in Sect.​ 16.​8. Let v = (v 0, v 1). Show that the smallest invariant subspace of V ⊕ V containing v is V ⊕ V.

Note: This shows that V ⊕ V has a cyclic vector, even though V ⊕ V is not irreducible.

6.

Compute explicit bases for the two irreducible invariant subspaces W 0 ≅V 3 ∕ 2 and ![
$$W_{0}^{\\perp }\\mathop{\\cong}V _{1/2}$$
](A272900_1_En_17_Chapter_IEq266.gif) of V 1 ⊗ V 1 ∕ 2. Each basis element for W 0 or W 0 ⊥ should be expressed as a linear combination of the elements v j ⊗ e k in the proof of Proposition 17.22.

7.

Let V l , V m , and V n be irreducible representation of so(3) of dimension 2l \+ 1, 2m \+ 1, and 2n \+ 1, respectively. Suppose that Φ and Ψ are nonzero intertwining maps of V l into V m ⊗ V n . Show that Φ = c Ψ for some ![
$$c \\in \\mathbb{C}.$$
](A272900_1_En_17_Chapter_IEq267.gif)

Hint: Use Proposition 17.23 and Schur's lemma.

Note: This result is closely related to the Wigner–Eckart theorem for "irreducible tensor operators."

References

[10].

G.B. Folland, A Course in Abstract Harmonic Analysis (CRC Press, Boca Raton, FL, 1995)

[21].

B.C. Hall, Lie Groups, Lie Algebras, and Representations: An Elementary Introduction. Graduate Texts in Mathematics, vol. 222 (Springer, New York, 2003)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_18

© Springer Science+Business Media New York 2013

# 18. Radial Potentials and the Hydrogen Atom

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

If V is any radial function on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq01.gif), let ![
$$\\hat{H} = -\({\\hslash }^{2}/\(2m\)\)\\Delta + V$$
](A272900_1_En_18_Chapter_IEq02.gif) be the corresponding Hamiltonian operator, acting on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq03.gif) We will look for solutions to the time-independent Schrödinger equation ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_18_Chapter_IEq04.gif) of the form ![
$$\\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \),$$
](A272900_1_En_18_Chapter_IEq05.gif) where f is a smooth function on (0,∞) and p is a harmonic polynomial on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq06.gif) that is homogeneous of degree l.

## 18.1 Radial Potentials

If V is any radial function on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq1.gif), let ![
$$\\hat{H} = -\({\\hslash }^{2}/\(2m\)\)\\Delta + V$$
](A272900_1_En_18_Chapter_IEq2.gif) be the corresponding Hamiltonian operator, acting on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq3.gif) We will look for solutions to the time-independent Schrödinger equation ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_18_Chapter_IEq4.gif) of the form ![
$$\\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \),$$
](A272900_1_En_18_Chapter_IEq5.gif) where f is a smooth function on (0, ∞) and p is a harmonic polynomial on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq6.gif) that is homogeneous of degree l.

Proposition 18.1.

Let p be a harmonic polynomial on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq7.gif) that is homogeneous of degree l and let f be a smooth function on (0,∞). Let ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq001.gif) be the function on ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_18_Chapter_IEq8.gif) given by

![
$$\\displaystyle{ \\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \). }$$
](A272900_1_En_18_Chapter_Equ1.gif)

(18.1)

Then on ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_18_Chapter_IEq9.gif) we have

![
$$\\displaystyle{\\Delta \\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)\\left \[\\frac{{d}^{2}f} {d{r}^{2}} + \\frac{2\(l + 1\)} {r} \\frac{df} {dr}\\right\].}$$
](A272900_1_En_18_Chapter_Equa.gif)

Proof.

We begin with the case l = 0, so that p is a constant—which we take to be 1—and ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq002.gif) is just the radial function ![
$$f\(\\left \\vert \\mathbf{x}\\right\\vert \).$$
](A272900_1_En_18_Chapter_IEq10.gif) Then

![
$$\\displaystyle\\begin{array}{rcl} \\frac{\\partial } {\\partial x_{j}}f\(\\left \\vert \\mathbf{x}\\right\\vert \)& =& \\frac{df} {dr} \\frac{d} {dx_{j}}\\sqrt{ x_{1}^{2} + x_{2}^{2} + x_{3}^{2}} {}\\\\ & =& \\frac{df} {dr} \\frac{x_{j}} {\\left \\vert \\mathbf{x}\\right\\vert } {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ2.gif)

and so

![
$$\\displaystyle\\begin{array}{rcl} \\sum _{j=1}^{3} \\frac{{\\partial }^{2}} {\\partial x_{j}^{2}}f\(\\left \\vert \\mathbf{x}\\right\\vert \)& =& \\sum _{j=1}^{3}\\left \[\\frac{{d}^{2}f} {d{r}^{2}} \\frac{x_{j}^{2}} {{\\left \\vert \\mathbf{x}\\right\\vert }^{2}} + \\frac{df} {dr}\\left \( \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert } -\\frac{x_{j}^{2}} {{\\left \\vert \\mathbf{x}\\right\\vert }^{3}} \\right\)\\right\] {}\\\\ & =& \\frac{{d}^{2}f} {d{r}^{2}} + \\frac{2} {r} \\frac{df} {dr}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ3.gif)

For the general case, the product rule for the Laplacian gives

![
$$\\displaystyle{\\Delta \\psi = \(\\Delta p\)f\(\\left \\vert \\mathbf{x}\\right\\vert \) + 2\\nabla p \\cdot \\nabla f\(\\left \\vert \\mathbf{x}\\right\\vert \) + p\\Delta f\(\\left \\vert \\mathbf{x}\\right\\vert \).}$$
](A272900_1_En_18_Chapter_Equb.gif)

Now, Δ p = 0 by assumption. Furthermore, since ![
$$f\(\\left \\vert \\mathbf{x}\\right\\vert \)$$
](A272900_1_En_18_Chapter_IEq11.gif) is radial, its gradient points in the radial direction. Thus, only the radial component of ∇ p is relevant. Moreover, on each ray through the origin, p behaves like a constant times r l . Thus, the r-derivative of p is (l ∕ r)p, giving

![
$$\\displaystyle{\\Delta \\psi = \\frac{2l} {r} p\\frac{df} {dr} + p\\frac{{d}^{2}f} {d{r}^{2}} + \\frac{2} {r}p\\frac{df} {dr},}$$
](A272900_1_En_18_Chapter_Equc.gif)

which simplifies to the desired expression.

Although the decomposition of functions in Definition 17.18 is for many purposes the most convenient one, it is not quite the customary way of turning spherical harmonics into functions on ![
$${\\mathbb{R}}^{3}.$$
](A272900_1_En_18_Chapter_IEq12.gif) Conventionally, one works in polar coordinates and considers functions of the form

![
$$\\displaystyle{\\psi \(r,\\theta,\\phi \) = p\(\\theta,\\phi \)g\(r\),}$$
](A272900_1_En_18_Chapter_Equd.gif)

where p is the restriction to S 2 of an element of V l . We can express this decomposition in rectangular coordinates as

![
$$\\displaystyle{\\psi \(\\mathbf{x}\) = p\\left \(\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\)g\(\\left \\vert \\mathbf{x}\\right\\vert \) = \\frac{p\(\\mathbf{x}\)} {{\\left \\vert \\mathbf{x}\\right\\vert }^{l}} g\(\\left \\vert \\mathbf{x}\\right\\vert \).}$$
](A272900_1_En_18_Chapter_Eque.gif)

We can then obtain a more customary form of Proposition 18.1 as follows.

Proposition 18.2.

Suppose p ∈ V l and f is a smooth function on (0,∞), and let ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq003.gif) by the function on ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_18_Chapter_IEq13.gif) given by

![
$$\\displaystyle{\\psi \(\\mathbf{x}\) = p\\left \(\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\)g\(\\left \\vert \\mathbf{x}\\right\\vert \).}$$
](A272900_1_En_18_Chapter_Equf.gif)

Then

![
$$\\displaystyle{ \(\\Delta \\psi \)\(r\\mathbf{x}\) = p\(\\mathbf{x}\)\\left \[\\frac{{d}^{2}g} {d{r}^{2}} + \\frac{2} {r} \\frac{dg} {dr} -\\frac{l\(l + 1\)} {{r}^{2}} g\(r\)\\right\] }$$
](A272900_1_En_18_Chapter_Equ4.gif)

(18.2)

for all x ∈ S 2 and r ∈ (0,∞).

Proof.

Since p is homogeneous of degree l,

![
$$\\displaystyle{p\\left \(\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\) = \\frac{p\(\\mathbf{x}\)} {{\\left \\vert \\mathbf{x}\\right\\vert }^{l}}.}$$
](A272900_1_En_18_Chapter_Equg.gif)

Thus,

![
$$\\displaystyle{\\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)\\left \(\\frac{f\(\\left \\vert \\mathbf{x}\\right\\vert \)} {{\\left \\vert \\mathbf{x}\\right\\vert }^{l}} \\right\).}$$
](A272900_1_En_18_Chapter_Equh.gif)

Applying Proposition 18.1 gives

![
$$\\displaystyle{\\Delta \\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)\\left \[ \\frac{{d}^{2}} {d{r}^{2}} + \\frac{2\(l + 1\)} {r} \\frac{d} {dr}\\right\]\\left \(\\frac{f\(r\)} {{r}^{l}} \\right\).}$$
](A272900_1_En_18_Chapter_Equi.gif)

From here it is straightforward but unilluminating calculation to verify the formula in the proposition.

Still another way to write functions on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq14.gif) is in the form

![
$$\\displaystyle{ \\psi \(\\mathbf{x}\) = \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }p\\left \(\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert }\\right\)h\(\\left \\vert \\mathbf{x}\\right\\vert \), }$$
](A272900_1_En_18_Chapter_Equ5.gif)

(18.3)

so that h(r) = rg(r). If we replace g(r) by h(r) ∕ r in (18.2), we obtain, after a short calculation,

![
$$\\displaystyle{ \(\\Delta \\psi \)\(r\\mathbf{x}\) = \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }p\(\\mathbf{x}\)\\left \[\\frac{{d}^{2}h} {d{r}^{2}} -\\frac{l\(l + 1\)} {{r}^{2}} h\(r\)\\right\],\\quad \\mathbf{x} \\in {S}^{2}. }$$
](A272900_1_En_18_Chapter_Equ6.gif)

(18.4)

Writing wave functions in the form (18.3) is convenient because we then have, for any radial potential,

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2m}\\Delta \\psi + V \(\\left \\vert \\mathbf{x}\\right\\vert \)\\psi = \\frac{1} {\\left \\vert \\mathbf{x}\\right\\vert }p\(\\mathbf{x}\)\\left \[-\\frac{{\\hslash }^{2}} {2m} \\frac{{d}^{2}h} {d{r}^{2}} + V _{\\mathrm{eff}}\(r\)h\(r\)\\right\], }$$
](A272900_1_En_18_Chapter_Equ7.gif)

(18.5)

where V eff is the effective potential given by

![
$$\\displaystyle{ V _{\\mathrm{eff}}\(r\) = V \(r\) + \\frac{{\\hslash }^{2}l\(l + 1\)} {2m{r}^{2}}. }$$
](A272900_1_En_18_Chapter_Equ8.gif)

(18.6)

Note that the quantity in square brackets in (18.5) is just an ordinary one-dimensional Schrödinger operator, since the first derivative term in (18.2) has been eliminated. Despite the naturalness of the form (18.3), it is the form (18.1) that is ultimately most convenient for finding the bound states of the hydrogen atom Hamiltonian.

Now, as the discussion following Proposition 9.34 illustrates, even if ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq004.gif) is square-integrable over ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_18_Chapter_IEq15.gif) and Δ ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq005.gif) is square-integrable over ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\},$$
](A272900_1_En_18_Chapter_IEq16.gif) ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq006.gif) may not be in the domain of the Laplacian, since the distributional Laplacian of ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq07.gif) may contain a term that is supported at the origin. In the case of the hydrogen atom, however, we will consider functions ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq08.gif) of the form (18.1) where f and df ∕ dr are bounded near the origin and have exponential decay near infinity. Proposition 9.35 then tells us that ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq09.gif) is in the domain of Δ.

## 18.2 The Hydrogen Atom: Preliminaries

A hydrogen atom is formed out of a single electron that is "bound" to a proton by means of the electromagnetic attraction between the oppositely charged particles. The study of the hydrogen atom is a very important test case in quantum mechanics, and the ability of the Schrödinger equation to explain the observed energy levels of hydrogen was a crucial early success of the theory.

A proton is approximately 1,800 times as massive as an electron. Thus, to first approximation, we may think of the location of the proton as being fixed, with the electron "orbiting" around this location. A more careful analysis considers both the proton and the electron as orbiting around their center of mass. The Hamiltonian for the relative position of the two particles is precisely that of a particle orbiting around a fixed center, except that the mass of the electron is replaced by the reduced mass μ of the electron–proton system. (See Exercise 1.) Here, as in Proposition 2.16 in the classical case,

![
$$\\displaystyle{\\mu = \\frac{m_{e}m_{p}} {m_{e} + m_{p}},}$$
](A272900_1_En_18_Chapter_Equj.gif)

where m e and m p are the masses of the proton and electron, respectively. Since m p ≫ m e , the reduced mass is nearly the same as the mass of the electron.

After separating out the motion of the center of mass, we are left with the following Hamiltonian for the relative position of the electron:

![
$$\\displaystyle{ \\hat{H} = -\\frac{{\\hslash }^{2}} {2\\mu } \\Delta -\\frac{{Q}^{2}} {\\left \\vert \\mathbf{x}\\right\\vert }, }$$
](A272900_1_En_18_Chapter_Equ9.gif)

(18.7)

where Q is the charge of the electron. (We use a system of units, such as "electrostatic" or "Gaussian" units, in which the Coulomb constant is equal to 1.) It follows from Theorem 9.38 that ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq17.gif) is self-adjoint on Dom(Δ) and that ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq18.gif) is bounded below.

Note that the classical Hamiltonian H(x, p) for a hydrogen atom is not bounded below. After all, we can simply take p = 0 and take x very close to the origin. This unboundedness would cause strange behavior for a hypothetical classical hydrogen atom. After all, modeling a hydrogen atom using the 1 ∕ r potential is only an approximation. We are using an electrostatic formula for the force, the correct one when the positions of the particles are held fixed, in a dynamical situation. A more realistic model of hydrogen takes into account radiation, that is, the interaction of the charged electron with the electromagnetic fields. Classically, a negatively charge particle orbiting a positively charged nucleus would radiate, thus giving up energy to the electromagnetic fields. The classical particle would spiral rapidly toward the origin, with the particle's energy going to − ∞ and the energy of the electromagnetic field going to + ∞. Thus, if hydrogen were made up of classical charged particles, the electron would go into a "death spiral" and emit a giant burst of electromagnetic radiation.

Fortunately for us, this is not how real particles behave! In actuality, the electron is a quantum particle. A quantum electron "orbiting" a proton can still give up energy to the electromagnetic field. The Hamiltonian for the quantum hydrogen atom, however, is bounded below, as a consequence of Theorem 9.38. Thus, the electron can only drop to its ground state (the state of lowest energy), at which point it becomes stable.

## 18.3 The Bound States of the Hydrogen Atom

Our goal in this section is to find the eigenvectors for the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq19.gif) in (18.7) with negative eigenvalues. Such eigenvectors constitute "bound states," that is, states in which the electron is bound to the proton. For each negative number E, we look at the eigenspace V E for ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq20.gif) with eigenvalue E, that is, the space of all ![
$$\\psi \\in \\mathrm{ Dom}\(\\hat{H}\)$$
](A272900_1_En_18_Chapter_IEq21.gif) satisfying ![
$$\\hat{H}\\psi = E\\psi.$$
](A272900_1_En_18_Chapter_IEq22.gif) Since ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq23.gif) is self-adjoint and, therefore, closed, this eigenspace will be a closed subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq24.gif) Since, also, ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq25.gif) commutes with rotations, V E will be invariant under the usual action (Definition 17.1) of SO(3) on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq26.gif) Thus, by the discussion at the end of Sect.​ 17.​7, V E decomposes as a direct sum of finite-dimensional, irreducible SO(3)-invariant subspaces.

We now look for such subspaces of V E . In the following theorem, we assume that the radial part of the wave function (the function f in the notation V l, f in Definition 17.18) has a certain very special form. After analyzing this case, we argue that we have found in this way all of the eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq27.gif) with negative eigenvalues.

Theorem 18.3.

For each positive integer n, let

![
$$\\displaystyle{ E_{n} = -\\frac{\\mu {Q}^{4}} {2{\\hslash }^{2}} \\frac{1} {{n}^{2}} }$$
](A272900_1_En_18_Chapter_Equ10.gif)

(18.8)

where Q is the charge of the electron and μ is the reduced mass of the electron–proton system, and let

![
$$\\displaystyle{\\rho _{n}\(\\mathbf{x}\) = \\frac{\\sqrt{8\\mu \\left \\vert E_{n}\\right\\vert }} {\\hslash } \\left \\vert \\mathbf{x}\\right\\vert.}$$
](A272900_1_En_18_Chapter_Equk.gif)

Then for each ![
$$l = 0,1,\\ldots,n - 1,$$
](A272900_1_En_18_Chapter_IEq28.gif) there exists a polynomial L n,l such that for each homogeneous harmonic polynomial q of degree l, the function

![
$$\\displaystyle{ \\psi \(\\mathbf{x}\) = q\(\\mathbf{x}\){e}^{-\\rho _{n}\(\\mathbf{x}\)/2}L_{ n,l}\(\\rho _{n}\(\\mathbf{x}\)\) }$$
](A272900_1_En_18_Chapter_Equ11.gif)

(18.9)

satisfies

![
$$\\displaystyle{\\hat{H}\\psi = E_{n}\\psi.}$$
](A272900_1_En_18_Chapter_Equl.gif)

It follows from Proposition 9.35 that the functions ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq010.gif) in (18.9) belong to Dom(Δ) and thus, by Theorem 9.38, to ![
$$\\mathrm{Dom}\(\\hat{H}\).$$
](A272900_1_En_18_Chapter_IEq29.gif) The polynomials L n, l are the Laguerre polynomials. The coefficient of ![
$$-1/{n}^{2}$$
](A272900_1_En_18_Chapter_IEq30.gif) in the formula (18.8) for E n is the Rydberg constant (compare Sect.​ 1.​2.​1).

Let us see how to connect Theorem 18.3 to the usual expression for the hydrogen atom eigenvectors in the physics literature. In the first place, physicists choose a certain basis q l, m for the space of harmonic polynomials, which is—up to normalization constants—the basis in Theorem 17.4. In the second place, physicists write the solutions in spherical coordinates. When changing to spherical coordinates, we should keep in mind that q l, m is homogeneous of degree l and that ρ n (x) is just a constant multiple of the distance from the origin. We obtain, then, the following expression:

![
$$\\displaystyle{ \\psi _{n,l,m}\(r,\\theta,\\phi \) = Y _{l,m}\(\\theta,\\phi \)\\rho _{n}^{l}{e}^{-\\rho _{n}/2}L_{ n,l}\(\\rho _{n}\), }$$
](A272900_1_En_18_Chapter_Equ12.gif)

(18.10)

where Y l, m (θ, ![
$$\\phi$$
](A272900_1_En_18_Chapter_IEq011.gif)) is the restriction to the unit sphere of p l, m .

Proof.

If E is a negative real number, we look for solutions to ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_18_Chapter_IEq31.gif) of the form ![
$$q\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \),$$
](A272900_1_En_18_Chapter_IEq32.gif) where q ∈ V l . Provided that f(r) and f ′ (r) are bounded near the origin, Proposition 9.35 allows us to compute Δ ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq012.gif) on ![
$${\\mathbb{R}}^{3}\\setminus \\{0\\}$$
](A272900_1_En_18_Chapter_IEq33.gif) without worrying about whether ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq013.gif) is differentiable at the origin. Using Proposition 18.1, the equation for f is

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2\\mu } \\left \[\\frac{{d}^{2}f} {d{r}^{2}} + \\frac{2\(l + 1\)} {r} \\frac{df} {dr}\\right\] -\\frac{{Q}^{2}} {r} f\(r\) = Ef\(r\). }$$
](A272900_1_En_18_Chapter_Equ13.gif)

(18.11)

For large r, where the two terms that involve a factor of 1 ∕ r become negligible, and so

![
$$\\displaystyle{ -\\frac{{\\hslash }^{2}} {2\\mu } \\frac{{d}^{2}f} {d{r}^{2}} \\approx Ef. }$$
](A272900_1_En_18_Chapter_Equ14.gif)

(18.12)

Recalling that E is negative, (18.12) tells us that near infinity, f should behave like a combination of a growing and a decaying exponential. Since we want square-integrable solutions, we require that only the exponentially decaying term be present.

We therefore postulate a solution of the form

![
$$\\displaystyle{ f\(r\) =\\exp \\left \\{-\\frac{\\sqrt{2\\mu \\left \\vert E\\right\\vert }} {\\hslash } r\\right\\}g\(r\), }$$
](A272900_1_En_18_Chapter_Equ15.gif)

(18.13)

for some function g. If we plug (18.13) into (18.11) for f, there are canceling terms equal to Eg(r) on each side, leaving

![
$$\\displaystyle\\begin{array}{rcl} & -& \\frac{{\\hslash }^{2}} {2\\mu } \\left \[\\frac{{d}^{2}g} {d{r}^{2}} - 2\\frac{\\sqrt{2\\mu \\left \\vert E\\right\\vert }} {\\hslash } \\frac{dg} {dr} + \\frac{2\(l + 1\)} {r} \\frac{dg} {dr} -\\frac{2\(l + 1\)} {r} \\frac{\\sqrt{2\\mu \\left \\vert E\\right\\vert }} {\\hslash } g\(r\)\\right\] {}\\\\ & =& \\frac{{Q}^{2}} {r} g\(r\). {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ16.gif)

We now introduce the new variable ![
$$\\rho = \(\\sqrt{8\\mu \\left \\vert E\\right\\vert }/\\hslash \)r.$$
](A272900_1_En_18_Chapter_IEq34.gif) After making this change of variable, we find that each term in square brackets obtains a factor of ![
$$8\\mu \\left \\vert E\\right\\vert /{\\hslash }^{2},$$
](A272900_1_En_18_Chapter_IEq35.gif) so that our equation becomes

![
$$\\displaystyle{-\\frac{{\\hslash }^{2}} {2\\mu } \\frac{8\\mu \\left \\vert E\\right\\vert } {{\\hslash }^{2}} \\left \[\\frac{{d}^{2}g} {{d\\rho }^{2}} -\\frac{dg} {d\\rho } + \\frac{2\(l + 1\)} {\\rho } \\frac{dg} {d\\rho } -\\frac{\(l + 1\)} {\\rho } g\(\\rho \)\\right\] = \\frac{2\\sqrt{2\\mu \\left \\vert E\\right\\vert }} {\\hslash } \\frac{{Q}^{2}} {\\rho } g\(\\rho \).}$$
](A272900_1_En_18_Chapter_Equm.gif)

Multiplying through by ρ and simplifying yields the equation.

![
$$\\displaystyle{ \\rho \\frac{{d}^{2}g} {{d\\rho }^{2}} -\\rho \\frac{dg} {d\\rho } + 2\(l + 1\)\\frac{dg} {d\\rho } + \\left \[ \\frac{{Q}^{2}\\sqrt{\\mu }} {\\hslash \\sqrt{2\\left \\vert E\\right\\vert }} - \(l + 1\)\\right\]g\(\\rho \) = 0. }$$
](A272900_1_En_18_Chapter_Equ17.gif)

(18.14)

If we postulate for g a power series ![
$$\\sum _{k=0}^{\\infty }a{_{k}\\rho }^{k},$$
](A272900_1_En_18_Chapter_IEq36.gif) we obtain the following recurrence relations for the coefficients:

![
$$\\displaystyle{ a_{k+1} = a_{k} \\frac{\[k + l + 1-\\lambda \]} {k\[\(k + 1\) + 2\(l + 1\)\]} }$$
](A272900_1_En_18_Chapter_Equ18.gif)

(18.15)

where

![
$$\\displaystyle{\\lambda = \\frac{{Q}^{2}\\sqrt{\\mu }} {\\hslash \\sqrt{2\\left \\vert E\\right\\vert }}.}$$
](A272900_1_En_18_Chapter_Equn.gif)

The series for g will terminate, yielding a polynomial solution to (18.14), provided that λ is an integer n with n ≥ l \+ 1. We can then solve for the energy in terms of n as follows:

![
$$\\displaystyle{\\left \\vert E\\right\\vert = \\frac{\\mu {Q}^{4}} {2{n}^{2}{\\hslash }^{2}}.}$$
](A272900_1_En_18_Chapter_Equo.gif)

Recalling that E is negative, we have obtained the desired form for the energy levels. Furthermore, the condition n ≥ l \+ 1 is the same as l ≤ n − 1. Finally, if we plug in the formula for ρ in terms of r and the formula for f in terms of g, we obtain the form of the solution stated in the theorem.

It is important to emphasize that the functions in Theorem 18.3 do not span the entire Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq37.gif) After all, these functions are all eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq38.gif) with negative eigenvalues. If these vectors spanned ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_18_Chapter_IEq39.gif) then the expectation value of the energy would always be negative. But it is easy to produce functions ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq014.gif) in the domain of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq40.gif) for which ![
$$\\langle \\psi,\\hat{H}\\psi \\rangle > 0.$$
](A272900_1_En_18_Chapter_IEq41.gif) Simply take ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq015.gif) to be a Gaussian wave packet with mean position far from the origin and with very large mean momentum. Then ![
$$\\left \\langle \\psi,V \\psi \\right\\rangle$$
](A272900_1_En_18_Chapter_IEq42.gif) will be close to zero but ![
$$\\langle \\psi,{P}^{2}\\psi \\rangle$$
](A272900_1_En_18_Chapter_IEq43.gif) will be large and positive. Nevertheless, it can be shown that the functions in Theorem 18.3 span the negative energy subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq44.gif) It is possible to analyze also the positive part of the spectrum of ![
$$\\hat{H},$$
](A272900_1_En_18_Chapter_IEq45.gif) but the spectrum above zero is purely continuous and represents a hydrogen atom that has ionized, that is, in which the electron has escaped from the proton.

Theorem 18.4.

As n varies over all positive integers, l varies from 0 to n − 1, and g varies over all homogeneous harmonic polynomials of degree l, the eigenvectors in Theorem 18.3 span the negative-energy subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_18_Chapter_IEq46.gif) that is, the range of the projection ![
$${\\mu }^{\\hat{H}}\(\(-\\infty,0\)\),$$
](A272900_1_En_18_Chapter_IEq47.gif) where ![
$${\\mu }^{\\hat{H}}$$
](A272900_1_En_18_Chapter_IEq48.gif) is the projection-valued measure associated to ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq49.gif) by the spectral theorem.

Proof.

The proof requires results from spectral theory that go beyond the machinery that we have developed in Chaps.​ 9 and , and which we cannot reproduce in full here. Specifically, we make use of Theorem V.5.7 of [27], which tells us that the negative-energy portion of the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq50.gif) is discrete, consisting of eigenvalues of finite multiplicity accumulating only at zero.

We indicate briefly why the above result holds. If A and B are unbounded self-adjoint operators, let us say that B is a relatively compact perturbation of A if ![
$$A{\(B -\\lambda I\)}^{-1}$$
](A272900_1_En_18_Chapter_IEq51.gif) is a compact operator for every λ in the resolvent set of B. According to Lemma V.5.8 of [27], the potential energy operator for the hydrogen atom is a relatively compact perturbation of the kinetic energy operator. This is a strengthening of what we showed in the proof of Theorem 9.38, namely that the potential energy operator is relatively bounded with respect to the kinetic energy operator, with relative bound less than 1. The proof of relative compactness relies on the fact that the potential for the hydrogen atom goes to zero at infinity.

Meanwhile, let us say that λ belongs to the essential spectrum of an unbounded self-adjoint operator A if either λ is a nonisolated point in σ(A) or λ is an eigenvalue for A with infinite multiplicity. According to Theorem IV.5.35 of [27], a relatively compact perturbation of a self-adjoint operator does not change the essential spectrum. Thus, the essential spectrum of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq52.gif) is equal to the essential spectrum of the kinetic energy operator, which is certainly contained in [0, ∞), since the kinetic energy operator is non-negative. It follows that any point in the negative-energy part of the spectrum of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq53.gif) must be an isolated point in ![
$$\\sigma \(\\hat{H}\)$$
](A272900_1_En_18_Chapter_IEq54.gif) and an eigenvalue of finite multiplicity.

In light of the preceding result, there is no continuous spectrum for ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq55.gif) below zero, and we need only look for square-integrable eigenvectors. Since, also, each eigenspace for ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq56.gif) with eigenvalue E < 0 is finite dimensional, it will decompose as a direct sum of irreducible, SO(3)-invariant subspaces. Such subspaces, according to Proposition 17.19, are always of the form V l, f for some l and f, where V l, f is as in Definition 17.18. Thus, we look for functions ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq016.gif) of the form ![
$$\\psi \(\\mathbf{x}\) = p\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \)$$
](A272900_1_En_18_Chapter_IEq57.gif) such that ![
$$\\hat{H}\\psi = E\\psi$$
](A272900_1_En_18_Chapter_IEq58.gif) for some E < 0.

Now, if a function of the form ![
$$p\(\\mathbf{x}\)f\(\\left \\vert \\mathbf{x}\\right\\vert \)$$
](A272900_1_En_18_Chapter_IEq59.gif) is to be an eigenfunction of the Hamiltonian, f must satisfy the differential equation (18.11). By elementary results from the theory of linear ordinary differential equations, this equation has precisely two linearly independent solutions, for any value of E. Both solutions can be constructed by postulating a solution of the form (18.13), introducing the new variable ρ, and then using a power series expansion for g(ρ) (Exercise 9). One of the solutions for g(ρ) will have a power series starting with ![
$${\\rho }^{-\(2l+1\)},$$
](A272900_1_En_18_Chapter_IEq60.gif) in which case ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq017.gif)(x) will blow up like ![
$$1/{\\left \\vert \\mathbf{x}\\right\\vert }^{\(l+1\)}$$
](A272900_1_En_18_Chapter_IEq61.gif) near the origin; such a function is not in the domain of the Hamiltonian (Exercise 14 in Chap.​ 9). The other solution for g(ρ) will start with ρ 0 and may be obtained by using the form (18.13), changing from the variable r to the variable ρ, and then using the recurrence relation (18.15) to define the coefficients of a power series. If the resulting series does not terminate, it is not hard to see that the terms will behave for large k like the series for e ρ . Since the function f is equal to ![
$${e}^{-\\rho /2}g\(\\rho \),$$
](A272900_1_En_18_Chapter_IEq62.gif) this function will grow like e ρ ∕ 2 near infinity, which means that ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq018.gif) will not be in ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq63.gif) Thus, to get a square-integrable solution, the series for g(ρ) must terminate, in which case ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq019.gif) is one of the functions in Theorem 18.3.

Corollary 18.5.

Each eigenvalue E n , as given in Theorem 18.3, has multiplicity n 2

Proof.

According to Theorem 18.4, the eigenvectors in Theorem 18.3 constitute all of the eigenvectors for ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq64.gif) with eigenvalue E n . The number of independent eigenvectors with eigenvalue E n is thus the sum of the dimensions of the spaces V l of spherical harmonics, with ![
$$l = 0,1,\\ldots,n - 1.$$
](A272900_1_En_18_Chapter_IEq65.gif) This number is, by Theorem 17.12,

![
$$\\displaystyle{\\sum _{l=0}^{n-1}\(2l + 1\) = {n}^{2},}$$
](A272900_1_En_18_Chapter_Equp.gif)

as claimed.

## 18.4 The Runge–Lenz Vector in the Quantum Kepler Problem

In Sect.​ 2.​6, we showed that the classical Kepler problem can be solved almost completely by making use of the Runge–Lenz vector, which is a conserved quantity. The quantum version of the Runge–Lenz vector commutes with the Hamiltonian and can elucidate a number of special properties of the quantum Kepler problem, which we typically think of as describing a hydrogen atom. In particular, the Runge–Lenz vector will help to explain (1) the simple form ![
$$-R/{n}^{2}$$
](A272900_1_En_18_Chapter_IEq66.gif) of the negative energies of the hydrogen atom and (2) the apparent coincidence by which energy of the states in (18.9) is independent of l for a given n. Note that the rotational symmetry of the problem explains why the energy of the states in (18.9) is independent of the choice of the harmonic polynomial q. Nevertheless, rotational symmetry cannot explain why states for different values of l—and thus different radial dependence in the wave function—have the same energy. This apparent coincidence will be explained by an additional symmetry of the problem, that is expressible in terms of the Runge–Lenz vector. See also Sect. 7 of [17] for a somewhat different (but related) explanation for the structure of the eigenvalues of the hydrogen atom and their multiplicities.

There are several computations involving the Runge–Lenz vector that, while elementary, are laborious. Those computations are deferred to Sect. 18.6.

### 18.4.1 Some Notation

To keep the notation as simple as possible, we will adopt in this section Einstein's summation convention, which states that repeated indices are always summed on, even if there is no summation sign written. In this section, the sum will always range from 1 to 3. Using this convention, we write, say, the dot product of two vectors u, v in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq67.gif) as u ⋅v = u j v j , where the summation convention frees us from having to write out explicitly the sum over j.

We will make frequent use of the totally antisymmetric symbol ![
$$\\varepsilon _{jkl},$$
](A272900_1_En_18_Chapter_IEq68.gif) where j, k, and l range from 1 to 3, defined as follows,

Definition 18.6.

For j,k,l ∈{ 1,2,3}, define ![
$$\\varepsilon _{jkl}$$
](A272900_1_En_18_Chapter_IEq69.gif) by the formula

![
$$\\displaystyle{\\varepsilon _{jkl} = \\left \\{\\begin{array}{rl} 1&\\text{\\it if }\(j,k,l\) \\text{\\, \\it is an even permutation of }\(1,2,3\) \\\\ - 1&\\text{\\it if}\(j,k,l\)\\text{\\it \\, is an odd permutation of }\(1,2,3\) \\\\ 0&\\text{\\it if any two of }j,k,l\\text{\\it \\, are equal} \\end{array} \\right..}$$
](A272900_1_En_18_Chapter_Equq.gif)

Thus, for example, ![
$$\\varepsilon _{321} = -1$$
](A272900_1_En_18_Chapter_IEq70.gif) and ![
$$\\varepsilon _{212} = 0.$$
](A272900_1_En_18_Chapter_IEq71.gif) The commutation relations for the basis ![
$$\\{F_{1},F_{2},F_{3}\\}$$
](A272900_1_En_18_Chapter_IEq72.gif) for so(3) may be written (using the summation convention!) as

![
$$\\displaystyle{ \[F_{j},F_{k}\] =\\varepsilon _{jkl}F_{l}. }$$
](A272900_1_En_18_Chapter_Equ19.gif)

(18.16)

For instance, if we take j = 1 and k = 2 in (18.16), then the sum on l gives a nonzero value only when l = 3, and we recover the relation ![
$$\[F_{1},F_{2}\] = F_{3}.$$
](A272900_1_En_18_Chapter_IEq73.gif)

### 18.4.2 The Classical Runge–Lenz Vector, Revisited

We have already introduced, in Sect.2.6, the Runge–Lenz vector A in the classical mechanics of a particle moving in a 1 ∕ r potential. We require a few more properties of A before turning to the quantum version. We consider a classical particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq74.gif) with Hamiltonian given by

![
$$\\displaystyle{ H\(\\mathbf{x},\\mathbf{p}\) = \\frac{{\\left \\vert \\mathbf{p}\\right\\vert }^{2}} {2\\mu } -\\frac{{Q}^{2}} {\\left \\vert \\mathbf{x}\\right\\vert }. }$$
](A272900_1_En_18_Chapter_Equ20.gif)

(18.17)

This is just the Hamiltonian for the classical Kepler problem, except that we replace the mass m of the planet by the reduced mass μ of the electron–proton system, and we replace the constant k : = m M G by Q 2.

For the Hamiltonian in (18.17), the Runge–Lenz vector is given by the formula

![
$$\\displaystyle{\\mathbf{A}\(\\mathbf{x},\\mathbf{p}\) = \\frac{1} {\\mu {Q}^{2}}\\mathbf{p} \\times \\mathbf{J} -\\frac{\\mathbf{x}} {\\left \\vert \\mathbf{x}\\right\\vert },}$$
](A272900_1_En_18_Chapter_Equr.gif)

where J : = x × p is the angular momentum. By Proposition 2.34, the Runge–Lenz vector is a conserved quantity for the classical Kepler problem, in addition to H and J, which are conserved quantities for any radial potential. By results of Sect.​ 2.​6, we have the following relations among these conserved quantities:

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{A} \\cdot \\mathbf{J}& =& 0 {}\\\\ { \\left \\vert \\mathbf{A}\\right\\vert }^{2}& =& 1 + \\frac{2H} {\\mu {Q}^{4}}{ \\left \\vert \\mathbf{J}\\right\\vert }^{2}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ21.gif)

Lemma 18.7.

The Runge–Lenz vector A and the Hamiltonian H in (18.17) satisfy the following Poisson bracket relations:

![
$$\\displaystyle\\begin{array}{rcl} \\{A_{j},H\\}& =& 0 \\\\ \\{A_{j},A_{m}\\}& =& - \\frac{2} {\\mu {Q}^{4}}\\varepsilon _{jml}J_{l}H.{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ22.gif)

(18.18)

We have already shown that the Runge–Lenz vector is a conserved quantity (Proposition 2.34), which is equivalent (Proposition 2.25) to saying that the Poisson bracket of A j with H is zero, as claimed. The proof of (18.18) is deferred to Sect. 18.6. We now introduce certain combinations of the Runge–Lenz vector, the angular momentum, and the Hamiltonian that form a Lie algebra under the Poisson bracket. In the construction of these functions, we need to take a square root of the Hamiltonian, which necessitates separating the positive-energy and negative-energy parts of the phase space. Our interest is primarily in the negative-energy case.

Definition 18.8.

Let U − denote the negative-energy part of the classical phase space,

![
$$\\displaystyle{{U}^{-} = \\left \\{\\left.\(\\mathbf{x},\\mathbf{p}\) \\in {\\mathbb{R}}^{6}\\right\\vert H\(\\mathbf{x},\\mathbf{p}\) < 0\\right\\}.}$$
](A272900_1_En_18_Chapter_Equs.gif)

Consider on U − the normalized Runge–Lenz vector B given by

![
$$\\displaystyle{\\mathbf{B} = \\sqrt{ \\frac{\\mu {Q}^{4 } } {2\\left \\vert H\\right\\vert }}\\ \\mathbf{A}.}$$
](A272900_1_En_18_Chapter_Equt.gif)

Define also vector-valued functions I and K on U − by

![
$$\\displaystyle{\\mathbf{I} = \\frac{\\mathbf{J} + \\mathbf{B}} {2} ;\\quad \\mathbf{K} = \\frac{\\mathbf{J} -\\mathbf{B}} {2}.}$$
](A272900_1_En_18_Chapter_Equu.gif)

Theorem 18.9.

The functions I and K Poisson-commute with the Hamiltonian and satisfy the following Poisson-bracket relations on the negative-energy set U − :

![
$$\\displaystyle\\begin{array}{rcl} \\{I_{j},I_{k}\\}& =& \\varepsilon _{jkl}I_{l} {}\\\\ \\{K_{j},K_{k}\\}& =& \\varepsilon _{jkl}K_{l} {}\\\\ \\{I_{j},K_{k}\\}& =& 0. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ23.gif)

The functions I and K also satisfy the following algebraic relations:

![
$$\\displaystyle{{\\left \\vert \\mathbf{I}\\right\\vert }^{2} ={ \\left \\vert \\mathbf{K}\\right\\vert }^{2} = \\frac{\\mu {Q}^{4}} {8\\left \\vert H\\right\\vert }.}$$
](A272900_1_En_18_Chapter_Equv.gif)

In Theorem 18.9, we use the summation convention introduced in the previous subsection. The proof of this theorem is elementary but rather laborious, and is deferred to Sect. 18.6.

The span of the functions ![
$$I_{1},I_{2},I_{3}$$
](A272900_1_En_18_Chapter_IEq75.gif) and ![
$$K_{1},K_{2},K_{3}$$
](A272900_1_En_18_Chapter_IEq76.gif) on U −, which is the same as the span of the functions ![
$$B_{1},B_{2},B_{3}$$
](A272900_1_En_18_Chapter_IEq77.gif) and ![
$$J_{1},J_{2},J_{3}$$
](A272900_1_En_18_Chapter_IEq78.gif), forms a 6-dimensional Lie algebra under the Poisson bracket. Comparing the Poisson-bracket relations among the I's and among the K's to the relations among the basis elements ![
$$F_{1},F_{2},F_{3}$$
](A272900_1_En_18_Chapter_IEq79.gif) for so(3), we see that the span of the I's and the span of the K's are both isomorphic to so(3) [or, if you prefer, to su(2)]. Since also each I j commutes with each K k , the 6-dimensional Lie algebra spanned by the I's and the K's is isomorphic to so(3) ⊕ so(3). Meanwhile, as demonstrated in Exercise 4, so(3) ⊕ so(3) is isomorphic to the Lie algebra so(4). Since all the I's and K's Poisson-commute with the Hamiltonian, we say that the Kepler problem has so(4) symmetry. This is in contrast to the dynamics of a particle moving in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq80.gif) in the force generated by a typical radial potential, which has only so(3) symmetry.

To be more precise, "so(4) symmetry" prevails only on the negative-energy subset U − of the classical phase space. On the positive-energy subset U +, the span of the functions ![
$$B_{1},B_{2},B_{3}$$
](A272900_1_En_18_Chapter_IEq81.gif) and ![
$$J_{1},J_{2},J_{3}$$
](A272900_1_En_18_Chapter_IEq82.gif) again forms a 6-dimensional Lie algebra. This Lie algebra, however, is not isomorphic to so(4), but rather to so(3, 1), where so(3, 1) is the Lie algebra of the group of 4 × 4 matrices that preserve the quadratic form ![
$$x_{1}^{2} + x_{2}^{2} + x_{3}^{2} - x_{4}^{2}.$$
](A272900_1_En_18_Chapter_IEq83.gif) The reason the formulas on U + are different from those on U − is that calculations of the relevant Poisson brackets involves the function ![
$$H/\\left \\vert H\\right\\vert,$$
](A272900_1_En_18_Chapter_IEq84.gif) which has the value 1 on U + and the value − 1 on U −. (The factor of H comes from Lemma 18.7 and the factor of ![
$$\\left \\vert H\\right\\vert$$
](A272900_1_En_18_Chapter_IEq85.gif) from the factor of ![
$$\\sqrt{\\left \\vert H\\right\\vert }$$
](A272900_1_En_18_Chapter_IEq86.gif) in the definition of ![
$$\\mathbf{B}.$$
](A272900_1_En_18_Chapter_IEq87.gif))

### 18.4.3 The Quantum Runge–Lenz Vector

We now introduce the quantum counterpart ![
$$\\mathbf{\\hat{A}}$$
](A272900_1_En_18_Chapter_IEq88.gif) of the classical Runge–Lenz vector A. The quantum Runge–Lenz satisfies most of the same properties as the classical version, with a few small but crucial "quantum corrections."

Definition 18.10.

Define the quantum Runge–Lenz vector by

![
$$\\displaystyle{\\mathbf{\\hat{A}} = \\frac{1} {\\mu {Q}^{2}} \\frac{1} {2}\\left \(\\mathbf{P} \\times \\mathbf{\\hat{J}} -\\mathbf{\\hat{J}} \\times \\mathbf{P}\\right\) -\\frac{\\mathbf{X}} {\\left \\vert \\mathbf{X}\\right\\vert }.}$$
](A272900_1_En_18_Chapter_Equw.gif)

Note that in the quantum case, ![
$$-\\mathbf{\\hat{J}} \\times \\mathbf{P}$$
](A272900_1_En_18_Chapter_IEq89.gif) is not the same as ![
$$\\mathbf{P} \\times \\mathbf{\\hat{J},}$$
](A272900_1_En_18_Chapter_IEq90.gif) because of the noncommutativity of the factors. The particular combination of ![
$$\\mathbf{P} \\times \\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq91.gif) and ![
$$\\mathbf{\\hat{J}} \\times \\mathbf{P}$$
](A272900_1_En_18_Chapter_IEq92.gif) in Definition 18.10 is used because it is yields a self-adjoint operator. The Runge–Lenz vector can also be computed as

![
$$\\displaystyle{ \\mathbf{\\hat{A}} = \\frac{1} {\\mu {Q}^{2}}\\left \(\\mathbf{P} \\times \\mathbf{\\hat{J}} - i\\hslash \\mathbf{P}\\right\) -\\frac{\\mathbf{X}} {\\left \\vert \\mathbf{X}\\right\\vert }, }$$
](A272900_1_En_18_Chapter_Equ24.gif)

(18.19)

as will be verified in Sect. 18.6.

In the interests of keeping the exposition manageable, we will not concern ourselves in what follows with determining the precise domains on which various identities hold.

Proposition 18.11.

The quantum Runge–Lenz vector ![
$$\\mathbf{\\hat{A}}$$
](A272900_1_En_18_Chapter_IEq93.gif) satisfies the following relations:

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\hat{A}} \\cdot \\mathbf{\\hat{J}}& =& \\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{A}} = 0 \\\\ \\mathbf{\\hat{A}} \\cdot \\mathbf{\\hat{A}}& =& 1 + \\frac{2\\hat{H}} {\\mu {Q}^{4}} \\left \(\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}} + {\\hslash }^{2}\\right\).{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ25.gif)

(18.20)

Note that there is a "quantum correction" in (18.20); the factor of J ⋅J in the classical expression for A ⋅A is replaced by ![
$$\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}} + {\\hslash }^{2}.$$
](A272900_1_En_18_Chapter_IEq94.gif) This correction gives rise to a quantum correction in (18.22), which in turn is essential to getting the correct value for the energy eigenvalues in Corollary 18.17. The proof of this result and the other results of this section are deferred to Sect. 18.6.

Lemma 18.12.

The quantum Runge–Lenz vector ![
$$\\mathbf{\\hat{A}}$$
](A272900_1_En_18_Chapter_IEq95.gif) and the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq96.gif) satisfy the following commutation relations:

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {i\\hslash }\[\\hat{A}_{j,}\\hat{H}\]& =& 0 \\\\ \\frac{1} {i\\hslash }\[\\hat{A}_{j},\\hat{A}_{m}\]& =& - \\frac{2} {\\mu {Q}^{4}}\\varepsilon _{jml}\\hat{J}_{l}\\hat{H}.{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ26.gif)

(18.21)

Note that since ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq97.gif) commutes with rotations, it commutes with the angular momentum operators ![
$$\\hat{J}_{l}.$$
](A272900_1_En_18_Chapter_IEq98.gif) Thus, in (18.21), we could just as well write ![
$$\\hat{H}\\hat{J}_{l}$$
](A272900_1_En_18_Chapter_IEq99.gif) in place of ![
$$\\hat{J}_{l}\\hat{H}.$$
](A272900_1_En_18_Chapter_IEq100.gif) As in the classical case, if we normalize the components of the Runge–Lenz vector by dividing by the square root of the Hamiltonian, then these operators together with the angular momentum operators form a 6-dimensional Lie algebra.

Definition 18.13.

Let V − denote the negative-energy subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_18_Chapter_IEq101.gif) that is, the range of the spectral projection ![
$${\\mu }^{\\hat{H}}\(\(-\\infty,0\)\).$$
](A272900_1_En_18_Chapter_IEq102.gif) Let ![
$$\\vert \\hat{H}\\vert $$
](A272900_1_En_18_Chapter_IEq103.gif) denote the restriction to V − of the operator ![
$$-\\hat{H}.$$
](A272900_1_En_18_Chapter_IEq104.gif) On V − , define operators ![
$$\\mathbf{\\hat{B}}$$
](A272900_1_En_18_Chapter_IEq105.gif) by

![
$$\\displaystyle{\\mathbf{\\hat{B}} = \\frac{\\mu {Q}^{2}} {\\sqrt{2\\mu \\vert \\hat{H}\\vert }}\\ \\mathbf{\\hat{A}}.}$$
](A272900_1_En_18_Chapter_Equx.gif)

Define also operators ![
$$\\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq106.gif) and ![
$$\\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq107.gif) , as in the classical case, by

![
$$\\displaystyle{\\mathbf{\\hat{I}} = \\frac{\\mathbf{\\hat{J}} + \\mathbf{\\hat{B}}} {2} ;\\quad \\mathbf{\\hat{K}} = \\frac{\\mathbf{\\hat{J}} -\\mathbf{\\hat{B}}} {2}.}$$
](A272900_1_En_18_Chapter_Equy.gif)

It is possible to define the absolute value of any self-adjoint operator by means of the functional calculus. However, since the restriction of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq108.gif) to V − is, by definition, negative definite, the restriction of ![
$$\\vert \\hat{H}\\vert $$
](A272900_1_En_18_Chapter_IEq109.gif) to V − coincides with the restriction to V − of ![
$$-\\hat{H}.$$
](A272900_1_En_18_Chapter_IEq110.gif) The operator ![
$$1/\\sqrt{\\vert \\hat{H}\\vert }$$
](A272900_1_En_18_Chapter_IEq111.gif) is the operator with a restriction to the energy eigenspace with eigenvalue E n that is ![
$$1/\\sqrt{\\vert E_{n } \\vert }I.$$
](A272900_1_En_18_Chapter_IEq112.gif) The components of ![
$$\\mathbf{\\hat{B}}$$
](A272900_1_En_18_Chapter_IEq113.gif) are unbounded operators, defined on suitable dense subspaces of the Hilbert space V −.

Theorem 18.14.

The operators ![
$$\\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq114.gif) and ![
$$\\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq115.gif) commute with the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq116.gif) and satisfy the following commutation relations:

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {i\\hslash }\[\\hat{I}_{j},\\hat{I}_{k}\]& =& \\varepsilon _{jkl}\\hat{I}_{l} {}\\\\ \\frac{1} {i\\hslash }\[\\hat{K}_{j},\\hat{K}_{k}\]& =& \\varepsilon _{jkl}\\hat{K}_{l} {}\\\\ \\frac{1} {i\\hslash }\[\\hat{I}_{j},\\hat{K}_{k}\]& =& 0. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ27.gif)

These operators also satisfy the following algebraic relations:

![
$$\\displaystyle{ \\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}} = \\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}} = \\frac{\\mu {Q}^{4}} {8\\vert \\hat{H}\\vert }-\\frac{{\\hslash }^{2}} {4}. }$$
](A272900_1_En_18_Chapter_Equ28.gif)

(18.22)

### 18.4.4 Representations of so(4)

In light of the commutation relations in Theorem 18.14, we can define a representation π of the Lie algebra so(4) ≅so(3) ⊕ so(3) on the negative-energy subspace V − as follows:

![
$$\\displaystyle{ \\pi \(F_{j},0\) = \\frac{1} {i\\hslash }\\hat{I}_{j};\\quad \\pi \(0,F_{j}\) = \\frac{1} {i\\hslash }\\hat{K}_{j}. }$$
](A272900_1_En_18_Chapter_Equ29.gif)

(18.23)

It is therefore desirable to classify the irreducible finite-dimensional representations of so(3) ⊕ so(3), which we do in the following proposition.

Proposition 18.15.

Suppose V k and V l are irreducible representations of so(3) of dimensions 2k + 1 and 2l + 1, respectively. Then V k ⊗ Vl is irreducible when viewed as a representation of so(3) ⊕ so(3) as in Remark 16.49. Furthermore, every irreducible finite-dimensional representation of so(3) ⊕ so(3) is isomorphic to V k ⊗ V l for a unique ordered pair (k,l).

For any representation V k ⊗ V l of so(3) ⊕so(3), define Casimir operators C 1 and C 2 by the formula

![
$$\\displaystyle{C_{1} =\\sum _{ j=1}^{3}\\pi _{ k}{\(F_{j}\)}^{2} \\otimes I;\\quad C_{ 2} =\\sum _{ j=1}^{3}I \\otimes \\pi _{ l}{\(F_{j}\)}^{2}.}$$
](A272900_1_En_18_Chapter_Equz.gif)

Then we have

![
$$\\displaystyle{C_{1} = -k\(k + 1\)I;\\quad C_{2} = -l\(l + 1\)I.}$$
](A272900_1_En_18_Chapter_Equaa.gif)

Proof.

To classify the irreducible representations of so(3) ⊕ so(3), we could appeal to the general theory of representations of direct sums of Lie algebras. It is not hard, however, to give a direct proof using the same sort of reasoning we used in the classifications of irreducible representations of so(3). We will omit the details of this computation. The result on the Casimir operators follows easily from Proposition 17.8.

In any finite-dimensional subspace of V − that is invariant and irreducible under the action of so(3) ⊕ so(3) in (18.23), the Casimir operators are given by ![
$$C_{1} = -\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}/}{\\hslash }^{2}$$
](A272900_1_En_18_Chapter_IEq117.gif) and ![
$$C_{2} = -\\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}/{\\hslash }^{2}.$$
](A272900_1_En_18_Chapter_IEq118.gif) Since, by Theorem 18.14, ![
$$\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}} = \\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq119.gif) on V −, all of the irreducible representations of so(3) ⊕ so(3) that arise inside V − will be of the form V k ⊗ V k .

Theorem 18.16.

Let W (n) denote the eigenspace for the Hamiltonian with eigenvalue E n . Then W (n) is invariant and irreducible under the action of so(3) ⊕so(3) in (18.23). More specifically, we have the isomorphism

![
$$\\displaystyle{{W}^{\(n\)}\\mathop{\\cong}V _{ k} \\otimes V _{k},}$$
](A272900_1_En_18_Chapter_Equab.gif)

as representations of so(3) ⊕so(3), where ![
$$k = \(n - 1\)/2$$
](A272900_1_En_18_Chapter_IEq120.gif) and where V k is the irreducible representation of so(3) of dimension ![
$$2k + 1 = n.$$
](A272900_1_En_18_Chapter_IEq121.gif)

Corollary 18.17.

If n, k, and W (n) are as in Theorem 18.16, then for all ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq0121.gif) ∈ W (n), we have

![
$$\\displaystyle{\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}}\\psi = \\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}}\\psi = {\\hslash }^{2}k\(k + 1\).}$$
](A272900_1_En_18_Chapter_Equac.gif)

Using (18.22), the eigenvalue E n of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq122.gif) on W (n) can be solved for as

![
$$\\displaystyle{E_{n} = - \\frac{\\mu {Q}^{4}} {8{\\hslash }^{2}{\\left \(k + \\frac{1} {2}\\right\)}^{2}} = - \\frac{\\mu {Q}^{2}} {2{\\hslash }^{2}{n}^{2}}.}$$
](A272900_1_En_18_Chapter_Equad.gif)

The expression for E n in Corollary 18.17 is the same as in Theorem 18.3. The remarkable thing about the proof of Theorem 18.17 is that it is purely algebraic, relying only on the commutation relations among the operators ![
$$\\hat{I}_{k}$$
](A272900_1_En_18_Chapter_IEq123.gif) and ![
$$\\hat{K}_{l},$$
](A272900_1_En_18_Chapter_IEq124.gif) along with the relationship (18.22) between the Hamiltonian operator ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq125.gif) and the ![
$$\\hat{I}_{k}$$
](A272900_1_En_18_Chapter_IEq126.gif)'s and ![
$$\\hat{K}_{l}$$
](A272900_1_En_18_Chapter_IEq127.gif)'s.

Proof of Corollary 18.17. It is easily seen that the operators ![
$$\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq128.gif) and ![
$$\\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq129.gif), when restricted to an irreducible subspace for the action of so(3) ⊕ so(3), are equal to ![
$$-{\\hslash }^{2}C_{1}$$
](A272900_1_En_18_Chapter_IEq130.gif) and ![
$$-{\\hslash }^{2}C_{2},$$
](A272900_1_En_18_Chapter_IEq131.gif) where C 1 and C 2 are the Casimir operators appearing in Proposition 18.15. Thus, if W (n) is isomorphic to V k ⊗ V k , with ![
$$k = \(n - 1\)/2,$$
](A272900_1_En_18_Chapter_IEq132.gif) then ![
$$\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq133.gif) and ![
$$\\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq134.gif) will be equal to ![
$${\\hslash }^{2}k\(k + 1\)I,$$
](A272900_1_En_18_Chapter_IEq135.gif) as claimed. On the other hand, ![
$$\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq136.gif) and ![
$$\\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq137.gif) are related to the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq138.gif) by (18.22), from which we can solve for E n . ■

Proof of Theorem 18.16. Since each component of A and ![
$$\\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq139.gif) commutes with ![
$$\\hat{H},$$
](A272900_1_En_18_Chapter_IEq140.gif) each component of ![
$$\\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq141.gif) and ![
$$\\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq142.gif) will also commute with ![
$$\\hat{H}.$$
](A272900_1_En_18_Chapter_IEq143.gif) Each eigenspace of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq144.gif) is therefore invariant under the action of ![
$$\\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq145.gif) and ![
$$\\mathbf{\\hat{K}}.$$
](A272900_1_En_18_Chapter_IEq146.gif) Since the ![
$$\\hat{I}$$
](A272900_1_En_18_Chapter_IEq147.gif)'s and ![
$$\\hat{K}$$
](A272900_1_En_18_Chapter_IEq148.gif)'s are self-adjoint and W (n) is finite-dimensional, W (n) will decompose as a direct sum of irreducible invariant subspaces. By Proposition 18.15, these irreducible subspaces will be of the form V k ⊗ V l , where V k and V l are irreducible representations of so(3) of dimension 2k \+ 1 and 2l \+ 1, respectively. But now, the operators ![
$$\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq149.gif) and ![
$$\\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq150.gif), when restricted to one of the irreducible subspaces of W (n), are equal to ![
$$-{\\hslash }^{2}C_{1}$$
](A272900_1_En_18_Chapter_IEq151.gif) and ![
$$-{\\hslash }^{2}C_{2},$$
](A272900_1_En_18_Chapter_IEq152.gif) where C 1 and C 2 are the Casimir operators appearing in Proposition 18.15. Since ![
$$\\mathbf{\\hat{I}} \\cdot \\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq153.gif) ![
$$= \\mathbf{\\hat{K}} \\cdot \\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq154.gif) on all of V −, the eigenvalues of C 1 and C 2 must be equal on each irreducible subspace of W (n). Thus, we must have k = l, meaning that only irreducible subspaces of the form V k ⊗ V k arise.

Now, under the isomorphism of some irreducible subspace of W (n) with V k ⊗ V k , the operators ![
$$\\hat{I}_{k}$$
](A272900_1_En_18_Chapter_IEq155.gif) and ![
$$\\hat{K}_{k}$$
](A272900_1_En_18_Chapter_IEq156.gif) act as ![
$$i\\hslash F_{k} \\otimes I$$
](A272900_1_En_18_Chapter_IEq157.gif) and ![
$$i\\hslash I \\otimes F_{k},$$
](A272900_1_En_18_Chapter_IEq158.gif) respectively, where the F k 's are the usual basis for so(3). Since ![
$$\\mathbf{\\hat{J}} = \\mathbf{\\hat{I}} + \\mathbf{\\hat{K}},$$
](A272900_1_En_18_Chapter_IEq159.gif) each ![
$$\\hat{J}_{k}$$
](A272900_1_En_18_Chapter_IEq160.gif) acts as ![
$$i\\hslash \(F_{k} \\otimes I + I \\otimes F_{k}\).$$
](A272900_1_En_18_Chapter_IEq161.gif) This means that V k ⊗ V k , under the action of the ![
$$\\hat{J}_{k}$$
](A272900_1_En_18_Chapter_IEq162.gif)'s, can be thought of as a tensor product of two representations of so(3), viewed as another representation of so(3) as in Definition 16.48. Viewed this way, V k ⊗ V k decomposes as in Proposition 17.23 as

![
$$\\displaystyle{ V _{k} \\otimes V _{k}\\mathop{\\cong}V _{0} \\oplus V _{1} \\oplus \\cdots \\oplus V _{2k}. }$$
](A272900_1_En_18_Chapter_Equ30.gif)

(18.24)

On the other hand, we know from Theorem 18.3 that W (n) decomposes under the action of so(3) as

![
$$\\displaystyle{ V _{0} \\oplus V _{1} \\oplus \\cdots \\oplus V _{n-1}. }$$
](A272900_1_En_18_Chapter_Equ31.gif)

(18.25)

Thus, the space of the form V k ⊗ V k must be all of W (n); if there were another term then the trivial representation V 0 would occur more than once in W (n). This being the case, matching the decompositions (18.24) and (18.25) requires that ![
$$2k = n - 1,$$
](A272900_1_En_18_Chapter_IEq163.gif) as claimed in the theorem.

The proof of Theorem 18.16 relies to some extent on the results of Sect. 18.3. Using only algebraic manipulations involving the Runge–Lenz vector, however, we could still argue that the eigenvalues of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq164.gif) must be of the form given in Corollary 18.17. We would not, however, know that for every positive integer n, the number E n is actually an eigenvalue for ![
$$\\hat{H}.$$
](A272900_1_En_18_Chapter_IEq165.gif) We would also not know that each eigenspace W (n) is irreducible under the action of so(4); conceivably, based only on the algebra, W (n) could have, say, dimension 2n 2 instead of n 2.

## 18.5 The Role of Spin

The spin of the electron is 1/2. As discussed in Sect.​ 17.​8, this means that the Hilbert space for an electron is ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{1/2},$$
](A272900_1_En_18_Chapter_IEq166.gif) where V 1 ∕ 2 is a 2-dimensional vector space that carries an irreducible projective unitary representation of SO(3). Up to now, we have neglected the spin in our calculations. The reason for this omission is simple: to first approximation, the spin plays no role in the calculation. Specifically, in the simplest model of a hydrogen atom with spin, the Hamiltonian is simply ![
$$\\hat{H} \\otimes I,$$
](A272900_1_En_18_Chapter_IEq167.gif) where ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq168.gif) is the operator in (18.7), acting on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq169.gif) For any n > 0, we can obtain a basis of eigenvectors for ![
$$\\hat{H} \\otimes I$$
](A272900_1_En_18_Chapter_IEq170.gif) with eigenvalue E n by taking vectors of the form ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq0122.gif) n, l, m ⊗ e j , where the ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq0123.gif) n, l, m 's are as in (18.10) and where {e 1, e 2} forms a basis for V 1 ∕ 2.

Now, from the point of view of rotational symmetry, the basis ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq0124.gif) n, l, m ⊗ e j is not the most natural one. Rather, we should decompose the eigenspaces into irreducible invariant subspaces for the (projective) action of SO(3), where SO(3) acts on both ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_18_Chapter_IEq171.gif) and V 1 ∕ 2. We have already decomposed the eigenspaces inside ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_18_Chapter_IEq172.gif) into irreducible invariant subspaces, namely the span of ![
$$\\psi$$
](A272900_1_En_18_Chapter_IEq0126.gif) n, l, m where n and l are fixed and m varies. Thus, to obtain the irreducible invariant subspaces inside ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{1/2},$$
](A272900_1_En_18_Chapter_IEq173.gif) we use the method of "addition of angular momentum" from Sect.​ 17.​9.​ According to Proposition 17.22, V l ⊗ V 1 ∕ 2 is irreducible if l = 0 and isomorphic to ![
$$V _{l+1/2} \\oplus V _{l-1/2}$$
](A272900_1_En_18_Chapter_IEq174.gif) if l > 0. Consider, for example, the case n = 3, l = 1, the so-called "3p states" in traditional chemistry terminology. Since V 1 ⊗ V 1 ∕ 2 decomposes as ![
$$V _{3/2} \\oplus V _{1/2},$$
](A272900_1_En_18_Chapter_IEq175.gif) when we take spin into account, we obtain a 4-dimensional space and a 2-dimensional space. We can obtain bases for these spaces by tracing through the proof of Proposition 17.22.

The decomposition described in the previous paragraph is essential when considering the "fine structure" of hydrogen. Our model of hydrogen using the Hamiltonian (18.7) is only a first approximation. More realistic models take into account various corrections, including radiative corrections, a finite size for the nucleus, and "spin–orbit coupling," among other things. The notion of spin–orbit coupling adds a term into the Hamiltonian involving the operator ![
$$\\mathbf{\\hat{J}} \\cdot \\mathbf{\\sigma },$$
](A272900_1_En_18_Chapter_IEq176.gif) where σ 1, σ 2, and σ 3 are the operators describing the action of so(3) on V 1 ∕ 2. When this term is included, the Hamiltonian is no longer of the form A ⊗ I for some operator A on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_18_Chapter_IEq177.gif) Thus, we can no longer simply append the spin to the end of the computation, but must take it into account from the beginning.

The various corrections to the Hamiltonian for the hydrogen atom have the effect of reducing the multiplicities of the eigenvalues. Almost any correction we make, for example, will destroy the independence of the eigenvalue on l for a given n, simply because the correction terms in the Hamiltonian will not commute with the quantum Runge–Lenz vector. Nevertheless, all of the corrections that make up the fine structure of hydrogen preserve the rotational symmetry of the problem. Thus, the same irreducible representations of SO(3) that we had in the simple model will appear after the corrections are made. For n = 2, l = 1, for example, we will still have a 4-dimensional space and 2-dimensional space, but these two spaces will no longer have the same energy.

## 18.6 Runge–Lenz Calculations

In this section, we fill in many of the computations that we passed over without proof in Sect. 18.4. Although all the calculations are, in principle, elementary, there are a number of nonobvious tricks that help simplify the algebra. We will make frequent use of the concepts of functions that transform like vectors (on the classical side) and of vector operators (on the quantum side), including Propositions 17.25 and 17.27 (Sect.​ 17.​10). In particular, we note that the position x, the momentum p, the angular momentum j, and the Runge–Lenz vector A all transform like vectors, and that the corresponding quantum quantities are all vector operators. (Compare Exercise 7.) In the "![
$$\\varepsilon$$
](A272900_1_En_18_Chapter_IEq178.gif)" notation of Sect. 18.4.1, Proposition 17.27 takes the form

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[C_{j},\\hat{J}_{k}\] = \\frac{1} {i\\hslash }\[\\hat{J}_{j},C_{k}\] =\\varepsilon _{jkl}C_{l}. }$$
](A272900_1_En_18_Chapter_Equ32.gif)

(18.26)

In the quantum mechanical calculations, there are a number of "quantum corrections," in which dot products and cross products of vector operators do not behave as they do in the classical case.

Lemma 18.18.

The ![
$$\\varepsilon$$
](A272900_1_En_18_Chapter_IEq179.gif) -function in Definition 18.6 satisfies the relations

![
$$\\displaystyle\\begin{array}{rcl} \\varepsilon _{jkl}\\varepsilon _{jmn}& =& \\delta _{km}\\delta _{ln} -\\delta _{kn}\\delta _{lm} {}\\\\ \\varepsilon _{jkl}\\varepsilon _{jkm}& =& 2\\delta _{lm}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ33.gif)

The proof of these results is not difficult and is left to the reader (Exercise 6). The following identities involving the cross product of vector operators will be useful to us.

Lemma 18.19.

If C, D , and E are arbitrary vector operators, we have

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{C} \\cdot \(\\mathbf{D} \\times \\mathbf{E}\)& =& \(\\mathbf{C} \\times \\mathbf{D}\) \\cdot \\mathbf{E}{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ34.gif)

(18.27)

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{C} \\times \\mathbf{D} + \\mathbf{D} \\times \\mathbf{C}& =& \\varepsilon _{jkl}\[C_{k},D_{l}\]{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ35.gif)

(18.28)

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{C} \\times \\mathbf{C}& =& \\frac{1} {2}\\varepsilon _{jkl}\[C_{k},C_{l}\].{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ36.gif)

(18.29)

In particular, if the different components of C commute, then C × C = 0. Finally,

![
$$\\displaystyle{ \(\\mathbf{C} \\times \(\\mathbf{D} \\times \\mathbf{E}\)\)_{j} = C_{k}D_{j}E_{k} - C_{k}D_{k}E_{j}. }$$
](A272900_1_En_18_Chapter_Equ37.gif)

(18.30)

As special cases of these results, we have

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\hat{J}} \\times \\mathbf{P} + \\mathbf{P} \\times \\mathbf{\\hat{J}}& =& 2i\\hslash \\mathbf{P}{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ38.gif)

(18.31)

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\hat{J}} \\times \\mathbf{\\hat{J}}& =& i\\hslash \\mathbf{\\hat{J}}{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ39.gif)

(18.32)

Note that if the entries of D and E commute, then the right-hand side of (18.30) reduces to the classical expression, (C ⋅E)D − (C ⋅D)E. Using (18.31), we can easily verify the alternative expression (18.19) for the Runge–Lenz vector.

Proof.

The right-hand side of (18.27) is computed as ![
$$\\varepsilon _{jkl}C_{k}D_{l}E_{j}.$$
](A272900_1_En_18_Chapter_IEq180.gif) If we note that ![
$$\\varepsilon _{jkl} =\\varepsilon _{klj}$$
](A272900_1_En_18_Chapter_IEq181.gif) and then relabel the indices, we obtain ![
$$\\varepsilon _{jkl}C_{j}D_{k}E_{l},$$
](A272900_1_En_18_Chapter_IEq182.gif) which is equal to the left-hand side of (18.27). For (18.28), we compute that

![
$$\\displaystyle\\begin{array}{rcl} \(\\mathbf{C} \\times \\mathbf{D} + \\mathbf{D} \\times \\mathbf{C}\)_{j}& =& \\varepsilon _{jkl}C_{k}D_{l} +\\varepsilon _{jkl}D_{k}C_{l} \\\\ & =& \\varepsilon _{jkl}C_{k}D_{l} +\\varepsilon _{jkl}C_{l}D_{k} -\\varepsilon _{jkl}\[C_{l},D_{k}\].{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ40.gif)

(18.33)

If we note that ![
$$\\varepsilon _{jkl} = -\\varepsilon _{jlk}$$
](A272900_1_En_18_Chapter_IEq183.gif) and then relabel the indices k and l, we see that ![
$$\\varepsilon _{jkl}C_{l}D_{k} = -\\varepsilon _{jkl}C_{k}D_{l},$$
](A272900_1_En_18_Chapter_IEq184.gif) so that the first two terms in the second line of (18.33) cancel. The remaining term can be put into the claimed form by relabeling the indices k and l. The identity (18.29) is just the D = C case of (18.28). Finally, (18.30) follows easily from Lemma 18.18.

To obtain (18.31) and (18.32), we apply (18.28) and (18.29), respectively. Since both ![
$$\\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq185.gif) and P are vector operators, the desired result follows easily from Lemma 18.18.

We now turn to the proofs of the results of Sect. 18.4. We prove only the quantum versions of the results, since the classical results are extremely similar, except that certain quantum corrections can be ignored.

Proof of Lemma 18.12, First Part. We begin by showing that ![
$$\\hat{A}_{j}$$
](A272900_1_En_18_Chapter_IEq186.gif) commutes with ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq187.gif) for each j. Since ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq188.gif) commutes with ![
$$\\mathbf{\\hat{J}},$$
](A272900_1_En_18_Chapter_IEq189.gif) we have

![
$$\\displaystyle{\[\\hat{A}_{j},\\hat{H}\] = \\frac{1} {\\mu {Q}^{2}} \\frac{1} {2}\\left \(\\varepsilon _{jkl}\[P_{k},\\hat{H}\]\\hat{J}_{l} -\\hat{ J}_{k}\[P_{l},\\hat{H}\]\\right\) -\\left \[\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert },\\hat{H}\\right\].}$$
](A272900_1_En_18_Chapter_Equae.gif)

Meanwhile, since the P's commute among themselves, we have

![
$$\\displaystyle{\[P_{k},\\hat{H}\] = -{Q}^{2}\\left \[P_{ k}, \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\right\] = -i\\hslash {Q}^{2}\\frac{X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}.}$$
](A272900_1_En_18_Chapter_Equaf.gif)

Thus,

![
$$\\displaystyle\\begin{array}{rcl} \\varepsilon _{jkl}\[P_{k},\\hat{H}\]\\hat{J}_{l}& =& -i\\hslash {Q}^{2}\\varepsilon _{ jkl}\\varepsilon _{lmn}\\frac{X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}} X_{m}P_{n} \\\\ & =& -i\\hslash {Q}^{2}\(\\delta _{ jm}\\delta _{kn} -\\delta _{jn}\\delta _{km}\)\\frac{X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}} X_{m}P_{n} \\\\ & =& -i\\hslash {Q}^{2} \\frac{1} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}\(X_{n}X_{j}P_{n} - X_{m}X_{m}P_{j}\) \\\\ & =& -i\\hslash {Q}^{2} \\frac{1} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}\\left \(X_{j}\(\\mathbf{X} \\cdot \\mathbf{P}\) - \(\\mathbf{X} \\cdot \\mathbf{X}\)P_{j}\\right\).{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ41.gif)

(18.34)

We compute ![
$$\\varepsilon _{jkl}\\hat{J}_{k}\[P_{l},\\hat{H}\]$$
](A272900_1_En_18_Chapter_IEq190.gif) in a similar way. Note that ![
$$\\hat{J}_{k} =\\varepsilon _{kmn}X_{m}P_{n} =\\varepsilon _{kmn}P_{n}X_{m},$$
](A272900_1_En_18_Chapter_IEq191.gif) since X m and P n commute except when m = n, in which case ![
$$\\varepsilon _{kmn} = 0.$$
](A272900_1_En_18_Chapter_IEq192.gif) The result is

![
$$\\displaystyle{\\varepsilon _{jkl}\\hat{J}_{k}\[P_{l},\\hat{H}\] = -i\\hslash \(P_{j}\(\\mathbf{X} \\cdot \\mathbf{X}\) - \(\\mathbf{P} \\cdot \\mathbf{X}\)X_{j}\) \\frac{1} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}.}$$
](A272900_1_En_18_Chapter_Equag.gif)

Meanwhile, since the X's commute among themselves, we have

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \[\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert },\\hat{H}\\right\] \\\\ & =& \\left \[\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert }, \\frac{{P}^{2}} {2\\mu } \\right\] \\\\ & =& \\frac{1} {2\\mu }\\left \[\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert },P_{k}\\right\]P_{k} + \\frac{1} {2\\mu }P_{k}\\left \[\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert },P_{k}\\right\] \\\\ & =& \\frac{i\\hslash } {2\\mu } \\left \( \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\delta _{jk} -\\frac{X_{j}X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}} \\right\)P_{k} + \\frac{i\\hslash } {2\\mu } P_{k}\\left \( \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\delta _{jk} -\\frac{X_{j}X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}} \\right\) \\\\ & =& \\frac{i\\hslash } {2\\mu } \\left \( \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }P_{j} -\\frac{X_{j}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}\(\\mathbf{X} \\cdot \\mathbf{P}\)\\right\) + \\frac{i\\hslash } {2\\mu } \\left \(P_{j} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } - \(\\mathbf{P} \\cdot \\mathbf{X}\)\\frac{X_{j}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}\\right\).{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ42.gif)

(18.35)

It is now a simple matter to compute ![
$$\[\\hat{A}_{j},\\hat{H}\]$$
](A272900_1_En_18_Chapter_IEq193.gif) by combining (18.34) and (18.35) and verify that everything cancels. We have, for example, a term involving ![
$$\(X_{j}/{\\left \\vert \\mathbf{X}\\right\\vert }^{3}\)\(\\mathbf{X} \\cdot \\mathbf{P}\)$$
](A272900_1_En_18_Chapter_IEq194.gif) in (18.34) and a canceling term in (18.35).

Before proceeding with the remaining results concerning the Runge–Lenz vector, we verify some results that will be needed later. There are some quantum corrections compared to the corresponding classical results.

Lemma 18.20.

As in the classical case, the following "orthogonality" relations among vector operators hold:

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\hat{J}} \\cdot \\mathbf{P}& =& \\mathbf{P} \\cdot \\mathbf{\\hat{J}} = 0{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ43.gif)

(18.36)

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\hat{J}} \\cdot \\mathbf{X}& =& \\mathbf{X} \\cdot \\mathbf{\\hat{J}} = 0{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ44.gif)

(18.37)

![
$$\\displaystyle\\begin{array}{rcl} \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) \\cdot \\mathbf{\\hat{J}}& =& \\mathbf{\\hat{J}} \\cdot \\mathbf{\(P} \\times \\mathbf{\\hat{J}}\) = 0.{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ45.gif)

(18.38)

Meanwhile, there is a quantum correction in the dot product between P and ![
$$\\mathbf{P} \\times \\mathbf{\\hat{J}},$$
](A272900_1_En_18_Chapter_IEq195.gif) as follows:

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{P} \\cdot \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)& =& 0{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ46.gif)

(18.39)

![
$$\\displaystyle\\begin{array}{rcl} \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) \\cdot \\mathbf{P}& =& 2i\\hslash \(\\mathbf{P} \\cdot \\mathbf{P}\).{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ47.gif)

(18.40)

Finally, we have

![
$$\\displaystyle\\begin{array}{rcl} \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) \\cdot \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)& =& \(\\mathbf{P} \\cdot \\mathbf{P}\)\(\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}}\){}\\end{array}$$
](A272900_1_En_18_Chapter_Equ48.gif)

(18.41)

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{X} \\cdot \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)& =& \\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}}{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ49.gif)

(18.42)

![
$$\\displaystyle\\begin{array}{rcl} \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) \\cdot \\mathbf{X}& =& \\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}} + 2i\\hslash \\mathbf{P} \\cdot \\mathbf{X.}{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ50.gif)

(18.43)

Proof.

By (18.27) and (18.29), we have

![
$$\\displaystyle{\\mathbf{\\hat{J}} \\cdot \\mathbf{P = \(X} \\times \\mathbf{P}\) \\cdot \\mathbf{P = X} \\cdot \(\\mathbf{P \\times P}\) = 0,}$$
](A272900_1_En_18_Chapter_Equah.gif)

since the different components of P commute. The same reasoning shows that ![
$$\\mathbf{P} \\cdot \\mathbf{\\hat{J},}$$
](A272900_1_En_18_Chapter_IEq196.gif) ![
$$\\mathbf{\\hat{J}} \\cdot \\mathbf{X,}$$
](A272900_1_En_18_Chapter_IEq197.gif) and ![
$$\\mathbf{X} \\cdot \\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq198.gif) are all zero. To compute ![
$$\(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) \\cdot \\mathbf{\\hat{J},}$$
](A272900_1_En_18_Chapter_IEq199.gif) we first use (18.27), then use (18.32), and then use that ![
$$\\mathbf{P} \\cdot \\mathbf{\\hat{J}} = 0.$$
](A272900_1_En_18_Chapter_IEq200.gif) For ![
$$\\mathbf{\\hat{J}} \\cdot \\mathbf{\(P} \\times \\mathbf{\\hat{J}}\),$$
](A272900_1_En_18_Chapter_IEq201.gif) we rewrite ![
$$\\mathbf{P} \\times \\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq202.gif) in terms of ![
$$\\mathbf{\\hat{J}} \\times \\mathbf{P},$$
](A272900_1_En_18_Chapter_IEq203.gif) using (18.31). The correction term involves P, which has a dot product of zero with ![
$$\\mathbf{\\hat{J}},$$
](A272900_1_En_18_Chapter_IEq204.gif) and so the answer is again zero.

We use (18.27) and (18.29) again to establish (18.39). To get (18.40), we first rewrite ![
$$\\mathbf{P} \\times \\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq205.gif) in terms of ![
$$\\mathbf{\\hat{J}} \\times \\mathbf{P}$$
](A272900_1_En_18_Chapter_IEq206.gif) using (18.31) and then apply (18.39). To establish (18.41), we apply (18.27) and then (18.30), giving

![
$$\\displaystyle{ \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) \\cdot \(\\mathbf{P} \\times \\mathbf{\\hat{J}}\) = P_{j}\\hat{J}_{k}P_{j}\\hat{J}_{k} - P_{j}J_{k}P_{k}\\hat{J}_{j}. }$$
](A272900_1_En_18_Chapter_Equ51.gif)

(18.44)

The second term on the right-hand side of (18.44) is zero because ![
$$\\mathbf{\\hat{J}} \\cdot \\mathbf{P} = 0.$$
](A272900_1_En_18_Chapter_IEq207.gif) For the first term, we move ![
$$\\hat{J}_{k}$$
](A272900_1_En_18_Chapter_IEq208.gif) to the right past P j . This generates the term we want plus a correction term equal to ![
$$i\\hslash \\varepsilon _{kjl}P_{j}P_{l}\\hat{J}_{k}$$
](A272900_1_En_18_Chapter_IEq209.gif). The correction term is zero because P j and P l commute and ![
$$\\varepsilon _{kjl}$$
](A272900_1_En_18_Chapter_IEq210.gif) is changes sign under interchange of j and l. The identity (18.42) follows immediately from (18.27) and the definition of ![
$$\\mathbf{\\hat{J}}.$$
](A272900_1_En_18_Chapter_IEq211.gif) The identity (18.43) follows from (18.27) and (18.28).

Lemma 18.21.

For all j and m, we have

![
$$\\displaystyle{\[\(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)_{j},\(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)_{m}\] = -i\\hslash \(\\mathbf{P} \\cdot \\mathbf{P}\)\\varepsilon _{jml}\\hat{J}_{l}.}$$
](A272900_1_En_18_Chapter_Equai.gif)

Proof.

In computing ![
$$\[P_{k}\\hat{J}_{l},P_{n}\\hat{J}_{o}\],$$
](A272900_1_En_18_Chapter_IEq212.gif) we use repeatedly the product rule for commutators (Point 3 of Proposition 3.15). We obtain four terms, one of which is zero (the term involving [P k , P n ]). We use Proposition 17.27 (in the form (18.26)) to evaluate all remaining terms, giving

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{1} {i\\hslash }\[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},\\varepsilon _{mno}P_{n}\\hat{J}_{o}\] \\\\ & =& \\varepsilon _{jkl}\\varepsilon _{mno}\\left \(P_{k}\[\\hat{J}_{l},P_{n}\]\\hat{J}_{o} + P_{n}P_{k}\[\\hat{J}_{l},\\hat{J}_{o}\] + P_{n}\[P_{k},\\hat{J}_{o}\]\\hat{J}_{l}\\right\).{}\\end{array}$$
](A272900_1_En_18_Chapter_Equ52.gif)

(18.45)

Let us compute the first of the three terms on the right-hand side of (18.45). Using Lemma 18.18 and the fact that P is a vector operator, we get

![
$$\\displaystyle\\begin{array}{rcl} \\varepsilon _{jkl}\\varepsilon _{mno}P_{k}\[\\hat{J}_{l},P_{n}\]\\hat{J}_{o}& =& \\varepsilon _{jkl}\(\\delta _{op}\\delta _{ml} -\\delta _{ol}\\delta _{mp}\)P_{k}P_{p}\\hat{J}_{o} {}\\\\ & =& \\varepsilon _{jkm}P_{k}P_{p}\\hat{J}_{p} -\\varepsilon _{jko}P_{k}P_{m}\\hat{J}_{o} {}\\\\ & =& \\varepsilon _{jkm}P_{k}\(\\mathbf{P} \\cdot \\mathbf{\\hat{J}}\) - P_{m}\(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)_{j}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ53.gif)

If we compute the second and third terms similarly, we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{1} {i\\hslash }\[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},\\varepsilon _{mno}P_{n}\\hat{J}_{o}\] =\\varepsilon _{jkm}P_{k}\(\\mathbf{P} \\cdot \\mathbf{\\hat{J}}\) - P_{m}\(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)_{j} {}\\\\ & +& \(\\mathbf{P} \\times \\mathbf{P}\)_{j}\\hat{J}_{m} -\\varepsilon _{jkm}P_{k}\(\\mathbf{P} \\cdot \\mathbf{\\hat{J}}\) + P_{m}\(\\mathbf{P} \\times \\mathbf{\\hat{J}}\)_{j} - \(\\mathbf{P} \\cdot \\mathbf{P}\)\\varepsilon _{jml}\\hat{J}_{l}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ54.gif)

Three of the above terms are zero (those involving ![
$$\\mathbf{P} \\cdot \\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq213.gif) or P × P) and two other terms cancel, leaving us with

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},\\varepsilon _{mno}P_{n}\\hat{J}_{o}\] = -\(\\mathbf{P} \\cdot \\mathbf{P}\)\\varepsilon _{jml}\\hat{J}_{l},}$$
](A272900_1_En_18_Chapter_Equaj.gif)

as claimed.

We now continue with the proof of the properties of the Runge–Lenz vector.

Proof Proposition 18.11.

From the first set of orthogonality relations in Lemma 18.20, we can see easily that ![
$$\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{A}} = \\mathbf{\\hat{A}} \\cdot \\mathbf{\\hat{J}} = 0.$$
](A272900_1_En_18_Chapter_IEq214.gif) Meanwhile, using the expression (18.19) for ![
$$\\mathbf{\\hat{A}}$$
](A272900_1_En_18_Chapter_IEq215.gif) and expanding out ![
$$\\mathbf{\\hat{A}} \\cdot \\mathbf{\\hat{A}}$$
](A272900_1_En_18_Chapter_IEq216.gif) yields, after a little simplification,

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{\\hat{A}} \\cdot \\mathbf{\\hat{A}}& =& 1 +{ \\frac{1} {\\mu }^{2}{Q}^{4}}\\left \(\\mathbf{P} \\cdot \\mathbf{P}\\right\)\\left \(\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}} + {\\hslash }^{2}\\right\) {}\\\\ & -& \\frac{1} {\\mu {Q}^{2}}\\left \(2\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } + i\\hslash \\left \(\\mathbf{P} \\cdot \\frac{\\mathbf{X}} {\\left \\vert \\mathbf{X}\\right\\vert } -\\frac{\\mathbf{X}} {\\left \\vert \\mathbf{X}\\right\\vert } \\cdot \\mathbf{P}\\right\)\\right\). {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ55.gif)

Now,

![
$$\\displaystyle{\\frac{\\mathbf{X}} {\\left \\vert \\mathbf{X}\\right\\vert } \\cdot \\mathbf{P - P} \\cdot \\frac{\\mathbf{X}} {\\left \\vert \\mathbf{X}\\right\\vert } = i\\hslash \\left \(\\frac{\\delta _{kk}} {\\left \\vert \\mathbf{X}\\right\\vert } -\\frac{X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{2}} \\frac{X_{k}} {\\left \\vert \\mathbf{X}\\right\\vert } \\right\) = 2i\\hslash \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }.}$$
](A272900_1_En_18_Chapter_Equak.gif)

Thus,

![
$$\\displaystyle{\\mathbf{\\hat{A}} \\cdot \\mathbf{\\hat{A}} = 1 + \\left \(\(\\mathbf{\\hat{J}} \\cdot \\mathbf{\\hat{J}}\) + {\\hslash }^{2}\\right\) \\frac{2} {\\mu {Q}^{4}}\\left \(\\frac{\(\\mathbf{P} \\cdot \\mathbf{P}\)} {2\\mu } - {Q}^{2} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\right\),}$$
](A272900_1_En_18_Chapter_Equal.gif)

as claimed.

Proof of Lemma 18.12, Second Part.

We write ![
$$\\mathbf{\\hat{A}}$$
](A272900_1_En_18_Chapter_IEq217.gif) in the form given in (18.19). In computing the commutator of ![
$$\\hat{A}_{j}$$
](A272900_1_En_18_Chapter_IEq218.gif) with ![
$$\\hat{A}_{m},$$
](A272900_1_En_18_Chapter_IEq219.gif) we get several different types of terms, which we compute one at a time. Of course, the commutator of ![
$$X_{j}/\\left \\vert \\mathbf{X}\\right\\vert$$
](A272900_1_En_18_Chapter_IEq220.gif) with ![
$$X_{m}/\\left \\vert \\mathbf{X}\\right\\vert$$
](A272900_1_En_18_Chapter_IEq221.gif) is zero. The commutator of the ![
$$\\mathbf{P} \\times \\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq222.gif) terms has been computed in Lemma 18.21.

Meanwhile, to compute the commutator of ![
$$P_{k}\\hat{J}_{l}$$
](A272900_1_En_18_Chapter_IEq223.gif) with ![
$$X_{m}\(1/\\left \\vert \\mathbf{X}\\right\\vert \),$$
](A272900_1_En_18_Chapter_IEq224.gif) we again get four terms and, again, one of these is zero, namely the one involving ![
$$\\{\\hat{J}_{l},1/\\left \\vert \\mathbf{X}\\right\\vert \\},$$
](A272900_1_En_18_Chapter_IEq225.gif) since ![
$$1/\\left \\vert \\mathbf{X}\\right\\vert$$
](A272900_1_En_18_Chapter_IEq226.gif) is invariant under rotations. We have, then,

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{1} {i\\hslash }\\left \[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},X_{m} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\right\] {}\\\\ & =& \\varepsilon _{jkl}\[P_{k},X_{m}\]\\hat{J}_{l} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } +\\varepsilon _{jkl}P_{k}\[\\hat{J}_{l},X_{m}\] \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } +\\varepsilon _{jkl}X_{m}\\left \[P_{k}, \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\right\]\\hat{J}_{l} {}\\\\ & =& -\\varepsilon _{jkl}\\delta _{km}\\hat{J}_{l} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } +\\varepsilon _{jkl}\\varepsilon _{lmn}P_{k}X_{n} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } +\\varepsilon _{jkl}X_{m}\\frac{X_{k}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}} \\varepsilon _{lno}X_{n}P_{o}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ56.gif)

If we apply Lemma 18.18 and carry out some computations similar to ones we have already performed, we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{1} {i\\hslash }\\left \[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},X_{m} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert }\\right\] = -\\varepsilon _{jml}\\hat{J}_{l} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } +\\delta _{jm}\(\\mathbf{P} \\cdot \\mathbf{X}\) \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } \\\\ & +& X_{m}X_{j} \\frac{1} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}}\(\\mathbf{X} \\cdot \\mathbf{P}\) -\\left \(P_{m}\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert } + \\frac{X_{m}} {\\left \\vert \\mathbf{X}\\right\\vert } P_{j}\\right\). {}\\end{array}$$
](A272900_1_En_18_Chapter_Equ57.gif)

(18.46)

In a commutator of the form ![
$$\[\\alpha _{j} +\\beta _{j},\\alpha _{m} +\\beta _{m}\],$$
](A272900_1_En_18_Chapter_IEq227.gif) the terms involving the commutator of an α with a β will be ![
$$\[\\alpha _{j},\\beta _{m}\] + \[\\beta _{j},\\alpha _{m}\],$$
](A272900_1_En_18_Chapter_IEq228.gif) which is equal to ![
$$\[\\alpha _{j},\\beta _{m}\] - \[\\alpha _{m},\\beta _{j}\].$$
](A272900_1_En_18_Chapter_IEq229.gif) This quantity is skew-symmetric j with m, meaning that it changes sign when we interchange j with m. Thus, terms in (18.46) that are symmetric in j and m will disappear when we compute the full commutator of ![
$$\\hat{A}_{j}$$
](A272900_1_En_18_Chapter_IEq230.gif) with ![
$$\\hat{A}_{m}.$$
](A272900_1_En_18_Chapter_IEq231.gif) Thus, the second and third terms in (18.46) can be ignored. In the last term, we can commute P m past X j to obtain

![
$$\\displaystyle{ P_{m}\\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert } + \\frac{X_{m}} {\\left \\vert \\mathbf{X}\\right\\vert } P_{j} = \\frac{X_{j}} {\\left \\vert \\mathbf{X}\\right\\vert } P_{m} + \\frac{X_{m}} {\\left \\vert \\mathbf{X}\\right\\vert } P_{j} - i\\hslash \\left \(\\frac{\\delta _{jm}} {\\left \\vert \\mathbf{X}\\right\\vert } -\\frac{X_{j}X_{m}} {{\\left \\vert \\mathbf{X}\\right\\vert }^{3}} \\right\), }$$
](A272900_1_En_18_Chapter_Equ58.gif)

(18.47)

which is also symmetric. Thus, only the first term in (18.46) contributes to the computation of ![
$$\[\\hat{A}_{j},\\hat{A}_{m}\].$$
](A272900_1_En_18_Chapter_IEq232.gif) This term is skew-symmetric in j and m and will be doubled when we compute ![
$$\[\\hat{A}_{j},\\hat{A}_{m}\].$$
](A272900_1_En_18_Chapter_IEq233.gif)

Now, it is straightforward to compute ![
$$\[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},P_{m}\]$$
](A272900_1_En_18_Chapter_IEq234.gif) and ![
$$\[P_{j},X_{m}/\\left \\vert \\mathbf{X}\\right\\vert \]$$
](A272900_1_En_18_Chapter_IEq235.gif) and to verify that these commutators are symmetric in j and m (Exercise 8) and therefore do not contribute to the computation of ![
$$\[\\hat{A}_{j},\\hat{A}_{m}\].$$
](A272900_1_En_18_Chapter_IEq236.gif) We are left, then, with the following

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {i\\hslash }\[\\hat{A}_{j},\\hat{A}_{m}\]& =& -{ \\frac{1} {\\mu }^{2}{Q}^{4}}\\varepsilon _{jml}\(\\mathbf{P} \\cdot \\mathbf{P\)}\\hat{J}_{l} + \\frac{1} {\\mu {Q}^{2}}2\\varepsilon _{jml}\\hat{J}_{l} \\frac{1} {\\left \\vert \\mathbf{X}\\right\\vert } {}\\\\ & =& - \\frac{2} {\\mu {Q}^{4}}\\varepsilon _{jml}\\hat{J}_{l}\\left \(\\frac{\\mathbf{P} \\cdot \\mathbf{P}} {2\\mu } -\\frac{{Q}^{2}} {\\left \\vert \\mathbf{X}\\right\\vert } \\right\), {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ59.gif)

which is what is claimed in the lemma.

Proof of Theorem 18.14.

Since the Hamiltonian ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq237.gif) is invariant under rotations, ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq238.gif) commutes with each component of the angular momentum. We have also established that ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq239.gif) commutes with each component of the Runge–Lenz vector. From this it follows easily that ![
$$\\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq240.gif) and ![
$$\\mathbf{\\hat{K}}$$
](A272900_1_En_18_Chapter_IEq241.gif) commute with the Hamiltonian.

Since A k commutes with ![
$$\\hat{H},$$
](A272900_1_En_18_Chapter_IEq242.gif) it also commutes with any function of ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq243.gif). It then follows from Lemma 18.12 that

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\[\\hat{B}_{k},\\hat{B}_{l}\] = \\frac{\\mu {Q}^{4}} {2\\vert \\hat{H}\\vert }\[\\hat{A}_{k},\\hat{A}_{l}\] = - \\frac{\\mu {Q}^{4}} {2\\vert \\hat{H}\\vert }\\ \\frac{2} {\\mu {Q}^{4}}\\varepsilon _{jml}\\hat{J}_{l}\\hat{H}. }$$
](A272900_1_En_18_Chapter_Equam.gif)

Since ![
$$\\hat{H}/\\vert \\hat{H}\\vert = -I$$
](A272900_1_En_18_Chapter_IEq244.gif) on the negative-energy subspace V −, the above expression reduces to ![
$$\\varepsilon _{jml}\\hat{J}_{l}.$$
](A272900_1_En_18_Chapter_IEq245.gif) (The result on the positive-energy subspace will differ by a crucial minus sign from what we have on V −.)

Meanwhile, since both ![
$$\\mathbf{\\hat{B}}$$
](A272900_1_En_18_Chapter_IEq246.gif) and ![
$$\\mathbf{\\hat{J}}$$
](A272900_1_En_18_Chapter_IEq247.gif) are vector operators, we have, by Proposition 17.27, ![
$$\(1/\(i\\hslash \)\)\[\\hat{B}_{j},\\hat{J}_{k}\] =\\varepsilon _{jkl}\\hat{B}_{l}$$
](A272900_1_En_18_Chapter_IEq248.gif) and ![
$$\(1/\(i\\hslash \)\)\[\\hat{J}_{j},\\hat{J}_{k}\] =\\varepsilon _{jkl}\\hat{J}_{l}.$$
](A272900_1_En_18_Chapter_IEq249.gif) From the commutation relations among the ![
$$\\hat{B}_{j}$$
](A272900_1_En_18_Chapter_IEq250.gif)'s and ![
$$\\hat{J}_{j}$$
](A272900_1_En_18_Chapter_IEq251.gif)'s, it is an easy calculation to verify the claimed commutation relations among the components of ![
$$\\mathbf{\\hat{I}}$$
](A272900_1_En_18_Chapter_IEq252.gif) and ![
$$\\mathbf{\\hat{K}}.$$
](A272900_1_En_18_Chapter_IEq253.gif)

## 18.7 Exercises

1.

Consider the quantum Hamiltonian for two particles in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_18_Chapter_IEq254.gif) interacting by means of a 1 ∕ r potential:

![
$$\\displaystyle{\\hat{H} = - \\frac{{\\hslash }^{2}} {2m_{1}}\\Delta _{1} - \\frac{{\\hslash }^{2}} {2m_{2}}\\Delta _{2} - \\frac{{Q}^{2}} {\\left \\vert {\\mathbf{x}}^{1} -{\\mathbf{x}}^{2}\\right\\vert }.}$$
](A272900_1_En_18_Chapter_Equan.gif)

Here, as in Sect.​ 3.​11, Δ 1 is the Laplacian with respect to the variable x 1 and Δ 2 is the Laplacian with respect to the variable x 2. As in Sect.​ 2.​3.​3, introduce new variables consisting of the center of mass, ![
$$\\mathbf{c} = \(m_{1}{\\mathbf{x}}^{1} + m_{2}{\\mathbf{x}}^{2}\)/\(m_{1} + m_{2}\),$$
](A272900_1_En_18_Chapter_IEq255.gif) and the relative position, ![
$$\\mathbf{y} ={ \\mathbf{x}}^{1} -{\\mathbf{x}}^{2}.$$
](A272900_1_En_18_Chapter_IEq256.gif)

Show that ![
$$\\hat{H}_{2}$$
](A272900_1_En_18_Chapter_IEq257.gif) can be expressed in these variables as

![
$$\\displaystyle{- \\frac{{\\hslash }^{2}} {2\(m_{1} + m_{2}\)}\\Delta _{\\mathbf{c}} -\\frac{{\\hslash }^{2}} {2\\mu } \\Delta _{\\mathbf{y}} -\\frac{{Q}^{2}} {\\left \\vert \\mathbf{y}\\right\\vert },}$$
](A272900_1_En_18_Chapter_Equao.gif)

where μ is the reduced mass, given by ![
$$\\mu = m_{1}m_{2}/\(m_{1} + m_{2}\).$$
](A272900_1_En_18_Chapter_IEq258.gif)

Note: In the new variables, ![
$$\\hat{H}$$
](A272900_1_En_18_Chapter_IEq259.gif) is the sum of two terms, one of which involves only the variable c and one of which involves only the variable y. The term involving only c is the Hamiltonian for a free particle with mass m 1 \+ m 2, whereas the term involving only y is the Hamiltonian for a particle of mass μ moving in a 1 ∕ r potential.

2.

Let ![
$$H\(\\mathbf{x},\\mathbf{p}\) ={ \\left \\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\mu \) - {Q}^{2}/\\left \\vert \\mathbf{x}\\right\\vert$$
](A272900_1_En_18_Chapter_IEq260.gif) denote the Hamiltonian for the classical Kepler problem in ![
$${\\mathbb{R}}^{3}.$$
](A272900_1_En_18_Chapter_IEq261.gif) Show that for every ![
$$\\varepsilon > 0,$$
](A272900_1_En_18_Chapter_IEq262.gif) the region in ![
$${\\mathbb{R}}^{6}$$
](A272900_1_En_18_Chapter_IEq263.gif) given by ![
$$\\{\(\\mathbf{x},\\mathbf{p}\)\\left \\vert H\(\\mathbf{x},\\mathbf{p}\) < -\\varepsilon \\right.\\}$$
](A272900_1_En_18_Chapter_IEq264.gif) has finite volume.

3.

Let ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq265.gif) denote the real span of the following four elements of ![
$$M_{2}\(\\mathbb{C}\)$$
](A272900_1_En_18_Chapter_IEq266.gif):

![
$$\\displaystyle\\begin{array}{rcl} \\mathbf{1}& :=& \\left \(\\begin{array}{cc} 1&0\\\\ 0 &1\\end{array} \\right\);\\quad \\mathbf{i} := \\left \(\\begin{array}{rr} i& 0\\\\ 0 & - i\\end{array} \\right\);\\quad {}\\\\ \\mathbf{j}& :=& \\left \(\\begin{array}{rr} 0&1\\\\ - 1 &0\\end{array} \\right\);\\quad \\mathbf{j} := \\left \(\\begin{array}{cc} 0& i\\\\ i &0\\end{array} \\right\).{}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ60.gif)

(a)

Show that ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq267.gif) forms an associative algebra over ![
$$\\mathbb{R},$$
](A272900_1_En_18_Chapter_IEq268.gif) under the operation of matrix multiplication, and that the following relations are satisfied:

![
$$\\displaystyle\\begin{array}{rcl}{ \\mathbf{i}}^{2}& =&{ \\mathbf{j}}^{2} ={ \\mathbf{k}}^{2} = -\\mathbf{1} {}\\\\ \\mathbf{ij}& =& -\\mathbf{ji} = \\mathbf{k} {}\\\\ \\mathbf{jk}& =& -\\mathbf{kj} = \\mathbf{i} {}\\\\ \\mathbf{ki}& =& -\\mathbf{ik} = \\mathbf{j}. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ61.gif)

The algebra ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq269.gif) is (one particular realization of) the quaternion algebra.

(b)

Show that each nonzero element of ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq270.gif) has a multiplicative inverse.

Hint: Imitate the argument that each nonzero complex number has a multiplicative inverse.

4.

Let ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq271.gif) denote the quaternion algebra defined in Exercise 3. This exercise establishes explicitly an isomorphism between the Lie algebras so(4) and so(3) ⊕ so(3) (compare Definition 16.14).

(a)

Let V be the subspace of ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq272.gif) spanned by i, j, and k. Show that V forms a Lie algebra under the bracket ![
$$\[\\alpha,\\beta \] =\\alpha \\beta -\\beta \\alpha$$
](A272900_1_En_18_Chapter_IEq273.gif) and that V is isomorphic as a Lie algebra to so(3).

(b)

Let ![
$$\\mathrm{End}\(\\mathbb{H}\)$$
](A272900_1_En_18_Chapter_IEq274.gif) denote the algebra of real-linear maps of ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq275.gif) to itself. Given α ∈ V, let ![
$$L_{\\alpha } \\in \\mathrm{ End}\(\\mathbb{H}\)$$
](A272900_1_En_18_Chapter_IEq276.gif) be the "left multiplication by α" map, L α (β) = α β, and let ![
$$R_{\\alpha } \\in \\mathrm{ End}\(\\mathbb{H}\)$$
](A272900_1_En_18_Chapter_IEq277.gif) be the "right multiplication by α" map, R α (β) = β α. Show that the maps α↦L α and α↦ − R α are Lie algebra homomorphisms of V into ![
$$\\mathrm{End}\(\\mathbb{H}\).$$
](A272900_1_En_18_Chapter_IEq278.gif)

(c)

Consider the inner product on ![
$$\\mathbb{H}$$
](A272900_1_En_18_Chapter_IEq279.gif) in which {1, i, j, k} forms an orthonormal basis. Given α ∈ V, show that

![
$$\\displaystyle\\begin{array}{rcl} \\left \\langle L_{\\alpha }\\beta,\\gamma \\right\\rangle & =& -\\left \\langle \\beta,L_{\\alpha }\\gamma \\right\\rangle {}\\\\ \\left \\langle R_{\\alpha }\\beta,\\gamma \\right\\rangle & =& -\\left \\langle \\beta,R_{\\alpha }\\gamma \\right\\rangle. {}\\\\ \\end{array}$$
](A272900_1_En_18_Chapter_Equ62.gif)

That is to say, L α and R α belong to so(4), which we identify with the space of elements of ![
$$\\mathrm{End}\(\\mathbb{H}\)$$
](A272900_1_En_18_Chapter_IEq280.gif) that are skew-symmetric with respect to the inner product in Part (c).

(d)

Show that the map (α, β)↦L α − R β is a Lie algebra isomorphism of so(3) ⊕ so(3) to so(4).

(e)

Let D denote the diagonal subalgebra of so(3) ⊕ so(3), that is, the set of elements of the form (X, X). Show that the image of D under the isomorphism in Part (d) is the set of elements Y of ![
$$\\mathsf{so}\(4\) \\subset \\mathrm{ End}\(\\mathbb{H}\)$$
](A272900_1_En_18_Chapter_IEq281.gif) having the following form with respect to the basis in Part (c):

![
$$\\displaystyle{Y = \\left \(\\begin{array}{cc} 0& 0\\\\ 0 &Z\\end{array} \\right\),}$$
](A272900_1_En_18_Chapter_Equap.gif)

where Z ∈ so(3).

5.

Describe explicitly the two subalgebras of so(4) corresponding to the two copies of so(3) in the isomorphism

![
$$\\displaystyle{\\mathsf{so}\(4\)\\mathop{\\cong}\\mathsf{so}\(3\) \\oplus \\mathsf{so}\(3\)}$$
](A272900_1_En_18_Chapter_Equaq.gif)

in Exercise 4.

6.

Verify Lemma 18.18.

Hint: First show that ![
$$\\varepsilon _{jkl}\\varepsilon _{jmn} = 0$$
](A272900_1_En_18_Chapter_IEq282.gif) unless (k, l) = (m, n) or (k, l) = (n, m).

7.

In this exercise, we use the summation convention of Sect. 18.4.1.

(a)

Show that for any 3 × 3 matrix M and any indices j, k, l ∈ { 1, 2, 3}, we have

![
$$\\displaystyle{\\varepsilon _{mno}M_{jm}M_{kn}M_{lo} =\\varepsilon _{jkl}\(\\det M\).}$$
](A272900_1_En_18_Chapter_Equar.gif)

(b)

Show that if C is a vector operator, then for all R ∈ SO(3), we have

![
$$\\displaystyle{\\Pi \(R\)C_{k}\\Pi {\(R\)}^{-1} = R_{ lk}C_{l}.}$$
](A272900_1_En_18_Chapter_Equas.gif)

(c)

Show that the cross product of two vector operators is a vector operator.

Hint: Write the definition of a vector operator in the equivalent form

![
$$\\displaystyle{\\mathbf{v} \\cdot \\mathbf{C} = \\Pi \(R\)\(\({R}^{-1}\\mathbf{v}\) \\cdot \\mathbf{C}\)\\Pi {\(R\)}^{-1}.}$$
](A272900_1_En_18_Chapter_Equat.gif)

8.

Compute ![
$$\[\\varepsilon _{jkl}P_{k}\\hat{J}_{l},P_{m}\]$$
](A272900_1_En_18_Chapter_IEq283.gif) and ![
$$\[P_{j},X_{m}/\\left \\vert \\mathbf{X}\\right\\vert \]$$
](A272900_1_En_18_Chapter_IEq284.gif) and show that both of these quantities are symmetric in j and m, meaning that the value is unchanged if we interchange j and m.

9.

Show that the Eq. (18.14) has two power series solutions for g(ρ), one starting with ![
$${\\rho }^{-\(2l+1\)}$$
](A272900_1_En_18_Chapter_IEq285.gif) and one starting with ρ 0.

References

[17].

V. Guillemin, S. Sternberg, Variations on a Theme by Kepler. Colloquium Publications, vol. 42 (American Mathematical Society, Providence, RI, 1990)

[27].

T. Kato, Perturbation Theory for Linear Operators (Reprint of the 1980 edition). (Springer, Berlin, 1995)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_19

© Springer Science+Business Media New York 2013

# 19. Systems and Subsystems, Multiple Particles

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

Up to this point, we have considered the state of a quantum system to be described by a unit vector in the corresponding Hilbert space, or more properly, an equivalence class of unit vectors under the equivalence relation ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq01.gif) ∼ e i θ ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq02.gif). We will see in this section that this notion of the state of a quantum system is too limited. We will introduce a more general notion of the state of a system, described by a density matrix. The special case in which the system can be described by a unit vector will be called a pure state.

## 19.1 Introduction

Up to this point, we have considered the state of a quantum system to be described by a unit vector in the corresponding Hilbert space, or more properly, an equivalence class of unit vectors under the equivalence relation ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq03.gif) ∼ e i θ ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq04.gif). We will see in this section that this notion of the state of a quantum system is too limited. We will introduce a more general notion of the state of a system, described by a density matrix. The special case in which the system can be described by a unit vector will be called a pure state.

One way to see the inadequacy of the notion of state as a unit vector is to consider systems and subsystems. We will examine this topic in greater detail in Sect. 19.5, but for now let us consider the example of a system of two spinless "distinguishable" particles moving in ![
$${\\mathbb{R}}^{3}.$$
](A272900_1_En_19_Chapter_IEq1.gif) (For now, the reader need not worry about the notion of distinguishable particles; just think of them as being two different types of particles, with, say, different masses or charges.) Let us assume the combined state of the two particles can be described by a unit vector in the corresponding Hilbert space, which is (according to Sect.​ 3.​11) ![
$${L}^{2}\({\\mathbb{R}}^{6}\).$$
](A272900_1_En_19_Chapter_IEq2.gif) We have, then, a wave function ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq05.gif)(x, y), where x is the position of the first particle and y is the position of the second particle.

Given a wave function ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq06.gif)(x, y) for the combined system, what is the wave function describing the state of the first particle only? If the wave function of the combined system happens to be a product, say, ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq07.gif)(x, y) = ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq08.gif) 1(x)![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq09.gif) 2(y), then, naturally, we would say that the state of the first particle is simply ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq010.gif) 1. Of course, one might object that we could rewrite ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq011.gif) as ![
$$\\psi \(\\mathbf{x},\\mathbf{y}\) = \[c\\psi _{1}\(\\mathbf{x}\)\]\[\\psi _{2}\(\\mathbf{y}\)/c\]$$
](A272900_1_En_19_Chapter_IEq3.gif) for any constant c, but this only affects the wave function for the first particle by a constant, which does not affect the physical state.

In general, however, the wave function of the combined system need not be a product. Already when ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq012.gif) is a linear combination of two products, ![
$$\\psi \(\\mathbf{x},\\mathbf{y}\) =\\psi _{1}\(\\mathbf{x}\)\\psi _{2}\(\\mathbf{y}\) +\\phi _{1}\(\\mathbf{x}\)\\phi _{2}\(\\mathbf{y\),}$$
](A272900_1_En_19_Chapter_IEq4.gif) it is unclear what the correct wave function is for the first particle. At first glance, it might seem natural to try ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq013.gif) 1(x) + ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq014.gif) 1(x), but upon closer examination, this is not an unambiguous proposal. After all, we can just as well write ![
$$\\psi \(\\mathbf{x},\\mathbf{y}\) = \[c_{1}\\psi _{1}\(\\mathbf{x}\)\]\[\\psi _{2}\(\\mathbf{y}\)/c_{1}\] + \[c_{2}\\phi _{1}\(\\mathbf{x}\)\]\[\\phi _{2}\(\\mathbf{y}\)/c_{2}\],$$
](A272900_1_En_19_Chapter_IEq5.gif) but then the resulting wave functions for the first particle, ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq015.gif) 1(x) + ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq016.gif) 2(x) and ![
$$c_{1}\\psi _{1}\(\\mathbf{x}\) + c_{2}\\psi _{2}\(\\mathbf{x}\),$$
](A272900_1_En_19_Chapter_IEq6.gif) are not scalar multiples of one another. For a general unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq017.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{6}\)$$
](A272900_1_En_19_Chapter_IEq7.gif), the situation is even worse. The conclusion is this: There does not seem to be any way to associate to ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq018.gif) a general unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq019.gif) ′ in ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_19_Chapter_IEq8.gif) such that ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq020.gif) ′ could sensibly be described as "the state of the first particle."

Although we cannot associate with ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq021.gif) a wave function ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq022.gif) ′ for the first particle, there is no difficulty in taking expectation values of observables related to the first particle. We can make perfect sense of, say, the expected position of the first particle, as

![
$$\\displaystyle{\\left \\langle \\psi,X_{j}^{\(1\)}\\psi \\right\\rangle =\\int _{{ \\mathbb{R}}^{6}}x_{j}{\\left \\vert \\psi \(\\mathbf{x},\\mathbf{y}\)\\right\\vert }^{2}\\ d\\mathbf{x}\\ d\\mathbf{y}.}$$
](A272900_1_En_19_Chapter_Equa.gif)

Here X j (1) indicates the operator of multiplication by the jth component of the first vector in the function ![
$$\\psi \(\\cdot,\\cdot \) : {\\mathbb{R}}^{3} \\times {\\mathbb{R}}^{3} \\rightarrow \\mathbb{C}.$$
](A272900_1_En_19_Chapter_IEq9.gif) That is to say, the operator X j acting on ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_19_Chapter_IEq10.gif) can be "promoted" to an operator on ![
$${L}^{2}\({\\mathbb{R}}^{6}\)$$
](A272900_1_En_19_Chapter_IEq11.gif) by having it act in the first variable only. Similarly, the momentum operator P j on ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_19_Chapter_IEq12.gif) can be promoted to an operator ![
$$P_{j}^{\(1\)}$$
](A272900_1_En_19_Chapter_IEq13.gif) on ![
$${L}^{2}\({\\mathbb{R}}^{6}\),$$
](A272900_1_En_19_Chapter_IEq14.gif) by letting it act on the first variable, meaning that P j (1) ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq023.gif) is ![
$$-i\\hslash $$
](A272900_1_En_19_Chapter_IEq15.gif) times the partial derivative with respect to the jth component of the first vector in ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq024.gif)( ⋅, ⋅). In fact, as we will see in Sect. 19.5, given any self-adjoint operator on ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_19_Chapter_IEq16.gif) there is a natural way to promote it into an operator on ![
$${L}^{2}\({\\mathbb{R}}^{6}\),$$
](A272900_1_En_19_Chapter_IEq17.gif) where its expectation value may then be defined.

Thus, although there is no natural way to associate with a unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq025.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{6}\)$$
](A272900_1_En_19_Chapter_IEq18.gif) a unit vector in ![
$${L}^{2}\({\\mathbb{R}}^{3}\),$$
](A272900_1_En_19_Chapter_IEq19.gif) there is a natural way to associate with ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq026.gif) expectation values of observables on ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_19_Chapter_IEq20.gif) This suggests that we should introduce a more general notion of the "state" of a quantum system, a notion in which with each "reasonable" family of expectation values for the quantum observables there is associated a quantum state. This notion turns out to be that of density matrices (positive, self-adjoint operators with trace 1).

In Sect. 19.3, we introduce the notion of a density matrix. Theorem 19.9 in that section will tell us that, given any reasonable assignment ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq027.gif) of expectation values to observables, there is a unique density matrix ρ such that ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq028.gif)(A) = trace(ρ A) for all observables A. In the special case in which the state of the system is given by a unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq029.gif) in the Hilbert space, then ρ will be just the projection onto ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq030.gif) and trace(ρ A) will be equal to the familiar expression ![
$$\\left \\langle \\psi,A\\psi \\right\\rangle.$$
](A272900_1_En_19_Chapter_IEq21.gif) In Sect. 19.5, we will consider composite quantum systems and introduce a method (the partial trace) of defining a density matrix for a subsystem from a density matrix for the whole system. Finally, in Sect. 19.6, we will consider the important special case of composite systems made up of multiple identical particles.

## 19.2 Trace-Class and Hilbert–Schmidt Operators

In this section, we explore notions related to the trace of an operator on a Hilbert space. The results of this section are presented without proof; see Chap. VI in Volume I of [34] for proofs and additional information.

Proposition 19.1.

Suppose ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq22.gif) is non-negative and self-adjoint. Then for any two orthonormal bases {e j} and {f j} for H, we have

![
$$\\displaystyle{\\sum _{j}\\left \\langle e_{j},Ae_{j}\\right\\rangle =\\sum _{j}\\left \\langle f_{j},Af_{j}\\right\\rangle.}$$
](A272900_1_En_19_Chapter_Equb.gif)

Note that since A is non-negative, ![
$$\\left \\langle e_{j},Ae_{j}\\right\\rangle$$
](A272900_1_En_19_Chapter_IEq23.gif) and ![
$$\\left \\langle f_{j},Af_{j}\\right\\rangle$$
](A272900_1_En_19_Chapter_IEq24.gif) are non-negative real numbers. Thus, the sums are always well defined, but may have the value of + ∞.

Definition 19.2.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq25.gif) is non-negative and self-adjoint, the value of ![
$$\\sum _{j}\\left \\langle e_{j},Ae_{j}\\right\\rangle,$$
](A272900_1_En_19_Chapter_IEq26.gif) for any arbitrarily chosen orthonormal basis, is called the trace of A. If trace (A) < +∞, then we say that A is trace class.

For a general ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq27.gif) we say that A is trace class if the non-negative self-adjoint operator ![
$$\\sqrt{{ A}^{{\\ast}}A}$$
](A272900_1_En_19_Chapter_IEq28.gif) is a trace class.

Note that for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq29.gif) A ∗ A is self-adjoint and non-negative. Thus, the square root of A ∗ A may be defined by the functional calculus (Definition 7.13 or Proposition 8.4).

Proposition 19.3.

1.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq30.gif) is trace class, then for any orthonormal basis {e j}, the sum ![
$$\\sum _{j}\\left \\langle e_{j},Ae_{j}\\right\\rangle$$
](A272900_1_En_19_Chapter_IEq31.gif) is absolutely convergent. Furthermore, the value of this sum, which we denote as trace (A), is independent of the choice of orthonormal basis.

2.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq32.gif) is trace class, then A ∗ is also trace class and

![
$$\\displaystyle{\\mathrm{trace}\({A}^{{\\ast}}\) = \\overline{\\mathrm{trace}\(A\)}.}$$
](A272900_1_En_19_Chapter_Equc.gif)

3.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq33.gif) is trace class, then for all ![
$$B \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq34.gif) the operators AB and BA are also trace class, and

![
$$\\displaystyle{\\mathrm{trace}\(AB\) =\\mathrm{ trace}\(BA\).}$$
](A272900_1_En_19_Chapter_Equd.gif)

Recall that ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq35.gif) is said to be compact if A maps every bounded set in H to a set with compact closure. If a self-adjoint operator A is trace class, it is necessarily compact and thus has an orthonormal basis {e j } of eigenvectors, for which the associated eigenvalues λ j are real and tend to zero as j tends to infinity. (See Theorem VI.16 in Volume I of [34]. One can deduce the result from, say, the direct integral form of the spectral theorem for bounded self-adjoint operators by verifying that unless A has point spectrum with eigenvalues tending to zero, the operator of multiplication by λ in the direct integral will not be compact.) Point 1 of Proposition 19.3 then tells us that ![
$$\\sum _{j}\\left \\vert \\lambda _{j}\\right\\vert < \\infty $$
](A272900_1_En_19_Chapter_IEq36.gif) and that ![
$$\\mathrm{trace}\(A\) =\\sum _{j}\\lambda _{j}.$$
](A272900_1_En_19_Chapter_IEq37.gif) Conversely, if A is a self-adjoint operator having an orthonormal basis of eigenvectors for which the associated eigenvalues satisfy ![
$$\\sum _{j}\\left \\vert \\lambda _{j}\\right\\vert < \\infty,$$
](A272900_1_En_19_Chapter_IEq38.gif) then A is trace class.

Definition 19.4.

An operator ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq39.gif) is said to be Hilbert–Schmidt if trace (A ∗ A) < ∞.

Since A ∗ A is self-adjoint and non-negative, trace(A ∗ A) is defined (but possibly infinite) for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq40.gif) If A is trace class, then (by definition) the trace of ![
$$\\sqrt{{ A}^{{\\ast}}A}$$
](A272900_1_En_19_Chapter_IEq41.gif) is finite, in which case, the trace of ![
$$\\sqrt{{A}^{{\\ast} } A}\\sqrt{{A}^{{\\ast} } A}$$
](A272900_1_En_19_Chapter_IEq42.gif) is also finite, by Point 3 of Proposition 19.3. Thus, every trace-class operator is Hilbert–Schmidt (but not vice versa).

Proposition 19.5.

If ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq43.gif) is Hilbert–Schmidt, so is A ∗ . If ![
$$A,B \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq44.gif) are Hilbert–Schmidt, then AB and BA are trace class and trace (AB) equals trace (BA).

If A and B are Hilbert–Schmidt operators, the Hilbert–Schmidt inner product of A and B is ![
$$\\left \\langle A,B\\right\\rangle _{HS} :=\\mathrm{ trace}\({A}^{{\\ast}}B\)$$
](A272900_1_En_19_Chapter_IEq45.gif) and the Hilbert–Schmidt norm of A satisfies ![
$$\\left \\Vert A\\right\\Vert _{HS}^{2} = \\left \\langle A,A\\right\\rangle _{HS}.$$
](A272900_1_En_19_Chapter_IEq46.gif) The space of Hilbert–Schmidt operators is a Hilbert space with respect to ![
$$\\left \\langle \\cdot,\\cdot \\right\\rangle _{HS}.$$
](A272900_1_En_19_Chapter_IEq47.gif)

## 19.3 Density Matrices: The General Notion of the State of a Quantum System

Typically, we think of the quantum observables—the ones with expectations values that we wish to take—as being unbounded self-adjoint operators. But of course we can also take expectation values of bounded self-adjoint operators, and indeed expectations for bounded operators determine those for unbounded operators. After all, suppose A is an unbounded self-adjoint operator and suppose we know the expectation value for 1 E (A) for every Borel set ![
$$E \\subset \\mathbb{R},$$
](A272900_1_En_19_Chapter_IEq48.gif) where 1 E is the indicator function of E and 1 E (A) is defined by the functional calculus (Definition 7.13). The expectation value for 1 E (A) is the probability of obtaining a value in E for a measurement of the observable A. If we know this probability for each E, then we know the full probability distribution of the measurements, and thus we can compute the expectation value of A. Furthermore, we can always introduce expectation values for (bounded) non-self-adjoint operators. Each such operator A is of the form ![
$$A = A_{1} + iA_{2}$$
](A272900_1_En_19_Chapter_IEq49.gif) with A 1 and A 2 self-adjoint, and so we may reasonably define the expectation value of A to be the expectation value of A 1 plus i times the expectation value of A 2.

We then postulate that the general notion of the "state" of a quantum system should be simply a "list" of expectation values for all bounded operators, satisfying some reasonable hypotheses.

Definition 19.6.

A linear map ![
$$\\Phi : \\mathcal{B}\(\\mathbf{H}\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_19_Chapter_IEq50.gif) is a family of expectation values if the following conditions hold.

1.

![
$$\\Phi \(I\) = 1.$$
](A272900_1_En_19_Chapter_IEq51.gif)

2.

Φ(A) is real whenever A is self-adjoint.

3.

Φ(A) ≥ 0 whenever A is self-adjoint and non-negative.

4.

For any sequence A n in ![
$$\\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq52.gif) if ![
$$\\left \\Vert A_{n}\\psi - A\\psi \\right\\Vert \\rightarrow 0$$
](A272900_1_En_19_Chapter_IEq53.gif) for all ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0105.gif) ∈ H, then Φ(A n ) → Φ(A).

Point 4 in the definition says that Φ is continuous with respect to the strong (sequential) convergence in ![
$$\\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq54.gif) By Exercise 3, any linear map on ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq55.gif) satisfying Points 1, 2, and 3 is automatically continuous with respect to the operator norm topology, meaning that if ![
$$\\left \\Vert A_{n} - A\\right\\Vert \\rightarrow 0$$
](A272900_1_En_19_Chapter_IEq56.gif) then Φ(A n ) → Φ(A). However, to establish our characterization of families of expectation values in terms of density matrices, we need continuity of Φ under a more general sort of convergence, where we only assume that ![
$$\\left \\Vert A_{n}\\psi - A\\psi \\right\\Vert \\rightarrow 0$$
](A272900_1_En_19_Chapter_IEq57.gif) for each ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq091.gif). This stronger continuity property does not follow from Properties 1–3. Exercise 5 gives an example of a linear functional on ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq58.gif) that satisfies Points 1–3 of Definition 19.6, but not Point 4.

Definition 19.7.

An operator ![
$$\\rho \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq59.gif) is a density matrix if ρ is self-adjoint and non-negative and trace (ρ) = 1.

Of course, since the trace of a density matrix is assumed to be finite, every density matrix is trace class. The next two results give a precise characterization of families of expectation values in terms of density matrices.

Proposition 19.8.

Suppose ρ is a density matrix on H . Then the map ![
$$\\Phi _{\\rho } : \\mathcal{B}\(\\mathbf{H}\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_19_Chapter_IEq60.gif) given by

![
$$\\displaystyle{\\Phi _{\\rho }\(A\) =\\mathrm{ trace}\(\\rho A\) =\\mathrm{ trace}\(A\\rho \)}$$
](A272900_1_En_19_Chapter_Eque.gif)

is a family of expectation values.

Proof.

If we define Φ ρ (A) = trace(ρ A), then ![
$$\\Phi _{\\rho }\(I\) =\\mathrm{ trace}\(\\rho \) = 1.$$
](A272900_1_En_19_Chapter_IEq61.gif) For any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq62.gif) we have,

![
$$\\displaystyle{\\mathrm{trace}\(\\rho {A}^{{\\ast}}\) =\\mathrm{ trace}\({A}^{{\\ast}}\\rho \) =\\mathrm{ trace}\({\(\\rho A\)}^{{\\ast}}\) = \\overline{\\mathrm{trace}\(\\rho A\)}.}$$
](A272900_1_En_19_Chapter_Equf.gif)

It follows that trace(ρ A) is real when A is self-adjoint. Let ρ 1 ∕ 2 be the non-negative self-adjoint square root of ρ. Then ρ 1 ∕ 2 and A ρ 1 ∕ 2 are Hilbert–Schmidt (in the latter case, by Point 3 of Proposition 19.3). It follows that ![
$$\\mathrm{trace}\({A\\rho {}^{1/2}\\rho }^{1/2}\) =\\mathrm{ trace}{\(\\rho }^{1/2}{A\\rho }^{1/2}\),$$
](A272900_1_En_19_Chapter_IEq63.gif) by Proposition 19.5. Thus, if A is self-adjoint and non-negative,

![
$$\\displaystyle{ \\mathrm{trace}\(\\rho A\) =\\mathrm{ trace}{\(\\rho {}^{1/2}\\rho }^{1/2}A\) =\\mathrm{ trace}{\(\\rho }^{1/2}{A\\rho }^{1/2}\) \\geq 0, }$$
](A272900_1_En_19_Chapter_Equ1.gif)

(19.1)

because ![
$${\\rho }^{1/2}{A\\rho }^{1/2}$$
](A272900_1_En_19_Chapter_IEq64.gif) is self-adjoint and non-negative. We have established that Φ ρ satisfies Points 1, 2, and 3 of Definition 19.6.

Meanwhile, suppose A n ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq092.gif) converges in norm to A ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0106.gif), for each ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq093.gif) in H. Then ![
$$\\left \\Vert A_{n}\\psi \\right\\Vert$$
](A272900_1_En_19_Chapter_IEq65.gif) is bounded as a function of n for each fixed ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq094.gif). Thus, by the principle of uniform boundedness (Theorem A.40), there is a constant C such that ![
$$\\left \\Vert A_{n}\\right\\Vert \\leq C.$$
](A272900_1_En_19_Chapter_IEq66.gif) Now, if ![
$$\\left \\{e_{j}\\right\\}$$
](A272900_1_En_19_Chapter_IEq67.gif) is an orthonormal basis for H, we have

![
$$\\displaystyle{\\left \\vert \\left \\langle e_{j}{,\\rho }^{1/2}A{_{ n}\\rho }^{1/2}e_{ j}\\right\\rangle \\right\\vert = \\left \\vert \\left \\langle {\\rho }^{1/2}e_{ j},A_{n}{\\rho }^{1/2}e_{ j}\\right\\rangle \\right\\vert \\leq C\\left \\Vert {\\rho }^{1/2}e_{ j}\\right\\Vert {}^{2},}$$
](A272900_1_En_19_Chapter_Equg.gif)

and,

![
$$\\displaystyle{\\sum {_{j}\\left \\Vert {\\rho }^{1/2}e_{ j}\\right\\Vert }^{2} =\\sum _{ j}\\left \\langle {\\rho }^{1/2}e_{ j},{\\rho }^{1/2}e_{ j}\\right\\rangle =\\sum _{j}\\left \\langle e_{j},\\rho e_{j}\\right\\rangle =\\mathrm{ trace}\(\\rho \) < \\infty.}$$
](A272900_1_En_19_Chapter_Equh.gif)

Furthermore, since ![
$$A_{n}{\(\\rho }^{1/2}e_{j}\)$$
](A272900_1_En_19_Chapter_IEq68.gif) converges to ![
$$A{\(\\rho }^{1/2}e_{j}\)$$
](A272900_1_En_19_Chapter_IEq69.gif) for each j, dominated convergence tells us that

![
$$\\displaystyle\\begin{array}{rcl} \\mathrm{trace}{\(\\rho }^{1/2}{A\\rho }^{1/2}\)& =& \\sum _{ j}\\left \\langle e_{j}{,\\rho }^{1/2}{A\\rho }^{1/2}e_{ j}\\right\\rangle {}\\\\ & =& \\lim _{n\\rightarrow \\infty }\\sum _{j}\\left \\langle e_{j}{,\\rho }^{1/2}A{_{ n}\\rho }^{1/2}e_{ j}\\right\\rangle {}\\\\ & =& \\lim _{n\\rightarrow \\infty }\\mathrm{trace}{\(\\rho }^{1/2}A{_{ n}\\rho }^{1/2}\). {}\\\\ \\end{array}$$
](A272900_1_En_19_Chapter_Equ2.gif)

As in (19.1), we can shift the second factor of ρ 1 ∕ 2 to the front of the trace to obtain Point 4 in Definition 19.6.

Theorem 19.9.

For any family of expectation values ![
$$\\Phi : \\mathcal{B}\(\\mathbf{H}\) \\rightarrow \\mathbb{C},$$
](A272900_1_En_19_Chapter_IEq70.gif) there is a unique density matrix ρ such that ![
$$\\Phi \(A\) =\\mathrm{ trace}\(\\rho A\)$$
](A272900_1_En_19_Chapter_IEq71.gif) for all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq72.gif)

Proof.

Recall from Sect.​ 3.​12 the Dirac notation, in which the expression ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_19_Chapter_IEq73.gif) denotes the linear operator taking any vector χ ∈ H to the vector ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\vert \\chi \\right\\rangle$$
](A272900_1_En_19_Chapter_IEq74.gif) (in physics notation), that is, the vector ![
$$\\left \\langle \\psi,\\chi \\right\\rangle \\phi$$
](A272900_1_En_19_Chapter_IEq75.gif) (in math notation). If ρ is trace class, then by Exercise 2,

![
$$\\displaystyle{\\mathrm{trace}\(\\rho \\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \) = \\left \\langle \\psi,\\rho \\phi \\right\\rangle.}$$
](A272900_1_En_19_Chapter_Equi.gif)

Thus, if an operator ρ with the desired properties is to exist, we must have

![
$$\\displaystyle{\\left \\langle \\psi,\\rho \\phi \\right\\rangle = \\Phi \(\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \).}$$
](A272900_1_En_19_Chapter_Equj.gif)

Now, by Exercise 3, Φ satisfies ![
$$\\left \\Vert \\Phi \(A\)\\right\\Vert \\leq \\left \\Vert A\\right\\Vert.$$
](A272900_1_En_19_Chapter_IEq76.gif) From this, we can see that the map

![
$$\\displaystyle{L_{\\Phi }\(\\phi,\\psi \) := \\Phi \(\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \)}$$
](A272900_1_En_19_Chapter_Equk.gif)

is a bounded sesquilinear form, so that (by Proposition A.63), there is a unique bounded operator ρ such that ![
$$\\Phi \(\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \) = \\left \\langle \\psi,\\rho \\phi \\right\\rangle$$
](A272900_1_En_19_Chapter_IEq77.gif) for all ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq031.gif) and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq032.gif). Since ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\phi \\right\\vert$$
](A272900_1_En_19_Chapter_IEq78.gif) is self-adjoint and non-negative, L Φ (![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq033.gif), ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq034.gif)) is real and non-negative, which means that ρ is self-adjoint (by Proposition A.63) and non-negative.

Meanwhile, if {e j } is an orthonormal basis for H, then by Definition 19.2,

![
$$\\displaystyle\\begin{array}{rcl} \\mathrm{trace}\(\\rho \)& =& \\lim _{N\\rightarrow \\infty }\\sum _{j=1}^{N}\\left \\langle e_{ j},\\rho e_{j}\\right\\rangle {}\\\\ & =& \\lim _{N\\rightarrow \\infty }\\Phi \\left \(\\left \\vert e_{1}\\right\\rangle \\left \\langle e_{1}\\right\\vert + \\cdots + \\left \\vert e_{N}\\right\\rangle \\left \\langle e_{N}\\right\\vert \\right\) {}\\\\ & =& \\Phi \(I\) = 1. {}\\\\ \\end{array}$$
](A272900_1_En_19_Chapter_Equ3.gif)

In passing from the second line to the third, we have used Point 4 of Definition 19.6. Thus, ρ is a density matrix.

We have now found a density matrix ρ such that ![
$$\\Phi \(\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \)$$
](A272900_1_En_19_Chapter_IEq79.gif) agrees with ![
$$\\mathrm{trace}\(\\rho \\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \)$$
](A272900_1_En_19_Chapter_IEq80.gif) for all ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq035.gif), ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq036.gif) ∈ H. By linearity, Φ(A) = trace(ρ A) for all finite-rank operators A (see Exercise 4). Now, if {e j } is an orthonormal basis for H, let P N be the orthogonal projection onto the span of e 1,..., e N . Then for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq81.gif) the operator P N A has finite rank and P N A ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0107.gif) → A ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0108.gif) for all ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq037.gif) ∈ H. Thus, for all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq82.gif)

![
$$\\displaystyle{\\Phi \(A\) =\\lim _{N\\rightarrow \\infty }\\Phi \(P_{N}A\) =\\lim _{N\\rightarrow \\infty }\\mathrm{trace}\(\\rho P_{N}A\) =\\mathrm{ trace}\(\\rho A\),}$$
](A272900_1_En_19_Chapter_Equl.gif)

by Proposition 19.8

Our next result shows that our new notion of the state of a system includes our old notion.

Proposition 19.10.

For any unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0109.gif) ∈ H , let ![
$$\\left \\vert \\psi \\right\\rangle \\left \\langle \\psi \\right\\vert,$$
](A272900_1_En_19_Chapter_IEq83.gif) in accordance with Notation 3.28, denote the orthogonal projection onto the span of ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0110.gif). Then ![
$$\\left \\vert \\psi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_19_Chapter_IEq84.gif) is a density matrix and for all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq85.gif) we have

![
$$\\displaystyle{\\mathrm{trace}\(\\left \\vert \\psi \\right\\rangle \\left \\langle \\psi \\right\\vert A\) = \\left \\langle \\psi,A\\psi \\right\\rangle.}$$
](A272900_1_En_19_Chapter_Equm.gif)

Note that if ![
$$\\psi _{2} = {e}^{i\\theta }\\psi _{1,}$$
](A272900_1_En_19_Chapter_IEq86.gif) then ![
$$\\left \\vert \\psi _{1}\\right\\rangle \\left \\langle \\psi _{1}\\right\\vert = \\left \\vert \\psi _{2}\\right\\rangle \\left \\langle \\psi _{2}\\right\\vert.$$
](A272900_1_En_19_Chapter_IEq87.gif) Thus, from our new point of view, we may say that the reason ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq095.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq038.gif) 2 represent the same "physical state" is that they determine the same density matrix.

Proof.

Since it is an orthogonal projection, ![
$$\\left \\vert \\psi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_19_Chapter_IEq88.gif) is bounded, self-adjoint, and non-negative. To compute its trace, we choose an orthonormal basis {e j } for H with e 1 = ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq039.gif), which gives ![
$$\\mathrm{trace}\(\\left \\vert \\psi \\right\\rangle \\left \\langle \\psi \\right\\vert \) = 1.$$
](A272900_1_En_19_Chapter_IEq89.gif) Using the same orthonormal basis, we compute that, for any ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq90.gif)

![
$$\\displaystyle{\\mathrm{trace}\(\\left \\vert \\psi \\right\\rangle \\left \\langle \\psi \\right\\vert A\) =\\sum _{j}\\left \\langle e_{j},\\psi \\right\\rangle \\left \\langle \\psi,Ae_{j}\\right\\rangle = \\left \\langle \\psi,A\\psi \\right\\rangle,}$$
](A272900_1_En_19_Chapter_Equn.gif)

as desired.

Definition 19.11.

A density matrix ![
$$\\rho \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq91.gif) is a pure state if there exists a unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0111.gif) ∈ H such that ρ is equal to the orthogonal projection onto the span of ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0112.gif). The density matrix ρ is called a mixed state if no such unit vector ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0113.gif) exists.

An isolated system that is in a pure state initially will remain in a pure state for all later times, since the initial state ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq040.gif) 0 evolves to the pure state ![
$${e}^{-i\\hat{H}t/\\hslash }\\psi _{0},$$
](A272900_1_En_19_Chapter_IEq92.gif) where ![
$$\\hat{H}$$
](A272900_1_En_19_Chapter_IEq099.gif) is the Hamiltonian for the system. But if a system is interacting with its environment, then as discussed in Sect. 19.5, the system may move into a mixed state at a later time.

There are several different ways of characterizing the pure states as a subset of the density matrices. First, it is not hard to see (Exercise 6) that a density matrix ρ is a pure state if and only if trace(ρ 2) = 1. Second, the set of density matrices is a convex set, since if ρ 1 and ρ 2 are non-negative and have trace 1, then so is ![
$$\\lambda \\rho _{1} + \(1-\\lambda \)\\rho _{2},$$
](A272900_1_En_19_Chapter_IEq93.gif) for 0 < λ < 1. According to Exercise 7, the pure states are precisely the extreme points of this set. That is, a density matrix ρ is a pure state if and only if it cannot be expressed as ![
$$\\rho =\\lambda \\rho _{1} + \(1-\\lambda \)\\rho _{2}$$
](A272900_1_En_19_Chapter_IEq94.gif) where ρ 1 and ρ 2 are distinct density matrices and λ belongs to (0, 1). Third, we may define the von Neumann entropy S(ρ) of a density matrix ρ by

![
$$\\displaystyle{S\(\\rho \) =\\mathrm{ trace}\(-\\rho \\log \\rho \),}$$
](A272900_1_En_19_Chapter_Equo.gif)

where ρ log ρ is defined by the functional calculus. (Since ![
$$\\lim _{\\lambda \\rightarrow {0}^{+}}\\lambda \\log \\lambda = 0,$$
](A272900_1_En_19_Chapter_IEq95.gif) we interpret 0log0 as being 0.) Since the eigenvalues of ρ are all between 0 and 1, we see that − ρ log ρ is a non-negative self-adjoint operator, which has a well-defined trace, which may have the value + ∞. According to Exercise 8, a density matrix ρ is a pure state if and only if S(ρ) = 0.

Suppose that we have two pure states, coming from unit vectors ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq041.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq042.gif) 2. Then there are two different senses in which we can take a superposition, that is, linear combination, of the corresponding quantum states. If we use our old point of view, in which the states are vectors in H, then we may take the linear combination ![
$$c_{1}\\psi _{1} + c_{2}\\psi _{2},$$
](A272900_1_En_19_Chapter_IEq96.gif) and then normalize this vector to be a unit vector. If we use our new point of view, in which the states are density matrices, then we may take the linear combination ![
$$c_{1}\\left \\vert \\psi _{1}\\right\\rangle \\left \\langle \\psi _{1}\\right\\vert + c_{2}\\left \\vert \\psi _{2}\\right\\rangle \\left \\langle \\psi _{2}\\right\\vert,$$
](A272900_1_En_19_Chapter_IEq97.gif) where in this case c 1 and c 2 should be non-negative and should add to 1. These two notions of superposition are different, since

![
$$\\displaystyle{ C\\left \\vert c_{1}\\psi _{1} + c_{2}\\psi _{2}\\right\\rangle \\left \\langle c_{1}\\psi _{1} + c_{2}\\psi _{2}\\right\\vert \\neq c_{1}\\left \\vert \\psi _{1}\\right\\rangle \\left \\langle \\psi _{1}\\right\\vert + c_{2}\\left \\vert \\psi _{2}\\right\\rangle \\left \\langle \\psi _{2}\\right\\vert, }$$
](A272900_1_En_19_Chapter_Equ4.gif)

(19.2)

no matter how the constant C is chosen. After all, the state on the left-hand side of (19.2) is a pure state, whereas (unless ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq043.gif) 2 is a multiple of ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq044.gif) 1), the state on the right-hand side of (19.2) is a mixed state, since the range of this operator is 2-dimensional rather than 1-dimensional.

Physicists call the first sort of superposition (in which we take a linear combination of vectors in H) coherent superposition or quantum superposition, and they call the second sort of superposition (in which we take a linear combination of the associated density matrices) incoherent superposition. The reason for the term "coherent" is that coherent superposition depends on the phases of the coefficients. That is, if ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq045.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq046.gif) 2 are linearly independent, the vector ![
$$c_{1}{e}^{i\\theta }\\psi _{1} + c_{2}{e}^{i\\phi }\\psi _{2}$$
](A272900_1_En_19_Chapter_IEq98.gif) does not represent the same quantum state as ![
$$c_{1}\\psi _{1} + c_{2}\\psi _{2},$$
](A272900_1_En_19_Chapter_IEq99.gif) unless e i θ = ![
$$e^{i\\phi}$$
](A272900_1_En_19_Chapter_IEq0100.gif). By contrast, the density matrix associated with e i θ ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq047.gif) is the same as the density matrix associated with ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq048.gif), and so the phases have no effect when taking linear combinations of the density matrices associated to vectors in H. When taking a coherent superposition, there is no simple relationship between the expectation value of an observable in the states ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq049.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq050.gif) 2 and the expectation value of the same observable in the state ![
$$c_{1}\\psi _{1} + c_{2}\\psi _{2}.$$
](A272900_1_En_19_Chapter_IEq100.gif) On the other hand, when taking an incoherent superposition, expectation values in the new state are just linear combinations of the original expectation values:

![
$$\\displaystyle{\\mathrm{trace}\\left \(\(c_{1}\\left \\vert \\psi _{1}\\right\\rangle \\left \\langle \\psi _{1}\\right\\vert + c_{2}\\left \\vert \\psi _{2}\\right\\rangle \\left \\langle \\psi _{2}\\right\\vert \)A\\right\) = c_{1}\\left \\langle \\psi _{1},A\\psi _{1}\\right\\rangle + c_{2}\\left \\langle \\psi _{2},A\\psi _{2}\\right\\rangle.}$$
](A272900_1_En_19_Chapter_Equp.gif)

## 19.4 Modified Axioms for Quantum Mechanics

We may now modify the axioms of quantum mechanics introduced in Sect.​ 3.​6 to incorporate density matrices, beginning with our revised notion of a state.

Axiom 6

The state of a quantum system is described by a density matrix ρ on an appropriate Hilbert space H . If A is any bounded operator on H , the expectation value of A in the state ρ is given by the quantity ![
$$\\mathrm{trace}\(\\rho A\) =\\mathrm{ trace}\(A\\rho \).$$
](A272900_1_En_19_Chapter_IEq101.gif)

In Axiom 6, we assume that A is bounded, so that trace(ρ A) and trace(A ρ) are defined and equal by Proposition 19.3. If A is unbounded and self-adjoint, we can construct a probability measure μ ρ A describing the probabilities for measurements of A in the state ρ, by the formula

![
$$\\displaystyle{\\mu _{\\rho }^{A}\(E\) =\\mathrm{ trace}\(\\rho 1_{ E}\(A\)\),}$$
](A272900_1_En_19_Chapter_Equq.gif)

where 1 E (A) is defined by the functional calculus.

We then define the expectation value of A in the state ρ as ![
$$\\int _{\\mathbb{R}}\\lambda \\ d\\mu _{\\rho }^{A}\(\\lambda \),$$
](A272900_1_En_19_Chapter_IEq102.gif) provided the integral is absolutely convergent. If the integral is absolutely convergent, it is reasonable to hope that both ρ A and A ρ will be densely defined and bounded, that (the bounded extension to H of) these operators will be trace class, and that both trace(ρ A) and trace(A ρ) will coincide with ![
$$\\int _{\\mathbb{R}}\\lambda \\ d\\mu _{\\rho }^{A}\(\\lambda \).$$
](A272900_1_En_19_Chapter_IEq103.gif) We will not, however, enter into an investigation of this issue.

Next, we propose a variant of Axiom 4, describing the "collapse of the wave function."

Axiom 7

Suppose a quantum system is initially in a state ρ and a measurement of a self-adjoint operator A with point spectrum is performed. If the measurement results in the value λ for A, then immediately after the measurement, the system will be in the state ρ ′ , where

![
$$\\displaystyle{{\\rho }^{{\\prime}} = \\frac{1} {Z}P_{\\lambda }\\rho P_{\\lambda }.}$$
](A272900_1_En_19_Chapter_Equr.gif)

Here P λ is the orthogonal projection onto the λ-eigenspace of A and Z = trace (P λ ρP λ ).

Note that if ρ is non-negative, self-adjoint, and trace class, then P λ ρ P λ is also non-negative, self-adjoint, and trace class. Implicit in Axiom 7 is the assumption that the measurement can only result in values λ for which P λ ρ P λ is nonzero. In particular, λ must be an eigenvalue for A.

Finally, we introduce the notion of time-evolution for our new notion of "state."

Axiom 8

The time evolution of the state of the system is described by the following equation for a time-dependent density matrix ρ(t):

![
$$\\displaystyle{ \\frac{d\\rho } {dt} = -\\frac{1} {i\\hslash }\[\\rho,\\hat{H}\]. }$$
](A272900_1_En_19_Chapter_Equ5.gif)

(19.3)

This equation may be solved, formally, by setting

![
$$\\displaystyle{ \\rho \(t\) = {e}^{-it\\hat{H}/\\hslash }\\rho _{ 0}{e}^{it\\hat{H}/\\hslash }, }$$
](A272900_1_En_19_Chapter_Equ6.gif)

(19.4)

where ρ 0 is the state of the system at time t = 0.

There are some domain issues involved in the interpretation of the equation (19.3). Rather than entering into an examination of those issues here, we will simply take (19.4) as the definition of the time-evolution of a density matrix. Presumably, if ρ 0 is nice enough, then the map t↦ρ(t) will be differentiable as a curve in the Banach space ![
$$\\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq104.gif) and its derivative will be (an extension of) the operator on the right-hand side of (19.3). By comparison, it follows from Stone's theorem and Lemma 10.17 that the family of pure states ![
$$\\psi \(t\) := {e}^{-it\\hat{H}/\\hslash }\\psi _{0}$$
](A272900_1_En_19_Chapter_IEq105.gif) satisfies the Schrödinger equation in the natural Hilbert space sense if and only if ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq096.gif) 0 belongs to the domain of ![
$$\\hat{H}.$$
](A272900_1_En_19_Chapter_IEq106.gif) To see that the time-evolution in (19.4) is consistent with the previously defined time-evolution of pure states, observe that

![
$$\\displaystyle{{e}^{-it\\hat{H}/\\hslash }\\left \\vert \\psi _{ 0}\\right\\rangle \\left \\langle \\psi _{0}\\right\\vert {e}^{it\\hat{H}/\\hslash } = \\vert {e}^{-it\\hat{H}/\\hslash }\\psi _{ 0}\\rangle \\langle {e}^{-it\\hat{H}/\\hslash }\\psi _{ 0}\\vert = \\left \\vert \\psi \(t\)\\right\\rangle \\left \\langle \\psi \(t\)\\right\\vert,}$$
](A272900_1_En_19_Chapter_Equs.gif)

since ![
$${\({e}^{it\\hat{H}/\\hslash }\)}^{{\\ast}} = {e}^{-it\\hat{H}/\\hslash }.$$
](A272900_1_En_19_Chapter_IEq107.gif)

It should be noted that (19.3) differs by a minus sign from the time-evolution in the Heisenberg picture of quantum mechanics (Definition 3.19). Although this difference may seem strange, keep in mind that in Axiom 8, we are not adopting the Heisenberg point of view, in which the states are independent of time and the observables evolve in time. Rather, we are adopting a modified version of the Schrödinger picture, in which it is the states that evolve in time, but where the states are now certain sorts of operators. Even though both the states and the observables are now operators, the observables (in the Heisenberg picture) and the states (in the Schrödinger picture) must evolve in opposite directions in time, in order for the expectation values of the observables to be the same in the two pictures.

## 19.5 Composite Systems and the Tensor Product

As discussed in Sect.​ 3.​11, the Hilbert space for two (nonidentical, spinless) particles moving in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq108.gif) is ![
$${L}^{2}\({\\mathbb{R}}^{6}\).$$
](A272900_1_En_19_Chapter_IEq109.gif) Given a unit vector (i.e., a pure state) ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq051.gif) in ![
$${L}^{2}\({\\mathbb{R}}^{6}\),$$
](A272900_1_En_19_Chapter_IEq110.gif) the quantity ![
$${\\left \\vert \\psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\)\\right\\vert }^{2}$$
](A272900_1_En_19_Chapter_IEq111.gif) represents the joint probability distribution for the position x 1 of the first particle and the position x 2 of the second particle. The following result shows that ![
$${L}^{2}\({\\mathbb{R}}^{6}\)$$
](A272900_1_En_19_Chapter_IEq112.gif) is naturally isomorphic to the Hilbert tensor product of two copies of the Hilbert space for the individual particles, namely ![
$${L}^{2}\({\\mathbb{R}}^{3}\).$$
](A272900_1_En_19_Chapter_IEq113.gif)

Proposition 19.12.

Suppose that (X 1 ,μ 1 ) and (X 2 ,μ 2 ) are σ-finite measure spaces. Then there is a unique unitary map

![
$$\\displaystyle{p : {L}^{2}\(X_{ 1},\\mu _{1}\)\\hat{ \\otimes } {L}^{2}\(X_{ 2},\\mu _{2}\) \\rightarrow {L}^{2}\(X_{ 1} \\times X_{2},\\mu _{1} \\times \\mu _{2}\)}$$
](A272900_1_En_19_Chapter_Equt.gif)

such that

![
$$\\displaystyle{p\(\\phi \\otimes \\psi \)\(x,y\) =\\phi \(x\)\\psi \(y\)}$$
](A272900_1_En_19_Chapter_Equu.gif)

for all ![
$$\\phi \\in {L}^{2}\(X_{1},\\mu _{1}\)$$
](A272900_1_En_19_Chapter_IEq114.gif) and ![
$$\\psi \\in {L}^{2}\(X_{2},\\mu _{2}\).$$
](A272900_1_En_19_Chapter_IEq115.gif)

Here ![
$$\\hat{\\otimes }$$
](A272900_1_En_19_Chapter_IEq116.gif) denotes the Hilbert tensor product defined in Appendix A.4.5.

Proof.

For simplicity of notation, we suppress the dependence of L 2 spaces on the measure, writing, say, L 2(X 1) rather than ![
$${L}^{2}\(X_{1},\\mu _{1}\)$$
](A272900_1_En_19_Chapter_IEq117.gif). Consider first the algebraic (i.e., uncompleted) tensor product ![
$${L}^{2}\(X_{1}\) \\otimes {L}^{2}\(X_{2}\).$$
](A272900_1_En_19_Chapter_IEq118.gif) Using the universal property of tensor products, we can construct a linear map p of ![
$${L}^{2}\(X_{1}\) \\otimes {L}^{2}\(X_{2}\) \\rightarrow {L}^{2}\(X_{1} \\times X_{2}\)$$
](A272900_1_En_19_Chapter_IEq119.gif) determined uniquely by the requirement that

![
$$\\displaystyle{p\(\\phi \\otimes \\psi \)\(x,y\) =\\phi \(x\)\\psi \(y\).}$$
](A272900_1_En_19_Chapter_Equv.gif)

Now, every element of the algebraic tensor product ![
$${L}^{2}\(X_{1}\) \\otimes {L}^{2}\(X_{2}\)$$
](A272900_1_En_19_Chapter_IEq120.gif) can be expressed as a linear combination of elements of the form ![
$$\\phi _{j} \\otimes \\psi _{j},$$
](A272900_1_En_19_Chapter_IEq121.gif) with ![
$$\\phi _{j} \\in {L}^{2}\(X_{1}\)$$
](A272900_1_En_19_Chapter_IEq122.gif) and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq052.gif) j in L 2(X 2). By computing on such linear combinations, we can easily verify that p is isometric. Thus, by the bounded linear transformation (BLT) theorem (Theorem A.36), p has a unique isometric extension to a map of the completed tensor product ![
$${L}^{2}\(X_{1}\)\\hat{ \\otimes } {L}^{2}\(X_{2}\)$$
](A272900_1_En_19_Chapter_IEq123.gif) into ![
$${L}^{2}\(X_{1} \\times X_{2}\).$$
](A272900_1_En_19_Chapter_IEq124.gif)

It remains only to show that p is surjective. Since both measures are σ-finite, it is a simple exercise to reduce the problem to the case where μ 1 and μ 2 are finite, which we henceforth assume. Suppose ![
$$\\psi \\in {L}^{2}\(X_{1} \\times X_{2}\)$$
](A272900_1_En_19_Chapter_IEq125.gif) is orthogonal to the image of p. Then ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq053.gif) is orthogonal to the indicator function of every measurable rectangle, and hence to the indicator function of any finite disjoint union of measurable rectangles. The collection ![
$$\\mathcal{A}$$
](A272900_1_En_19_Chapter_IEq126.gif) of such disjoint unions is an algebra of sets. Let ![
$$\\mathcal{M}$$
](A272900_1_En_19_Chapter_IEq127.gif) denote the collection of measurable subsets E of X 1 × X 2 such that the integral of ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq054.gif) over E is zero. Then ![
$$\\mathcal{M}$$
](A272900_1_En_19_Chapter_IEq128.gif) is a monotone class containing ![
$$\\mathcal{A}.$$
](A272900_1_En_19_Chapter_IEq129.gif) By the monotone class lemma (Theorem A.8), ![
$$\\mathcal{M}$$
](A272900_1_En_19_Chapter_IEq130.gif) contains the σ-algebra generated by ![
$$\\mathcal{A},$$
](A272900_1_En_19_Chapter_IEq131.gif) which is the σ-algebra on which μ 1 × μ 2 is defined. Thus, the integral of ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq055.gif) over every measurable set is zero, which implies that ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq056.gif) is zero almost everywhere.

The preceding example suggests the following general principle.

Axiom 9

The Hilbert space for a composite system made up of two subsystems is the Hilbert tensor product ![
$$\\mathbf{H}_{1}\\hat{ \\otimes }\\mathbf{H}_{2}$$
](A272900_1_En_19_Chapter_IEq132.gif) of the Hilbert spaces H 1 and H 2 describing the subsystems.

If A and B are bounded operators on H 1 and H 2, respectively, then there is a unique bounded operator A ⊗ B on ![
$$\\mathbf{H}_{1}\\hat{ \\otimes }\\mathbf{H}_{2}$$
](A272900_1_En_19_Chapter_IEq133.gif) such that

![
$$\\displaystyle{\(A \\otimes B\)\(\\phi \\otimes \\psi \) = \(A\\phi \) \\otimes \(B\\psi \)}$$
](A272900_1_En_19_Chapter_Equw.gif)

for all ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq057.gif) ∈ H 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq058.gif) ∈ H 2. (See Appendix A.4.5.)

Theorem 19.13.

Suppose that ρ is a density matrix on ![
$$\\mathbf{H}_{1}\\hat{ \\otimes }\\mathbf{H}_{2}.$$
](A272900_1_En_19_Chapter_IEq134.gif) Then there exists a unique density matrix ρ (1) on H 1 with the property that

![
$$\\displaystyle{ \\mathrm{trace}{\(\\rho }^{\(1\)}A\) =\\mathrm{ trace}\(\\rho \(A \\otimes I\)\) }$$
](A272900_1_En_19_Chapter_Equ7.gif)

(19.5)

for all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}_{1}\).$$
](A272900_1_En_19_Chapter_IEq135.gif) We call ρ (1) the partial trace of ρ with respect to H 2 . If {f k } is an orthonormal basis for H 2 , then the operator ρ (1) satisfies

![
$$\\displaystyle{ \\langle \\phi {,\\rho }^{\(1\)}\\psi \\rangle =\\sum _{ k}\\left \\langle \\phi \\otimes f_{k},\\rho \(\\psi \\otimes f_{k}\)\\right\\rangle }$$
](A272900_1_En_19_Chapter_Equ8.gif)

(19.6)

for all ![
$$\\phi,\\,\\psi$$
](A272900_1_En_19_Chapter_IEq0101.gif) ∈ H 1 . Similarly, there is a unique density matrix ρ (2) on H 2 satisfying trace (ρ (2) B) = trace (ρ(I ⊗ B)) for all ![
$$B \\in \\mathcal{B}\(\\mathbf{H}_{2}\).$$
](A272900_1_En_19_Chapter_IEq136.gif) If {e j } is an orthonormal basis for H 1 , then ρ (2) satisfies

![
$$\\displaystyle{ \\langle \\phi {,\\rho }^{\(2\)}\\psi \\rangle =\\sum _{ j}\\left \\langle e_{j}\\otimes \\phi,\\rho \(e_{j}\\otimes \\psi \)\\right\\rangle }$$
](A272900_1_En_19_Chapter_Equ9.gif)

(19.7)

for all ![
$$\\phi,\\,\\psi$$
](A272900_1_En_19_Chapter_IEq0102.gif) ∈ H 2.

The motivation for the terminology "partial trace" is provided by (19.6) and (19.7), which are similar to the formula for the trace of an operator, except that the sums range only over a basis for one of the two Hilbert spaces. One special case of Theorem 19.13 is the one in which the density matrix ρ is of the form ρ = ρ 1 ⊗ ρ 2, where ρ 1 and ρ 2 are density matrices on H 1 and H 2, respectively. (Any operator ρ of this form is a density matrix on H 1 × H 2.) In that case, it is not hard to see that ρ (1) = ρ 1 and ρ (2) = ρ 2. We may describe this case by saying that the state of the first system is "independent" of the state of the second system.

Lemma 19.14.

For any sequence ![
$$A_{n} \\in \\mathcal{B}\(\\mathbf{H}_{1}\),$$
](A272900_1_En_19_Chapter_IEq137.gif) if ![
$$\\left \\Vert A_{n}\\psi - A\\psi \\right\\Vert \\rightarrow 0$$
](A272900_1_En_19_Chapter_IEq138.gif) for some ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq139.gif) and all ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0116.gif) ∈ H 1 , then

![
$$\\displaystyle{\\left \\Vert \(A_{n} \\otimes I\)\\phi - \(A \\otimes I\)\\phi \\right\\Vert \\rightarrow 0}$$
](A272900_1_En_19_Chapter_Equx.gif)

for all ![
$${\\phi}$$
](A272900_1_En_19_Chapter_IEq0103.gif) ∈ H 1 ⊗ H 2 . A similar result holds for operators of the form I ⊗ B n.

Proof.

See Exercise 9.

Proof of Theorem 19.13.

(1) and ρ (2) follow from Lemma 19.14 and Theorem 19.9. Meanwhile, if {e j } is an orthonormal basis for H 1 and {f k } is an orthonormal basis for H 2, we have

![
$$\\displaystyle\\begin{array}{rcl} \\langle \\phi {,\\rho }^{\(1\)}\\psi \\rangle & =& \\mathrm{trace}{\(\\rho }^{\(1\)}\\left \\vert \\psi \\right\\rangle \\left \\langle \\phi \\right\\vert \) {}\\\\ & =& \\sum _{j,k}\\left \\langle e_{j} \\otimes f_{k},\\rho \(\\left \\vert \\psi \\right\\rangle \\left \\langle \\phi \\right\\vert \\otimes I\)\(e_{j} \\otimes f_{k}\)\\right\\rangle {}\\\\ & =& \\sum _{j,k}\\left \\langle e_{j} \\otimes f_{k},\\rho \(\\psi \\left \\langle \\phi,e_{j}\\right\\rangle \\otimes f_{k}\)\\right\\rangle {}\\\\ & =& \\sum _{k}\\left \\langle \\left \(\\sum _{j}\\left \\langle e_{j},\\phi \\right\\rangle e_{j}\\right\) \\otimes f_{k},\\rho \(\\psi \\otimes f_{k}\)\\right\\rangle {}\\\\ & =& \\sum _{k}\\left \\langle \\phi \\otimes f_{k},\\rho \(\\psi \\otimes f_{k}\)\\right\\rangle. {}\\\\ \\end{array}$$
](A272900_1_En_19_Chapter_Equ10.gif)

This is the desired formula for ![
$$\\left \\langle \\phi {,\\rho }^{\(1\)}\\psi \\right\\rangle.$$
](A272900_1_En_19_Chapter_IEq140.gif) Note that because ρ is trace class and ![
$$\\left \\vert \\psi \\right\\rangle \\left \\langle \\phi \\right\\vert \\otimes I$$
](A272900_1_En_19_Chapter_IEq141.gif) is bounded, ![
$$\\rho \(\\left \\vert \\psi \\right\\rangle \\left \\langle \\phi \\right\\vert \\otimes I\)$$
](A272900_1_En_19_Chapter_IEq142.gif) is trace class, in which case the sum in the second line is absolutely convergent, by Proposition 19.3. Thus, we are allowed to rearrange the sum freely.

Suppose we have two quantum systems with Hilbert spaces H 1 and H 2 and Hamiltonians ![
$$\\hat{H}_{1}$$
](A272900_1_En_19_Chapter_IEq143.gif) and ![
$$\\hat{H}_{2}$$
](A272900_1_En_19_Chapter_IEq144.gif). If the two systems do not interact with each other and the composite system is initially in a (pure) state of the form ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq059.gif) 0 ⊗ ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq060.gif) 0, then we expect that at some later time, the composite system will be in the state ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq097.gif)(t) ⊗ ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq061.gif)(t), where ![
$$\\phi \(t\) = {e}^{-it\\hat{H}_{1}/\\hslash }\\psi _{0}$$
](A272900_1_En_19_Chapter_IEq145.gif) and ![
$$\\psi \(t\) = {e}^{-it\\hat{H}_{2}/\\hslash }.$$
](A272900_1_En_19_Chapter_IEq146.gif) Ignoring domain considerations, we may compute that

![
$$\\displaystyle\\begin{array}{rcl} i\\hslash \\frac{d} {dt}\\left \[\\phi \(t\) \\otimes \\psi \(t\)\\right\]& =& \(\\hat{H}_{1}\\phi \(t\)\) \\otimes \\psi \(t\) +\\phi \(t\) \\otimes \(\\hat{H}_{2}\\psi \(t\)\) {}\\\\ & =& \(\\hat{H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2}\)\(\\phi \(t\) \\otimes \\psi \(t\)\). {}\\\\ \\end{array}$$
](A272900_1_En_19_Chapter_Equ11.gif)

This calculation suggests that the correct Hamiltonian for a noninteracting composite system is the operator ![
$$\\hat{H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2}.$$
](A272900_1_En_19_Chapter_IEq147.gif)

It is not, however, obvious how to select a domain for ![
$$\\hat{H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2}$$
](A272900_1_En_19_Chapter_IEq148.gif) in such a way that this operator will be self-adjoint. (The reader is invited to try to choose such a domain "by hand.") The easiest way to deal with this issue is to use Stone's theorem, as in the following definition.

Definition 19.15.

If A and B are self-adjoint operators on H 1 and H 2 , define the operator A ⊗ I + I ⊗ B to be the infinitesimal generator of the strongly continuous one-parameter unitary group e itA ⊗ e itB . Thus, by Stone's theorem, A ⊗ I + I ⊗ B is self-adjoint.

It is not hard to check that e i t A ⊗ e i t B is indeed strongly continuous. In the case B = 0, the operator A ⊗ I is defined as the infinitesimal generator of e i t A ⊗ I. If A and B happen to be bounded, then A ⊗ I \+ I ⊗ B defined by Definition 19.15 coincides with A ⊗ I \+ I ⊗ B defined as the sum of tensor products of bounded operators, as in Sect. A.4.5.

Axiom 10

Suppose H 1 and H 2 are the Hilbert spaces for two quantum systems, with Hamiltonians ![
$$\\hat{H}_{1}$$
](A272900_1_En_19_Chapter_IEq149.gif) and ![
$$\\hat{H}_{2},$$
](A272900_1_En_19_Chapter_IEq150.gif) respectively. Then the Hamiltonian for the noninteracting composite system is ![
$$\\hat{H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2},$$
](A272900_1_En_19_Chapter_IEq151.gif) where the domain of ![
$$\\hat{H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2}$$
](A272900_1_En_19_Chapter_IEq152.gif) is as in Definition 19.15.

A physicist would write ![
$$\\hat{H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2}$$
](A272900_1_En_19_Chapter_IEq153.gif) simply as ![
$$\\hat{H}_{1} +\\hat{ H}_{2},$$
](A272900_1_En_19_Chapter_IEq154.gif) with the understanding that ![
$$\\hat{H}_{1}$$
](A272900_1_En_19_Chapter_IEq155.gif) acts only on the first factor in the tensor product and ![
$$\\hat{H}_{2}$$
](A272900_1_En_19_Chapter_IEq156.gif) acts only on the second factor.

In general, the two components of a composite system will interact, in which case the Hamiltonian for the composite system is typically of the form

![
$$\\displaystyle{\\hat{H} =\\hat{ H}_{1} \\otimes I + I \\otimes \\hat{ H}_{2} +\\hat{ H}_{\\mathrm{int}},}$$
](A272900_1_En_19_Chapter_Equy.gif)

where ![
$$\\hat{H}_{\\mathrm{int}}$$
](A272900_1_En_19_Chapter_IEq157.gif) is an "interaction term." Often, the interaction term may be considered "small" compared with the other terms in the Hamiltonian. Consider, for example, a system consisting of particles in a box, with a barrier dividing the box in half. Suppose the particles interact by means of a two-particle potential of the form ![
$$\\sum _{j<k}V \({\\mathbf{x}}^{j} -{\\mathbf{x}}^{k}\)$$
](A272900_1_En_19_Chapter_IEq158.gif) (Sect.​ 2.​3.​2) and that V (x j − x k ) is very small unless the two particles are close together. There will typically be far more pairs of nearby particles in which the two particles are on the same side of the box than nearby pairs on opposite sides. Thus, even though the interaction between the two systems may substantially affect the behavior of the composite system over long periods of time, it is still reasonable to think of ![
$$\\hat{H}_{1} \\otimes I$$
](A272900_1_En_19_Chapter_IEq159.gif) as "the energy of the first subsystem" and ![
$$I \\otimes \\hat{ H}_{2}$$
](A272900_1_En_19_Chapter_IEq160.gif) as "the energy of the second subsystem."

Suppose we start out in a state ρ of the composite system for which the state ρ (1) of the first subsystem is a pure state. If the system is an interacting one, the first subsystem will probably not remain in a pure state at later times. Indeed, suppose that the second subsystem is very large system having temperature T. Then, according to the postulates of quantum statistical mechanics, we are supposed to believe that once the two systems have reached thermal equilibrium, the state of the first subsystem will be given by the following highly mixed state:

![
$$\\displaystyle{{ \\rho }^{\(1\)} = \\frac{1} {Z\(\\beta \)}{e}^{-\\beta \\hat{H}_{1} }. }$$
](A272900_1_En_19_Chapter_Equ12.gif)

(19.8)

Here ![
$$\\beta = 1/\(k_{B}T\),$$
](A272900_1_En_19_Chapter_IEq161.gif) where k B is Boltzmann's constant, and Z(β) is a normalization constant, known as the partition function of the theory, given by ![
$$Z\(\\beta \) =\\mathrm{ trace}\({e}^{-\\beta \\hat{H}_{1}}\).$$
](A272900_1_En_19_Chapter_IEq162.gif)

Of course, for this idea to make sense, ![
$${e}^{-\\beta \\hat{H}_{1}}$$
](A272900_1_En_19_Chapter_IEq163.gif) must be trace class. This will be the case provided that ![
$$\\hat{H}_{1}$$
](A272900_1_En_19_Chapter_IEq164.gif) has discrete spectrum with eigenvalues tending to + ∞ at some reasonable rate. Thus, in quantum statistical mechanics, the expectation value of some observable A for the first subsystem will be (once equilibrium is reached)

![
$$\\displaystyle{ \\left \\langle A\\right\\rangle = \\frac{1} {Z}\\mathrm{trace}\({e}^{-\\beta \\hat{H}_{1} }A\). }$$
](A272900_1_En_19_Chapter_Equ13.gif)

(19.9)

In particular, when ![
$$A =\\hat{ H}_{1},$$
](A272900_1_En_19_Chapter_IEq165.gif) (19.9) provides a natural generalization of Planck's model of blackbody radiation; compare Exercise 2 in Chap. 1.

## 19.6 Multiple Particles: Bosons and Fermions

As discussed in Sect.​ 17.​8, each type of particle (electron, proton, neutron, etc.) has a spin l, where the possible value for l are

![
$$\\displaystyle{l = 0, \\frac{1} {2},1, \\frac{3} {2},\\ldots.}$$
](A272900_1_En_19_Chapter_Equz.gif)

The Hilbert space for a particle moving in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq166.gif) and having spin l is ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{l},$$
](A272900_1_En_19_Chapter_IEq167.gif) where V l is a finite-dimensional Hilbert space that carries an irreducible projective unitary representation of SO(3) of dimension 2l \+ 1. There is a natural unitary identification of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{l}$$
](A272900_1_En_19_Chapter_IEq168.gif) with ![
$${L}^{2}\({\\mathbb{R}}^{3};V _{l}\),$$
](A272900_1_En_19_Chapter_IEq169.gif) the space of square-integrable functions on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq170.gif) with values in V l , in which the element ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq062.gif) ⊗ v of ![
$${L}^{2}\({\\mathbb{R}}^{3}\)\\hat{ \\otimes } V _{l}$$
](A272900_1_En_19_Chapter_IEq171.gif) is identified with the function

![
$$\\displaystyle{\\mathbf{x}\\mapsto \\psi \(\\mathbf{x}\)v}$$
](A272900_1_En_19_Chapter_Equaa.gif)

in ![
$${L}^{2}\({\\mathbb{R}}^{3};V _{l}\).$$
](A272900_1_En_19_Chapter_IEq172.gif)

Now, we have already mentioned, in Sect.​ 3.​11, the idea that in quantum mechanics, identical particles are indistinguishable. Let us think about this in the case of two identical particles with spin l. Our first guess as to the Hilbert space for such a system is the tensor product of two copies of ![
$${L}^{2}\({\\mathbb{R}}^{3};V _{l}\),$$
](A272900_1_En_19_Chapter_IEq173.gif) which may be identified with

![
$$\\displaystyle{{L}^{2}\({\\mathbb{R}}^{6};V _{ l} \\otimes V _{l}\).}$$
](A272900_1_En_19_Chapter_Equab.gif)

If ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq063.gif) is a unit vector in this space, thought of as a pure state, then saying that the two particles are "indistinguishable" means that ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq064.gif)(x 2, x 1) should represent the same physical state as ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq065.gif)(x 1, x 2), that is, ![
$$\\psi \({\\mathbf{x}}^{2},{\\mathbf{x}}^{1}\) = c\\psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\)$$
](A272900_1_En_19_Chapter_IEq174.gif) for some nonzero constant c. Applying this rule twice shows that c must be either 1 or − 1.

A variety of theoretical and experimental considerations suggest the following principle: For particles with integer spin (l = 0, 1,...), the constant c in the preceding paragraph is 1, whereas for particles with half-integer spin (![
$$l = 1/2,3/2,\\ldots$$
](A272900_1_En_19_Chapter_IEq175.gif)) the constant c is − 1. Particles with integer spin are called bosons and particles with half-integer spin are called fermions. We encode the discussion in the two preceding paragraphs in the following axiom.

Axiom 11

Consider a collection of N identical particles moving in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq176.gif) and having integer spin l. Then the Hilbert space for such a collection is the subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3N};{\(V _{l}\)}^{\\otimes N}\)$$
](A272900_1_En_19_Chapter_IEq177.gif) consisting of those square-integrable functions ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0104.gif) for which

![
$$\\displaystyle{\\psi \({\\mathbf{x}}^{\\sigma \(1\)},{\\mathbf{x}}^{\\sigma \(2\)},\\ldots,{\\mathbf{x}}^{\\sigma \(N\)}\) =\\psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\)}$$
](A272900_1_En_19_Chapter_Equac.gif)

for every permutation σ. Consider also a collection of N identical particles moving in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq178.gif) and having half-integer spin l. Then the Hilbert space for such a collection is the subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3N};{\(V _{l}\)}^{\\otimes N}\)$$
](A272900_1_En_19_Chapter_IEq179.gif) consisting of those square-integrable functions ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq0117.gif) for which

![
$$\\displaystyle{\\psi \({\\mathbf{x}}^{\\sigma \(1\)},{\\mathbf{x}}^{\\sigma \(2\)},\\ldots,{\\mathbf{x}}^{\\sigma \(N\)}\) =\\mathrm{ sign}\(\\sigma \)\\psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\)}$$
](A272900_1_En_19_Chapter_Equad.gif)

for every permutation σ.

One may well ask why Axiom 11 holds. More specifically, one may first ask why it is that identical particles are indistinguishable, and then separately ask why integer-spin particles are bosons and half-integer-spin particles are fermions. Both questions are best answered from the point of view of quantum field theory, to which ordinary nonrelativistic quantum mechanics is an approximation.

In field theory, one starts with a "classical" field theory, meaning a differential equation for functions ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq066.gif)(x, t) on ![
$${\\mathbb{R}}^{4}$$
](A272900_1_En_19_Chapter_IEq180.gif) with values in some finite-dimensional vector space. Electromagnetic fields, for example, are—at any one fixed time—functions on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq181.gif) with values in ![
$${\\mathbb{R}}^{6},$$
](A272900_1_En_19_Chapter_IEq182.gif) where ![
$${\\mathbb{R}}^{6}$$
](A272900_1_En_19_Chapter_IEq183.gif) describes the three components of the electric field and the three components of the magnetic field. These functions on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq184.gif) then evolve in time according to Maxwell's equation. In quantum field theory, one regards, say, Maxwell's equations as a sort of infinite-dimensional dynamical system, which we may quantize in something like the way we quantize Newton's equation to get ordinary nonrelativistic quantum mechanics. In the quantum version of Maxwell's equations, the energy in each mode of the fields is "quantized," meaning that one can only add energy to each mode in multiples of a certain unit (or "quantum") of energy. This is analogous to the quantum harmonic oscillator, in which the allowed energies differ by integer multiples of the ![
$$\\hslash \\omega.$$
](A272900_1_En_19_Chapter_IEq185.gif) In quantum field theory, then, a particle is one quantum of excitation of a certain field.

For simplicity, let us think of a field theory in which the classical fields take values in ![
$$\\mathbb{R}.$$
](A272900_1_En_19_Chapter_IEq186.gif) Then even at the classical level, it is possible to think that we have something like particles, namely localized bumps in the field ![
$$\\phi \(\\mathbf{x}\)$$
](A272900_1_En_19_Chapter_IEq187.gif) located at several different points in space. These bumps might, for example, be in the shape of a Gaussian wave-packet, that is, a Gaussian envelope multiplied by a sinusoidally oscillating function. From this point of view, we can gain some understanding of why identical particles are indistinguishable. Suppose we have a Gaussian wave packet near a point a in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq188.gif) and then an identically shaped Gaussian wave packet near another point b. The state ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq067.gif)(x) of the field is precisely the same as if we have a packet near b and then also a packet near a. That is to say, there is no distinct state of the system that corresponds to interchanging the two particles; whichever bump we think of as the "first" particle, we have the same field ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq068.gif)(x). Even in the quantum version of such a system, there no meaning to asking which is the first particle and which is the second. Thus, even in nonrelativistic quantum mechanics, which is a low-energy approximation to quantum field theory, we expect identical particles to be indistinguishable.

Although the preceding discussion does not explain the distinction between bosons and fermions, that distinction also emerges from quantum field theory, through something called the spin–statistics theorem (see,e.g., [38]).

## 19.7 "Statistics" and the Pauli Exclusion Principle

The spin of an electron is equal to 1 ∕ 2 and electrons are, therefore, fermions. The famous Pauli exclusion principle is a consequence of the fermionic nature of electrons. Pauli's principle states that two electrons cannot be in the same state at the same time. This means that if ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq069.gif) is a square-integrable, ![
$${\\mathbb{C}}^{2}$$
](A272900_1_En_19_Chapter_IEq189.gif)-valued function on ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq190.gif) (which could describe the state of a single electron), then the function ![
$$\\Psi : {\\mathbb{R}}^{6} \\rightarrow {\\mathbb{C}}^{2} \\otimes {\\mathbb{C}}^{2}$$
](A272900_1_En_19_Chapter_IEq191.gif) given by

![
$$\\displaystyle{\\Psi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\) =\\psi \({\\mathbf{x}}^{1}\) \\otimes \\psi \({\\mathbf{x}}^{2}\)}$$
](A272900_1_En_19_Chapter_Equae.gif)

is not a possible state of a two-electron system, since Ψ does not satisfy Axiom 11. On the other hand, if ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq070.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq071.gif) 2 are two linearly independent elements of ![
$${L}^{2}\({\\mathbb{R}}^{3}; {\\mathbb{C}}^{2}\),$$
](A272900_1_En_19_Chapter_IEq192.gif) then the function ![
$$\\Phi : {\\mathbb{R}}^{6} \\rightarrow {\\mathbb{C}}^{2} \\otimes {\\mathbb{C}}^{2}$$
](A272900_1_En_19_Chapter_IEq193.gif) given by

![
$$\\displaystyle{ \\Phi \({\\mathbf{x}}^{1},{\\mathbf{x}}^{2}\) =\\psi _{ 1}\({\\mathbf{x}}^{1}\)\\psi _{ 2}\({\\mathbf{x}}^{2}\) -\\psi _{ 2}\({\\mathbf{x}}^{1}\)\\psi _{ 1}\({\\mathbf{x}}^{2}\) }$$
](A272900_1_En_19_Chapter_Equ14.gif)

(19.10)

is a possible state of a two-electron system. [If ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq072.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq073.gif) 2 are independent, then Φ is a nonzero element of ![
$${L}^{2}\({\\mathbb{R}}^{6}; {\\mathbb{C}}^{2} \\otimes {\\mathbb{C}}^{2}\),$$
](A272900_1_En_19_Chapter_IEq194.gif) which can then be normalized to be a unit vector. See Exercise 10.]

Let us try to understand the implications of the Pauli exclusion principle for multielectron atoms. Let us model an N-electron atom as having a nucleus with positive charge Nq, where the charge of a single electron is − q. Since the nucleus is much more massive than the electrons, we can treat the nucleus as being fixed and the electrons as moving in potential of the form ![
$$-Nq/\\left \\vert \\mathbf{x}\\right\\vert.$$
](A272900_1_En_19_Chapter_IEq195.gif) As a very rough approximation to the structure of such an atom, we can ignore the electron–electron interaction and take a Hamiltonian of the form

![
$$\\displaystyle{\\hat{H} =\\sum _{ j=1}^{N}\\left \(-\\frac{{\\hslash }^{2}} {2m}{\\Delta }^{j} -\\frac{N{q}^{2}} {\\left \\vert {\\mathbf{x}}^{j}\\right\\vert } \\right\),}$$
](A272900_1_En_19_Chapter_Equaf.gif)

where Δ j is the Laplacian acting on the jth variable. That is, we are taking our Hamiltonian to be simply

![
$$\\displaystyle{\(\\hat{H} \\otimes I \\otimes I \\otimes \\cdots \\otimes I\) + \(I \\otimes \\hat{ H} \\otimes I \\otimes \\cdots \\otimes I\) + \(I \\otimes I \\otimes \\hat{ H} \\otimes \\cdots \\otimes I\) + \\cdots \\,,}$$
](A272900_1_En_19_Chapter_Equag.gif)

where ![
$$\\hat{H}$$
](A272900_1_En_19_Chapter_IEq196.gif) is the Hamiltonian for a single electron.

If, say, N is even, the lowest-energy state for this Hamiltonian in the antisymmetric subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3N};{\({\\mathbb{C}}^{2}\)}^{\\otimes N}\)$$
](A272900_1_En_19_Chapter_IEq197.gif) will be

![
$$\\displaystyle\\begin{array}{rcl} & & \\Psi _{0}\({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\) \\\\ & =& \\mathrm{AS}\\left \(\\psi _{0}^{+}\({\\mathbf{x}}^{1}\) \\otimes \\psi _{ 0}^{-}\({\\mathbf{x}}^{2}\) \\otimes \\psi _{ 1}^{+}\({\\mathbf{x}}^{3}\) \\otimes \\cdots \\otimes \\psi _{ N/2}^{+}\({\\mathbf{x}}^{N-1}\) \\otimes \\psi _{ N/2}^{-}\({\\mathbf{x}}^{N}\)\\right\).{}\\end{array}$$
](A272900_1_En_19_Chapter_Equ15.gif)

(19.11)

If N is odd, the product ends with ![
$$\\psi _{\(N+1\)/2}^{+}\({\\mathbf{x}}^{N}\).$$
](A272900_1_En_19_Chapter_IEq198.gif) The notation in (19.11) is as follows. First, AS is the antisymmetrization operator, given by

![
$$\\displaystyle{\\mathrm{AS}\(f\)\({\\mathbf{x}}^{1},\\ldots,{\\mathbf{x}}^{N}\) =\\sum _{\\sigma \\in {S}^{N}}\\mathrm{sign}\(\\sigma \)f\({\\mathbf{x}}^{\\sigma \(1\)},{\\mathbf{x}}^{\\sigma \(2\)},\\cdots \\,,{\\mathbf{x}}^{\\sigma \(N\)}\).}$$
](A272900_1_En_19_Chapter_Equah.gif)

Second, the functions ![
$$\\psi _{0},\\psi _{1},\\psi _{2},\\ldots$$
](A272900_1_En_19_Chapter_IEq199.gif) are the eigenvectors in ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_19_Chapter_IEq200.gif) for the Hamiltonian of a single particle in ![
$${\\mathbb{R}}^{3}$$
](A272900_1_En_19_Chapter_IEq201.gif) moving in a potential of the form ![
$$-N{q}^{2}/\\left \\vert \\mathbf{x}\\right\\vert,$$
](A272900_1_En_19_Chapter_IEq202.gif) arranged so that the eigenvalues of ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq074.gif) j are weakly increasing with j. The ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq075.gif) j 's are just the states computed in Chap.​ 18, but with q replaced by ![
$$\\sqrt{N}q.$$
](A272900_1_En_19_Chapter_IEq203.gif) Third, ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq076.gif) j +(x) denotes ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq077.gif) j (x) ⊗ e 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq098.gif) j −(x) denotes ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq078.gif) j (x) ⊗ e 2, where {e 1, e 2} is the standard basis for ![
$${\\mathbb{C}}^{2}.$$
](A272900_1_En_19_Chapter_IEq204.gif)

What the expression for Ψ 0 means is that, if we ignore (at first) the interaction between the electrons, but retain the Pauli exclusion principle, then we put the first electron into the ground state of the single-electron system, with "spin up" (i.e., tensored with e 1). Then we put the second electron into the ground state with "spin down" (tensored with e 2). Then the third electron goes into the first excited state of the single-electron system with spin up, and so on. Of course, this model of a multielectron atom is very rough, since the interaction between the electrons actually plays a significant role. Nevertheless, this model highlights the critical role played by the exclusion principle, which forces successive electrons to go into higher and higher energy states. In particular, this crude approximation suggests (correctly!) that even for more realistic models of a multielectron atom, the lowest energy level in the antisymmetric subspace of ![
$${L}^{2}\({\\mathbb{R}}^{3N};{\({\\mathbb{C}}^{2}\)}^{\\otimes N}\)$$
](A272900_1_En_19_Chapter_IEq205.gif) is much higher than the lowest energy level of the same Hamiltonian in all of ![
$${L}^{2}\({\\mathbb{R}}^{3N};{\({\\mathbb{C}}^{2}\)}^{\\otimes N}\).$$
](A272900_1_En_19_Chapter_IEq206.gif)

Meanwhile, in quantum statistical mechanics, one considers a large collection of identical particles confined to some finite region of space. If the system is isolated (rather than in thermal equilibrium with its environment), the goal of statistical mechanics is to "count" the number N(E) of quantum states with energy less than E, as a function of E. [That is, N(E) is number of eigenvalues for the Hamiltonian less than E, counted with their multiplicity.] As the preceding discussion of the Pauli exclusion principle suggests, we will get very different answers for N(E) if the particles are fermions than if they are bosons. Bosons are said to follow Bose–Einstein statistics, whereas fermions are said to follow Fermi–Dirac statistics. The term "statistics" here refers to the different behavior of the two types of particles in quantum statistical mechanics. The spin–statistics theorem in quantum field theory tells us that particles with integer spin have to be bosons (obeying Bose–Einstein statistics) and particles with half-integer spin have to be fermions (obeying Fermi–Dirac statistics).

One fascinating example of quantum statistical mechanics occurs when the particles are bosons and the interaction between particles is negligible. In that case, the lowest energy state will simply be

![
$$\\displaystyle{\\Psi _{0}\({\\mathbf{x}}^{1},{\\mathbf{x}}^{2},\\ldots,{\\mathbf{x}}^{N}\) =\\psi _{ 0}\({\\mathbf{x}}^{1}\) \\otimes \\psi _{ 0}\({\\mathbf{x}}^{2}\) \\otimes \\cdots \\otimes \\psi _{ 0}\({\\mathbf{x}}^{N}\),}$$
](A272900_1_En_19_Chapter_Equai.gif)

where ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq079.gif) 0 is the ground state of the single-particle system. Now, quantum statistical mechanics tells us that at a given temperature, the state of the system will be an (incoherent) superposition of the ground state and the various excited states. If the temperature is low enough, then the coefficient of the ground state will be close to 1, and thus, "all the particles are in the ground state." A system in such a state is called a Bose–Einstein condensate, a state that was predicted on theoretical grounds by Satyendra Nath Bose and Einstein in the 1920s. Bose–Einstein condensates were first observed experimentally in laser-cooled gases in June 1995 by Eric Cornell and Carl Wieman, in work for which they, along with Wolfgang Ketterle, were awarded the 2001 Nobel Prize in physics.

## 19.8 Exercises

1.

Suppose that X is a Hilbert–Schmidt operator on H and that {e j } is an orthonormal basis for H. Show that

![
$$\\displaystyle{\\left \\Vert X\\right\\Vert _{HS}^{2} =\\sum _{ j,k}{\\left \\vert \\left \\langle e_{j},Xe_{k}\\right\\rangle \\right\\vert }^{2}.}$$
](A272900_1_En_19_Chapter_Equaj.gif)

2.

Given ![
$$\\phi$$
](A272900_1_En_19_Chapter_IEq080.gif), ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq081.gif) ∈ H, let ![
$$\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert$$
](A272900_1_En_19_Chapter_IEq207.gif) denote the operator defined in Notation 3.27. Show that if ![
$$A\\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq208.gif) is trace class, then

![
$$\\displaystyle{\\mathrm{trace}\(A\\left \\vert \\phi \\right\\rangle \\left \\langle \\psi \\right\\vert \) = \\left \\langle \\psi,A\\phi \\right\\rangle.}$$
](A272900_1_En_19_Chapter_Equak.gif)

Hint: If {e j } is an orthonormal basis for H, then for any χ ∈ H, we have ![
$$\\chi =\\sum _{j}\\left \\langle e_{j},\\chi \\right\\rangle e_{j}.$$
](A272900_1_En_19_Chapter_IEq209.gif)

3.

Suppose ![
$$\\Phi : \\mathcal{B}\(\\mathbf{H}\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_19_Chapter_IEq210.gif) is a linear functional with the properties (1) that Φ(A) is real whenever A is self-adjoint and (2) that Φ(A) is real and non-negative whenever A is self-adjoint and non-negative. Show that if A is self-adjoint, then

![
$$\\displaystyle{-\\left \\Vert A\\right\\Vert \\Phi \(I\) \\leq \\Phi \(A\) \\leq \\left \\Vert A\\right\\Vert \\Phi \(I\).}$$
](A272900_1_En_19_Chapter_Equal.gif)

Conclude that Φ is bounded relative to the operator norm on ![
$$\\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq211.gif)

Hint: Show that if A is self-adjoint, then ![
$$\\left \\Vert A\\right\\Vert I + A$$
](A272900_1_En_19_Chapter_IEq212.gif) and ![
$$\\left \\Vert A\\right\\Vert I - A$$
](A272900_1_En_19_Chapter_IEq213.gif) are non-negative.

4.

An operator ![
$$A\\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq214.gif) is said to have finite rank if range(A) is finite dimensional.

(a)

Show that if ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq215.gif) has finite rank, then so does A ∗.

(b)

Given ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq216.gif) show that A has finite rank if and only if there exist vectors ![
$$\\phi _{1},\\ldots,\\phi _{N}$$
](A272900_1_En_19_Chapter_IEq217.gif) and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq082.gif) 1,..., ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq083.gif) N such that

![
$$\\displaystyle{A = \\left \\vert \\phi _{1}\\right\\rangle \\left \\langle \\psi _{1}\\right\\vert + \\cdots + \\left \\vert \\phi _{N}\\right\\rangle \\left \\langle \\psi _{N}\\right\\vert.}$$
](A272900_1_En_19_Chapter_Equam.gif)

(c)

Let A be any element of ![
$$\\mathcal{B}\(\\mathbf{H}\),$$
](A272900_1_En_19_Chapter_IEq218.gif) let {e j } be an orthonormal basis for H, and let P N be the orthogonal projection onto the span of e 1,..., e N . Show that P N A has finite rank and that for all ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq084.gif) ∈ H, we have

![
$$\\displaystyle{\\lim _{N\\rightarrow \\infty }\\left \\Vert P_{N}A\\psi - A\\psi \\right\\Vert = 0.}$$
](A272900_1_En_19_Chapter_Equan.gif)

Note: This result shows that each bounded operator can be expressed as a strong limit of finite-rank operators. By contrast, if dim H = ∞, then Part (a) of Exercise 5 shows that not every bounded operator can be expressed as an operator-norm limit of finite-rank operators.

5.

In this exercise, assume that dim H = ∞.

(a)

Show that if A has finite rank, then ![
$$\\left \\Vert A + cI\\right\\Vert \\geq \\left \\vert c\\right\\vert$$
](A272900_1_En_19_Chapter_IEq219.gif) for any ![
$$c \\in \\mathbb{C}.$$
](A272900_1_En_19_Chapter_IEq220.gif) (With ![
$$c = -1,$$
](A272900_1_En_19_Chapter_IEq221.gif) this shows that I is not an operator-norm limit of finite-rank operators.)

(b)

Let ![
$$\\mathcal{K}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq222.gif) denote the closure of the finite-rank operators with respect to the operator norm on ![
$$\\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq223.gif) Let V denote the space of operators of the form B \+ cI, with ![
$$B \\in \\mathcal{K}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq224.gif) Define a linear functional ![
$$\\Phi : V \\rightarrow \\mathbb{C}$$
](A272900_1_En_19_Chapter_IEq225.gif) by ![
$$\\Phi \(B + cI\) = c$$
](A272900_1_En_19_Chapter_IEq226.gif) for all ![
$$B \\in \\mathcal{K}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq227.gif) Show that ![
$$\\left \\vert \\Phi \(A\)\\right\\vert \\leq \\left \\Vert A\\right\\Vert$$
](A272900_1_En_19_Chapter_IEq228.gif) for all A ∈ V.

Note: It can be shown that ![
$$\\mathcal{K}\(\\mathbf{H}\)$$
](A272900_1_En_19_Chapter_IEq229.gif) is precisely the space of compact operators on H.

(c)

Let ![
$$\\Psi _{1} : \\mathcal{B}\(\\mathbf{H}\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_19_Chapter_IEq230.gif) be any linear functional such that Ψ 1 = Φ on V and such that ![
$$\\left \\vert \\Psi _{1}\(A\)\\right\\vert \\leq \\left \\Vert A\\right\\Vert$$
](A272900_1_En_19_Chapter_IEq231.gif) for all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq232.gif) (Such a functional exists by the Hahn–Banach theorem.) Let ![
$$\\Psi _{2} : \\mathcal{B}\(\\mathbf{H}\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_19_Chapter_IEq233.gif) be defined by

![
$$\\displaystyle{\\Psi _{2}\(A\) = \\frac{1} {2}\(\\Psi _{1}\(A\) + \\overline{\\Psi _{1}\({A}^{{\\ast}}\)}\).}$$
](A272900_1_En_19_Chapter_Equao.gif)

Show that Ψ 2 satisfies Properties 1, 2, and 3 of Definition 19.6, but that there does not exist any density matrix ρ such that Ψ 2(A) = trace(ρ A) for all ![
$$A \\in \\mathcal{B}\(\\mathbf{H}\).$$
](A272900_1_En_19_Chapter_IEq234.gif) (Thus, in light of Theorem 19.9, Ψ 2 must not satisfy Property 4 of Definition 19.6.)

6.

In Exercises 6, 7, and 8, assume that each density matrix ρ is compact, so that ρ has an orthonormal basis {e j } of eigenvectors, for which the associated eigenvalues {λ j } are real and tend to zero as j tends to infinity. (Compare Theorem VI.16 in [34].)

Show that a density matrix ρ is a pure state if and only if trace(ρ 2) = 1.

7.

(a)

Show that each mixed state ρ is a nontrivial convex combination of other density matrices.

(b)

Show that a pure state cannot be expressed as a nontrivial convex combination of other density matrices.

Hint: Show that the function ![
$$f\(\\lambda \) :=\\mathrm{ trace}\\left \({\\left \(\\lambda \\rho _{1} + \(1-\\lambda \)\\rho _{2}\\right\)}^{2}\\right\)$$
](A272900_1_En_19_Chapter_IEq235.gif) is a convex function of λ.

8.

For any density matrix ρ, show that the von Neumann entropy ![
$$S\(\\rho \) :=\\mathrm{ trace}\(-\\rho \\log \\rho \)$$
](A272900_1_En_19_Chapter_IEq236.gif) is zero if and only if ρ is a pure state.

9.

Prove Lemma 19.14.

Hint: First use the principle of uniform boundedness (Theorem A.40) to show that there exists a constant C with ![
$$\\left \\Vert A_{n}\\right\\Vert \\leq C$$
](A272900_1_En_19_Chapter_IEq237.gif) for all n. Then, if {f j } is an orthonormal basis for H 2, decompose ![
$$\\mathbf{H} _{1}\\hat{ \\otimes }\\mathbf{H}_{2}$$
](A272900_1_En_19_Chapter_IEq238.gif) as the Hilbert space direct sum of the subspaces H 1 ⊗ f j , where each of these subspaces is isometrically identified with H 1 in the obvious way.

10.

Suppose that ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq085.gif) 1 and ![
$$\\psi$$
](A272900_1_En_19_Chapter_IEq086.gif) 2 are two linearly independent elements of ![
$${L}^{2}\({\\mathbb{R}}^{3}; {\\mathbb{C}}^{2}\).$$
](A272900_1_En_19_Chapter_IEq239.gif) Show that the function Φ in (19.10) is a nonzero element of ![
$${L}^{2}\({\\mathbb{R}}^{6}; {\\mathbb{C}}^{2} \\otimes {\\mathbb{C}}^{2}\).$$
](A272900_1_En_19_Chapter_IEq240.gif)

References

[34].

M. Reed, B. Simon, Methods of Modern Mathematical Physics. Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)

[38].

R.F. Streater, A.S. Wightman, PCT, Spin and Statistics, and All That (Corrected third printing of the 1978 edition). Princeton Landmarks in Physics (Princeton University Press, Princeton, NJ, 2000)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_20

© Springer Science+Business Media New York 2013

# 20. The Path Integral Formulation of Quantum Mechanics

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

We turn now to a topic that is important already for ordinary quantum mechanics and essential in quantum field theory: the so-called path integral. In the setting of ordinary quantum mechanics (of the sort we have been considering in this book), the integrals in question are over spaces of "paths," that is, maps of some interval [a, b] into ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq1.gif) In the setting of quantum field theory, the integrals are integrals over spaces of "fields," that is, maps of some region inside ![
$${\\mathbb{R}}^{d}$$
](A272900_1_En_20_Chapter_IEq2100.gif) into ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq3.gif) Formal integrals of this sort abound in the physics literature, and it is typically difficult to make rigorous mathematical sense of them—although much effort has been expended in the attempt! In this chapter, we will develop a rigorous integral over spaces of paths by using the Wiener measure, resulting in the Feynman–Kac formula.

We turn now to a topic that is important already for ordinary quantum mechanics and essential in quantum field theory: the so-called path integral. In the setting of ordinary quantum mechanics (of the sort we have been considering in this book), the integrals in question are over spaces of "paths," that is, maps of some interval [a, b] into ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq1500.gif) In the setting of quantum field theory, the integrals are integrals over spaces of "fields," that is, maps of some region inside ![
$${\\mathbb{R}}^{d}$$
](A272900_1_En_20_Chapter_IEq2.gif) into ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq300.gif) Formal integrals of this sort abound in the physics literature, and it is typically difficult to make rigorous mathematical sense of them—although much effort has been expended in the attempt! In this chapter, we will develop a rigorous integral over spaces of paths by using the Wiener measure, resulting in the Feynman–Kac formula.

We begin with the Trotter product formula, which will be our main tool in deriving the path integral formulas. From there we turn to the (heuristic) path integral formula of Feynman, and then to the rigorous version of Feynman's result obtained by M. Kac, the so-called Feynman–Kac formula. Although it is not feasible to give complete proofs of all results presented here, we give enough proofs to get a flavor of the mathematics involved. We will prove a version of the Trotter product formula and, assuming the existence of the Wiener measure, a version of the Feynman–Kac formula.

## 20.1 Trotter Product Formula

The Lie product formula (Point 7 of Theorem 16.15) says that for all X and Y in ![
$$M_{n}\(\\mathbb{C}\),$$
](A272900_1_En_20_Chapter_IEq4.gif) we have

![
$$\\displaystyle{{e}^{X+Y } =\\lim _{ m\\rightarrow \\infty }{\({e}^{X/m}{e}^{Y/m}\)}^{m}.}$$
](A272900_1_En_20_Chapter_Equa.gif)

The Trotter product formula asserts that a similar result holds for certain classes of unbounded operators on Hilbert spaces.

Theorem 20.1 (Trotter Product Formula)

Suppose that A and B are self-adjoint operators on H and that A + B is densely defined and essentially self-adjoint on Dom (A ∩) Dom (B). Then the following results hold.

1.

For all ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq01.gif) ∈ H, we have

![
$$\\displaystyle{ \\lim _{N\\rightarrow \\infty }\\left \\Vert {e}^{it\(A+B\)}\\psi - {\({e}^{itA/N}{e}^{itB/N}\)}^{N}\\psi \\right\\Vert. }$$
](A272900_1_En_20_Chapter_Equ1.gif)

(20.1)

2.

If A and B are bounded below, then for all ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq02.gif) ∈ H, we have

![
$$\\displaystyle{ \\lim _{N\\rightarrow \\infty }\\left \\Vert {e}^{-t\(A+B\)}\\psi - {\({e}^{-tA/N}{e}^{-tB/N}\)}^{N}\\psi \\right\\Vert. }$$
](A272900_1_En_20_Chapter_Equ2.gif)

(20.2)

In both results, the expression A + B refers to the unique self-adjoint extension of the operator defined on Dom (A) ∩ Dom (B).

In the usual terminology of functional analysis, (20.1) asserts that the operators ![
$${\({e}^{itA/N}{e}^{itB/N}\)}^{N}$$
](A272900_1_En_20_Chapter_IEq5.gif) converge to e it(A \+ B) in the "strong operator topology," and similarly with (20.2).

We will give a proof of this result in the special case in which A \+ B is densely defined and self-adjoint on Dom(A) ∩ Dom(B). This condition holds, for example, whenever the Kato–Rellich theorem (Theorem 9.37) applies. See Sect. A.5 of [14] for a proof of the version stated above.

Proof.

Since all the operators in Point 1 of the theorem are unitary, it is easy to see that if the result holds on some dense subspace W of H, it holds on all of H. In Point 2 of the theorem, we first make a simple reduction to the case where A and B are non-negative, and then have the same conclusion, since all operators involved will then be contractions.

We will prove Point 1 of the theorem, with the proof of Point 2 being similar. Let us introduce the notation ![
$$S_{s} := {e}^{is\(A+B\)}$$
](A272900_1_En_20_Chapter_IEq6.gif) and ![
$$T_{s} := {e}^{isA}{e}^{isB}.$$
](A272900_1_En_20_Chapter_IEq7.gif) What we want to prove is that for each ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq03.gif) ∈ H, the quantity ![
$$\\left \\Vert \(S_{t} - {\(T_{t/N}\)}^{N}\)\\psi \\right\\Vert$$
](A272900_1_En_20_Chapter_IEq8.gif) tends to zero as N tends to infinity. Now, a simple calculation shows that

![
$$\\displaystyle{ \\left \\Vert \(S_{t} - {\(T_{t/N}\)}^{N}\)\\psi \\right\\Vert = \\left \\Vert \\sum _{ j=0}^{N-1}{\(T_{ t/N}\)}^{j}\(S_{ t/N} - T_{t/N}\){\(S_{t/N}\)}^{N-j-1}\\psi \\right\\Vert. }$$
](A272900_1_En_20_Chapter_Equ3.gif)

(20.3)

Since S ⋅ is a one-parameter unitary group, ![
$${\(S_{t/N}\)}^{N-j-1}\\psi = S_{s}\\psi,$$
](A272900_1_En_20_Chapter_IEq9.gif) where ![
$$s = \(N - j - 1\)t/N.$$
](A272900_1_En_20_Chapter_IEq10.gif) Thus, if we let ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq04.gif) s = S s ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq05.gif), we have

![
$$\\displaystyle{ \\left \\Vert \(S_{t} - {\(T_{t/N}\)}^{N}\)\\psi \\right\\Vert \\leq N\\sup _{ 0\\leq s\\leq t}\\left \\Vert \(S_{t/N} - T_{t/N}\)\\psi _{s}\\right\\Vert. }$$
](A272900_1_En_20_Chapter_Equ4.gif)

(20.4)

Now, for any ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq06.gif) in Dom(A \+ B), we have

![
$$\\displaystyle{\\lim _{N\\rightarrow \\infty }N\(S_{t/N}\\psi -\\psi \) = it\(A + B\)\\psi,}$$
](A272900_1_En_20_Chapter_Equb.gif)

by Stone's theorem. Meanwhile, according to Exercise 2, we have

![
$$\\displaystyle{ \\lim _{s\\rightarrow 0}\\frac{1} {s}\(T_{s} - I\)\\psi = iA\\psi + iB\\psi, }$$
](A272900_1_En_20_Chapter_Equ5.gif)

(20.5)

for all ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq07.gif) ∈ Dom(A) ∩ Dom(B). (This result is clear at the heuristic level.) Thus,

![
$$\\displaystyle\\begin{array}{rcl} \\lim _{N\\rightarrow \\infty }N\(S_{t/N} - T_{t/N}\)\\psi & =& \\lim _{N\\rightarrow \\infty }N\(S_{t/N} - I\)\\psi -\\lim _{N\\rightarrow \\infty }N\(T_{t/N} - I\)\\psi \\\\ & =& it\(A + B\)\\psi - it\(A + B\)\\psi = 0 {}\\end{array}$$
](A272900_1_En_20_Chapter_Equ6.gif)

(20.6)

for every ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq08.gif) ∈ Dom(A) ∩ Dom(B).

Let W = Dom(A) ∩ Dom(B), which is, by assumption, dense in H, equipped with the norm ![
$$\\left \\Vert \\cdot \\right\\Vert _{1}$$
](A272900_1_En_20_Chapter_IEq11.gif) given by

![
$$\\displaystyle{\\left \\Vert \\psi \\right\\Vert _{1} = \\left \\Vert \\psi \\right\\Vert + \\left \\Vert \(A + B\)\\psi \\right\\Vert.}$$
](A272900_1_En_20_Chapter_Equc.gif)

Since we are assuming A \+ B is self-adjoint, and thus also closed, on W, we see that W is a Banach space with respect ![
$$\\left \\Vert \\cdot \\right\\Vert _{1}$$
](A272900_1_En_20_Chapter_IEq12.gif) (Exercise 6 in Chap.​ 9). Now, the operators ![
$$N\(S_{t/N} - T_{t/N}\)$$
](A272900_1_En_20_Chapter_IEq13.gif) are certainly bounded from W to H, for each N. Furthermore, (20.6) shows that for each ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq09.gif) ∈ W, we have

![
$$\\displaystyle{\\sup _{N}\\left \\Vert N\(S_{t/N} - T_{t/N}\)\\psi \\right\\Vert <\\infty.}$$
](A272900_1_En_20_Chapter_Equd.gif)

Thus, by the principle of uniform boundedness (Theorem A.40), there is a constant C such that

![
$$\\displaystyle{\\left \\Vert N\(S_{t/N} - T_{t/N}\)\\psi \\right\\Vert \\leq C\\left \\Vert \\psi \\right\\Vert _{1}}$$
](A272900_1_En_20_Chapter_Eque.gif)

for all ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq010.gif) ∈ W. It then follows (Exercise 3) that ![
$$\\left \\Vert N\(S_{t/N} - T_{t/N}\)\\psi \\right\\Vert$$
](A272900_1_En_20_Chapter_IEq14.gif) tends to zero uniformly on every compact subset of W.

Suppose, now, that for each ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq011.gif) ∈ W, the s↦![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq012.gif) s is continuous in W. If so, the image of the compact interval [0, t] under s↦![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq013.gif) s will be compact in W, and so ![
$$\\left \\Vert N\(S_{t/N} - T_{t/N}\)\\psi _{s}\\right\\Vert$$
](A272900_1_En_20_Chapter_IEq15.gif) will tend to zero uniformly in s. Thus, by (20.4), we will have Point 1 of the theorem. To establish the desired continuity, we first note that by Lemma 10.17, the operators ![
$$S_{s} = {e}^{is\(A+B\)}$$
](A272900_1_En_20_Chapter_IEq16.gif) preserve Dom(A \+ B), which is equal to W, by assumption. Then for any s, r ∈ [0, t] and ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq014.gif) ∈ W, we have

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \\Vert {e}^{is\(A+B\)}\\psi - {e}^{ir\(A+B\)}\\psi \\right\\Vert _{ 1} \\\\ & & = \\left \\Vert {e}^{is\(A+B\)}\\psi - {e}^{ir\(A+B\)}\\psi \\right\\Vert + \\left \\Vert \(A + B\)\({e}^{is\(A+B\)}\\psi - {e}^{ir\(A+B\)}\\psi \)\\right\\Vert \\\\ & & = \\left \\Vert \({e}^{is\(A+B\)} - {e}^{ir\(A+B\)}\)\\psi \\right\\Vert + \\left \\Vert \({e}^{is\(A+B\)} - {e}^{ir\(A+B\)}\)\(A + B\)\\psi \\right\\Vert,{}\\end{array}$$
](A272900_1_En_20_Chapter_Equ7.gif)

(20.7)

where we have used Lemma 10.17 again in the second equality. The strong continuity of e is(A \+ B) (Proposition 10.14) then ensures that the right-hand side of (20.7) tends to zero as s approaches r.

## 20.2 Formal Derivation of the Feynman Path Integral

In this section, we apply Point 1 of the Trotter product formula to the operator

![
$$\\displaystyle{ -\\frac{1} {\\hslash }\\hat{H} = \\frac{\\hslash } {2m}\\Delta -\\frac{1} {\\hslash }V \(X\). }$$
](A272900_1_En_20_Chapter_Equ8.gif)

(20.8)

Let us call the operators on the right-hand side of (20.8) A and B, respectively, and let us assume V is sufficiently nice that ![
$$\\hat{H}$$
](A272900_1_En_20_Chapter_IEq17.gif) is essentially self-adjoint on Dom(A) ∩ Dom(B). Any bounded potential certainly has this property, as do many unbounded potentials. (See, e.g., Theorem 9.38.)

Point 1 of Theorem 20.1 then tells us that

![
$$\\displaystyle{{e}^{-it\\hat{H}/\\hslash }\\psi =\\lim _{ N\\rightarrow \\infty }{\\left \(\\exp \\left \\{ \\frac{it\\hslash \\Delta } {2mN}\\right\\}\\exp \\left \\{-\\frac{itV \(X\)} {N\\hslash } \\right\\}\\right\)}^{N}\\psi.}$$
](A272900_1_En_20_Chapter_Equf.gif)

Under mild assumptions on ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq015.gif), Theorem 4.5 (extended to n dimensions) tells us that exp(it ℏ Δ ∕ (2mN)) may be computed as

![
$$\\displaystyle{{e}^{it\\hslash \\Delta /\(2mN\)}\\psi \(\\mathbf{x}_{ 0}\) ={ \\left \(\\frac{mN} {it\\hslash } \\right\)}^{n/2}\\int _{{ \\mathbb{R}}^{n}}\\exp \\left \\{i\\frac{mN} {2t\\hslash }{ \\left \\vert \\mathbf{x}_{1} -\\mathbf{x}_{0}\\right\\vert }^{2}\\right\\}\\psi \(\\mathbf{x}_{ 1}\)\\ d\\mathbf{x}_{1}.}$$
](A272900_1_En_20_Chapter_Equg.gif)

Meanwhile, ![
$$\\exp \(-itV \(X\)/\(N\\hslash \)\)$$
](A272900_1_En_20_Chapter_IEq18.gif) is simply a multiplication operator.

Thus, assuming that Theorem 4.5 applies at each stage, we have

![
$$\\displaystyle\\begin{array}{rcl} & & \\left \[{\\left \(\\exp \\left \\{ \\frac{it\\hslash \\Delta } {2mN}\\right\\}\\exp \\left \\{-\\frac{itV \(X\)} {N\\hslash } \\right\\}\\right\)}^{N}\\psi \\right\]\(\\mathbf{x}_{ 0}\) {}\\\\ & & = C\\int _{{\\mathbb{R}}^{n}}\\exp \\left \\{i\\frac{mN} {2t\\hslash }{ \\left \\vert \\mathbf{x}_{1} -\\mathbf{x}_{0}\\right\\vert }^{2}\\right\\}\\exp \\left \\{-\\frac{itV \(\\mathbf{x}_{1}\)} {N\\hslash } \\right\\} {}\\\\ & & \\times \\int _{{\\mathbb{R}}^{n}}\\exp \\left \\{i\\frac{mN} {2t\\hslash }{ \\left \\vert \\mathbf{x}_{N-1} -\\mathbf{x}_{N-2}\\right\\vert }^{2}\\right\\}\\exp \\left \\{-\\frac{itV \(\\mathbf{x}_{N-1}\)} {N\\hslash } \\right\\} {}\\\\ & & \\times \\cdots \\times \\int _{{\\mathbb{R}}^{n}}\\exp \\left \\{i\\frac{mN} {2t\\hslash }{ \\left \\vert \\mathbf{x}_{N} -\\mathbf{x}_{N-1}\\right\\vert }^{2}\\right\\}\\exp \\left \\{-\\frac{itV \(\\mathbf{x}_{N}\)} {N\\hslash } \\right\\} {}\\\\ & & \\times \\psi \(\\mathbf{x}_{N}\)\\ d\\mathbf{x}_{N}\\ d\\mathbf{x}_{N-1}\\cdots \\ d\\mathbf{x}_{1}, {}\\\\ \\end{array}$$
](A272900_1_En_20_Chapter_Equ9.gif)

where ![
$$C = {\(mN/\(it\\hslash \)\)}^{nN/2}.$$
](A272900_1_En_20_Chapter_IEq19.gif) Letting ![
$$\\varepsilon = t/N$$
](A272900_1_En_20_Chapter_IEq20.gif) and assuming we can freely rearrange the order of integration, we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \({e}^{-it\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}_{ 0}\) \\\\ & & =\\lim _{N\\rightarrow \\infty }C\\int _{{\({\\mathbb{R}}^{n}\)}^{N}}\\exp \\left \\{ \\frac{i} {\\hslash }\\sum _{j=1}^{N}\\varepsilon \\left \[\\frac{m} {2}{ \\left \\vert \\frac{\\mathbf{x}_{j} -\\mathbf{x}_{j-1}} {\\varepsilon } \\right\\vert }^{2} - V \(\\mathbf{x}_{ j-1}\)\\right\]\\right\\} \\\\ & & \\times \\psi \(\\mathbf{x}_{N}\)\\ d\\mathbf{x}_{1}\\ d\\mathbf{x}_{2}\\cdots d\\mathbf{x}_{N}. {}\\end{array}$$
](A272900_1_En_20_Chapter_Equ10.gif)

(20.9)

So far, the argument is mostly rigorous, coming from the Trotter product formula and Theorem 4.5. The nonrigorous part comes in attempting to evaluate the limit on the right-hand side of (20.9). Let us think of the values x j , j = 0,..., N as constituting the values of a path x(s) at the points ![
$$s_{j} := j\\varepsilon = jt/N$$
](A272900_1_En_20_Chapter_IEq21.gif):

![
$$\\displaystyle{\\mathbf{x}_{j} = \\mathbf{x}\(jt/N\).}$$
](A272900_1_En_20_Chapter_Equh.gif)

Since the distance between s j − 1 and s j is ![
$$\\varepsilon,$$
](A272900_1_En_20_Chapter_IEq22.gif) the quantity ![
$$\\vert \\mathbf{x}_{j} -\\mathbf{x}_{j-1}\\vert /\\varepsilon$$
](A272900_1_En_20_Chapter_IEq23.gif) is an approximation to the derivative of x(s) with respect to s. Meanwhile, the sum over j in the right-hand side of (20.9) is an approximation to an integral. Thus, if we then take the limit of the right-hand of (20.9) in a totally nonrigorous fashion, we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \({e}^{-it\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}_{ 0}\) \\\\ & & = C\\int _{\\begin{array}{c}\\text{paths with } \\\\ \\mathbf{x}\(0\)=\\mathbf{x}_{0} \\end{array}}\\exp \\left \\{ \\frac{i} {\\hslash }\\int _{0}^{t}\\left \[\\frac{m} {2}{ \\left \\vert \\frac{d\\mathbf{x}} {ds}\\right\\vert }^{2} - V \(\\mathbf{x}\(s\)\)\\right\]\\ ds\\right\\}\\psi \(\\mathbf{x}\(t\)\)\\ \\mathcal{D}\\mathbf{x}.{}\\end{array}$$
](A272900_1_En_20_Chapter_Equ11.gif)

(20.10)

Here, C is a normalization constant and ![
$$\\mathcal{D}\\mathbf{x}$$
](A272900_1_En_20_Chapter_IEq24.gif) is something like "Lebesgue measure" on the space of all paths x( ⋅) mapping [0, t] into ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq25.gif) (The quantity x in the expression ![
$$\\mathcal{D}\\mathbf{x}$$
](A272900_1_En_20_Chapter_IEq26.gif) is a path, not a point in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq27.gif))

The reader who is familiar with the Lagrangian approach to mechanics will recognize the expression in square brackets in the exponent on the right-hand side of (20.10) as the Lagrangian of the particle, ![
$$L = T - V,$$
](A272900_1_En_20_Chapter_IEq28.gif) where ![
$$T = \(1/2\)m{\\left \\vert v\\right\\vert }^{2}$$
](A272900_1_En_20_Chapter_IEq29.gif) is the kinetic energy and V is the potential energy. The integral of the Lagrangian over some time interval is called the action functional, denoted by the letter ![
$$\\mathcal{S}.$$
](A272900_1_En_20_Chapter_IEq30.gif) That is to say, given a path x( ⋅), we define the action functional of x( ⋅) over a time-interval [a, b] as follows:

![
$$\\displaystyle{ \\mathcal{S}\(\\mathbf{x}\(\\cdot \),a,b\) :=\\int _{ a}^{b}\\left \[\\frac{m} {2}{ \\left \\vert \\frac{d\\mathbf{x}} {ds}\\right\\vert }^{2} - V \(\\mathbf{x}\(s\)\)\\right\]\\ ds. }$$
](A272900_1_En_20_Chapter_Equ12.gif)

(20.11)

In Lagrangian mechanics, one shows that the solutions to Newton's law are precisely the stationary points of the action functional. Using the notation in (20.11), we may rewrite (20.10) as

![
$$\\displaystyle{ \({e}^{-it\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}_{ 0}\) = C\\int _{\\begin{array}{c}\\text{paths with } \\\\ \\mathbf{x}\(0\)=\\mathbf{x}_{0} \\end{array}}\\exp \\left \\{ \\frac{i} {\\hslash }\\mathcal{S}\(\\mathbf{x}\(\\cdot \),0,t\)\\right\\}\\psi \(\\mathbf{x}\(t\)\)\\ \\mathcal{D}\\mathbf{x}. }$$
](A272900_1_En_20_Chapter_Equ13.gif)

(20.12)

This formula is the Feynman path integral formula.

Now, knowledge of Lagrangian mechanics is not directly relevant to the derivation of the Feynman path integral formula. Nevertheless, it is intriguing that the an important quantity from classical mechanics should appear in the Feynman path integral formula in quantum mechanics. Indeed, this appearance raises the possibility that one can use the path integral formula to make connections between quantum mechanics and classical mechanics. Indeed, the "method of stationary phase" (when applied, formally, in an infinite-dimensional setting) asserts that for small values of ![
$$\\hslash,$$
](A272900_1_En_20_Chapter_IEq31.gif) the main contribution to the right-hand side of (20.12) comes from regions near the stationary points of the action functional, namely the classical trajectories. Using this method, Gutzwiller was able to derive his famous trace formula, which provides predictions of typical eigenvalue spacings for Schrödinger operators based on the behavior of the underlying classical system. More information about this fascinating subject can be found in books on "quantum chaos," including [19] by Gutzwiller himself.

It is notoriously difficult to attach a rigorous meaning to the right-hand side of the Feynman path integral formula. Note that the formal expression "![
$$\\mathcal{D}\\mathbf{x}$$
](A272900_1_En_20_Chapter_IEq32.gif)" is the limit as N tends to infinity of the integral over ![
$${\({\\mathbb{R}}^{n}\)}^{N}$$
](A272900_1_En_20_Chapter_IEq33.gif) in (20.9) with respect to the Lebesgue measure (i.e., the measure given by ![
$$d\\mathbf{x}_{1}\\ d\\mathbf{x}_{2}\\cdots d\\mathbf{x}_{N}$$
](A272900_1_En_20_Chapter_IEq34.gif)). Thus, "![
$$\\mathcal{D}\\mathbf{x}$$
](A272900_1_En_20_Chapter_IEq35.gif)" should be something like Lebesgue measure on the space of all paths (maps from [0, t] into ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_20_Chapter_IEq36.gif)). However, it is known that an infinite-dimensional vector space (say, a Banach space) does not have any "reasonable" (say, σ-finite) translation-invariant measure that could play the role of Lebesgue measure. Furthermore, the absolute value of the constant C is easily seen to be infinite. Thus, we certainly cannot take the right-hand side of (20.12) literally.

A better approach is to avoid looking at the component parts of the Feynman path integral and instead to look at the whole expression against which the function ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq016.gif)(x(t)) is being integrated. If we could attach a rigorous meaning to the expression

![
$$\\displaystyle{ C\\exp \\left \\{ \\frac{i} {\\hslash }\\mathcal{S}\(\\mathbf{x}\(\\cdot \),0,t\)\\right\\}\\ \\mathcal{D}\\mathbf{x}, }$$
](A272900_1_En_20_Chapter_Equ14.gif)

(20.13)

as, say, a complex-valued measure on the space of continuous paths, then this could serve to give a meaning to the path integral. It is known, however, that there is no complex measure on the space of paths that makes the Feynman path integral formula true. The oscillatory behavior produced by the i in the exponent in (20.13) makes it difficult to give a rigorous meaning to the Feynman path integral in its original form.

## 20.3 The Imaginary-Time Calculation

In trying to give a rigorous meaning to the path integral formula of Feynman, Kac proceeded by considering the "imaginary time" time-evolution operator ![
$$\\exp \(-t\\hat{H}/\\hslash \),$$
](A272900_1_En_20_Chapter_IEq37.gif) which is just the usual time-evolution operator ![
$$\\exp \(-it\\hat{H}/\\hslash \)$$
](A272900_1_En_20_Chapter_IEq38.gif) evaluated with t replaced by − it. The idea is that if one can use path integrals to understand the operators ![
$$\\exp \(-t\\hat{H}/\\hslash \),$$
](A272900_1_En_20_Chapter_IEq39.gif) one can go back to the "real time" operator ![
$$\\exp \(-it\\hat{H}/\\hslash \)$$
](A272900_1_En_20_Chapter_IEq40.gif) by analytic continuation with respect to t.

The counterpart of Theorem 4.5 for ![
$$\\exp \(-t\\hslash \\Delta /\(2m\)\)$$
](A272900_1_En_20_Chapter_IEq41.gif) (proved in the same way) is

![
$$\\displaystyle{\({e}^{-t\\hslash \\Delta /\(2m\)}\\psi \)\(\\mathbf{x}_{ 0}\) ={ \\left \( \\frac{m} {2\\pi t\\hslash }\\right\)}^{n/2}\\int _{{ \\mathbb{R}}^{n}}\\exp \\left \\{- \\frac{m} {2t\\hslash }{\\left \\vert \\mathbf{x}_{1} -\\mathbf{x}_{0}\\right\\vert }^{2}\\right\\}\\psi \(\\mathbf{x}_{ 1}\)\\ d\\mathbf{x}_{1}.}$$
](A272900_1_En_20_Chapter_Equi.gif)

Unlike Theorem 4.5, however, the above expression holds for all ![
$$\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_20_Chapter_IEq42.gif) with absolute convergence of the integral for every ![
$$\\mathbf{x}_{0} \\in {\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq43.gif) Applying the Trotter product formula and rearranging the integral as before gives

![
$$\\displaystyle\\begin{array}{rcl} & & \({e}^{-t\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}_{ 0}\) \\\\ & & =\\lim _{N\\rightarrow \\infty }C\\int _{{\({\\mathbb{R}}^{n}\)}^{N}}\\exp \\left \\{-\\frac{1} {\\hslash }\\sum _{j=1}^{N}\\varepsilon \\left \[\\frac{m} {2}{ \\left \\vert \\frac{\\mathbf{x}_{j} -\\mathbf{x}_{j-1}} {\\varepsilon } \\right\\vert }^{2} + V \(\\mathbf{x}_{ j-1}\)\\right\]\\right\\} \\\\ & & \\times \\psi \(\\mathbf{x}_{N}\)\\ d\\mathbf{x}_{1}\\ d\\mathbf{x}_{2}\\cdots d\\mathbf{x}_{N}. {}\\end{array}$$
](A272900_1_En_20_Chapter_Equ15.gif)

(20.14)

If V is, say, bounded below, then there is no difficulty in changing the order of integration, because of the rapid decay of the integrand. Note that there is a relative sign change between the two terms in square brackets, compared to (20.9). Taking a formal limit as before gives

![
$$\\displaystyle\\begin{array}{rcl} & & \({e}^{-t\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}\) \\\\ & & = C\\int _{\\begin{array}{c}\\text{paths with } \\\\ \\mathbf{x}\(0\)=\\mathbf{x}_{0} \\end{array}}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{0}^{t}\\left \[\\frac{m} {2}{ \\left \\vert \\frac{d\\mathbf{x}} {ds}\\right\\vert }^{2} + V \(\\mathbf{x}\(s\)\)\\right\]\\ ds\\right\\}\\psi \(\\mathbf{x}\(t\)\)\\ \\mathcal{D}\\mathbf{x}.{}\\end{array}$$
](A272900_1_En_20_Chapter_Equ16.gif)

(20.15)

Note that the integral in the exponent on the right-hand side is not the classical action in (20.11), because the potential term has the wrong sign.

Kac's idea was to separate out the quadratic part of the exponent on the right-hand side of (20.15) and attempt to interpret the expression

![
$$\\displaystyle{ C\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{0}^{t}\\frac{m} {2}{ \\left \\vert \\frac{d\\mathbf{x}} {ds}\\right\\vert }^{2}\\ ds\\right\\}\\ \\mathcal{D}\\mathbf{x} }$$
](A272900_1_En_20_Chapter_Equ17.gif)

(20.16)

as a measure on the space of paths. Specifically, this is a Gaussian measure, one with a (formal) density with respect to the Lebesgue measure that is the exponential of a quadratic expression. There is a well-developed theory of Gaussian measures on infinite-dimensional spaces. Although there is no Lebesgue measure in the infinite-dimensional case, one can construct Gaussian measures as limits of Gaussian measures on spaces of large finite dimension.

## 20.4 The Wiener Measure

Kac identified the formal expression in (20.16) as the Wiener measure. To be precise, for each fixed ![
$$\\mathbf{x}_{0} \\in \\mathbb{R},$$
](A272900_1_En_20_Chapter_IEq44.gif) there is a Wiener measure ![
$$\\mu _{\\mathbf{x}_{0}}$$
](A272900_1_En_20_Chapter_IEq45.gif), where ![
$$\\mu _{\\mathbf{x}_{0}}$$
](A272900_1_En_20_Chapter_IEq46.gif) is supported on the set of paths ![
$$\\mathbf{x} : \[0,t\] \\rightarrow \\mathbb{R}$$
](A272900_1_En_20_Chapter_IEq47.gif) with x(0) = x 0. The Wiener measure was developed by Norbert Wiener as a rigorous embodiment of Albert Einstein's mathematical model of Brownian motion. Einstein, in one of his 1905 papers, had proposed that the random motion of a very small particle in water was due to collisions between the particle and the water molecules. Einstein postulated that the increments of a Brownian path x [quantities of the form x(t) − x(s)] should be independent for disjoint time intervals and should be normal random variables with mean zero and variance proportional to t − s. The following theorem shows that there is a unique measure on the space of continuous paths satisfying Einstein's criteria. Let ![
$$\\mathcal{C}_{\\mathbf{x}_{0}}\(\[0,t\]; {\\mathbb{R}}^{n}\)$$
](A272900_1_En_20_Chapter_IEq48.gif) denote the space of continuous maps x( ⋅) of [0, t] into ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_20_Chapter_IEq49.gif) satisfying x(0) = x 0, equipped with the supremum norm.

Theorem 20.2 (Wiener)

For each vector ![
$$\\mathbf{x}_{0} \\in {\\mathbb{R}}^{n}$$
](A272900_1_En_20_Chapter_IEq50.gif) and each pair of positive numbers σ and t, there exists a unique measure ![
$$\\mu _{\\mathbf{x}_{0}}^{\\sigma }$$
](A272900_1_En_20_Chapter_IEq51.gif) on the Borel σ-algebra in ![
$$\\mathcal{C}_{\\mathbf{x}_{0}}\(\[0,t\]; {\\mathbb{R}}^{n}\)$$
](A272900_1_En_20_Chapter_IEq52.gif) such that the following condition holds. For each sequence 0 = t 0 < t 1 < ⋯ < t N ≤ t of real numbers and each non-negative measurable function f on ![
$${\({\\mathbb{R}}^{n}\)}^{N},$$
](A272900_1_En_20_Chapter_IEq53.gif) we have

![
$$\\displaystyle\\begin{array}{rcl} & & \\int _{C_{\\mathbf{x}_{ 0}}\(\[0,t\];{\\mathbb{R}}^{n}\)}f\(\\mathbf{x}\(t_{1}\),\\mathbf{x}\(t_{2}\),\\ldots,\\mathbf{x}\(t_{N}\)\)\\ d\\mu _{\\mathbf{x}_{0}}^{\\sigma }\(\\mathbf{x}\) \\\\ & & = C\\int _{{\\mathbb{R}}^{N}}\\exp \\left \\{-\\frac{1} {2\\sigma }\\sum _{j=1}^{N}\\frac{{\\left \\vert \\mathbf{x}_{j} -\\mathbf{x}_{j-1}\\right\\vert }^{2}} {t_{j} - t_{j-1}} \\right\\}f\(\\mathbf{x}_{1},\\mathbf{x}_{2},\\ldots,\\mathbf{x}_{N}\)\\ d\\mathbf{x}_{1}\\cdots \\ d\\mathbf{x}_{N},{}\\end{array}$$
](A272900_1_En_20_Chapter_Equ18.gif)

(20.17)

where

![
$$\\displaystyle{C =\\prod _{ j=1}^{N} \\frac{1} {\\sqrt{2\\pi \\sigma \(t_{j } - t_{j-1 } \)}}.}$$
](A272900_1_En_20_Chapter_Equj.gif)

Note that the right-hand side of (20.17) is extremely similar to the right-hand side of (20.14), except that there are no terms involving the potential V in the exponent in (20.17). Thus, it is reasonable to think that the Wiener measure is a rigorous version of the formal expression in (20.16). It should be noted, however, that the heuristic expression (20.16) is misleading in one important respect. That expression suggests that the measure is supported on paths x( ⋅) for which d x ∕ dt belongs to L 2([0, t]; ℝ n ), since the exponential factor would seemingly "damp out" any paths for which this is not the case. This conclusion is, however, incorrect. [One should, in general, be extremely cautious in drawing conclusions based on purely formal expressions such as the one in (20.16).] Actually, the "typical" path with respect to the Wiener measure is nowhere differentiable; that is, the set of paths x(t) that are differentiable for even one value of t form a set of measure zero.

This discrepancy is actually a general feature of Gaussian measures on infinite-dimensional spaces: They are always supported on a larger space than the formal expression would suggest. In the case of the Wiener measure, the space on which the measure actually lives (the space of continuous functions) is nice enough that no difficulties arise in the formulation of our main result, the Feynman–Kac formula. In the setting of quantum field theory, however, issues concerning the support of a Gaussian measure become serious difficulties. See Sect. 20.6 for more information.

## 20.5 The Feynman–Kac Formula

The Wiener measure gives a rigorous interpretation to the expression in (20.16). Thus, the Wiener measure encapsulates everything in (20.15) except for the term involving V in the exponent and the factor of ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq017.gif)(x(t)). This reasoning accounts for the form of the following result.

Theorem 20.3 (Feynman–Kac Formula)

Suppose ![
$$V : {\\mathbb{R}}^{3} \\rightarrow \\mathbb{R}$$
](A272900_1_En_20_Chapter_IEq54.gif) can be expressed as the sum of a function in ![
$${L}^{2}\({\\mathbb{R}}^{3}\)$$
](A272900_1_En_20_Chapter_IEq55.gif) and a bounded function. Then for all ![
$$\\mathbf{x}_{0} \\in {\\mathbb{R}}^{3},$$
](A272900_1_En_20_Chapter_IEq56.gif) we have

![
$$\\displaystyle\\begin{array}{rcl} & & \({e}^{-t\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}_{ 0}\) {}\\\\ & & =\\int _{\\mathcal{C}_{\\mathbf{x}_{ 0}}\(\[0,t\];{\\mathbb{R}}^{3}\)}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{0}^{t}V \(\\mathbf{x}\(s\)\)\\ ds\\right\\}\\psi \\left \(\\mathbf{x}\(t\)\\right\)\\ d\\mu _{\\mathbf{ x}_{0}}^{\\sigma }\(\\mathbf{x}\), {}\\\\ \\end{array}$$
](A272900_1_En_20_Chapter_Equ19.gif)

where ![
$$\\mu _{\\mathbf{x}_{0}}^{\\sigma }$$
](A272900_1_En_20_Chapter_IEq57.gif) is the Wiener measure on ![
$$\\mathcal{C}_{\\mathbf{x}_{0}}\(\[0,t\]; {\\mathbb{R}}^{3}\)$$
](A272900_1_En_20_Chapter_IEq58.gif) and where ![
$$\\sigma = \\hslash /m.$$
](A272900_1_En_20_Chapter_IEq59.gif)

Of course, similar results hold in other dimensions, under suitable assumptions on the potential. We refer the interested reader to [37] or [14] for details on different versions of the Feynman–Kac formula. Theorem 20.3 cannot be obtained directly from the Trotter product formula, because the limit in (20.14) is an L 2 limit rather than a pointwise limit. We will content ourselves with proving an "integrated" version of the Feynman–Kac formula for nice potentials; Theorem 20.3 is Theorem 6.5 of [37].

Definition 20.4

Let ![
$$\\mathcal{C}\(\[0,t\]; {\\mathbb{R}}^{n}\)$$
](A272900_1_En_20_Chapter_IEq60.gif) denote the space of all continuous paths on [0, t] with values in ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_20_Chapter_IEq61.gif) For all σ > 0, let μ σ be the measure on ![
$$\\mathcal{C}\(\[0,t\]; {\\mathbb{R}}^{n}\)$$
](A272900_1_En_20_Chapter_IEq62.gif) given by

![
$$\\displaystyle{\\mu \(E\) =\\int _{{\\mathbb{R}}^{n}}\\mu _{\\mathbf{x}_{0}}^{\\sigma }\(E\)\\ d\\mathbf{x}_{0}.}$$
](A272900_1_En_20_Chapter_Equk.gif)

Proposition 20.5

Suppose ![
$$V : {\\mathbb{R}}^{n} \\rightarrow \\mathbb{R}$$
](A272900_1_En_20_Chapter_IEq63.gif) is bounded and continuous. Then for all ![
$$\\phi,\\psi \\in {L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_20_Chapter_IEq64.gif) we have

![
$$\\displaystyle\\begin{array}{rcl} & & \\langle \\phi,{e}^{-t\\hat{H}/\\hslash }\\psi \\rangle {}\\\\ & & =\\int _{\\mathcal{C}\(\[0,t\];{\\mathbb{R}}^{n}\)}\\overline{\\phi \(\\mathbf{x}\(0\)\)}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{0}^{t}V \(\\mathbf{x}\(s\)\)\\ ds\\right\\}\\psi \\left \(\\mathbf{x}\(t\)\\right\)\\ {d\\mu }^{\\sigma }\(\\mathbf{x}\), {}\\\\ \\end{array}$$
](A272900_1_En_20_Chapter_Equ20.gif)

where μ σ is as in Definition 20.4 and where ![
$$\\sigma = \\hslash /m.$$
](A272900_1_En_20_Chapter_IEq65.gif)

Proof.

We begin with (20.14) and apply Theorem 20.2 with parameters chosen as follows. We take ![
$$\\sigma = \\hslash /m,$$
](A272900_1_En_20_Chapter_IEq66.gif) we take the sequence ![
$$\\left \\langle t_{j}\\right\\rangle$$
](A272900_1_En_20_Chapter_IEq67.gif) to be given by ![
$$t_{j} = jt/N,$$
](A272900_1_En_20_Chapter_IEq68.gif) and we take f to be the function given by

![
$$\\displaystyle{f\(\\mathbf{x}_{1},\\mathbf{x}_{2},\\ldots,\\mathbf{x}_{N}\) =\\psi \(\\mathbf{x}_{N}\).}$$
](A272900_1_En_20_Chapter_Equl.gif)

Theorem 20.2 then allows us to express the right-hand side of (20.14) as an integral against the Wiener measure, giving

![
$$\\displaystyle\\begin{array}{rcl} & & \({e}^{-t\\hat{H}/\\hslash }\\psi \)\(\\mathbf{x}_{ 0}\) {}\\\\ & & =\\lim _{N\\rightarrow \\infty }\\int _{\\mathcal{C}_{\\mathbf{x}_{ 0}}\(\[0,t\];{\\mathbb{R}}^{n}\)}\\exp \\left \\{-\\frac{1} {\\hslash }\\sum _{j=1}^{N} \\frac{t} {N}V \\left \(\\mathbf{x}\\left \(\\frac{jt} {N}\\right\)\\right\)\\right\\}\\psi \(\\mathbf{x}\(t\)\)\\ d\\mu _{\\mathbf{x}_{0}}^{\\sigma }\(\\mathbf{x}\). {}\\\\ \\end{array}$$
](A272900_1_En_20_Chapter_Equ21.gif)

Since the limit in the above equation is an L 2 limit, we may move the inner product with ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq018.gif) inside the limit on the right-hand side. The integral with respect to ![
$$\\mu _{\\mathbf{x}_{ 0}}^{\\sigma }$$
](A272900_1_En_20_Chapter_IEq69.gif) and the integral with respect to d x 0 may then be combined into a single integral with respect to μ σ , giving

![
$$\\displaystyle\\begin{array}{rcl} & & \\langle \\phi,{e}^{-t\\hat{H}/\\hslash }\\psi \\rangle =\\lim _{ N\\rightarrow \\infty }\\int _{\\mathcal{C}\(\[0,t\];{\\mathbb{R}}^{n}\)}\\overline{\\phi \(\\mathbf{x}\(0\)\)} \\\\ & & \\times \\exp \\left \\{-\\frac{1} {\\hslash }\\sum _{j=1}^{N} \\frac{t} {N}V \\left \(\\mathbf{x}\\left \(\\frac{jt} {N}\\right\)\\right\)\\right\\}\\psi \\left \(\\mathbf{x}\(t\)\\right\)\\ {d\\mu }^{\\sigma }\(\\mathbf{x}\).{}\\end{array}$$
](A272900_1_En_20_Chapter_Equ22.gif)

(20.18)

Now, since V is continuous,

![
$$\\displaystyle{\\lim _{N\\rightarrow \\infty }\\sum _{j=1}^{N} \\frac{t} {N}V \\left \(\\mathbf{x}\\left \(\\frac{jt} {N}\\right\)\\right\) =\\int _{ 0}^{t}V \(\\mathbf{x}\(s\)\)\\ ds,}$$
](A272900_1_En_20_Chapter_Equm.gif)

for every continuous path x. Furthermore, it is easily seen that the "distribution" of the quantity x(s) with respect to the measure μ σ is the Lebesgue measure on ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_20_Chapter_IEq70.gif) for any s ∈ [0, t]. Thus, the function x↦![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq019.gif)(x(0)) is square-integrable with respect to μ σ , with L 2 norm equal to the L 2 norm of ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq020.gif) over ![
$${\\mathbb{R}}^{n},$$
](A272900_1_En_20_Chapter_IEq71.gif) and similarly for x↦![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq021.gif)(x(t)). It follows that the quantity ![
$$\\overline{\\phi \(\\mathbf{x}\(0\)\)}\\psi \\left \(\\mathbf{x}\(t\)\\right\)$$
](A272900_1_En_20_Chapter_IEq72.gif) is an L 1 function on ![
$$\\mathcal{C}\(\[0,t\]; {\\mathbb{R}}^{n}\).$$
](A272900_1_En_20_Chapter_IEq73.gif) Since V is bounded, we may apply dominated convergence to move the limit inside the integral, at which point we obtain the desired result.

## 20.6 Path Integrals in Quantum Field Theory

In this section, we briefly discuss the path integral approach to quantum field theory. We consider quantum field theory in a space–time of dimension d, so that space has dimension d − 1. The configuration space for the classical version of the theory is the collection of "spatial" fields, that is, maps ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq022.gif)(x) of ![
$${\\mathbb{R}}^{d-1}$$
](A272900_1_En_20_Chapter_IEq74.gif) into some finite-dimensional vector space V. A path in the space of fields is then a map ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq023.gif)(x, t) of ![
$${\\mathbb{R}}^{d-1} \\times \\mathbb{R}\\mathop{\\cong}{\\mathbb{R}}^{d}$$
](A272900_1_En_20_Chapter_IEq75.gif) into V. In the path integral approach to quantum field theory (which is the most commonly used approach to the subject), one considers integrals over the space of such paths.

Let us consider, as a simple example, what is called ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq024.gif) 4 theory. In this theory, the fields ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq025.gif) map into ![
$$\\mathbb{R}$$
](A272900_1_En_20_Chapter_IEq76.gif) and we consider a path integral of the form

![
$$\\displaystyle\\begin{array}{rcl} & & C\\int _{\\mathcal{F}_{d}}\\exp \\left \\{-\\frac{1} {\\hslash }\\int _{{\\mathbb{R}}^{d}}\\left \[c_{1}{\\left \\Vert \\nabla \\phi \(\\mathbf{x}\)\\right\\Vert }^{2} + c_{ 2}\\phi {\(\\mathbf{x}\)}^{2} + c_{ 3}\\phi {\(\\mathbf{x}\)}^{4}\\right\]\\ d\\mathbf{x}\\right\\} \\\\ & & \\times F\(\\phi \)\\ \\mathcal{D}\\phi, {}\\end{array}$$
](A272900_1_En_20_Chapter_Equ23.gif)

(20.19)

for some functional F(![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq0250.gif)) on the space of fields. [The expression in (20.19) is, more precisely, a "Euclidean" or "imaginary time" path integral. Such an integral is the counterpart in quantum field theory of the integral occurring in the Feynman–Kac formula in quantum mechanics.] In (20.19), ![
$$\\mathcal{F}_{d}$$
](A272900_1_En_20_Chapter_IEq77.gif) represents the space of all "fields" (i.e., functions) mapping our space–time ![
$${\\mathbb{R}}^{d}$$
](A272900_1_En_20_Chapter_IEq78.gif) into ![
$$\\mathbb{R}.$$
](A272900_1_En_20_Chapter_IEq79.gif) In an attempt to make sense of this heuristic expression, we may follow the strategy we used in deriving the Feynman–Kac formula by separating out the quadratic part of the exponent. We look, then, for a measure μ on ![
$$\\mathcal{F}_{d}$$
](A272900_1_En_20_Chapter_IEq80.gif) given by the heuristic expression

![
$$\\displaystyle { d\\mu \(\\phi \) \\quad ^{\\prime \\prime} =" \\quad C\\exp \\left \\{-\\frac{1} {\\hslash }\\int_{{\\mathbb{R}}^{d}}\\left \[c_{1}{\\left \\Vert \\nabla \\phi \(\\mathbf{x}\)\\right\\Vert }^{2} + c_{ 2}\\phi{\(\\mathbf{x}\)}^{2}\\right\]\\ d\\mathbf{x}\\right\\}{D}\\phi. }$$
](A272900_1_En_20_Chapter_Equ24.gif)

(20.20)

Using the theory of Gaussian measures, one can construct a rigorously defined measure corresponding to the heuristic expression in (20.20). There is, however, a serious difficulty with this approach: The measure μ is supported on very "rough" fields, much rougher than the heuristic expression suggests. In fact, we have the following result.

Proposition 20.6

For all d ≥ 1, there exists a Gaussian measure on the space ![
$$\\mathcal{F}_{d}$$
](A272900_1_En_20_Chapter_IEq81.gif) of fields on ![
$${\\mathbb{R}}^{d}$$
](A272900_1_En_20_Chapter_IEq82.gif) corresponding to the heuristic expression (20.20). For d ≥ 2, however, this measure is not supported on any space of ordinary functions, but rather on a space of distributions.

We will not prove this result here; see Sect. 8.5 of [14] for more information. Here, then, is the problem with the path integral approach to quantum field theory on space–times of dimension d ≥ 2: The functional ![
$$\\int _{{\\mathbb{R}}^{d}}\\phi {\(x\)}^{4}\\ dx$$
](A272900_1_En_20_Chapter_IEq83.gif) does not make sense for a "typical" field with respect to the measure μ in (20.20). As a result, we cannot make sense of (20.19) simply by absorbing all the Gaussian part into the definition of the measure μ, since what is left over is not a μ-almost everywhere defined functional of ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq026.gif). Indeed, even a local integral, of the form ∫ U ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq027.gif)(x)4 dx for some bounded region U in ![
$${\\mathbb{R}}^{d},$$
](A272900_1_En_20_Chapter_IEq84.gif) fails to be almost-everywhere defined with respect to μ. After all, if ∫ U ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq028.gif)(x)4 dx made sense, then ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq029.gif) would be a locally L 4 function, rather than a distribution.

It should be emphasized that the difficulty described in the previous paragraph is not just a technicality that can be swept away by some simple trick. Furthermore, this difficulty is not specific to ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq030.gif) 4 theory, but is present in all "nontrivial" field theories. In all interesting field theories, the fields defined by the Gaussian part of the path integral are fundamentally "too rough" to allow us to make sense of the non-Gaussian part of the integral. This phenomenon is the fundamental mathematical difficulty in the path integral approach to quantum field theory.

To have a chance to make rigorous sense of path integrals in quantum field theory, one has to employ a complicated regularization process known as renormalization. This process has, so far, been carried out in a rigorous fashion only for a very small number of field theories. One of the Clay Millennium Prize problems is to make rigorous sense out of the Yang–Mills field theory in four space–time dimensions. See [14] for a detailed survey of the mathematical issues connected with the path integral approach to quantum field theory. See also [13] for a treatment of quantum field theory and renormalization with a greater eye toward the physical content.

Since the roughness of the fields is a major problem in trying to give a rigorous meaning to path integrals, let us think for moment why it arises. Suppose we wish to construct a Gaussian measure from a certain heuristic expression of the form ![
$$\\mu = C{e}^{-Q\(x\)}\\mathcal{D}x,$$
](A272900_1_En_20_Chapter_IEq85.gif) where Q is a positive-definite quadratic functional of x. A reasonable approach is to consider the (real) Hilbert space H for which ![
$$\\left \\Vert x\\right\\Vert _{H}^{2} = Q\(x\).$$
](A272900_1_En_20_Chapter_IEq86.gif) [In the case of (20.20), H would be the "Sobolev space" of fields having one derivative in L 2. ] The heuristic expression for the Gaussian measure then takes the form

![
$$\\displaystyle{ d\\mu \(x\) = C{e}^{-\\left \\Vert x\\right\\Vert _{\\mathbf{H}}^{2} }\\ \\mathcal{D}x. }$$
](A272900_1_En_20_Chapter_Equ25.gif)

(20.21)

One might now try to approximate μ by Gaussian measures μ N on Hilbert spaces H N of dimension N < ∞. If dim H < ∞, then the expression (20.21) is perfectly rigorous, where the constant C may be taken to normalize μ to be a probability measure. A simple calculation (Exercise 4), however, shows that for any R, we have

![
$$\\displaystyle{\\lim _{N\\rightarrow \\infty }\\mu _{N}\(B_{R,N}\) = 0,}$$
](A272900_1_En_20_Chapter_Equn.gif)

where B R, N denotes the ball of radius R in H N . This means that in the N → ∞ limit, all of the "mass" of the measure is outside the ball of radius R, for every R. Thus, in the limit, the measure is supported entirely on points x where ![
$$\\left \\Vert x\\right\\Vert _{H} = \\infty,$$
](A272900_1_En_20_Chapter_IEq87.gif) that is, on points that are not actually in H. The measures μ N do converge to a measure μ as N tends to infinity, but μ does not live on H, but on some larger space B ⊃ H. The original space H is a set of μ-measure zero inside B. See [16] for more information. In the case of the measure μ corresponding to the heuristic expression in (20.20), μ does not—as the expression suggests—live on the Sobolev space of fields with one derivative in L 2, but on a larger space, which turns out to be a space of distributions.

## 20.7 Exercises

1.

Verify the identity (20.3) in the proof of the Trotter product formula.

2.

Verify (20.5) in the proof of the Trotter product formula, using Stone's theorem and the following identity:

![
$$\\displaystyle\\begin{array}{rcl} \\frac{1} {s}\({e}^{isA}{e}^{isB} - I\)\\psi & =& {e}^{isA}\(iB\\psi \) + {e}^{isA}\\left \(\\frac{1} {s}\({e}^{isB} - I\)\\psi - iB\\psi \\right\) {}\\\\ & +& \\frac{1} {s}\({e}^{isA} - I\)\\psi. {}\\\\ \\end{array}$$
](A272900_1_En_20_Chapter_Equ26.gif)

3.

Suppose {A N } is a family of bounded operators mapping a Banach space W 1 to a Banach space W 2. Suppose that for some constant C, we have ![
$$\\left \\Vert A_{N}\\right\\Vert \\leq C$$
](A272900_1_En_20_Chapter_IEq88.gif) for all N. Finally, suppose that ![
$$\\left \\Vert A_{N}\\psi \\right\\Vert \\rightarrow 0$$
](A272900_1_En_20_Chapter_IEq89.gif) as N → ∞, for every ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq031.gif) ∈ W.

(a)

Show that for each ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq032.gif) ∈ W and each ![
$$\\varepsilon> 0,$$
](A272900_1_En_20_Chapter_IEq90.gif) there exists a neighborhood U of ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq033.gif) and an integer M such that

![
$$\\displaystyle{\\left \\Vert A_{N}\\phi \\right\\Vert <\\varepsilon }$$
](A272900_1_En_20_Chapter_Equo.gif)

for all ![
$$\\phi$$
](A272900_1_En_20_Chapter_IEq034.gif) ∈ U and N ≥ M.

(b)

If K is a compact subset of W, show that ![
$$\\left \\Vert A_{N}\\psi \\right\\Vert$$
](A272900_1_En_20_Chapter_IEq91.gif) tends to zero uniformly for ![
$$\\psi$$
](A272900_1_En_20_Chapter_IEq035.gif) ∈ K.

4.

(a)

Let H N be an N-dimensional Hilbert space. Show that the measure

![
$$\\displaystyle{d\\mu _{N}\(x\) :{=\\pi }^{-N/2}{e}^{-{\\left \\Vert x\\right\\Vert }^{2} }dx}$$
](A272900_1_En_20_Chapter_Equp.gif)

is a probability measure. Here dx is the Lebesgue measure on H N , normalized to that the unit cube has volume 1.

Hint: Use Proposition A.22.

(b)

Let B R, N denote the ball of radius R in H N . Show that for each R < ∞, there exists number a R < 1 such that

![
$$\\displaystyle{\\mu _{N}\(B_{R,N}\) <{\(a_{R}\)}^{N}.}$$
](A272900_1_En_20_Chapter_Equq.gif)

Thus, ![
$$\\lim _{N\\rightarrow \\infty }\\mu _{N}\(B_{R,N}\) = 0.$$
](A272900_1_En_20_Chapter_IEq92.gif)

Hint: The ball B R, N is contained in a cube centered at the origin with side length 2R.

References

[13].

G.B. Folland, Quantum Field Theory: A Tourist Guide for Mathematicians. Mathematical Surveys and Monographs, vol. 149 (American Mathematical Society, Providence, RI, 2008)

[14].

J. Glimm, A. Jaffe, Quantum Physics: A Functional Integral Point of View, 2nd edn. (Springer, New York, 1987)

[16].

L. Gross, Abstract Wiener Spaces. In Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability (Berkeley, CA, 1965/1966), vol. II: Contributions to Probability Theory, Part 1 (University of California Press, Berkeley, CA, 1967), pp. 31–42

[19].

M. Gutzwiller, Chaos in Classical and Quantum Mechanics (Springer, Berlin, 1990)

[37].

B. Simon, Functional Integration and Quantum Physics, 2nd edn. (American Mathematical Society, Providence, RI, 2005)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_21

© Springer Science+Business Media New York 2013

# 21. Hamiltonian Mechanics on Manifolds

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In this chapter, we generalize the Hamiltonian approach to mechanics (introduced already in the Euclidean case in Sect. 2.5) to general manifolds. The chapter assumes familiarity with the basic notions of smooth manifolds, including tangent and cotangent spaces, vector fields, and differential forms. These notions are reviewed very briefly in Sect. 21.1, mainly in the interest of fixing the notation. See, for example, Chap. 2 of [40] for a concise treatment of manifolds and [29] for a detailed account. Throughout the chapter, we will use the summation convention, that repeated indices are always summed on.

In this chapter, we generalize the Hamiltonian approach to mechanics (introduced already in the Euclidean case in Sect.​ 2.​5) to general manifolds. The chapter assumes familiarity with the basic notions of smooth manifolds, including tangent and cotangent spaces, vector fields, and differential forms. These notions are reviewed very briefly in Sect. 21.1, mainly in the interest of fixing the notation. See, for example, Chap. 2 of [40] for a concise treatment of manifolds and [29] for a detailed account. Throughout the chapter, we will use the summation convention, that repeated indices are always summed on.

## 21.1 Calculus on Manifolds

Throughout this section, M will denote a smooth, n-dimensional manifold.

### 21.1.1 Tangent Spaces, Vector Fields, and Flows

For each x ∈ M, we have the tangent space to M at x, denoted T x M. Given a smooth coordinate system x 1,..., x n on M, the vectors

![
$$\\displaystyle{ \\frac{\\partial } {\\partial x_{1}},\\ldots, \\frac{\\partial } {\\partial x_{n}} }$$
](A272900_1_En_21_Chapter_Equ1.gif)

(21.1)

form a basis for the tangent space at each point. A vector field X on M is map assigning to each point x ∈ M an element X x of T x M. A vector field X is smooth if the coefficients of X in a basis of the form (21.1) are smooth functions, for every smooth coordinate system. As in Exercise 14 in Chap.​ 2, we think of a vector field as a first-order differential operator satisfying the Leibniz rule:

![
$$\\displaystyle{X\(fg\) = X\(f\)g + fX\(g\).}$$
](A272900_1_En_21_Chapter_Equa.gif)

Given a smooth vector field X on M and a point x ∈ M, there exists a curve γ x : (a, b) → M such that γ x (0) = x and

![
$$\\displaystyle{\\frac{d\\gamma _{x}} {dt} = X_{\\gamma _{x}\(t\)}.}$$
](A272900_1_En_21_Chapter_Equb.gif)

Any two such curves agree on the intersection of their intervals of definition. There is a largest interval ![
$$\(a_{x}^{\\max },b_{x}^{\\max }\)$$
](A272900_1_En_21_Chapter_IEq1.gif) on which such a curve can be defined. If, for each x ∈ M, we have ![
$$a_{x}^{\\max } = -\\infty $$
](A272900_1_En_21_Chapter_IEq2.gif) and ![
$$b_{x}^{\\max } = +\\infty,$$
](A272900_1_En_21_Chapter_IEq3.gif) we say that the vector field X is complete. If M is compact, then each smooth vector field on M is complete. We may assemble the curves γ x into the flow Φ generated by X, defined as

![
$$\\displaystyle{\\Phi _{t}\(x\) =\\gamma _{x}\(t\),}$$
](A272900_1_En_21_Chapter_Equc.gif)

whenever ![
$$a_{x}^{\\max } < t < b_{x}^{\\max }.$$
](A272900_1_En_21_Chapter_IEq4.gif) If t does not belong to ![
$$\(a_{x}^{\\max },b_{x}^{\\max }\),$$
](A272900_1_En_21_Chapter_IEq5.gif) then Φ t (x) is not defined. The flow Φ satisfies

![
$$\\displaystyle{ \\Phi _{0}\(x\) = x. }$$
](A272900_1_En_21_Chapter_Equ2.gif)

(21.2)

Furthermore, if x is in the domain of Φ t and Φ t (x) is in the domain of Φ s , then x is in the domain of Φ s \+ t and

![
$$\\displaystyle{ \\Phi _{s}\(\\Phi _{t}\(x\)\) = \\Phi _{s+t}\(x\). }$$
](A272900_1_En_21_Chapter_Equ3.gif)

(21.3)

In the other direction, given a family of maps Φ satisfying (21.2) and (21.3) and appropriate domain properties, there is a unique vector field X such that Φ is the flow generated by X. In particular, if Φ t (x) is defined for all x and t, is smooth as a map of ![
$$M \\times \\mathbb{R}$$
](A272900_1_En_21_Chapter_IEq6.gif) into M, and satisfies (21.2) and (21.3), there is a unique complete vector field X such that Φ is the flow generated by X.

### 21.1.2 Differential Forms

For each x, the tangent space T x M is an n-dimensional real vector space. The dual vector space to T x M is the cotangent space to M at x, denoted ![
$$ T_{x}^{*}M $$
](A272900_1_En_21_Chapter_IEq1001.gif). Given a smooth function f on M and a point x ∈ M, the differential of f at x is the element of ![
$$ T_{x}^{*}M $$
](A272900_1_En_21_Chapter_IEq1002.gif) given by

![
$$\\displaystyle{df\(X\) = X\(f\)}$$
](A272900_1_En_21_Chapter_Equd.gif)

for each X ∈ T x f. In particular, in any local coordinate system x 1,..., x n , the elements dx 1,..., dx n satisfy

![
$$\\displaystyle{dx_{j}\\left \( \\frac{\\partial } {\\partial x_{k}}\\right\) =\\delta _{jk}.}$$
](A272900_1_En_21_Chapter_Eque.gif)

Thus, the elements dx 1,..., dx n form a basis for ![
$$ T_{x}^{*}M $$
](A272900_1_En_21_Chapter_IEq1003.gif) at each point. For any smooth function f, we have

![
$$\\displaystyle{ df = \\frac{\\partial f} {\\partial x_{j}}dx_{j}. }$$
](A272900_1_En_21_Chapter_Equ4.gif)

(21.4)

A k -form α on M is a mapping assigning to each point x ∈ M a k-linear, alternating functional α x on T x M. A k-form is smooth if α(X 1,..., X k ) is a smooth function on M for each k-tuple of smooth vector fields X 1,..., X k on M. In particular, if f is a smooth function, then df is a smooth 1-form. If α is a smooth k-form and X a smooth vector field, we may define the contraction of α with X, which is the (k − 1)-form i X α given by

![
$$\\displaystyle{\(i_{X}\\alpha \)\(X_{1},\\ldots,X_{k-1}\) =\\alpha \(X,X_{1},\\ldots,X_{k-1}\).}$$
](A272900_1_En_21_Chapter_Equf.gif)

Given a k-linear form ![
$$\\phi$$
](A272900_1_En_21_Chapter_IEq1004.gif) on a vector space V, define the antisymmetrization AS(![
$$\\phi$$
](A272900_1_En_21_Chapter_IEq1005.gif)) of ![
$$\\phi$$
](A272900_1_En_21_Chapter_IEq1006.gif) by

![
$$\\displaystyle{\\mathrm{AS}\(\\phi \)\(v_{1},\\ldots,v_{k}\) =\\sum _{\\sigma \\in S_{k}}\\mathrm{sign}\(\\sigma \)\\phi \(v_{\\sigma \(1\)},v_{\\sigma \(2\)},\\ldots,v_{\\sigma \(k\)}\),}$$
](A272900_1_En_21_Chapter_Equg.gif)

where S k denotes the permutation group on k elements. Given a k-form α and an l-form β on M, let α ⊗ β be the (k \+ l)-linear form on each T x M given by

![
$$\\displaystyle{\(\\alpha \\otimes \\beta \)\(X_{1},\\ldots,X_{k+l}\) =\\alpha \(X_{1},\\ldots,X_{k}\)\\beta \(X_{k+1},\\ldots,X_{k+l}\).}$$
](A272900_1_En_21_Chapter_Equh.gif)

Then let α ∧ β denote the (k \+ l)-form given by

![
$$\\displaystyle{\\alpha \\wedge \\beta =\\mathrm{ AS}\(\\alpha \\otimes \\beta \).}$$
](A272900_1_En_21_Chapter_Equi.gif)

In particular, if α and β are 1-forms, then α ∧ β is the 2-form given by

![
$$\\displaystyle{\(\\alpha \\wedge \\beta \)\(X,Y \) =\\alpha \(X\)\\beta \(Y \) -\\alpha \(Y \)\\beta \(X\).}$$
](A272900_1_En_21_Chapter_Equj.gif)

In a smooth coordinate system x 1,..., x n , a smooth k-form α can be expressed uniquely as

![
$$\\displaystyle{\\alpha = a_{j_{1},\\ldots,j_{k}}\(x\)\\ dx_{j_{1}} \\wedge \\cdots \\wedge dx_{j_{k}}.}$$
](A272900_1_En_21_Chapter_Equk.gif)

A 2-form ω on M is said to be nondegenerate if ω defines a nondegenerate bilinear form on each T x M. More explicitly, this means that for each x ∈ M and each nonzero X ∈ T x M, there exists a Y ∈ T x M such that

![
$$\\displaystyle{\\omega \(X,Y \)\\neq 0.}$$
](A272900_1_En_21_Chapter_Equl.gif)

Suppose α is a smooth k-form on M and S is a compact, oriented, k-dimensional submanifold-with-boundary of M. Then one can define the integral of α over M. There is a map d, called the exterior derivative, mapping smooth k-forms to smooth (k \+ 1)-forms and having the property that

![
$$\\displaystyle{ \\int _{S}d\\beta =\\int _{\\partial S}\\beta }$$
](A272900_1_En_21_Chapter_Equ5.gif)

(21.5)

for every compact, oriented, k-dimensional submanifold-with-boundary S of M and every (k − 1)-form β on M. Here ∂ S is the boundary of S, with the natural orientation induced by the orientation on M. The relation (21.5) is known as Stoke's theorem. A k-form α is said to be closed if dα = 0.

The exterior derivative may be computed in coordinates by the formula

![
$$\\displaystyle{d\(f\\ dx_{j_{1}} \\wedge \\cdots \\wedge dx_{j_{k}}\) = \\frac{\\partial f} {\\partial x_{l}}dx_{l} \\wedge dx_{j_{1}} \\wedge \\cdots \\wedge dx_{j_{k}}.}$$
](A272900_1_En_21_Chapter_Equm.gif)

A coordinate-invariant formula for the exterior derivative of a k-form α is:

![
$$\\displaystyle\\begin{array}{rcl} d\\alpha \(X_{1},\\ldots,X_{k+1}\)& =& \\sum _{j=1}^{k+1}{\(-1\)}^{j+1}\\alpha \(X_{ 1},\\ldots,\\widehat{X_{j}},\\ldots,X_{k+1}\) {}\\\\ & +& \\sum _{j<l}{\(-1\)}^{j+l}\\alpha \(\[X_{ j},X_{l}\],X_{1},,\\ldots,\\widehat{X_{j}},\\ldots,X_{k+1}\), {}\\\\ \\end{array}$$
](A272900_1_En_21_Chapter_Equ6.gif)

where ![
$$\\widehat{X_{j}}$$
](A272900_1_En_21_Chapter_IEq7.gif) indicates that the X j term is omitted and where [X j , X l ] is the commutator of X j and X l as first-order differential operators. In particular, if α is a 1-form, we have

![
$$\\displaystyle{ \(d\\alpha \)\(X,Y \) = X\(\\alpha \(Y \)\) - Y \(\\alpha \(X\)\) -\\alpha \(\[X,Y \]\). }$$
](A272900_1_En_21_Chapter_Equ7.gif)

(21.6)

A key identity satisfied by the exterior derivative is

![
$$\\displaystyle{d\(d\\alpha \) = 0}$$
](A272900_1_En_21_Chapter_Equn.gif)

for all k-forms α. Conversely, if β is a closed (k \+ 1)-form (i.e., dβ = 0), then β can be expressed locally in the form β = dα for some k-form α. More precisely, if β is closed, then for any x ∈ M there exists a neighborhood U of x and a k-form α defined on U such that β = dα on U. If M satisfies certain topological conditions, then each closed k-form α on M can be expressed globally in the form α = dβ. In particular, if M is simply connected, then each closed 1-form β can be expressed globally in the form β = df for some smooth function (i.e., 0-form) f.

If X is a vector field and α is a k-form, we may define the Lie derivative of α in the direction of X, denoted ![
$$\\mathcal{L}_{X}\\alpha,$$
](A272900_1_En_21_Chapter_IEq8.gif) as follows:

![
$$\\displaystyle{\\mathcal{L}_{X}\\alpha = \\left. \\frac{d} {dt}\(\\Phi _{t}^{{\\ast}}\)\(\\alpha \)\\right\\vert _{ t=0},}$$
](A272900_1_En_21_Chapter_Equo.gif)

where Φ t is the flow generated by X and (![
$$ \\Phi_{t}^{*} $$
](A272900_1_En_21_Chapter_IEq101.gif) )(α) is the pullback of α by Φ t . The Lie derivative may be computed using the formula

![
$$\\displaystyle{ \\mathcal{L}_{X} = i_{X} \\circ d + d \\circ i_{X}. }$$
](A272900_1_En_21_Chapter_Equ8.gif)

(21.7)

## 21.2 Mechanics on Symplectic Manifolds

The reader is warned that sign conventions in the subject of Hamiltonian mechanics are not consistent from author to author.

### 21.2.1 Symplectic Manifolds

A symplectic manifold is, roughly, a manifold with enough additional structure to allow one to define the Poisson bracket of two functions.

Definition 21.1

A symplectic manifold is a smooth manifold N together with a closed, nondegenerate 2-form ω on N. If (N 1, ω 1) and (N 2, ω 2) are symplectic manifolds, a map Φ : N 1 → N 2 is a symplectomorphism if Φ is a diffeomorphism and in addition

![
$$\\displaystyle{{\\Phi }^{{\\ast}}\(\\omega _{ 2}\) =\\omega _{1}.}$$
](A272900_1_En_21_Chapter_Equp.gif)

It is not hard to see that every symplectic manifold must be even dimensional, for the simple reason that an odd-dimensional vector space does not admit a nondegenerate, skew-symmetric bilinear form.

Throughout this chapter, N will always denote a symplectic manifold of dimension 2n with symplectic form ω.

We now show that the cotangent bundle of any manifold has the structure of a symplectic manifold in a canonical way. Suppose x 1,..., x n is a coordinate system defined on an open set U ⊂ M. Then at each point x ∈ U, an element ![
$$\\phi\\ \\text{of}\\ T_{x}^{*}M $$
](A272900_1_En_21_Chapter_IEq1007.gif) can be expressed uniquely in the form

![
$$\\displaystyle{\\phi = p_{j}\\ dx_{j}}$$
](A272900_1_En_21_Chapter_Equq.gif)

for a sequence p 1,..., p n of real numbers. The quantities x 1,..., x n and p 1,..., p n constitute a coordinate system on π − 1(U). We refer to a coordinate system of this sort as a standard coordinate system on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq102.gif).

Example 21.2

For any smooth manifold M, define a 1-form θ on the cotangent bundle ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq103.gif) by

![
$$\\displaystyle{\\theta \(X\)_{\(x,\\phi \)} =\\phi \(\\pi _{{\\ast}}\(X\)\)}$$
](A272900_1_En_21_Chapter_Equr.gif)

for each tangent vector ![
$$ X\\ \\epsilon \\ T_{\(x,\\phi\)}\(T^{*}M\),$$
](A272900_1_En_21_Chapter_IEq1008.gif) where π: ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq113.gif) → M is the canonical projection. Then the 2-form ω : = dθ is closed and nondegenerate. We refer to θ and ω as the canonical 1-form and the canonical 2-form on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq114.gif) , respectively.

Proof.

Using a coordinate system ![
$$\\{x_{j}\\}$$
](A272900_1_En_21_Chapter_IEq9.gif) on X and the associated standard coordinate system ![
$$\\{x_{j},p_{j}\\}$$
](A272900_1_En_21_Chapter_IEq10.gif) on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq104.gif), the projection π is given by π(x, p) = x. Meanwhile, a tangent vector X to ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq105.gif) is expressible as a linear combination the ∂ ∕ ∂ x j 's and ∂ ∕ ∂ p j 's. Thus,

![
$$\\displaystyle{\\theta \\left \(a_{k} \\frac{\\partial } {\\partial x_{k}} + b_{k} \\frac{\\partial } {\\partial p_{k}}\\right\) = \\left \(p_{j}\\ dx_{j}\\right\)\\left \(a_{k} \\frac{\\partial } {\\partial x_{k}}\\right\).}$$
](A272900_1_En_21_Chapter_Equs.gif)

What this means is that

![
$$\\displaystyle{\\theta = p_{j}\\ dx_{j},}$$
](A272900_1_En_21_Chapter_Equt.gif)

where the x j 's are now viewed as functions on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq106.gif) rather than on M. We have, then,

![
$$\\displaystyle{\\omega = d\\theta = dp_{j} \\wedge dx_{j}.}$$
](A272900_1_En_21_Chapter_Equu.gif)

It is now easy to see that ω is nondegenerate (Exercise 1).

### 21.2.2 Poisson Brackets and Hamiltonian Vector Fields

If ω is nondegenerate, then it gives a canonical identification of T z N with ![
$$ T_{z}^{*}N $$
](A272900_1_En_21_Chapter_IEq01.gif) at each point, by identifying a vector X in T z N with the linear functional ω(X, ⋅) in ![
$$ T_{z}^{*}N $$
](A272900_1_En_21_Chapter_IEq02.gif). We can then transfer the bilinear form ω from T z N to ![
$$ T_{z}^{*}N $$
](A272900_1_En_21_Chapter_IEq03.gif) by means of this identification. We denote the resulting bilinear form on ![
$$ T_{z}^{*}N $$
](A272900_1_En_21_Chapter_IEq04.gif) by ω − 1.

Definition 21.3

If f and g are smooth functions on N, define the Poisson bracket ![
$$\\{f,g\\}$$
](A272900_1_En_21_Chapter_IEq11.gif) of f and g by

![
$$\\displaystyle{\\{f,g\\} = {-\\omega }^{-1}\(df,dg\).}$$
](A272900_1_En_21_Chapter_Equv.gif)

In particular, if 1 denotes the constant function on N, then ![
$$\\{\\mathbf{1},f\\} =\\{ f,\\mathbf{1}\\} = 0$$
](A272900_1_En_21_Chapter_IEq12.gif) for all smooth functions f.

Example 21.4

If ω is the canonical 2-form on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq107.gif) , then the associated Poisson bracket may be computed in standard coordinates as

![
$$\\displaystyle{\\{f,g\\} = \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial g} {\\partial p_{j}} - \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial g} {\\partial x_{j}}}$$
](A272900_1_En_21_Chapter_Equw.gif)

for all smooth functions f and g on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq108.gif).

Proof.

The linear functional

![
$$\\displaystyle{\\omega \\left \( \\frac{\\partial } {\\partial x_{j}},\\cdot \\right\)}$$
](A272900_1_En_21_Chapter_Equx.gif)

has a value of − 1 on the vector ∂ ∕ ∂ p j and a value of 0 on all the other basic partial derivatives. This means that ![
$$\\omega \(\\partial /\\partial x_{j},\\cdot \) = -dp_{j}.$$
](A272900_1_En_21_Chapter_IEq13.gif) Similarly, ![
$$\\omega \(\\partial /\\partial p_{j},\\cdot \) = dx_{j}.$$
](A272900_1_En_21_Chapter_IEq14.gif) We may thus compute, for example, that

![
$$\\displaystyle\\begin{array}{rcl} -1& =& \\omega \\left \( \\frac{\\partial } {\\partial x_{j}}, \\frac{\\partial } {\\partial p_{j}}\\right\) {}\\\\ & =& {\\omega }^{-1}\(-dp_{ j},dx_{j}\) {}\\\\ & =& {\\omega }^{-1}\(dx_{ j},dp_{j}\). {}\\\\ \\end{array}$$
](A272900_1_En_21_Chapter_Equ9.gif)

Meanwhile, ![
$${\\omega }^{-1}\(dx_{j},dx_{k}\) {=\\omega }^{-1}\(dp_{j},dp_{k}\) = 0$$
](A272900_1_En_21_Chapter_IEq15.gif) and ![
$${\\omega }^{-1}\(dp_{j},dx_{k}\) = 0$$
](A272900_1_En_21_Chapter_IEq16.gif) when j≠k. Thus, we compute that

![
$$\\displaystyle\\begin{array}{rcl} \\{f,g\\}& =& {-\\omega }^{-1}\\left \( \\frac{\\partial f} {\\partial x_{j}}dx_{j} + \\frac{\\partial f} {\\partial p_{j}}dp_{j}, \\frac{\\partial g} {\\partial x_{k}}dx_{k} + \\frac{\\partial g} {\\partial p_{k}}dp_{k}\\right\) {}\\\\ & =& \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial g} {\\partial p_{k}}\\delta _{jk} - \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial g} {\\partial x_{k}}\\delta _{jk}, {}\\\\ \\end{array}$$
](A272900_1_En_21_Chapter_Equ10.gif)

which reduces to the claimed expression.

Proposition 21.5

For any smooth functions f, g, h on N, we have

![
$$\\displaystyle{\\{g,f\\} = -\\{f,g\\}}$$
](A272900_1_En_21_Chapter_Equy.gif)

and

![
$$\\displaystyle{\\{f,gh\\} =\\{ f,g\\}h + g\\{f,h\\}.}$$
](A272900_1_En_21_Chapter_Equz.gif)

Proof.

Since ω is skew-symmetric on the tangent space to N at each point and ω − 1 is obtained from ω by means of an isomorphism of tangent and cotangent space, ω − 1 is a skew-symmetric form on the cotangent space. The skew-symmetry of the Poisson bracket follows. The second relation follows from the Leibniz product rule for d(gh) together with the bilinearity of ω − 1.

Definition 21.6

If f is a smooth function on N, let X f be the unique vector field on N such that

![
$$\\displaystyle{ df =\\omega \(X_{f},\\cdot \). }$$
](A272900_1_En_21_Chapter_Equ11.gif)

(21.8)

We call X f the Hamiltonian vector field associated to f.

That is to say, X f corresponds to df under the isomorphism between tangent and cotangent spaces established by ω.

Proposition 21.7

For all f and g,

![
$$\\displaystyle{X_{f}\(g\) =\\{ f,g\\} = -X_{g}\(f\).}$$
](A272900_1_En_21_Chapter_Equaa.gif)

Furthermore,

![
$$\\displaystyle{\\omega \(X_{f},X_{g}\) = -\\{f,g\\}.}$$
](A272900_1_En_21_Chapter_Equab.gif)

Proof.

For each z ∈ N, we are using ω to identify T z N with ![
$$ T_{z}^{*}N $$
](A272900_1_En_21_Chapter_IEq1102.gif). Equation (21.8) says that under this identification, X f is identified with df. Thus,

![
$$\\displaystyle{{-\\omega }^{-1}\(df,dg\) = -\\omega \(X_{ f},X_{g}\) = -df\(X_{g}\) = -X_{g}\(f\).}$$
](A272900_1_En_21_Chapter_Equac.gif)

Thus, ![
$$\\{f,g\\} = -X_{g}\(f\),$$
](A272900_1_En_21_Chapter_IEq17.gif) as claimed. A similar argument with the roles of f and g reversed gives the claimed relationship between X f (g) and ![
$$\\{g,f\\}.$$
](A272900_1_En_21_Chapter_IEq18.gif) Finally,

![
$$\\displaystyle{\\omega \(X_{f},X_{g}\) = df\(X_{g}\) = X_{g}\(f\) = -\\{f,g\\},}$$
](A272900_1_En_21_Chapter_Equad.gif)

as claimed.

Definition 21.8

For any smooth function f on N, the Hamiltonian flow generated by f, denoted Φ f , is the flow generated by the vector field − X f .

In the case ![
$$N = {T}^{{\\ast}}{\\mathbb{R}}^{n}\\mathop{\\cong}{\\mathbb{R}}^{2n}$$
](A272900_1_En_21_Chapter_IEq19.gif), this definition agrees with our notation in Sect.​ 2.​5.

Proposition 21.9

For any smooth function f on N, the Hamiltonian flow Φf preserves ω.

Proof.

In general, a flow Φ preserves a differential form α if and only if the Lie derivative L X α = 0, where X is the vector field generating Φ. In our case, since ω is closed, we have, by (21.7),

![
$$\\displaystyle{\\mathcal{L}_{X_{f}}\\omega = d\[i_{X_{f}}\\omega \] = {d}^{2}f = 0,}$$
](A272900_1_En_21_Chapter_Equae.gif)

since ![
$$i_{X_{f}}\\omega$$
](A272900_1_En_21_Chapter_IEq20.gif) is, by the definition of X f , equal to df.

Proposition 21.10

For any smooth functions f, g, h on N, the Jacobi identity holds:

![
$$\\displaystyle{\\{f,\\{g,h\\}\\} +\\{ g,\\{h,f\\}\\} +\\{ h,\\{f,g\\}\\} = 0.}$$
](A272900_1_En_21_Chapter_Equaf.gif)

This result shows that the space of smooth function on N forms a Lie algebra under the Poisson bracket. The proof of Proposition 21.10 relies on Proposition 21.9, which in turn relies on the fact that ω is closed.

Proof.

Since the Hamiltonian flow Φ f preserves ω, it also preserves ω − 1 and thus

![
$${\\displaystyle{\\omega }^{-1}\(d\(g \\circ \\Phi _{ t}^{f}\),d\(h \\circ \\Phi _{ t}^{f}\)\) {=\\omega }^{-1}\(dg,dh\) \\circ \\Phi _{ t}^{f},}$$
](A272900_1_En_21_Chapter_Equag.gif)

or, equivalently,

![
$$\\displaystyle{\\{g \\circ \\Phi _{t}^{f},h \\circ \\Phi _{ t}^{f}\\} =\\{ g,h\\} \\circ \\Phi _{ t}^{f}.}$$
](A272900_1_En_21_Chapter_Equah.gif)

Differentiating this relation with respect to t at t = 0 gives

![
$$\\displaystyle{\\{-X_{f}\(g\),h\\} +\\{ g,-X_{f}\(h\\}\\} = -X_{f}\(\\{g,h\\}\),}$$
](A272900_1_En_21_Chapter_Equai.gif)

or, equivalently,

![
$$\\displaystyle{-\\{\\{f,g\\},h\\} +\\{ g,\\{f,h\\}\\} = -\\{f,\\{g,h\\}\\}.}$$
](A272900_1_En_21_Chapter_Equaj.gif)

After moving − { f, {g, h}} to the left-hand side of the equation and using the skew-symmetry of the Poisson bracket, we obtain the Jacobi identity.

Proposition 21.11

For any smooth functions f and g on N, the Hamiltonian vector fields X f and X g satisfy

![
$$\\displaystyle{\[X_{f},X_{g}\] = X_{\\{f,g\\}}.}$$
](A272900_1_En_21_Chapter_Equak.gif)

Proof.

See Exercise 3.

### 21.2.3 Hamiltonian Flows and Conserved Quantities

We have seen (Proposition 21.9) that if f is a smooth function, then the flow generated by X f preserves ω. We have the following partial converse to this result.

Proposition 21.12

Suppose Φ is the flow generated by a vector field − X on N. If Φ preserves ω then X can be represented locally in the form X = X f for some smooth function f on N. If N is simply connected, the function f exists globally on N.

Proof.

The statement that Φ preserves ω can be expressed infinitesimally as

![
$$\\displaystyle{\\mathcal{L}_{X}\\omega = 0.}$$
](A272900_1_En_21_Chapter_Equal.gif)

Since also ω is closed, (21.7) tells us that

![
$$\\displaystyle{d\(i_{X}\\omega \) = 0.}$$
](A272900_1_En_21_Chapter_Equam.gif)

Since i X ω is closed, this 1-form can be expressed locally as i X ω = df for some smooth function f, which says precisely that X = X f . If N is simply connected, then every closed 1-form can be expressed globally as df, for some smooth function f.

A flow of the sort in Proposition 21.12 is said to be locally Hamiltonian. Such a flow is said to be (globally) Hamiltonian if the function f in the proposition can be defined on all of N. (Compare Definition 21.8.) If Φ is a Hamiltonian flow, the function f such that Φ = Φ f is called a Hamiltonian generator of Φ. If N is connected, then any two Hamiltonian generators of Φ must differ by a constant.

To see that, in general, f is only defined locally, consider the symplectic manifold ![
$${S}^{1} \\times \\mathbb{R},$$
](A272900_1_En_21_Chapter_IEq21.gif) with symplectic form ω = ![
$$d\\phi$$
](A272900_1_En_21_Chapter_IEq1019.gif) ∧ dx, where ![
$$\\phi$$
](A272900_1_En_21_Chapter_IEq1009.gif) is the angular coordinate on S 1 and x is the linear coordinate on ![
$$\\mathbb{R}.$$
](A272900_1_En_21_Chapter_IEq22.gif) Note that the 1-form ![
$$d\\phi$$
](A272900_1_En_21_Chapter_IEq1119.gif) is independent of the choice of a local angle variable on S 1, since any two such angle functions differ by a constant (an integer multiple of 2π). Thus, dϕ is a globally defined, smooth 1-form, even though there is no globally defined, smooth angle function ![
$$\\phi$$
](A272900_1_En_21_Chapter_IEq10010.gif). Define a flow Φ by

![
$$\\displaystyle{\\Phi _{t}\(\\phi,x\) = \(\\phi,x + t\).}$$
](A272900_1_En_21_Chapter_Equan.gif)

This flow certainly preserves ω, since dx is invariant under translations.

The flow Φ is generated by the vector field ![
$$-X = \\partial /\\partial x,$$
](A272900_1_En_21_Chapter_IEq23.gif) and

![
$$\\displaystyle{\\omega \(-\\partial /\\partial x,\\cdot \) = d\\phi.}$$
](A272900_1_En_21_Chapter_Equao.gif)

As we have already noted, however, there is no globally defined function ![
$$\\phi$$
](A272900_1_En_21_Chapter_IEq10012.gif) whose differential is ![
$$d \\phi$$
](A272900_1_En_21_Chapter_IEq101112.gif).

Although any smooth function on a symplectic manifold N generates a Hamiltonian flow, in physical examples there is usually one distinguished function with a Hamiltonian flow that is thought of as "the" time-evolution of the system.

Definition 21.13

A Hamiltonian system is a symplectic manifold N together with a distinguished Hamiltonian flow Φ H , generated by smooth function H on N, called the Hamiltonian of the system. A function f is called a conserved quantity for a Hamiltonian system (N, Φ H ) if f(Φ t H (x)) is independent of t for each fixed x ∈ N.

As in the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_21_Chapter_IEq24.gif) case, conserved quantities are useful in understanding the nature of the dynamics. See the discussion following Corollary 2.26.

Proposition 21.14

For any Hamiltonian system (N, Φ  H ), we have

![
$$\\displaystyle{ \\frac{d} {dt}f\(\\Phi _{t}^{H}\(z\)\) =\\{ f,H\\}\(\\Phi _{ t}^{H}\(z\)\),}$$
](A272900_1_En_21_Chapter_Equap.gif)

for all z ∈ N, or, more concisely,

![
$$\\displaystyle{\\frac{df} {dt} =\\{ f,H\\}.}$$
](A272900_1_En_21_Chapter_Equaq.gif)

In particular, a smooth function f on N is a conserved quantity for a Hamiltonian system ΦH if and only if ![
$$\\{f,H\\} = 0.$$
](A272900_1_En_21_Chapter_IEq25.gif)

Proof.

For the flow generated by any vector field X, we have

![
$$\\displaystyle{ \\frac{d} {dt}f\(\\Phi _{t}\(z\)\) = X_{\\Phi _{t}\(z\)}f.}$$
](A272900_1_En_21_Chapter_Equar.gif)

If ![
$$X = -X_{f},$$
](A272900_1_En_21_Chapter_IEq26.gif) then by Proposition 21.7, we have the claimed result.

Proposition 21.15

A smooth function f is a conserved quantity for a Hamiltonian system (N, Φ  H ) if and only if H is invariant under the Hamiltonian flow Φf generated by f.

Proof.

By the previous proposition, H is invariant under the flow generated by f if and only if ![
$$\\{H,f\\} = 0,$$
](A272900_1_En_21_Chapter_IEq27.gif) which holds if and only if ![
$$\\{f,H\\} = 0,$$
](A272900_1_En_21_Chapter_IEq28.gif) which holds if and only if f is a conserved quantity.

### 21.2.4 The Liouville Form

A symplectic manifold N has a natural volume form, which allows us to formulate an analog on N of Liouville's theorem (Theorem 2.27).

Definition 21.16

If N is a 2n-dimensional symplectic manifold, the Liouville form on N is the 2n-form λ given by

![
$$\\displaystyle{\\lambda ={ \\frac{1} {n!}\\omega }^{n},}$$
](A272900_1_En_21_Chapter_Equas.gif)

where ω n = ω ∧ ⋯ ∧ ω.

Since ω is, by assumption, a nondegenerate form on each tangent space T z N, it is not hard to check that λ is a nonvanishing (2n)-linear form on each T z N. Thus, λ determines an orientation on N. Given a compactly supported continuous function f on N, we can define the integral of f over N, computed with respect to the orientation determined by λ itself. Using the version of the Riesz representation theorem for locally compact topological spaces, one can show that there is a unique measure, called the Liouville volume measure, for which the integral of every continuous compactly supported function f is given by ∫ N f λ.

We are now ready to state the general form of Liouville's theorem.

Theorem 21.17 (Liouville's Theorem)

For any smooth function f on N, the Hamiltonian flow Φf preserves λ.

Proof.

The flow Φ f will preserve λ if and only if the vector field X f satisfies ![
$$\\mathcal{L}_{X_{f}}\\lambda = 0.$$
](A272900_1_En_21_Chapter_IEq29.gif) But

![
$$\\displaystyle\\begin{array}{rcl} \\mathcal{L}_{X_{f}}\\lambda & =& \\frac{1} {n!}\[\(\\mathcal{L}_{X_{f}}\\omega \) \\wedge \\omega \\wedge \\cdots \\wedge \\omega {}\\\\ & +& \\omega \\wedge \(\\mathcal{L}_{X_{f}}\\omega \) \\wedge \\omega \\wedge \\cdots \\wedge \\omega {}\\\\ & +& \\cdots +\\omega \\wedge \\cdots \\wedge \\omega \\wedge \(\\mathcal{L}_{X_{f}}\\omega \)\]. {}\\\\ \\end{array}$$
](A272900_1_En_21_Chapter_Equ12.gif)

Since we have already shown (Proposition 21.9) that ![
$$\\mathcal{L}_{X_{f}}\\omega = 0,$$
](A272900_1_En_21_Chapter_IEq30.gif) we see that ![
$$\\mathcal{L}_{X_{f}}\\lambda = 0.$$
](A272900_1_En_21_Chapter_IEq31.gif)

## 21.3 Exercises

1.

Show that the canonical 2-form ω on ![
$$ T^{*}M $$
](A272900_1_En_21_Chapter_IEq109.gif) is nondegenerate.

Hint: Work in standard coordinates ![
$$\\{x_{j},p_{j}\\}.$$
](A272900_1_En_21_Chapter_IEq32.gif)

2.

Show that if Φ : M → M is a diffeomorphism, then the induced map ![
$${\\Phi }^{{\\ast}} : {T}^{{\\ast}}M \\rightarrow {T}^{{\\ast}}M$$
](A272900_1_En_21_Chapter_IEq33.gif) is a symplectomorphism.

3.

Using Proposition 21.7 and the Jacobi identity for the Poisson bracket, verify that

![
$$\\displaystyle{\[X_{f},X_{g}\] = X_{\\{f,g\\}}}$$
](A272900_1_En_21_Chapter_Equat.gif)

for all smooth functions f and g on N.

4.

If N is compact, show that

![
$$\\displaystyle{\\int _{N}\\{f,g\\}\\ \\lambda = 0}$$
](A272900_1_En_21_Chapter_Equau.gif)

for all smooth function f and g on N.

Hint: Apply Liouville's theorem to the flow Φ t f .

References

[29].

J. Lee, Introduction to Smooth Manifolds, 2nd edn. (Springer, London, 2006)

[40].

W. Thirring, A Course in Mathematical Physics I: Classical Dynamical Systems (Translated by Evans M. Harrell). (Springer, New York, 1978)
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_22

© Springer Science+Business Media New York 2013

# 22. Geometric Quantization on Euclidean Space

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

In this chapter, we consider the geometric quantization program in the setting of the symplectic manifold ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq341.gif) with the canonical 2-form ω = dp j ∧ dx j . We begin with the "prequantum" Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq374.gif) and define "prequantum" operators Q pre(f). These operators satisfy

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(\\{f,g\\}\) = \\frac{1} {i\\hslash }\[Q_{\\mathrm{pre}}\(f\),Q_{\\mathrm{pre}}\(g\)\]}$$
](A272900_1_En_22_Chapter_Equ111.gif)

for all f and g. Nevertheless, there are several undesirable aspects to the prequantization map that make it physically unreasonable to interpret it as "quantization." To obtain the quantum Hilbert space, we reduce the number of variables from 2n to n. Depending on how we do this reduction, we will obtain either the position Hilbert space, the momentum Hilbert space, or the Segal–Bargmann space. Each of these subspaces is preserved by the prequantized position and momentum operators, and by certain other operators of the form Q pre(f).

## 22.1 Introduction

In this chapter, we consider the geometric quantization program in the setting of the symplectic manifold ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq1.gif) with the canonical 2-form ω = dp j ∧ dx j . We begin with the "prequantum" Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq2.gif) and define "prequantum" operators Q pre(f). These operators satisfy

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(\\{f,g\\}\) = \\frac{1} {i\\hslash }\[Q_{\\mathrm{pre}}\(f\),Q_{\\mathrm{pre}}\(g\)\]}$$
](A272900_1_En_22_Chapter_Equa.gif)

for all f and g. Nevertheless, there are several undesirable aspects to the prequantization map that make it physically unreasonable to interpret it as "quantization." To obtain the quantum Hilbert space, we reduce the number of variables from 2n to n. Depending on how we do this reduction, we will obtain either the position Hilbert space, the momentum Hilbert space, or the Segal–Bargmann space. Each of these subspaces is preserved by the prequantized position and momentum operators, and by certain other operators of the form Q pre(f).

Although the material in this chapter is a special case of what we do in Chap.​ 23, doing this case first allows us to get a feeling for the methods and results of geometric quantization quickly, without needing to develop the full machinery of line bundles, connections, and polarizations over general symplectic manifolds. In any case, we would need to carry out most of the calculations in this chapter eventually, as standard examples of the general theory.

Although this chapter does not require the full machinery of symplectic manifolds, we will make use of the notions of 1-forms and 2-forms on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq3.gif) along with the notion of the differential of a 1-form. In particular, the expression (21.​6) for the differential of a 1-form will be used.

The reader should be warned that sign conventions in geometric quantization are not consistent from author to author. The sign conventions used here are chosen to maintain consistency with the physics literature. In particular, we could eliminate an annoying minus sign in the definition of the holomorphic subspace if we were willing to allow the function p j to quantize to ![
$$i\\hslash $$
](A272900_1_En_22_Chapter_IEq4.gif) ∂ ∕ ∂ x j . Since, however, the convention ![
$$P_{j} = -i\\hslash \\ \\partial /\\partial x_{j}$$
](A272900_1_En_22_Chapter_IEq5.gif) is universal in the physics literature, we have chosen to be consistent with that convention and to accept some slightly inconvenient sign choices elsewhere. We continue to follow the summation convention, in which repeated indices are always summed on.

## 22.2 Prequantization

Ideally, a quantization procedure Q, mapping functions on a symplectic manifold N to operators on some Hilbert space H, should satisfy the following properties. First, Q(f) should be self-adjoint whenever f is real valued. Second, we should have Q(1) = I, where 1 is the constant function. Third, Q({f, g}) should be equal to ![
$$\[Q\(f\),Q\(g\)\]/\(i\\hslash \).$$
](A272900_1_En_22_Chapter_IEq6.gif) Fourth, there should be some sort of "smallness" assumption. In the case ![
$$N = {\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq7.gif) for example, we may require that H should be irreducible under the action of the (exponentiated) position and momentum operators. (See Definition 14.6.) Although Groenewold's theorem (Theorem 13.13) suggests that it is unrealistic to expect to find a quantization procedure that satisfies all of these properties exactly, we try to come as close as possible.

Throughout this chapter, we follow the convention of thinking of a "vector field" on ![
$${\\mathbb{R}}^{N}$$
](A272900_1_En_22_Chapter_IEq8.gif) as a first-order differential operator, as in Exercise 14 in Chap.​ 2. Given, for example, the vector-valued function

![
$$\\displaystyle{X = \(2x_{1} + x_{2},x_{1}x_{2}\)}$$
](A272900_1_En_22_Chapter_Equb.gif)

on ![
$${\\mathbb{R}}^{2},$$
](A272900_1_En_22_Chapter_IEq9.gif) we identify X with the operator of "differentiation in the direction of X, " that is, with the following first-order differential operator:

![
$$\\displaystyle{X = \(2x_{1} + x_{2}\) \\frac{\\partial } {\\partial x_{1}} + x_{1}x_{2} \\frac{\\partial } {\\partial x_{2}}.}$$
](A272900_1_En_22_Chapter_Equc.gif)

In particular, given a smooth function f on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq10.gif) the Hamiltonian vector field X f associated to f is thought of as a differential operator:

![
$$\\displaystyle{ X_{f} = \\left\\{f,\\cdot \\right\\} = \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial } {\\partial p_{j}} - \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial } {\\partial x_{j}}, }$$
](A272900_1_En_22_Chapter_Equ1.gif)

(22.1)

acting on ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_22_Chapter_IEq11.gif) (Compare Proposition 21.7.) By Proposition 21.11, the commutator (as differential operators) of two Hamiltonian vector fields X f and X g is X {f, g}. Thus, the operators ![
$$i\\hslash X_{f}$$
](A272900_1_En_22_Chapter_IEq12.gif) satisfy the desired commutation relations:

![
$$\\displaystyle{\[i\\hslash X_{f},i\\hslash X_{g}\] = {\(i\\hslash \)}^{2}X_{\\{ f,g\\}} = \(i\\hslash \)\(i\\hslash X_{\\{f,g\\}}\).}$$
](A272900_1_En_22_Chapter_Equd.gif)

It is tempting, then, to define a (pre)quantization map simply by taking ![
$$Q\(f\) = i\\hslash X_{f},$$
](A272900_1_En_22_Chapter_IEq13.gif) viewed as a self-adjoint operator on the Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_22_Chapter_IEq14.gif) This map, however, does not satisfy Q(1) = I. If we to correct our definition to ![
$$Q\(f\) = i\\hslash X_{f} + f,$$
](A272900_1_En_22_Chapter_IEq15.gif) where f means the operator of multiplication by f, then Q(1) = I but the desired commutation property is destroyed.

It is possible to achieve both Q(1) = I and the desired commutation relations by adding one more term as follows. If ω = dp j ∧ dx j is the canonical 2-form on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq16.gif), let θ be any symplectic potential for ω, that is, any one-form with

![
$$\\displaystyle{ d\\theta =\\omega. }$$
](A272900_1_En_22_Chapter_Equ2.gif)

(22.2)

(We may, e.g., take θ = p j dx j .) For a smooth function f on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq17.gif) define an operator Q pre(f), acting on ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_22_Chapter_IEq18.gif) by

![
$$\\displaystyle{ Q_{\\mathrm{pre}}\(f\) = i\\hslash \\left\(X_{f} - \\frac{i} {\\hslash }\\theta \(X_{f}\)\\right\) + f. }$$
](A272900_1_En_22_Chapter_Equ3.gif)

(22.3)

The expression f on the right-hand side of (22.3) means, more precisely, the operator of multiplication by f, and similarly for the function θ(X f ). Note that since θ is a 1-form and X f is a vector field, θ(X f ) is a function on ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_22_Chapter_IEq19.gif) The operator Q pre(f) is the prequantization of f and is to be viewed as an unbounded operator on ![
$${L}^{2}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_22_Chapter_IEq20.gif) where we refer to ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq21.gif) as the prequantum Hilbert space.

According to Exercise 1, any divergence free vector field on ![
$${\\mathbb{R}}^{N}$$
](A272900_1_En_22_Chapter_IEq22.gif) is a skew-symmetric operator on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{N}\) \\subset {L}^{2}\({\\mathbb{R}}^{N}\).$$
](A272900_1_En_22_Chapter_IEq23.gif) Meanwhile, each Hamiltonian vector field is divergence free, as we have already remarked in the proof of Liouville's theorem (Theorem 2.27). Thus, for any smooth, real-valued function f on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq24.gif) the operator Q pre(f) is at least symmetric. It can be shown that if X f is complete, meaning that the associated Hamiltonian flow is defined for all times, then Q pre(f) is actually self-adjoint on a natural domain. (See the discussion following the proof of Proposition 23.13.)

As it turns out, the θ(X f ) term in (22.3) is precisely what is needed to restore the desired commutation relations, while still allowing Q pre(1) to equal the identity.

Proposition 22.1

For all ![
$$f,g \\in {C}^{\\infty }\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_22_Chapter_IEq25.gif) we have

![
$$\\displaystyle{ \\frac{1} {i\\hslash }\\left\[Q_{\\mathrm{pre}}\(f\),Q_{\\mathrm{pre}}\(g\)\\right\] = Q_{\\mathrm{pre}}\(\\{f,g\\}\),}$$
](A272900_1_En_22_Chapter_Eque.gif)

where the identity is to be understood as an equality of operators on ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_22_Chapter_IEq26.gif)

Before proving this result, it is useful to understand the behavior of the expression ![
$$X_{f} - \(i/\\hslash \)\\theta \(X_{f}\)$$
](A272900_1_En_22_Chapter_IEq27.gif) occurring in the definition of Q pre(f).

Definition 22.2

For any symplectic potential θ and vector field X on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq28.gif) let ∇ X denote the covariant derivative operator, acting on ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_22_Chapter_IEq29.gif) given by

![
$$\\displaystyle{ \\nabla _{X} = X - \\frac{i} {\\hslash }\\theta \(X\). }$$
](A272900_1_En_22_Chapter_Equ4.gif)

(22.4)

Note that our prequantized operators can be written as

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(f\) = i\\hslash \\nabla _{X_{f}} + f.}$$
](A272900_1_En_22_Chapter_Equf.gif)

Proposition 22.3

For any symplectic potential θ, let ∇X denote the associated covariant derivative in ( 22.4 ). Then for all smooth vector fields X and Y on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq30.gif) we have

![
$$\\displaystyle{ \[\\nabla _{X},\\nabla _{Y }\] = \\nabla _{\[X,Y \]} - \\frac{i} {\\hslash }\\omega \(X,Y \). }$$
](A272900_1_En_22_Chapter_Equ5.gif)

(22.5)

In particular, if X = X f and Y = X g , we have

![
$$\\displaystyle{\\left\[\\nabla _{X_{f}},\\nabla _{X_{g}}\\right\] = \\nabla _{X_{\\{f,g\\}}} + \\frac{i} {\\hslash }\\{f,g\\}.}$$
](A272900_1_En_22_Chapter_Equg.gif)

According to standard differential geometric definitions, the 2-form ![
$$\\omega /\\hslash $$
](A272900_1_En_22_Chapter_IEq31.gif) on the right-hand side of (22.5) is the curvature of the covariant derivative ∇. For our purposes, the fact that ![
$$\\left\[\\nabla _{X_{f}},\\nabla _{X_{g}}\\right\]$$
](A272900_1_En_22_Chapter_IEq32.gif) in not simply ![
$$\\nabla _{X_{\\{f,g\\}}}$$
](A272900_1_En_22_Chapter_IEq33.gif) is an advantage. The extra term in the formula for the commutator is just what we need to compensate for the failure of the operators ![
$$i\\hslash X_{f} + f$$
](A272900_1_En_22_Chapter_IEq34.gif) to have the desired commutation relations.

Proof.

Using the easily verified identity [ ∇ X , f] = X(f), we obtain

![
$$\\displaystyle{\[\\nabla _{X},\\nabla _{Y }\] -\\nabla _{\[X,Y \]} = -\\frac{i} {\\hslash }\[X\(\\theta \(Y \)\) - Y \(\\theta \(X\)\) -\\theta \(\[X,Y \]\)\].}$$
](A272900_1_En_22_Chapter_Equh.gif)

In light of (21.​6), the right-hand side becomes ![
$$-\(i/\\hslash \)\(d\\theta \)\(X,Y \),$$
](A272900_1_En_22_Chapter_IEq35.gif) where d θ = ω.

We may now easily prove Proposition 22.1.

Proof of Proposition 22.1.

Using Proposition 22.3, we obtain

![
$$\\displaystyle\\begin{array}{rcl} & & \\frac{1} {i\\hslash }\\left\[i\\hslash \\nabla _{X_{f}} + f,i\\hslash \\nabla _{X_{g}} + g\\right\] {}\\\\ & & = \(i\\hslash \)\\left\(\\nabla _{X_{\\{f,g\\}}} + \\frac{i} {\\hslash }\\{f,g\\}\\right\) + X_{f}\(g\) - X_{g}\(f\) {}\\\\ & & = i\\hslash \\nabla _{X_{\\{f,g\\}}} -\\{ f,g\\} +\\{ f,g\\} +\\{ f,g\\}, {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ6.gif)

which reduces to what we want.

Example 22.4

If θ = p j dx j , the prequantized position and momentum operators are given by

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{pre}}\(x_{j}\)& =& x_{j} + i\\hslash \\frac{\\partial } {\\partial p_{j}} {}\\\\ Q_{\\mathrm{pre}}\(p_{j}\)& =& -i\\hslash \\frac{\\partial } {\\partial x_{j}}. {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ7.gif)

These operators are essentially self-adjoint on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq36.gif) and their self-adjoint extensions satisfy the exponentiated commutation relations of Definition 14.2.

Proof.

We compute that ![
$$X_{x_{j}} = \\partial /\\partial p_{j}$$
](A272900_1_En_22_Chapter_IEq37.gif) and that ![
$$\\theta \(X_{x_{j}}\) = 0,$$
](A272900_1_En_22_Chapter_IEq38.gif) giving the indicated expression for Q pre(x j ). Meanwhile, ![
$$X_{p_{j}} = -\\partial /\\partial x_{j}$$
](A272900_1_En_22_Chapter_IEq39.gif) and ![
$$\\theta \(X_{p_{j}}\) = -p_{j}.$$
](A272900_1_En_22_Chapter_IEq40.gif) There is a cancellation of the ![
$$\\theta \(X_{p_{j}}\)$$
](A272900_1_En_22_Chapter_IEq41.gif) term in the definition of Q pre(p j ) with the p j term, leaving ![
$$Q_{\\mathrm{pre}}\(p_{j}\) = i\\hslash X_{p_{j}}.$$
](A272900_1_En_22_Chapter_IEq42.gif)

The essential self-adjointness of the operators follows from Proposition 9.40. To verify the exponentiated commutation relations, we calculate the associated one-parameter unitary groups as

![
$$\\displaystyle\\begin{array}{rcl} \({e}^{itQ_{\\mathrm{pre}}\(x_{j}\)}\\psi \)\(\\mathbf{x},\\mathbf{p}\)& =& {e}^{itx_{j} }\\psi \(\\mathbf{x},\\mathbf{p} - t\\hslash \\mathbf{e}_{j}\) \\\\ \({e}^{itQ_{\\mathrm{pre}}\(p_{j}\)}\\psi \)\(\\mathbf{x},\\mathbf{p}\)& =& \\psi \(\\mathbf{x} + t\\hslash \\mathbf{e}_{ j},\\mathbf{p}\),{}\\end{array}$$
](A272900_1_En_22_Chapter_Equ8.gif)

(22.6)

where we now let Q pre(x j ) and Q pre(p j ) denote the unique self-adjoint extensions of the given operators on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{2n}\).$$
](A272900_1_En_22_Chapter_IEq43.gif) (Compare Proposition 13.5.) The exponentiated commutation relations can now be easily verified by direct calculation.

As we have presented things so far, the concept of covariant derivative, and thus also of prequantization, depends on the choice of symplectic potential θ. This dependence is, however, illusory; we will now show that the prequantum maps obtained with two different symplectic potentials are unitarily equivalent.

Proposition 22.5

Suppose that θ 1 and θ 2 are two different symplectic potentials for the canonical 2-form ω, so that ![
$$d{\(\\theta }^{1} {-\\theta }^{2}\) = 0.$$
](A272900_1_En_22_Chapter_IEq44.gif) Let the associated covariant derivatives be denoted by ∇1 and ∇2. Choose a real-valued function γ so that ![
$$d\\gamma {=\\theta }^{1} {-\\theta }^{2}$$
](A272900_1_En_22_Chapter_IEq45.gif) and let U γ be the unitary map of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq46.gif) to itself given by

![
$$\\displaystyle{U_{\\gamma }\\psi = {e}^{-i\\gamma /\\hslash }\\psi.}$$
](A272900_1_En_22_Chapter_Equi.gif)

Then for every vector field X, we have

![
$$\\displaystyle{ U_{\\gamma }\\nabla _{X}^{1}U_{\\gamma }^{-1} = \\nabla _{ X}^{2}. }$$
](A272900_1_En_22_Chapter_Equ9.gif)

(22.7)

If Q pre j (f), j = 1,2, are the associated prequantization maps, it follows that

![
$$\\displaystyle{ U_{\\gamma }Q_{\\mathrm{pre}}^{1}\(f\)U_{\\gamma }^{-1} = Q_{\\mathrm{ pre}}^{2}\(f\). }$$
](A272900_1_En_22_Chapter_Equ10.gif)

(22.8)

The map U γ is called a gauge transformation.

Proof.

The operation of multiplication by θ 1(X) commutes with multiplication by ![
$${e}^{-i\\gamma /\\hslash },$$
](A272900_1_En_22_Chapter_IEq47.gif) whereas

![
$$\\displaystyle{X\({e}^{i\\gamma /\\hslash }\\psi \) = {e}^{i\\gamma /\\hslash }X\\psi + \\frac{i} {\\hslash }{e}^{i\\gamma /\\hslash }X\(\\gamma \)\\psi.}$$
](A272900_1_En_22_Chapter_Equj.gif)

Since ![
$$X\(\\gamma \) = \(d\\gamma \)\(X\) {=\\theta }^{1}\(X\) {-\\theta }^{2}\(X\),$$
](A272900_1_En_22_Chapter_IEq48.gif) we obtain

![
$$\\displaystyle\\begin{array}{rcl} \\nabla _{X}^{1}\({e}^{i\\gamma /\\hslash }\\psi \)& =& {e}^{i\\gamma /\\hslash }\\left\(X + \\frac{i} {\\hslash }X\(\\gamma \) -{ \\frac{i} {\\hslash }\\theta }^{1}\(X_{ f}\)\\right\)\\psi {}\\\\ & =& {e}^{i\\gamma /\\hslash }\\left\(X -{ \\frac{i} {\\hslash }\\theta }^{2}\(X_{ f}\)\\right\)\\psi {}\\\\ & =& {e}^{i\\gamma /\\hslash }\\nabla _{ X}^{2}\\psi. {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ11.gif)

Multiplying both sides of this equality by ![
$${e}^{-i\\gamma /\\hslash }$$
](A272900_1_En_22_Chapter_IEq49.gif) gives (22.7). Equation (22.8) follows by observing that multiplication by f commutes with multiplication by ![
$${e}^{-i\\gamma /\\hslash }.$$
](A272900_1_En_22_Chapter_IEq50.gif)

## 22.3 Problems with Prequantization

Given the naturalness of the prequantization construction, it is tempting to think that prequantization could actually be considered as quantization. Why not take our Hilbert space to be ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq51.gif) and the quantized operators to be Q pre(f)? To answer this question, we now examine some undesirable properties of prequantization.

In the first place, the Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq52.gif) is very far from irreducible under the action of the quantized position and momentum operators, in contrast to the ordinary Schrödinger Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_22_Chapter_IEq53.gif) which is irreducible, by Proposition 14.7. Indeed, in Sect. 22.4, we will construct a large family of invariant subspaces. (See Proposition 22.13.)

In the second place, the prequantization map is very far from being multiplicative. Of course, since quantum operators do not commute, we cannot expect any quantization scheme Q to satisfy Q(fg) = Q(f)Q(g) for all f and g. Nevertheless, the standard quantization schemes we have considered in Chap.​ 13 do satisfy this relation for certain classes of observables f and g. In the Weyl quantization, for example, we have multiplicativity if f and g are both functions of x only, independent of p (or functions of p, independent of x). For the prequantization map, however, we almost never have multiplicativity, for the simple reason that Q pre(fg) is a first-order differential operator, whereas Q pre(f)Q pre(g) is second-order, provided there is at least one point where X f and X g are both nonzero.

In the third place, the prequantization map badly fails to map positive functions to positive operators. Although most of the quantization schemes in Chap.​ 13 do not always map positive functions to positive operators, they somehow come close to doing so. Indeed, Q Weyl, Q Wick, and Q anti−Wick all map the harmonic oscillator Hamiltonian to a non-negative operator, since ![
$${a}^{{\\ast}}a + \(1/2\)I,$$
](A272900_1_En_22_Chapter_IEq54.gif) a ∗ a, and aa ∗ are all non-negative. (See Exercise 4 in Chap.​ 13.) By contrast, the prequantized harmonic oscillator Hamiltonian has spectrum that is unbounded below, as we now demonstrate.

Proposition 22.6

Consider a harmonic oscillator Hamiltonian of the form

![
$$\\displaystyle{H\(x,p\) = \\frac{1} {2m}\\left\({p}^{2} + {\(m\\omega x\)}^{2}\\right\).}$$
](A272900_1_En_22_Chapter_Equk.gif)

Then for each integer n, the number ![
$$n\\hslash \\omega$$
](A272900_1_En_22_Chapter_IEq55.gif) is an eigenvalue for Q pre (H).

Note that n in the proposition is allowed to be negative, so that the spectrum of Q pre(H) is not even bounded below. On the other hand, in Sect. 22.5, we will consider a certain closed subspace H α of the prequantum Hilbert space, which is one candidate for the quantum Hilbert space. For appropriate choice of α, the space H α is invariant under Q pre(H) and the restriction of Q pre(H) is self-adjoint with spectrum ![
$$n\\hslash \\omega,$$
](A272900_1_En_22_Chapter_IEq56.gif) where n ranges over the non-negative integers. See Proposition 22.14. And finally, when we introduce half-forms in Sect.​ 23.​7, we will finally restore the spectrum ![
$$\(n + 1/2\)\\hslash \\omega,$$
](A272900_1_En_22_Chapter_IEq57.gif) where n ranges over the non-negative integers, that we found in Chap.​ 11

Proof.

We can write H as

![
$$\\displaystyle{H\(x,p\) = \\frac{1} {2m}\({p}^{2} + {y}^{2}\),}$$
](A272900_1_En_22_Chapter_Equl.gif)

where y = mωx. The flow associated to this Hamiltonian consists of rotations in the (y, p)-plane. If we choose our symplectic potential to be

![
$$\\displaystyle{\\theta = \\frac{1} {2}\\left\(p\\ dx - x\\ dp\\right\) = \\frac{1} {2m\\omega }\(p\\ dy - y\\ dp\),}$$
](A272900_1_En_22_Chapter_Equm.gif)

then the θ(X H ) term in Q pre(H) cancels with the H term, leaving

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{pre}}\(H\)& =& i\\hslash X_{H} {}\\\\ & =& i\\hslash \\left\({m\\omega }^{2}x \\frac{\\partial } {\\partial p} - \\frac{p} {m} \\frac{\\partial } {\\partial x}\\right\) {}\\\\ & =& i\\hslash \\omega \\left\(y \\frac{\\partial } {\\partial p} - p \\frac{\\partial } {\\partial y}\\right\). {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ12.gif)

Now, if ![
$$ {\\phi }$$
](A272900_1_En_22_Chapter_IEq218.gif) denotes the angular variable for polar coordinates in the (y, p)-plane, then ![
$$y\\ \\partial /\\partial p - p\\ \\partial /\\partial y$$
](A272900_1_En_22_Chapter_IEq58.gif) is just ![
$$ \\partial /\\partial {\\phi }$$
](A272900_1_En_22_Chapter_IEq128.gif). Thus, we can find eigenvectors for Q pre(H) of the form

![
$$\\displaystyle{\\psi _{n}\(r,\\phi \) = f\(r\){e}^{-in\\phi }}$$
](A272900_1_En_22_Chapter_Equn.gif)

where n is an integer and f is an arbitrary function with ![
$$\\int _{0}^{\\infty }{\\left\\vert f\(r\)\\right\\vert }^{2}r\\ dr<\\infty.$$
](A272900_1_En_22_Chapter_IEq59.gif)

The conclusion of the matter is that it is not physically reasonable to use prequantization as our quantization scheme. Instead, we will pass to a "smaller" Hilbert space on which the position and momentum operators act irreducibly.

## 22.4 Quantization

To obtain a Hilbert space that can be thought of as giving us a "quantization" (as opposed to a prequantization) of ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq60.gif), we restrict ourselves to a subspace of the prequantum Hilbert space. The idea is that we should be using only half of the variables on ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_22_Chapter_IEq61.gif) We might, for example, restrict ourselves to functions that depend only on the position variables and are independent of the momentum variables. Now, the space of functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq262.gif) that are, say, independent of p in the ordinary sense (i.e., ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq263.gif)(x, p) = ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq264.gif)(x, p ′ )) is not invariant under gauge transformations (the maps U γ in Proposition 22.5). The gauge-invariant notion of being independent of p is that the covariant derivatives of ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq265.gif) should be zero in the p-directions. Similarly, we may consider spaces of functions with covariant derivatives that are are zero in some other set of n directions.

Definition 22.7

Fix a symplectic potential θ. Define the position subspace as the subspace of ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq62.gif) consisting of functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq281.gif) for which

![
$$\\displaystyle{\\nabla _{\\partial /\\partial p_{j}}\\psi = 0}$$
](A272900_1_En_22_Chapter_Equo.gif)

for all j. Similarly, define the momentum subspace as the subspace of ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq63.gif) consisting of functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq283.gif) for which

![
$$\\displaystyle{\\nabla _{\\partial /\\partial x_{j}} = 0}$$
](A272900_1_En_22_Chapter_Equp.gif)

for all j. Finally, define the holomorphic subspace with parameter α to be the subspace of ![
$${C}^{\\infty }\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq64.gif) consisting of functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq287.gif) for which

![
$$\\displaystyle{\\nabla _{\\partial /\\partial \\bar{z}_{j}}\\psi = 0}$$
](A272900_1_En_22_Chapter_Equq.gif)

for all j, where ![
$$z_{j} = x_{j} - i\\alpha p_{j}$$
](A272900_1_En_22_Chapter_IEq65.gif) and where ∂ ∕ ∂ z j and ![
$$\\partial /\\partial \\bar{z}_{j}$$
](A272900_1_En_22_Chapter_IEq66.gif) are defined by

![
$$\\displaystyle{ \\frac{\\partial } {\\partial z_{j}} = \\frac{1} {2}\\left\( \\frac{\\partial } {\\partial x_{j}} + \\frac{i} {\\alpha } \\frac{\\partial } {\\partial p_{j}}\\right\);\\quad \\frac{\\partial } {\\partial \\bar{z}_{j}} = \\frac{1} {2}\\left\( \\frac{\\partial } {\\partial x_{j}} -\\frac{i} {\\alpha } \\frac{\\partial } {\\partial p_{j}}\\right\), }$$
](A272900_1_En_22_Chapter_Equ13.gif)

(22.9)

The operators ∂ ∕ ∂ z j and ![
$$\\partial /\\partial \\bar{z}_{j}$$
](A272900_1_En_22_Chapter_IEq67.gif) are nothing but the usual complex derivative operators on ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_22_Chapter_IEq68.gif) written in terms of the variables x and p, where we identify ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq69.gif) with ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_22_Chapter_IEq70.gif) by the map (x, p) ↦ x − i α p.

Of course, the exact form of the various subspaces in Definition 22.7 depends on the choice of symplectic potential. It is convenient to use the symplectic potential θ = p j dx j .

Proposition 22.8

Take the symplectic potential θ = p j dx j . Then the position, momentum, and holomorphic subspaces may be computed as follows. The position subspace consists of smooth functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq371.gif) on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq71.gif) of the form

![
$$\\displaystyle{\\psi \(\\mathbf{x},\\mathbf{p}\) =\\phi \(\\mathbf{x}\),}$$
](A272900_1_En_22_Chapter_Equr.gif)

where ![
$$ {\\phi }$$
](A272900_1_En_22_Chapter_IEq172.gif) is an arbitrary smooth function on ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_22_Chapter_IEq72.gif) . The momentum subspace consists of smooth functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq289.gif) of the form

![
$$\\displaystyle{ \\psi \(\\mathbf{x},\\mathbf{p}\) = {e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hbar}\\phi \(\\mathbf{p}\), }$$
](A272900_1_En_22_Chapter_Equ14.gif)

(22.10)

where ![
$$ {\\phi }$$
](A272900_1_En_22_Chapter_IEq124.gif) is an arbitrary smooth function on ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_22_Chapter_IEq73.gif) Finally, the holomorphic subspace consists of functions of the form

![
$$\\displaystyle{ \\psi \(\\mathbf{x},\\mathbf{p}\) = F\(z_{1},\\ldots,z_{n}\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }, }$$
](A272900_1_En_22_Chapter_Equ15.gif)

(22.11)

where F is an arbitrary holomorphic function on ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_22_Chapter_IEq74.gif) and where ![
$$z_{j} = x_{j} - i\\alpha p_{j}.$$
](A272900_1_En_22_Chapter_IEq75.gif)

Proof.

Since ![
$$\\theta \(\\partial /\\partial p_{j}\) = 0,$$
](A272900_1_En_22_Chapter_IEq76.gif) we have ![
$$\\nabla _{\\partial /\\partial p_{j}} = \\partial /\\partial p_{j},$$
](A272900_1_En_22_Chapter_IEq77.gif) so that functions that are covariantly constant in the p-directions are actually constant in the p-directions. Meanwhile, ![
$$\\theta \(\\partial /\\partial x_{j}\) = p_{j}$$
](A272900_1_En_22_Chapter_IEq78.gif) and so

![
$$\\displaystyle{\\nabla _{\\partial /\\partial x_{j}} = \\frac{\\partial } {\\partial x_{j}} - \\frac{i} {\\hslash }p_{j}.}$$
](A272900_1_En_22_Chapter_Equs.gif)

Now, any function ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq266.gif) on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq79.gif) can be written in the form ![
$${e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash }\\phi \(\\mathbf{x},\\mathbf{p}\)$$
](A272900_1_En_22_Chapter_IEq80.gif) for some other function ![
$$ {\\phi }$$
](A272900_1_En_22_Chapter_IEq219.gif). If we use this form to compute ![
$$\\nabla _{\\partial /\\partial p_{j}}\\psi,$$
](A272900_1_En_22_Chapter_IEq81.gif) there is a convenient cancellation, giving

![
$$\\displaystyle{\(\\nabla _{\\partial /\\partial x_{j}}\\psi \)\(\\mathbf{x},\\mathbf{p}\) = {e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash } \\frac{\\partial \\phi } {\\partial x_{j}}.}$$
](A272900_1_En_22_Chapter_Equt.gif)

Thus, ![
$$\\nabla _{\\partial /\\partial x_{j}}\\psi = 0$$
](A272900_1_En_22_Chapter_IEq82.gif) for all j if and only if ![
$$ {\\phi }$$
](A272900_1_En_22_Chapter_IEq220.gif) is independent of x.

Finally, we note that ![
$$\\theta \(\\partial /\\partial \\bar{z}_{j}\) = p_{j}/2$$
](A272900_1_En_22_Chapter_IEq83.gif), so that

![
$$\\displaystyle{\\nabla _{\\partial /\\partial \\bar{z}_{j}} = \\frac{\\partial } {\\partial \\bar{z}_{j}} - \\frac{i} {2\\hslash }p_{j}.}$$
](A272900_1_En_22_Chapter_Equu.gif)

Any function ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq267.gif) on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq84.gif) can be written in the form ![
$$\\psi \(\\mathbf{x},\\mathbf{p}\) = {e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }F$$
](A272900_1_En_22_Chapter_IEq85.gif) for some other function F, where we note that

![
$$\\displaystyle{{e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) } =\\exp \\left\(\\sum _{j}{\(\\bar{z}_{j} - z_{j}\)}^{2}/\(8\\alpha \\hslash \)\\right\).}$$
](A272900_1_En_22_Chapter_Equv.gif)

Thus,

![
$$\\displaystyle{ \\frac{\\partial } {\\partial \\bar{z}_{j}}{e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) } = \\frac{\\bar{z}_{j} - z_{j}} {4\\alpha \\hslash } {e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) } = \\frac{i} {2\\hslash }p_{j}{e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }.}$$
](A272900_1_En_22_Chapter_Equw.gif)

When we compute ![
$$\\nabla _{\\partial /\\partial \\bar{z}_{j}}\\psi$$
](A272900_1_En_22_Chapter_IEq86.gif) using the indicated form, there is another convenient cancellation, giving

![
$$\\displaystyle{\(\\nabla _{\\partial /\\partial \\bar{z}_{j}}\\psi \)\(\\mathbf{x},\\mathbf{p}\) = {e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) } \\frac{\\partial F} {\\partial \\bar{z}_{j}}.}$$
](A272900_1_En_22_Chapter_Equx.gif)

Thus, ![
$$\\nabla _{\\partial /\\partial \\bar{z}_{j}}\\psi = 0$$
](A272900_1_En_22_Chapter_IEq87.gif) for all j if and only if F is holomorphic as a function of the variables ![
$$z_{j} = x_{j} - i\\alpha p_{j}.$$
](A272900_1_En_22_Chapter_IEq88.gif)

From the physical standpoint, we do not merely want a vector space of functions, but a Hilbert space. It is natural, then, to look at functions of the forms computed in Proposition 22.8 that belong to ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq89.gif). In the case of the position and momentum subspaces, we encounter a serious problem: There are no nonzero functions of the indicated form that are square integrable over ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_22_Chapter_IEq90.gif) After all, if ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq268.gif) is in the position subspace, then ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq269.gif)(x, p) is independent of p and the integral of ![
$${\\left\\vert \\psi \\right\\vert }^{2}$$
](A272900_1_En_22_Chapter_IEq91.gif) over the p-variables will be infinite, unless ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq270.gif) is zero almost everywhere. If ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq271.gif) is in the momentum subspace, ![
$${\\left\\vert \\psi \\right\\vert }^{2}$$
](A272900_1_En_22_Chapter_IEq92.gif) is independent of x and we have a similar problem.

The solution to this problem is to integrate not over ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq93.gif) but over ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_22_Chapter_IEq94.gif) Although the "proper" way to make this change of integration is to introduce the notion of "half-forms," as in Chap.​ 23, we will content ourselves in this chapter with the following simplistic rule: integrate only over the variables on which ![
$${\\left\\vert \\psi \\right\\vert }^{2}$$
](A272900_1_En_22_Chapter_IEq95.gif) depends. If we want to get a Hilbert space (not just an inner product space), we must also allow functions of the specified form that are square integrable but not necessarily smooth. We may therefore identify the position Hilbert space and momentum Hilbert space as follows.

Conclusion 22.9

The position Hilbert space is the space of functions on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq96.gif) of the form

![
$$\\displaystyle{\\psi \(\\mathbf{x},\\mathbf{p}\) =\\phi \(\\mathbf{x}\),}$$
](A272900_1_En_22_Chapter_Equy.gif)

where ![
$$\\phi \\in {L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_22_Chapter_IEq97.gif) The norm of such a function is computed as

![
$$\\displaystyle{{\\left\\Vert \\psi \\right\\Vert }^{2} =\\int _{{ \\mathbb{R}}^{n}}{\\left\\vert \\phi \(\\mathbf{x}\)\\right\\vert }^{2}\\ d\\mathbf{x.}}$$
](A272900_1_En_22_Chapter_Equz.gif)

The momentum Hilbert space is the space of functions on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq98.gif) of the form

![
$$\\displaystyle{\\psi \(\\mathbf{x},\\mathbf{p}\) = {e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash }\\phi \(\\mathbf{p}\),}$$
](A272900_1_En_22_Chapter_Equaa.gif)

where ![
$$\\phi \\in {L}^{2}\({\\mathbb{R}}^{n}\).$$
](A272900_1_En_22_Chapter_IEq99.gif) The norm of such a function is computed as

![
$$\\displaystyle{{\\left\\Vert \\psi \\right\\Vert }^{2} =\\int _{{ \\mathbb{R}}^{n}}{\\left\\vert \\phi \(\\mathbf{p}\)\\right\\vert }^{2}\\ d\\mathbf{p}.}$$
](A272900_1_En_22_Chapter_Equab.gif)

If we consider the holomorphic subspace, we find that it behaves better than the position and momentum subspaces, in that there exist nonzero functions of the form (22.11) that are square integrable over ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq100.gif) as we will see shortly. Furthermore, the space of functions of the form (22.11) that are square integrable over ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq101.gif) form a closed subspace of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_22_Chapter_IEq102.gif) by the same argument as in the proof of Proposition 14.15.

Conclusion 22.10

The holomorphic Hilbert space consists of those functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq291.gif) of the form (22.11)that are square integrable over ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_22_Chapter_IEq103.gif) If ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq295.gif) is identified with the holomorphic function F in (22.11),then this Hilbert space may be identified with ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\nu \),$$
](A272900_1_En_22_Chapter_IEq104.gif) where

![
$$\\displaystyle{\\nu \(\\mathbf{z}\) = {e}^{-{\\left\\vert \\mathop{Im}\\nolimits \\mathbf{z}\\right\\vert }^{2}/\(\\alpha \\hslash \) }.}$$
](A272900_1_En_22_Chapter_Equac.gif)

The space ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\nu \)$$
](A272900_1_En_22_Chapter_IEq105.gif) is nothing but an invariant form of the Segal–Bargmann space (Definition 14.14), where here "invariant" means that the density ν is invariant under translations in the real directions. This space can be identified unitarily with the ordinary Segal–Bargmann space ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{2\\alpha \\hslash }\)$$
](A272900_1_En_22_Chapter_IEq106.gif) as follows. Define a map ![
$$\\Psi : \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{2\\alpha \\hslash }\) \\rightarrow \\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\nu \)$$
](A272900_1_En_22_Chapter_IEq107.gif) by

![
$$\\displaystyle{ \\Psi \(F\)\(\\mathbf{z}\) = {\(2\\pi \\alpha \\hslash \)}^{-n/2}{e}^{-{\\mathbf{z}}^{2}/\(4\\alpha \\hslash \) }F\(\\mathbf{z}\), }$$
](A272900_1_En_22_Chapter_Equ16.gif)

(22.12)

where ![
$${\\mathbf{z}}^{2} = z_{1}^{2} + \\cdots + z_{n}^{2}.$$
](A272900_1_En_22_Chapter_IEq108.gif) Then a simple calculation shows that

![
$$\\displaystyle{\\left\\Vert \\Psi \(F\)\\right\\Vert _{{L}^{2}\({\\mathbb{C}}^{n},\\nu \)}^{2} =\\int _{{ \\mathbb{C}}^{n}}{\\left\\vert F\(\\mathbf{z}\)\\right\\vert }^{2}\\mu _{ 2\\alpha \\hslash }\(\\mathbf{z}\)\\ d\\mathbf{z}.}$$
](A272900_1_En_22_Chapter_Equad.gif)

Since also ![
$${e}^{-{\\mathbf{z}}^{2}/\(4\\alpha \\hslash \) }$$
](A272900_1_En_22_Chapter_IEq109.gif) is holomorphic as a function of z, we see that Ψ maps ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\mu _{2\\alpha \\hslash }\)$$
](A272900_1_En_22_Chapter_IEq110.gif) isometrically into ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\nu \).$$
](A272900_1_En_22_Chapter_IEq111.gif) The map Ψ has an inverse given by multiplication by ![
$${\(2\\pi \\alpha \\hslash \)}^{n/2}{e}^{{\\mathbf{z}}^{2} /\(4\\alpha \\hslash \)},$$
](A272900_1_En_22_Chapter_IEq112.gif) showing that Ψ is actually unitary. In particular, there exist many nonzero holomorphic functions on ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_22_Chapter_IEq113.gif) that belong to ![
$$\\mathcal{H}{L}^{2}\({\\mathbb{C}}^{n},\\nu \).$$
](A272900_1_En_22_Chapter_IEq114.gif)

We will regard any of the Hilbert spaces in Conclusions 22.9 and 22.10 as our quantum Hilbert space. These spaces are to be compared to the prequantum Hilbert space ![
$${L}^{2}\({\\mathbb{R}}^{2n}\),$$
](A272900_1_En_22_Chapter_IEq115.gif) which is in some sense "bigger," consisting of functions of twice as many variables. Note there are multiple possibilities for the quantum Hilbert space. To reduce from the prequantum Hilbert space to the quantum Hilbert space, we have to choose a set of n variables, and then we look a functions that depend only on those n variables. Indeed, there are many other possibilities for the quantum Hilbert space; we have considered only the most common choices. We defer a discussion of the general theory until Chap.​ 23.

The reader may wonder why we are using the definition ![
$$z_{j} = x_{j} - i\\alpha p_{j}$$
](A272900_1_En_22_Chapter_IEq116.gif) (α > 0) rather than ![
$$z_{j} = x_{j} + i\\alpha p_{j}.$$
](A272900_1_En_22_Chapter_IEq117.gif) If we repeated the preceding calculations with ![
$$z_{j} = x_{j} + i\\alpha p_{j},$$
](A272900_1_En_22_Chapter_IEq118.gif) with a corresponding sign change in the definition of ![
$$\\partial /\\partial \\bar{z}_{j},$$
](A272900_1_En_22_Chapter_IEq119.gif) we would find that ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq272.gif) satisfies ![
$$\\nabla _{\\partial /\\partial \\bar{z}_{j}}\\psi$$
](A272900_1_En_22_Chapter_IEq120.gif) for all j if and only if ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq273.gif) is of the form

![
$$\\displaystyle{ \\psi \(\\mathbf{x},\\mathbf{p}\) = F\(z_{1},\\ldots,z_{n}\){e}^{\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }, }$$
](A272900_1_En_22_Chapter_Equ17.gif)

(22.13)

where F is holomorphic on ![
$${\\mathbb{C}}^{n}.$$
](A272900_1_En_22_Chapter_IEq121.gif) The change in sign in the exponent between (22.11) and (22.13) has a drastic effect: There are no nonzero holomorphic functions F for which the function ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq274.gif) in (22.13) is square integrable over ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_22_Chapter_IEq122.gif) (See Exercise 3.) Unlike the situation with the position and momentum Hilbert spaces, there is no natural way to alter the domain of integration to make a function of the form (22.13) have finite norm.

We see, then, that there is a big difference between the definitions ![
$$z_{j} = x_{j} - i\\alpha p_{j}$$
](A272900_1_En_22_Chapter_IEq123.gif) and ![
$$z_{j} = x_{j} + i\\alpha p_{j}.$$
](A272900_1_En_22_Chapter_IEq221.gif) In the general framework of geometric quantization, we will have a similar distinction, where complex structures satisfying a certain positivity condition behave well, whereas the "opposite" complex structures behave badly. (See Definition 23.19 in Sect.​ 23.​4.​)

## 22.5 Quantization of Observables

Now that we have constructed our quantum (as opposed to prequantum) Hilbert spaces, we need to construct operators on these spaces. According to the standard geometric quantization program, the quantum operator associated with a function f is supposed to be simply the restriction to the quantum Hilbert space of the prequantum operator Q pre(f), provided that Q pre(f) leaves the quantum Hilbert space invariant.

Proposition 22.11

The position, momentum, and holomorphic subspaces in Definition 22.7 are all invariant under the prequantum operators Q pre (x j) and Q pre (p j ). Specifically, in the position subspace, we have

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{pre}}\(x_{j}\)\\phi \(\\mathbf{x}\)& =& x_{j}\\phi \(\\mathbf{x}\) {}\\\\ Q_{\\mathrm{pre}}\(p_{j}\)\\phi \(\\mathbf{x}\)& =& -i\\hslash \\frac{\\partial \\phi } {\\partial x_{j}}, {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ18.gif)

in the momentum subspace, we have

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{pre}}\(x_{j}\)\({e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash }\\phi \(\\mathbf{p}\)\)& =& {e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash }\\left\(i\\hslash \\frac{\\partial \\phi } {\\partial p_{j}}\(\\mathbf{p}\)\\right\) {}\\\\ Q_{\\mathrm{pre}}\(p_{j}\)\({e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash }\\phi \(\\mathbf{p}\)\)& =& {e}^{i\\mathbf{x}\\cdot \\mathbf{p}/\\hslash }\(p_{ j}\\phi \(\\mathbf{p}\)\), {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ19.gif)

and in the holomorphic subspace, we have

![
$$\\displaystyle\\begin{array}{rcl} Q_{\\mathrm{pre}}\(x_{j}\)\(F\(\\mathbf{z}\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }\)& =& \\left\(\\alpha \\hslash \\frac{\\partial F} {\\partial z_{j}} + z_{j}F\(\\mathbf{z}\)\\right\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) } {}\\\\ Q_{\\mathrm{pre}}\(p_{j}\)\(F\(\\mathbf{z}\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }\)& =& \\left\(-i\\hslash \\frac{\\partial F} {\\partial z_{j}}\\right\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }. {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ20.gif)

Proof.

See Exercise 4.

The invariance of the three subspaces under the prequantized position and momentum operators follows from a general result in geometric quantization, that for a real-valued function f, the prequantum operator Q pre(f) preserves a given quantum space if and only if the Hamiltonian flow generated by f preserves the polarization defining the quantum space. The term "polarization" refers to the set of directions in which the elements of the quantum space are covariantly constant. In the case of the position, momentum, and holomorphic spaces, the set of such directions is the same at every point, which means that the polarization is invariant under translations. But the Hamiltonian flows generated by x j and p j are nothing but translations in the − p j -directions and the x j -directions, respectively. Of course, in this simple example, we can verify the invariance by direct computation, which also gives the indicated form of the operators on each subspace.

Note also that in each case, the "preferred" functions act simply as multiplication operators. In the position subspace, for example, the position operator Q pre(x j ) acts simply as multiplication by x j , whereas in the momentum subspace, the operator Q pre(p j ) acts as multiplication by p j . Finally, in the holomorphic subspace, the operator

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(z_{j}\)\\left\(F\(\\mathbf{z}\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) }\\right\) = \\left\(z_{j}F\(\\mathbf{z}\)\\right\){e}^{-\\alpha {\\left\\vert \\mathbf{p}\\right\\vert }^{2}/\(2\\hslash \) },}$$
](A272900_1_En_22_Chapter_Equae.gif)

where ![
$$z_{j} = x_{j} - i\\alpha p_{j}$$
](A272900_1_En_22_Chapter_IEq125.gif), since the terms involving ∂ F ∕ ∂ z j cancel.

We now focus on the position Hilbert space and look for operators of the form Q pre(f) that leave the position subspace invariant.

Proposition 22.12

The position subspace is invariant under Q pre (f) whenever f is of the form

![
$$\\displaystyle{ f\(\\mathbf{x},\\mathbf{p}\) = a\(\\mathbf{x}\) + b_{j}\(\\mathbf{x}\)p_{j} }$$
](A272900_1_En_22_Chapter_Equ21.gif)

(22.14)

for some smooth functions a and b 1 ,...,b n on ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_22_Chapter_IEq126.gif) On the other hand, the position subspace in not invariant under the operator Q pre (p j 2 ).

Proof.

If f is of the form (22.14), calculation shows that ![
$$\\theta \(X_{f}\) + f = a\(\\mathbf{x}\).$$
](A272900_1_En_22_Chapter_IEq127.gif) If we drop any terms in X f involving ∂ ∕ ∂ p j , since these are zero on the position subspace, we end up with

![
$$\\displaystyle{ Q_{\\mathrm{pre}}\(f\)\\,\\left\(\\phi \(\\mathbf{x}\)\\right\) = -i\\hslash b_{j}\(\\mathbf{x}\) \\frac{\\partial \\phi } {\\partial x_{j}} + a\(\\mathbf{x}\)\\phi \(\\mathbf{x}\), }$$
](A272900_1_En_22_Chapter_Equ22.gif)

(22.15)

which is again in the position subspace. [There is no p-dependence in the coefficient of ∂ ∕ ∂ x j in (22.15) because ∂ f ∕ ∂ p j is independent of p. ] On the other hand, direct calculation shows that the restriction to the position subspace of Q pre(f) is

![
$$\\displaystyle{-2i\\hslash p_{j} \\frac{\\partial } {\\partial x_{j}} - p_{j}^{2},}$$
](A272900_1_En_22_Chapter_Equaf.gif)

which does not preserve the space of functions on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_22_Chapter_IEq228.gif) that are independent of p.

It should be noted that the expression on the right-hand side of (22.15) is not a self-adjoint, or even symmetric, operator on ![
$${L}^{2}\({\\mathbb{R}}^{n}\),$$
](A272900_1_En_22_Chapter_IEq129.gif) unless the vector field b(x) happens to be divergence free. (Even though the vector field X f is divergence free on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq130.gif) the way X f acts on functions that are independent of p is not necessarily a divergence free vector field on ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_22_Chapter_IEq131.gif)) This undesirable feature of our quantization scheme is the result of our simplistic method of passing from ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq132.gif) to ![
$${L}^{2}\({\\mathbb{R}}^{n}\)$$
](A272900_1_En_22_Chapter_IEq133.gif) in our derivation of Conclusion 22.9. When we do this reduction properly, using half-forms, we will obtain a self-adjoint operator. See Sect.​ 23.​6.​

We now consider the behavior of the holomorphic subspace under the prequantized position and momentum operators.

Proposition 22.13

For any α > 0, let H α be the subspace of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq134.gif) consisting of smooth functions ![
$$ {\\psi}$$
](A272900_1_En_22_Chapter_IEq297.gif) that satisfy ![
$$\\nabla _{\\partial /\\partial \\bar{z}_{j}}\\psi = 0,$$
](A272900_1_En_22_Chapter_IEq135.gif) where ![
$$\\partial /\\partial \\bar{z}_{j}$$
](A272900_1_En_22_Chapter_IEq136.gif) is as in (22.9). Then H α is a closed subspace of ![
$${L}^{2}\({\\mathbb{R}}^{2n}\)$$
](A272900_1_En_22_Chapter_IEq137.gif) and H α is invariant under the one-parameter unitary groups generated by Q pre (x j ) and Q pre (p j ). Furthermore, Q pre (x j ) and Q pre (p j ) act irreducibly on H α in the sense of Definition 14.6.

For each α > 0, the holomorphic Hilbert space is a subspace of the prequantum Hilbert space invariant under the exponentiated position and momentum operators. Thus, the prequantum Hilbert space is far from being irreducible under the action of those operators.

Proof.

The invariance of H α is a simple calculation (Exercise 5). Irreducibility can be established by reducing to the previously established irreducibility of the Segal–Bargmann space under the operators T a in Theorem 14.16. To this end, we should check that the unitary map Ψ in (22.12) intertwines products of exponentials of Q pre(x j ) and Q pre(p j ) with operators of the form T a (with ![
$$\\hslash $$
](A272900_1_En_22_Chapter_IEq138.gif) replaced by ![
$$2\\alpha \\hslash $$
](A272900_1_En_22_Chapter_IEq139.gif)). This is a straightforward but tedious calculation, and we omit the details.

We conclude this section with an example of a quantum subspace that is invariant under the (pre)quantized Hamiltonian of a harmonic oscillator.

Proposition 22.14

Consider a harmonic oscillator with Hamiltonian

![
$$\\displaystyle{H = \\frac{1} {2m}\\left\({p}^{2} + {\(m\\omega x\)}^{2}\\right\).}$$
](A272900_1_En_22_Chapter_Equag.gif)

Consider also the subspace H α in Proposition 22.13, with ![
$$\\alpha = 1/\(m\\omega \).$$
](A272900_1_En_22_Chapter_IEq140.gif) Then the operator Q pre (H) leaves H α invariant. Furthermore, the restriction of Q pre (H) to H α has non-negative spectrum consisting of eigenvalues of the form ![
$$n\\hslash \\omega,$$
](A272900_1_En_22_Chapter_IEq141.gif) where n ranges over the non-negative integers.

Proposition 22.14 is a much more physically reasonable result for the spectrum of the quantization of the non-negative function H than on the full prequantum Hilbert space, where (Proposition 22.6) the spectrum of Q pre(H) is not even bounded below. When we introduce the "half-form correction" in Sect.​ 23.​7, we will finally be able to obtain the "correct" spectrum for the quantum harmonic oscillator, consisting of numbers of the form ![
$$\(n + 1/2\)\\hslash \\omega,$$
](A272900_1_En_22_Chapter_IEq142.gif) n = 0, 1, 2,.... See Example 23.53.

Proof.

As in the proof of Proposition 22.6, we introduce the variable y = m ω x. With ![
$$\\alpha = 1/\(m\\omega \),$$
](A272900_1_En_22_Chapter_IEq143.gif) this gives ![
$$z = \(y - ip\)/\(m\\omega \).$$
](A272900_1_En_22_Chapter_IEq144.gif) We use the symplectic potential

![
$$\\displaystyle{\\theta = \\frac{1} {2}\\left\(p\\ dx - x\\ dp\\right\) = \\frac{1} {2m\\omega }\(p\\ dy - y\\ dp\).}$$
](A272900_1_En_22_Chapter_Equah.gif)

Then

![
$$\\displaystyle{\\theta \\left\( \\frac{\\partial } {\\partial \\bar{z}}\\right\) = \\frac{1} {2}\\left\(p + \\frac{i} {\\alpha } x\\right\) = \\frac{i} {2\\alpha }z}$$
](A272900_1_En_22_Chapter_Equai.gif)

and so ![
$$\\nabla _{\\partial /\\partial \\bar{z}} = \\partial /\\partial \\bar{z} + z/\(2\\alpha \\hslash \).$$
](A272900_1_En_22_Chapter_IEq145.gif) From this, we can easily check that the holomorphic subspace consists of functions of the form

![
$$\\displaystyle{ F\(\\mathbf{z}\){e}^{-{\\left\\vert z\\right\\vert }^{2}/\(2\\alpha \\hslash \) } = F\(\\mathbf{z}\)\\exp \\left\\{-\\frac{\({y}^{2} + {p}^{2}\)} {2m\\omega \\hslash } \\right\\}, }$$
](A272900_1_En_22_Chapter_Equ23.gif)

(22.16)

where F is holomorphic.

Meanwhile, as in the proof of Proposition 22.6, we have

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(H\) = i\\hslash \\omega \\left\(y \\frac{\\partial } {\\partial p} - p \\frac{\\partial } {\\partial y}\\right\),}$$
](A272900_1_En_22_Chapter_Equaj.gif)

which is just an angular derivative in the (y, p)-plane. Since the exponential factor in (22.16) is rotationally invariant, Q pre(H) only hits F. Meanwhile,

![
$$\\displaystyle\\begin{array}{rcl} \\left\(y \\frac{\\partial } {\\partial p} - p \\frac{\\partial } {\\partial y}\\right\)F\\left\(\\frac{y - ip} {m\\omega } \\right\)& =& y\\frac{dF} {dz} \\left\(- \\frac{i} {m\\omega }\\right\) - p\\frac{dF} {dz} \\frac{1} {m\\omega } {}\\\\ & =& - \\frac{i} {m\\omega }\(y - ip\)\\frac{dF} {dz} {}\\\\ & =& -iz\\frac{dF} {dz}. {}\\\\ \\end{array}$$
](A272900_1_En_22_Chapter_Equ24.gif)

Thus,

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(H\)\(F\(\\mathbf{z}\){e}^{-{\\left\\vert z\\right\\vert }^{2}/\(2\\alpha \\hslash \) }\) = \\left\(\\hslash \\omega z\\frac{dF} {dz} \\right\){e}^{-{\\left\\vert z\\right\\vert }^{2}/\(2\\alpha \\hslash \) },}$$
](A272900_1_En_22_Chapter_Equak.gif)

which is again in the holomorphic subspace.

Finally, as in Proposition 14.15, the functions z n , n = 0, 1, 2,..., form an orthogonal basis for the Hilbert space H α . Each monomial z n is an eigenvector for the operator z d ∕ dz with eigenvalue n. This establishes the claim about the spectrum of the restriction to H α of Q pre(H).

The operator ![
$$F\\mapsto \\hslash \\omega z\\ dF/dz$$
](A272900_1_En_22_Chapter_IEq146.gif) is self-adjoint on the holomorphic Hilbert space, in contrast to the operators in (22.15) in the case of the position Hilbert space. Indeed, self-adjointness is "automatic" in this case, because the holomorphic Hilbert space is actually a subspace of the prequantum Hilbert space, and the restriction of a self-adjoint operator to an invariant subspace is self-adjoint.

## 22.6 Exercises

1.

Consider the vector field

![
$$\\displaystyle{X := a_{j}\(\\mathbf{x}\) \\frac{\\partial } {\\partial x_{j}}}$$
](A272900_1_En_22_Chapter_Equal.gif)

on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_22_Chapter_IEq147.gif) where the a j 's are smooth, real-valued functions. Show that X is skew-self-adjoint on ![
$$C_{c}^{\\infty }\({\\mathbb{R}}^{N}\)$$
](A272900_1_En_22_Chapter_IEq148.gif) if and only if the divergence of X (i.e., the quantity ∂ a j ∕ ∂ x j ) is identically zero.

2.

Using the symplectic potential θ = p dx, compute Q pre(xp 2). Show that Q pre(xp 2) is not in the algebra of operators generated by Q pre(x) and Q pre(p).

Hint: Consider how Q pre(xp 2) acts on functions that are independent of p.

3.

(a)

Suppose F is a holomorphic function on ℂ such that

![
$$\\displaystyle{\\int _{\\mathbb{C}}{\\left\\vert F\(z\)\\right\\vert }^{2}\\ dz < \\infty,}$$
](A272900_1_En_22_Chapter_Equam.gif)

where here dz denotes the 2-dimensional Lebesgue measure on ![
$$\\mathbb{C}\\mathop{\\cong}{\\mathbb{R}}^{2}.$$
](A272900_1_En_22_Chapter_IEq149.gif) Show that F is identically zero.

Hint: If F is not identically zero, use a power series argument to show that the L 2 norm of F over a disk of radius R tends to infinity as R tends to infinity.

(b)

Show that if a function of the form (22.13), with F holomorphic on ![
$${\\mathbb{C}}^{n},$$
](A272900_1_En_22_Chapter_IEq150.gif) is square integrable, then F must be identically zero.

4.

Prove Proposition 22.11, using the explicit form of Q pre(x j ) and Q pre(p j ) in Example 22.4.

Hint: In the case of the holomorphic subspace, express the operators ∂ ∕ ∂ x j and ∂ ∕ ∂ p j in terms of the operators ∂ ∕ ∂ z j and ![
$$\\partial /\\partial \\bar{z}_{j}$$
](A272900_1_En_22_Chapter_IEq151.gif) in (22.9).

5.

Show that the space of functions of the form in (22.11), where F is holomorphic on ![
$${\\mathbb{C}}^{n},$$
](A272900_1_En_22_Chapter_IEq152.gif) is invariant under the operators ![
$${e}^{itQ_{\\mathrm{pre}}\(x_{j}\)}$$
](A272900_1_En_22_Chapter_IEq153.gif) and ![
$${e}^{itQ_{\\mathrm{pre}}\(p_{j}\)}$$
](A272900_1_En_22_Chapter_IEq154.gif) computed in (22.6), for all ![
$$t \\in \\mathbb{R}$$
](A272900_1_En_22_Chapter_IEq155.gif) and j = 1, 2,..., n.
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5_23

© Springer Science+Business Media New York 2013

# 23. Geometric Quantization on Manifolds

Brian C. Hall1

(1)

Department of Mathematics, University of Notre Dame, Notre Dame, IN, USA

Abstract

Geometric quantization is a type of quantization, which is a general term for a procedure that associates a quantum system with a given classical system. In practical terms, if one is trying to deduce what sort of quantum system should model a given physical phenomenon, one often begins by observing the classical limit of the system. Electromagnetic radiation, for example, is describable on a macroscopic scale by Maxwell's equations. On a finer scale, quantum effects (photons) become important. How should one determine the correct quantum theory of electromagnetism? It seems that the only reasonable way to proceed is to "quantize" Maxwell's equations—and then to compare the resulting quantum system to experiment.

## 23.1 Introduction

Geometric quantization is a type of quantization, which is a general term for a procedure that associates a quantum system with a given classical system. In practical terms, if one is trying to deduce what sort of quantum system should model a given physical phenomenon, one often begins by observing the classical limit of the system. Electromagnetic radiation, for example, is describable on a macroscopic scale by Maxwell's equations. On a finer scale, quantum effects (photons) become important. How should one determine the correct quantum theory of electromagnetism? It seems that the only reasonable way to proceed is to "quantize" Maxwell's equations—and then to compare the resulting quantum system to experiment.

Meanwhile, not every physically interesting system has ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq1.gif) as its phase space. Geometric quantization, then, is an attempt to construct a quantum Hilbert space, together with appropriate operators, starting from a physical system having an arbitrary 2n-dimensional symplectic manifold N as its phase space. To perform geometric quantization on N, one must first choose a polarization, that is, roughly, a choice of n directions on N in which the wave functions will be constant. If N = T ∗ M, then one may use the "vertical polarization," in which the wave functions are constant along the fibers of T ∗ M. For cotangent bundles with the vertical polarization, geometric quantization reproduces the "half-density quantization" of Blattner [4]. (See Examples 23.45 and 23.48.) Even for cotangent bundles, however, it is of interest to use polarizations other than the vertical polarization, as we have seen already in the ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_23_Chapter_IEq2.gif) case. In the case of the cotangent bundle of a compact Lie group, for example, the paper [20] shows how quantization with a complex polarization gives rise to a generalized Segal–Bargmann transform.

Some phase spaces, meanwhile, may not even be in the form of a cotangent bundle. In the orbit method in representation theory, for example, the relevant symplectic manifolds are "coadjoint orbits," which typically are not cotangent bundles. [In the SU(2) case, for instance, these orbits are 2-spheres with the natural rotationally invariant symplectic form.] In quantum field theory, meanwhile, one encounters Lagrangians that are linear, rather than quadratic, in the "velocity" variables. In such cases, the initial velocity is determined by the initial position, and one cannot think of the space of initial conditions as a (co)tangent bundle. Systems of this form can still be symplectic, but they are not cotangent bundles. Furthermore, it is common to think of compact symplectic manifolds (such as S 2 with a rotationally invariant symplectic form) as classical models of internal degrees of freedom, such as spin.

To quantize these more general symplectic manifolds, one needs a more general approach to quantization. Given a symplectic manifold (N, ω) satisfying a certain integrality condition, one can construct a line bundle L over N along with a connection ∇ on L which has a curvature of ω ∕ ℏ. One can then define "prequantum" operators, acting on sections of L, in much the same way we did in the Euclidean case in Chap.​ 22, and these operators will have the desired relationship between Poisson brackets and commutators. One then chooses a polarization on N and defines the quantum Hilbert space to be the space of sections that are covariantly constant in the directions of that polarization. If the Hamiltonian flow generated by a function f preserves the relevant polarization, then Q pre(f) will preserve the quantum Hilbert space. In the case of real polarizations, there may fail to be any nonzero square-integrable sections that are covariantly constant in the directions of the polarization, a possibility that forces us to introduce the machinery of "half-forms."

Let us end this introduction with a brief critique of the framework of geometric quantization. In the first place, geometric quantization has too many definitions (bundles, connections, curvature, polarizations, half-forms) and too few theorems. In the second place, the class of functions that geometric quantization allows us to quantize—those functions for which the associated Hamiltonian flow preserves the polarization—is often dishearteningly small. In the case N = T ∗ M, for example, with the natural "vertical" polarization, geometric quantization does not allow us to quantize the kinetic energy function, at least not by the "standard procedure" of geometric quantization. Nevertheless, geometric quantization is the only game in town if one wants to quantize general symplectic manifolds in a way that produces an actual Hilbert space and operators thereon.

This chapter lays out in an orderly fashion all the ingredients needed to "do" geometric quantization. Furthermore, although this approach increases length, the chapter fills in the details of several arguments that are only sketched in the standard reference on the subject, the book 45] of Woodhouse. The presentation assumes basic results about symplectic manifolds from [Chap.​ 21. Besides the basic results about manifolds reviewed in Sect.​ 21.​1, we will make use of the Frobenius theorem (see, e.g., Chap.​ 19 of [29]).

As we have noted already in the introduction to Chap.​ 22, sign conventions in the subject of geometric quantization are not consistent from author to author.

## 23.2 Line Bundles and Connections

In this section, we develop the necessary machinery to extend the prequantization construction of Sect.​ 22.​2 to arbitrary symplectic manifolds. We introduce the notion of a line bundle over a manifold and sections thereof, which look locally like complex-valued functions. We then introduce the notion of covariant derivatives of sections of a line bundle, where locally these covariant derivatives take the form ![
$$\\nabla _{X} = X - i\\theta \(X\)$$
](A272900_1_En_23_Chapter_IEq3.gif) for a certain 1-form θ. We then introduce the curvature 2-form, which is a globally defined, closed 2-form that can be computed locally as dθ. We continue to observe the summation convention, in which repeated indices are always summed on.

Definition 23.1

If X is a smooth manifold, a complex line bundle over X is a smooth manifold L together with the following additional structures. First, we have a smooth, surjective map π : L → X. Second, for each x ∈ X, the set π − 1({x}) is equipped with the structure of a complex vector space of dimension 1. For each x ∈ N, the vector space π − 1({x}) is called the fiber of L over x.

These structures are assumed to satisfy the local triviality property, namely that each x ∈ X has a neighborhood U such that there exists a diffeomorphism ![
$$\\chi {:\\pi}^{-1}\(U\) \\rightarrow U \\times \\mathbb{C}$$
](A272900_1_En_23_Chapter_IEq4.gif) with the following properties. First,

![
$$\\displaystyle{\\pi \(p\) =\\pi _{1}\(\\chi \(p\)\),}$$
](A272900_1_En_23_Chapter_Equa.gif)

where ![
$$\\pi _{1} : U \\times \\mathbb{C} \\rightarrow U$$
](A272900_1_En_23_Chapter_IEq5.gif) is projection onto the first factor. Second, for each x ∈ U, the map p ↦ π 2(χ(p)) is a vector space isomorphism of π − 1({x}) with ![
$$\\mathbb{C}.$$
](A272900_1_En_23_Chapter_IEq6.gif)

A section of a line bundle L over X is a map s : X → L such that π(s(p)) = p for all p ∈ X.

For any manifold X, we can form the trivial line bundle ![
$$X \\times \\mathbb{C},$$
](A272900_1_En_23_Chapter_IEq7.gif) where π(x, z) = z and where the vector space structure on ![
$$\\{x\\} \\times \\mathbb{C}$$
](A272900_1_En_23_Chapter_IEq8.gif) is just the usual vector space structure on ![
$$\\mathbb{C}.$$
](A272900_1_En_23_Chapter_IEq9.gif) The local triviality property for a general line bundle L means that L "looks" locally like the trivial line bundle.

Definition 23.2

A connection ∇ on a line bundle L over N is a map associating to each vector field X on N and section s of L another section ∇ X (s) of L satisfying the following properties. First, for each smooth function f on N, we have

![
$$\\displaystyle{\\nabla _{fX}\(s\) = f\\nabla _{X}\(s\)}$$
](A272900_1_En_23_Chapter_Equ1.gif)

(23.1)

for all vector fields X and sections s. Second, for each smooth function f on N, we have the product rule

![
$$\\displaystyle{\\nabla _{X}\(fs\) = \(X\(f\)\)s + f\\nabla _{X}\(s\)}$$
](A272900_1_En_23_Chapter_Equ2.gif)

(23.2)

for all vector fields X and sections s.

Note that for any section s of L and any function f on N, the quantity fs is a section of s. Given a connection ∇ and a vector field X, the operator ∇ X is called the covariant derivative in the direction of X.

Definition 23.3

A Hermitian structure on a line bundle L over N is a choice of an inner product (⋅, ⋅) on each fiber π − 1({x}) of L such that for each smooth section s of L, (s, s) is a smooth function on N. A line bundle L together with a choice of a Hermitian structure on L will be called a Hermitian line bundle. A connection ∇ on a Hermitian line bundle L is called Hermitian if for every vector field on X, we have

![
$$\\displaystyle{\(\\nabla _{X}\(s_{1}\),s_{2}\) + \(s_{1},\\nabla _{X}\(s_{2}\)\) = X\(s_{1},s_{2}\)}$$
](A272900_1_En_23_Chapter_Equ3.gif)

(23.3)

for all smooth sections s 1 and s 2 of L.

We will let the expression "Hermitian line bundle with connection" refer to a Hermitian line bundle L together with a Hermitian connection on L; that is, in this expression, "Hermitian" applies both to the bundle and to the connection.

Given a Hermitian line bundle L with connection, it is always possible to choose a locally defined smooth section s 0 near any point such that ![
$$\(s_{0},s_{0}\) \\equiv 1.$$
](A272900_1_En_23_Chapter_IEq10.gif) We call s 0 a local isometric trivialization of L. Any section s of L can be written locally as s = fs 0 for a unique complex-valued function f. Given a vector field X, let θ(X) be the unique function such that

![
$$\\displaystyle{\\nabla _{X}\(s_{0}\) = -i\\theta \(X\)s_{0}.}$$
](A272900_1_En_23_Chapter_Equb.gif)

Using the assumption ∇ fX = f ∇ X , it can be shown (Exercise 1) that the value of θ(X) at a point p depends only on the value of X at p. Thus, θ defines a 1-form on N. Using the assumption that ∇ is Hermitian, it can be shown (Exercise 2) that θ(X) is always real valued.

Now, using the product rule (23.2) for covariant derivatives, we have

![
$$\\displaystyle\\begin{array}{rcl} \\nabla _{X}\(fs_{0}\)& =& X\(f\)s_{0} + f\\nabla _{X}\(s_{0}\) {}\\\\ & =& \(X\(f\) - i\\theta \(X\)f\)s_{0}. {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ4.gif)

Thus, if we identify sections of L locally with the coefficient function f, we have

![
$$\\displaystyle{\\nabla _{X}\(f\) = X\(f\) - i\\theta \(X\)f,}$$
](A272900_1_En_23_Chapter_Equ5.gif)

(23.4)

as in Sect.​ 22.​2. We call θ the connection 1-form associated to the particular local isometric trivialization.

Definition 23.4

For any Hermitian line bundle (L, ∇ ) with connection, define the curvature 2-form ω of ∇ by requiring that

![
$$\\displaystyle{\\omega \(X,Y\)s = i\\left\(\\nabla _{X}\\nabla _{Y} -\\nabla _{Y}\\nabla _{X} -\\nabla _{\[X,Y \]}\\right\)\(s\)}$$
](A272900_1_En_23_Chapter_Equc.gif)

for all sections s and vector fields X and Y.

Of course, one should check that the given expression for ω is really a 2-form, meaning that the value of ω(X, Y) at a point z depends only on the values of X and Y at z, and that it does not depend on the choice of section s, provided only that s(z) ≠ 0. One way to do this is to compute ω in a local isometric trivialization, as in the following result. (See Exercise 3 for a different approach.)

Proposition 23.5

Let s 0 be a local isometric trivialization of L and let θ be the associated connection 1-form. Then the curvature 2-form ω of ∇ is expressed locally as

![
$$\\displaystyle{\\omega = d\\theta.}$$
](A272900_1_En_23_Chapter_Equd.gif)

In particular, ω is a closed 2-form.

Proof.

The computation is precisely the same as in the proof of Proposition 22.3 in the Euclidean case.

A locally defined 1-form θ satisfying dθ = ω is called a (local) symplectic potential for ω. Our next result says that every symplectic potential is the connection 1-form for some local isometric trivialization of L.

Proposition 23.6

Let (L, ∇) be a Hermitian line bundle with connection over N with curvature 2-form ω. For each point z 0 ∈ N and 1-form θ defined in a neighborhood U of z 0 satisfying dθ = ω, there is a subneighborhood V ⊂ U of z 0 and a local isometric trivialization of L over V such that the connection 1-form of the trivialization is θ.

Proof.

Let s 0 be any isometric trivializing section defined in a neighborhood of z 0 and let η be the associated connection 1-form. Since ![
$$d\(\\eta -\\theta\) = 0,$$
](A272900_1_En_23_Chapter_IEq11.gif) there is a subneighborhood V ⊂ U of z 0 on which ![
$$\\eta -\\theta = df,$$
](A272900_1_En_23_Chapter_IEq12.gif) for some smooth function f. If s 1 = e if s 0, then

![
$$\\displaystyle\\begin{array}{rcl} \\nabla _{X}\(s_{1}\)& =& iX\(f\){e}^{if}s_{0} + {e}^{if}\\nabla _{X}\(s_{0}\) {}\\\\ & =& iX\(f\){e}^{if}s_{0} - i\\eta \(X\){e}^{if}s_{0} {}\\\\ & =& -i\(\\eta \(X\) - df\(X\)\)s_{1}. {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ6.gif)

Thus, the connection 1-form associated with the local isometric trivialization s 1 is ![
$$\\eta -df =\\theta.$$
](A272900_1_En_23_Chapter_IEq13.gif)

Proposition 23.7

If (L 1, ∇1 ) and (L 2, ∇ 2 ) are Hermitian line bundles with connection over N, let L 1 ⊗ L 2 denote the line bundle over N for which the fiber over x is L 1,x ⊗ L 2,x , with the natural inner product induced by the inner products on L 1,x and L 2,x . Then there is a unique Hermitian connection ∇ on L 1 ⊗ L 2 with the property that

![
$$\\displaystyle{\\nabla _{X}\(s_{1} \\otimes s_{2}\) = \(\\nabla _{X}^{1}s_{1}\) \\otimes s_{2} + s_{1} \\otimes \(\\nabla _{X}^{2}s_{2}\),}$$
](A272900_1_En_23_Chapter_Eque.gif)

for all vector fields X on N and all smooth sections s 1 of L 1 and s 2 of L 2 . The curvature 2-form ω for (L 1 ⊗ L 2 ,∇) is given by

![
$$\\displaystyle{\\omega =\\omega _{1} +\\omega _{2},}$$
](A272900_1_En_23_Chapter_Equf.gif)

where ω 1 and ω 2 are the curvature 2-forms for (L 1 ,∇ 1 ) and (L 2 ,∇ 2 ), respectively.

The proof of this proposition is a straightforward exercise in "definition chasing" and is left as an exercise to the reader.

Suppose that L is a Hermitian line bundle over N with connection ∇ and curvature 2-form ω. Given a loop γ : [a, b] → N, we can construct a section s of L that is defined over γ such that the covariant derivative of s in the directions along γ is zero. Indeed, in a local isometric trivialization, such a section can be constructed as

![
$$\\displaystyle{s\(\\gamma \(T\)\) =\\exp \\left\\{i\\int _{\\gamma \(a\)}^{\\gamma \(T\)}\\theta \(\\gamma \(t\)\)\\ dt\\right\\}.}$$
](A272900_1_En_23_Chapter_Equ7.gif)

(23.5)

The value of s at the endpoint of the loop will in general not agree with the value at the starting point, but will differ by multiplication by a constant of absolute value 1.

Definition 23.8

The holonomy of a loop γ : [a, b] → N is the unique constant α (of absolute value 1) such that s(γ(b)) = α s(γ(a)), where s is a nonzero section defined over γ that is covariantly constant in the directions of γ.

The value of the holonomy of γ is easily seen to be independent of the value of s at the starting point, provided this starting value is nonzero.

Suppose that S is a compact, oriented surface with boundary in N whose boundary ∂ S is a loop. It is not hard to show that the holonomy around ∂ S can be computed as

![
$$\\displaystyle{\\mathrm{holonomy}\(\\partial S\) =\\exp \\left\\{i\\int _{S}\\omega \\right\\}.}$$
](A272900_1_En_23_Chapter_Equ8.gif)

(23.6)

Indeed, if S is contained in the domain of a local isometric trivialization, then this result follows from (23.5) by means of Stoke's theorem (Sect.​ 21.​1.​2).

Now, if S is a closed (i.e., boundaryless) surface, its boundary is the trivial loop, which has a holonomy that is trivial, that is, equal to 1. (Think of approximating S by a surface for which the boundary is a very small loop.) Thus, for any closed surface S, (23.6) gives

![
$$\\displaystyle{\\exp \\left\\{i\\int _{S}\\omega \\right\\} = 1,\\quad \\partial S = \\varnothing.}$$
](A272900_1_En_23_Chapter_Equ9.gif)

(23.7)

Equivalently, we have

![
$$\\displaystyle{\\frac{1} {2\\pi}\\int _{S}\\omega \\in \\mathbb{Z}.}$$
](A272900_1_En_23_Chapter_Equ10.gif)

(23.8)

The condition (23.8) says that ω ∕ (2π) is an integral 2-form. Clearly, not every closed 2-form satisfies this property.

The closedness of ω (Proposition 23.5) and the condition (23.8) represent necessary conditions that the curvature of a Hermitian connection must satisfy. It turns out that these two conditions are also sufficient.

Theorem 23.9

Suppose ω is a closed 2-form on a manifold N for which ω∕(2π) is integral in the sense of ( 23.8 ). Then there exists a Hermitian line bundle L over N with Hermitian connection ∇ such that the curvature of ∇ is equal to ω. If, in addition, N is simply connected, then (L, ∇) is unique up to equivalence.

See Sect.​ 8.​3 of [45] for a proof of this result. An equivalence of two Hermitian line bundles L 1 and L 2 with Hermitian connection over N is a diffeomorphism Φ : L 1 → L 2 such that for each x ∈ N, the restriction of Φ to π 1 − 1({x}) is an isometric linear map onto π 2 − 1({x}) and such that for each section s of L 1, we have

![
$$\\displaystyle{\\Phi \(\\nabla _{X}\(s\)\) = \\nabla _{X}\(\\Phi \(s\)\).}$$
](A272900_1_En_23_Chapter_Equg.gif)

We now have the necessary tools to proceed with the program of geometric quantization on symplectic manifolds.

## 23.3 Prequantization

The first step in the program of geometric quantization for a symplectic manifold (N, ω) is to construct a Hermitian line bundle L over N with Hermitian connection for which the curvature 2-form is equal to ω ∕ ℏ. Theorem 23.9 gives the condition for the existence of such a bundle.

Definition 23.10

A symplectic manifold (N, ω) is quantizable (for a particular value of ℏ) if

![
$$\\displaystyle{\\frac{1} {2\\pi \\hslash}\\int _{S}\\omega \\in \\mathbb{Z}}$$
](A272900_1_En_23_Chapter_Equh.gif)

for every closed surface S in N.

Note that if (N, ω) is quantizable for a given value ℏ0 of Planck's constant, then (N, ω) is also quantizable for ![
$$\\hslash = \\hslash _{0}/k$$
](A272900_1_En_23_Chapter_IEq14.gif) for every positive integer k. Indeed, according to Proposition 23.7, if L is a Hermitian line bundle with connection having curvature ω ∕ ℏ0, then L ⊗ k (the tensor product of L with itself k times) is a Hermitian line bundle with connection having curvature ![
$$\\omega /\(\\hslash _{0}/k\).$$
](A272900_1_En_23_Chapter_IEq15.gif)

For the remainder of this chapter, we will assume that N is a quantizable symplectic manifold with symplectic form ω and that (L, ∇) is a fixed Hermitian line bundle with connection of N with curvature ω ∕ ℏ.

If L is a Hermitian line bundle over a symplectic manifold N, we say that a measurable section s of L is square integrable if

![
$$\\displaystyle{\\left\\Vert s\\right\\Vert :={\\left\(\\int _{N}\(s_{1}\(x\),s_{1}\(x\)\)\\ \\lambda \(x\)\\right\)}^{1/2}}$$
](A272900_1_En_23_Chapter_Equi.gif)

is finite, where λ is the Liouville volume form on N. Given two square-integrable sections s 1 and s 2 of L, we define the inner product of s 1 and s 2 by

![
$$\\displaystyle{\\left\\langle s_{1},s_{2}\\right\\rangle =\\int _{N}\(s_{1}\(x\),s_{2}\(x\)\)\\ \\lambda \(x\).}$$
](A272900_1_En_23_Chapter_Equ11.gif)

(23.9)

We use parentheses to denote the pointwise inner product (s 1(x), s 2(x)) of two sections s 1 and s 2, which is a function on N, and we use angled brackets to denote the global inner product ![
$$\\left\\langle s_{1},s_{2}\\right\\rangle$$
](A272900_1_En_23_Chapter_IEq16.gif) of the sections, which is a number.

Definition 23.11

The prequantum Hilbert space for N is the space of equivalence classes of square-integrable sections of L, where two sections are equivalent if they are equal almost everywhere with respect to the Liouville volume measure.

Definition 23.12

If f is a smooth complex-valued function on N, the prequantum operator Q pre(f) is the unbounded operator on the prequantum Hilbert space given by

![
$$\\displaystyle{Q_{\\mathrm{pre}}\(f\) = i\\hslash \\nabla _{X_{f}} + f,}$$
](A272900_1_En_23_Chapter_Equj.gif)

where f represents the operation of multiplying a section by f.

Proposition 23.13

If f is real-valued, then Q pre (f) is symmetric on the space of smooth compactly supported sections of L.

Proof.

Let s 1 and s 2 be smooth, compactly supported sections of L and let Φ f denote the Hamiltonian flow generated by f. For all sufficiently small t, every point in the supports of s 1 and s 2 will contained in the domain of Φ  t f . Furthermore, by Liouville's theorem, the value of

![
$$\\displaystyle{\\int _{N}\[\(s_{1},s_{2}\) \\circ \\Phi _{t}\]\\ \\lambda}$$
](A272900_1_En_23_Chapter_Equk.gif)

is independent of t. If we differentiate this relation with respect to t and evaluate at t = 0, we obtain, by (23.3),

![
$$\\displaystyle{0 =\\int _{N}\[\(\\nabla _{X_{f}}\(s_{1}\),s_{2}\) + \(s_{1},\\nabla _{X_{f}}\(s_{2}\)\)\]\\ \\lambda.}$$
](A272900_1_En_23_Chapter_Equl.gif)

Thus, ![
$$\\nabla _{X_{f}}$$
](A272900_1_En_23_Chapter_IEq17.gif) is a skew-symmetric operator on the space of smooth, compactly supported sections, from which it follows that Q pre(f) is symmetric.

By the product rule for covariant derivatives and the identity ![
$$X_{f}\(f\) =\\{f,f\\} = 0,$$
](A272900_1_En_23_Chapter_IEq18.gif) we see that the two terms in the definition of Q pre(f) commute. We would then expect the exponential ![
$${e}^{itQ_{\\mathrm{pre}}\(f\)}$$
](A272900_1_En_23_Chapter_IEq19.gif) to decompose as a product of two exponentials. One of these exponentials is just e itf and the other may be constructed as "parallel transport along the flow generated by X f . " Thus, if the flow generated by X f is complete, it is possible to use Stone's theorem to construct Q pre(f) as a self-adjoint operator on a domain that includes the space of smooth compactly supported sections.

Proposition 23.14

For any f, g ∈ C ∞ (X), we have

![
$$\\displaystyle{\\frac{1} {i\\hslash}\[Q_{\\mathrm{pre}}\(f\),Q_{\\mathrm{pre}}\(g\)\] = Q_{\\mathrm{pre}}\(\\{f,g\\}\),}$$
](A272900_1_En_23_Chapter_Equm.gif)

where the equality holds as operators on the space of smooth sections of L.

Proof.

The argument is precisely the same as in Proposition 22.1 in the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq20.gif) case.

As we have seen already in Sect.​ 22.​3 in the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq21.gif) case, the prequantum Hilbert space is "too large" to be considered the quantization of N.

## 23.4 Polarizations

In the ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_23_Chapter_IEq22.gif) case, we have the position, momentum, and holomorphic subspaces (Definition 22.7), consisting of functions that depend only on x, p, or z, in the sense that the covariant derivatives of functions in the directions of p, x, and ![
$$\\mathbf{\\bar{z}}$$
](A272900_1_En_23_Chapter_IEq23.gif) are zero. In each case, the "basic observables" of the particular representation (the x j 's, the p j 's, and the z j 's, respectively) act simply as multiplication operators.

To generalize this to a symplectic manifold N of dimension 2n, we may think of choosing n functions α 1,..., α n on N that are "independent," in the sense that d α 1,..., d α n are linearly independent at each point. We assume that the functions α j Poisson commute (![
$$\\{\\alpha _{j},\\alpha _{k}\\} = 0$$
](A272900_1_En_23_Chapter_IEq24.gif)), which makes it reasonable to hope that the quantizations of the α j 's could act as (commuting) multiplication operators. For each z ∈ N, we let P z be the n-dimensional space of directions in which the α j 's are constant, that is, the intersection of the kernels of d α 1,..., d α n . Since we wish to allow the functions α j to be complex valued, P z should be thought of as a subspace of the complexified tangent space ![
$$T_{z}^{\\mathbb{C}}\(N\).$$
](A272900_1_En_23_Chapter_IEq25.gif) The idea is that our quantum Hilbert space should consist of sections of a prequantum line bundle that are covariantly constant in the directions of P.

Now, at each point z, the Hamiltonian vector field ![
$$X_{\\alpha _{j}}$$
](A272900_1_En_23_Chapter_IEq26.gif) will belong to P z , because

![
$$\\displaystyle{d\\alpha _{j}\(X_{\\alpha _{k}}\) = X_{\\alpha _{k}}\(\\alpha _{j}\) =\\{\\alpha _{k},\\alpha _{j}\\} = 0.}$$
](A272900_1_En_23_Chapter_Equn.gif)

Furthermore, since the d α j 's are linearly independent, the ![
$$X_{\\alpha _{j}}$$
](A272900_1_En_23_Chapter_IEq27.gif)'s are also independent, since ![
$$X_{\\alpha _{j}}$$
](A272900_1_En_23_Chapter_IEq28.gif) is obtained from dα j by an isomorphism of tangent and cotangent spaces. Thus, the ![
$$X_{\\alpha _{j}}$$
](A272900_1_En_23_Chapter_IEq29.gif)'s must actually span P z at each point, by a dimension count. Since also ![
$$\\omega \(X_{\\alpha _{j}},X_{\\alpha _{k}}\) = -\\{\\alpha _{j},\\alpha _{k}\\} = 0,$$
](A272900_1_En_23_Chapter_IEq30.gif) we conclude that ω is identically zero on P z . Furthermore, if X and Y are vector fields lying in P at each point, we can express them as

![
$$\\displaystyle{X = a_{j}\(z\)X_{\\alpha _{j}},\\quad Y = b_{j}\(z\)X_{\\alpha _{j}},}$$
](A272900_1_En_23_Chapter_Equo.gif)

for some smooth functions a j and b j . Then

![
$$\\displaystyle{\[X,Y \] = a_{j}\(z\)X_{\\alpha _{j}}\(b_{k}\)X_{\\alpha _{k}} - b_{k}\(z\)X_{\\alpha _{k}}\(a_{j}\)X_{\\alpha _{j}},}$$
](A272900_1_En_23_Chapter_Equp.gif)

because ![
$$\[X_{\\alpha _{j}},X_{\\alpha _{k}}\] = X_{\\{\\alpha _{j},\\alpha _{k}\\}} = 0.$$
](A272900_1_En_23_Chapter_IEq31.gif) Thus, the commutator of two vector fields lying in P will again lie in P.

Definition 23.15

For any z ∈ N, a subspace P of T z N is said to be Lagrangian if dim P = n and ω(X, Y) = 0 for all X, Y ∈ P.

Definition 23.16

A polarization of a symplectic manifold N is a choice at each point z ∈ N of a Lagrangian subspace ![
$$P_{z} \\subset T_{z}^{\\mathbb{C}}\(X\),$$
](A272900_1_En_23_Chapter_IEq32.gif) satisfying the following two conditions.

1.

If two complex vector fields X and Y lie in P z at each point z, then so does [X, Y ].

2.

The dimension of ![
$$P_{z} \\cap \\overline{P_{z}}$$
](A272900_1_En_23_Chapter_IEq33.gif) is constant.

The first condition is called integrability, and we have motivated this condition in the discussion preceding the definition. The second condition is a technical one that prevents problems with certain constructions, such as the pairing map. (Although, in practice, one sometimes needs to work with "polarizations" in which the second condition is violated, extra care is needed in such cases.)

There is one small inaccuracy in our discussion of polarizations: For purely conventional reasons, the quantum Hilbert space is defined as the space of sections that are covariantly constant in the direction of ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq34.gif) rather than P. Thus, P should really be the complex conjugate of the space of directions in which the sections are constant. This convention, however, makes no difference to the definition of a polarization, since if P satisfies the conditions of Definition 23.16, so does ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq35.gif)

Example 23.17

If M is any smooth manifold, let N = T ∗ M be the cotangent bundle of M, equipped with the canonical 2-form ω (Example 21.2). For each z ∈ T ∗ M, let P z be the complexification of the tangent space to the fiber T z ∗ M. Then P is a polarization on T ∗ M, called the vertical polarization.

Proof.

If ![
$$\\{x_{j}\\}$$
](A272900_1_En_23_Chapter_IEq36.gif) is any local coordinate system on M, let ![
$$\\{x_{j},p_{j}\\}$$
](A272900_1_En_23_Chapter_IEq37.gif) be the associated local coordinate system on T ∗ M. The canonical 2-form is given by ω = dp j ∧ dx j . At each point z ∈ T ∗ M, the vertical subspace P z is spanned by the vectors ∂ ∕ ∂ p j . Since ![
$$\\omega \(\\partial /\\partial p_{j},\\partial /\\partial p_{k}\) = 0,$$
](A272900_1_En_23_Chapter_IEq38.gif) we see that P z is Lagrangian. Furthermore, ![
$$P_{z} =\\bar{P}_{z}$$
](A272900_1_En_23_Chapter_IEq39.gif) at every point, and so ![
$$\\dim P_{z} \\cap \\overline{P_{z}}$$
](A272900_1_En_23_Chapter_IEq40.gif) has the constant value n = dim M. Finally, the integrability of P follows by computing the commutator of two vector fields of the form f j (x, p) ∂ ∕ ∂ p j , which will again be a linear combination of the ∂ ∕ ∂ p j 's. Integrability also follows from the easy direction of the Frobenius theorem, since the fibers of T ∗ M are integral submanifolds for P.

We may identify two special classes of polarizations, those that are purely real (i.e., ![
$$\\overline{P_{z}} = P_{z}$$
](A272900_1_En_23_Chapter_IEq41.gif) for all z ∈ N) and those that are purely complex (i.e., ![
$$P_{z} \\cap \\overline{P_{z}} =\\{0\\}$$
](A272900_1_En_23_Chapter_IEq42.gif) for all z ∈ N). The vertical polarization, for example, is purely real.

If P is purely real, the integrability of P implies, by the Frobenius theorem, that every point in N is contained in a unique submanifold R that is maximal in the class of connected integral submanifolds for P. [An integral submanifold R for P is submanifold for which ![
$$T_{z}^{\\mathbb{C}}\(R\) = P_{z}$$
](A272900_1_En_23_Chapter_IEq43.gif) for all z ∈ R. ] We will refer to the maximal connected, integral submanifolds of a purely real polarization as the leaves of the polarization.

In general, the leaves may not be embedded submanifolds of N. Suppose, for example, that N = S 1 ×S 1, with ![
$$\\omega = d\\theta \\ \\wedge d\\phi$$
](A272900_1_En_23_Chapter_IEq501.gif), where θ and ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq502.gif) are angular coordinates on the two copies of S 1. Then the tangent space to N at any point may be identified with ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq44.gif) by means of the basis ![
$$\\{\\partial /\\partial \\theta,\\partial /\\partial \\phi \\}.$$
](A272900_1_En_23_Chapter_IEq45.gif) We may define a polarization P on N by defining P z to be the span of the vector

![
$$\\displaystyle{\\frac{\\partial} {\\partial \\theta} + a\\frac{\\partial} {\\partial \\phi},}$$
](A272900_1_En_23_Chapter_Equq.gif)

for some fixed irrational number a. Each leaf of P is then a set of the form

![
$$\\displaystyle{\\left\\{\({e}^{i\\theta _{0}}{e}^{it},{e}^{iat}\) \\in \\left.{S}^{1} \\times {S}^{1}\\right\\vert t \\in \\mathbb{R}\\right\\},}$$
](A272900_1_En_23_Chapter_Equr.gif)

for some θ 0, which is an "irrational line" in S 1 × S 1. Each leaf is then dense in S 1 × S 1 and, thus, not embedded. We will need to avoid such pathological examples if we hope to successfully carry out the program of geometric quantization with respect to a real polarization. Much more information about the structure of real polarizations may be found in Sects.​ 4.​5–4.7 of [45].

We now consider some elementary results concerning purely complex polarizations.

Proposition 23.18

Suppose P is a purely complex polarization on N. For each z ∈ N, let ![
$$J_{z} : T_{z}^{\\mathbb{C}}N \\rightarrow T_{z}^{\\mathbb{C}}N$$
](A272900_1_En_23_Chapter_IEq46.gif) be the unique linear map such that J z = iI on P z and ![
$$J_{z} = -iI$$
](A272900_1_En_23_Chapter_IEq47.gif) on ![
$$\\overline{P_{z}}.$$
](A272900_1_En_23_Chapter_IEq48.gif) Then J z is real (i.e., it maps the real tangent space to itself) and ω is J z -invariant [i.e., ![
$$\\omega \(J_{z}X_{1},J_{z}X_{2}\) =\\omega \(X_{1},X_{2}\)$$
](A272900_1_En_23_Chapter_IEq49.gif) for all ![
$$X_{1},X_{2} \\in T_{z}^{\\mathbb{C}}N$$
](A272900_1_En_23_Chapter_IEq50.gif) ].

Proof.

Since the restriction of J z to ![
$$\\overline{P_{z}}$$
](A272900_1_En_23_Chapter_IEq51.gif) is the complex-conjugate of its restriction to P z , the map J z commutes with complex conjugation and thus maps real vectors (those satisfying ![
$$\\bar{X} = X$$
](A272900_1_En_23_Chapter_IEq52.gif)) to real vectors. Meanwhile, since P z is Lagrangian and ω is real, ![
$$\\overline{P_{z}}$$
](A272900_1_En_23_Chapter_IEq53.gif) is also Lagrangian. Given two vectors ![
$$X_{1} = Y _{1} + Z_{1}$$
](A272900_1_En_23_Chapter_IEq54.gif) and ![
$$X_{2} = Y _{2} + Z_{2},$$
](A272900_1_En_23_Chapter_IEq55.gif) with Y j ∈ P z and ![
$$Z_{j} \\in \\overline{P_{z}},$$
](A272900_1_En_23_Chapter_IEq56.gif) we compute that

![
$$\\displaystyle\\begin{array}{rcl} & & \\omega \(J_{z}X_{1},J_{z}X_{2}\) {}\\\\ & & =\\omega \(iY _{1},iY _{2}\) +\\omega \(iY _{1},-iZ_{2}\) +\\omega \(-iZ_{1},iY _{2}\) +\\omega \(-iZ_{1},-iZ_{2}\) {}\\\\ & & =\\omega \(Y _{1},Z_{2}\) +\\omega \(Z_{1},Y _{2}\). {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ12.gif)

A similar calculation gives the same value for ω(X 1, X 2), showing that ω is J z -invariant.

A complex structure on a 2n-dimensional manifold N is a collection of "holomorphic" coordinate systems that cover N and such that the transition maps between coordinate systems are holomorphic as maps between open sets in ![
$${\\mathbb{R}}^{2n}\\mathop{\\cong}{\\mathbb{C}}^{n}.$$
](A272900_1_En_23_Chapter_IEq57.gif) At each point z ∈ N, there is a linear map J z : T z N → T z N defined by the expression

![
$$\\displaystyle{J_{z}\\left\(\\frac{\\partial} {\\partial x_{j}}\\right\) = \\frac{\\partial} {\\partial y_{j}};\\quad J_{z}\\left\(\\frac{\\partial} {\\partial y_{j}}\\right\) = - \\frac{\\partial} {\\partial x_{j}},}$$
](A272900_1_En_23_Chapter_Equs.gif)

where the x j 's and y j 's are the real and imaginary parts of holomorphic coordinates. This map is independent of the choice of holomorphic coordinates and satisfies ![
$$J_{z}^{2} = -I$$
](A272900_1_En_23_Chapter_IEq58.gif). At each point z ∈ N, the complexified tangent space ![
$$T_{z}^{\\mathbb{C}}N$$
](A272900_1_En_23_Chapter_IEq59.gif) can be decomposed into eigenspaces for J z with eigenvalues i and − i; these are called the (1, 0)- and (0, 1)-tangent spaces, respectively.

Meanwhile, if N is any 2n-dimensional manifold and J is a smoothly varying family of linear maps on each tangent space satisfying ![
$$J_{z}^{2} = -I$$
](A272900_1_En_23_Chapter_IEq60.gif) for all z, then J is called an almost-complex structure. Given an almost complex structure, we can divide the complexified tangent space into ± i eigenspaces for J. The Newlander–Nirenberg theorem asserts that if the family of + i eigenspaces is integrable (in the sense of Point 1 of Definition 23.16), then there exists a unique complex structure on N for which these are the (1, 0)-tangent spaces.

A purely complex polarization P gives rise to a complex structure on N, as follows. By Proposition 23.18 and the Newlander–Nirenberg theorem, there is a unique complex structure on N for which P z is the (1, 0)-tangent space, for all z ∈ N.

Now, we have already seen in the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq61.gif) case that some purely complex polarizations behave better than others. Compare (22.​11) to (22.​13). The geometric condition that characterizes the "good" polarizations is the following.

Definition 23.19

For any purely complex polarization P, let J be the unique almost-complex structure on N such that J z = iI on P  z and ![
$$J_{z} = -iI$$
](A272900_1_En_23_Chapter_IEq62.gif) on ![
$$\\overline{P_{z}}.$$
](A272900_1_En_23_Chapter_IEq63.gif) We say that P is a Kähler polarization if the bilinear form

![
$$\\displaystyle{g\(X,Y\) :=\\omega \(X,J_{z}Y\)}$$
](A272900_1_En_23_Chapter_Equ13.gif)

(23.10)

is positive definite for each z ∈ N.

For any purely complex polarization, the bilinear form g in (23.10) is symmetric, as the reader may easily verify using the J z -invariance of ω.

Suppose, for example, that we identify ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq64.gif) with ![
$$\\mathbb{C}$$
](A272900_1_En_23_Chapter_IEq65.gif) by the map ![
$$z = x - i\\alpha p,$$
](A272900_1_En_23_Chapter_IEq66.gif) for some fixed α > 0. If we define a purely complex polarization on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq67.gif) by taking P z to be the span of the vector ∂ ∕ ∂ z in (22.​9), then (Exercise 4), P is a Kähler polarization.

## 23.5 Quantization Without Half-Forms

To construct a prequantum Hilbert space, we must choose a line bundle (L, ∇) over (N, ω) having curvature ![
$$\\omega /\\hslash.$$
](A272900_1_En_23_Chapter_IEq68.gif) Such a bundle exists if ![
$$\\omega /\\hslash $$
](A272900_1_En_23_Chapter_IEq69.gif) is an integral 2-form and is unique (up to equivalence) if N is simply connected. To pass to the quantum Hilbert space, we must make a substantial additional choice, that of a polarization P on N. In our first attempt at defining the quantum Hilbert space associated with P, we consider the space of sections of (L, ∇) that are covariantly constant in the directions of ![
$$\\overline{P}.$$
](A272900_1_En_23_Chapter_IEq70.gif) Although this approach works reasonably well for a purely complex polarization, in the case of a purely real polarization, there typically are no square-integrable sections satisfying this condition. (Indeed, we have seen this problem already in the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq71.gif) case, in Sect.​ 22.​4.​) In the next section, we will introduce half-forms to address this problem.

In the remainder of the chapter, we will let P denote a fixed polarization on N.

### 23.5.1 The General Case

As we have remarked, it is customary to consider sections that are covariantly constant in the directions of ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq72.gif) rather than in the directions of P.

Definition 23.20

A smooth section s of L is polarized (with respect to P) if

![
$$\\displaystyle{\\nabla _{X}s = 0}$$
](A272900_1_En_23_Chapter_Equ14.gif)

(23.11)

for every vector field X lying in ![
$$\\overline{P}.$$
](A272900_1_En_23_Chapter_IEq73.gif) The quantum Hilbert space associated with P is the closure in the prequantum Hilbert space of the space of smooth, square-integrable, polarized sections of L.

As in the Euclidean case, we will simply restrict the prequantum operators to the quantum Hilbert space, in those cases where Q pre(f) preserves the space of polarized sections.

Definition 23.21

A smooth, complex-valued function f on N is quantizable with respect to P if Q pre(f) preserves the space of smooth sections that are polarized with respect to P.

The following definition will provide a natural geometric condition guaranteeing quantizability of a function.

Definition 23.22

A possibly complex vector field X preserves a polarization P if for every vector field Y lying in P, the vector field [X, Y] also lies in P.

Note that if X lies in P, then X preserves P, by the integrability assumption on P. There will typically be, however, many vector fields that do not lie in P but nevertheless preserve P.

If X is a real vector field, then [X, Y ] is the same as the Lie derivative ![
$$\\mathcal{L}_{X}\(Y\).$$
](A272900_1_En_23_Chapter_IEq74.gif) It is then not hard to show that X preserves P if and only if the flow generated by X preserves P, that is, if and only if ![
$$\(\\Phi _{t}\)_{{\\ast}}\(P_{z}\) = P_{\\Phi _{t}\(z\)}$$
](A272900_1_En_23_Chapter_IEq75.gif) for all z and t, where Φ is the flow of X. Furthermore, if X is real, then X preserves P if and only if X preserves ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq76.gif)

Example 23.23

If N = T ∗ M for some manifold M and P is the vertical polarization on N, then a Hamiltonian vector field X f preserves P if and only if ![
$$f = f_{1} + f_{2},$$
](A272900_1_En_23_Chapter_IEq77.gif) where f 1 is constant on each fiber and f 2 is linear on each fiber.

Proof.

In local coordinates ![
$$\\{x_{j},p_{j}\\},$$
](A272900_1_En_23_Chapter_IEq78.gif) a vector field X lying in P has the form ![
$$X = g_{j}\\ \\partial /\\partial p_{j}.$$
](A272900_1_En_23_Chapter_IEq79.gif) Thus,

![
$$\\displaystyle{\[X_{f},X\] = \\left\[ \\frac{\\partial f} {\\partial p_{j}} \\frac{\\partial} {\\partial x_{j}},g_{k} \\frac{\\partial} {\\partial p_{k}}\\right\] -\\left\[ \\frac{\\partial f} {\\partial x_{j}} \\frac{\\partial} {\\partial p_{j}},g_{k} \\frac{\\partial} {\\partial p_{k}}\\right\].}$$
](A272900_1_En_23_Chapter_Equt.gif)

This commutator will consist of three "good" terms, which involve only p-derivatives, along with the following "bad" term:

![
$$\\displaystyle{-g_{k} \\frac{{\\partial}^{2}f} {\\partial p_{k}\\partial p_{j}} \\frac{\\partial} {\\partial x_{j}}.}$$
](A272900_1_En_23_Chapter_Equu.gif)

If ∂ 2 f ∕ ∂p k ∂p j is 0 for all j and k, then the bad term vanishes and [X f , X] again lies in P. Conversely, if we want the bad term to vanish for each choice of the coefficient functions g j , we must have ![
$${\\partial}^{2}f/\\partial p_{k}\\partial p_{j} = 0$$
](A272900_1_En_23_Chapter_IEq80.gif) for all j and k. Thus, for each fixed value of x, f must contain only terms that are independent of p and terms that are linear in p.

We now identify the condition for quantizability of functions.

Theorem 23.24

For any smooth, complex-valued function f on N, if the X f preserves ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq81.gif) then f is quantizable.

Since we do not assume that f is real-valued, the condition that X f preserve ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq82.gif) is not equivalent to the condition that X f preserve P.

Proof.

Given a polarized section s, we apply Q pre(f) to s and then test whether Q pre(f)s is still polarized, by applying ∇ X for some vector field X lying in ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq83.gif) To this end, it is useful to compute the commutator of ∇ X and Q pre(f), as follows:

![
$$\\displaystyle\\begin{array}{rcl} \\left\[\\nabla _{X},Q_{\\mathrm{pre}}\(f\)\\right\]& =& i\\hslash \\left\[\\nabla _{X},\\nabla _{X_{f}}\\right\] + \[\\nabla _{X},f\] \\\\ & =& i\\hslash \\left\(\\nabla _{\[X,X_{f}\]} - \\frac{i} {\\hslash}\\omega \(X,X_{f}\)\\right\) + X\(f\) \\\\ & =& i\\hslash \\nabla _{\[X,X_{f}\]}, {}\\end{array}$$
](A272900_1_En_23_Chapter_Equ15.gif)

(23.12)

where we have used that

![
$$\\displaystyle{\\omega \(X,X_{f}\) = -\\omega \(X_{f},X\) = -df\(X\) = -X\(f\),}$$
](A272900_1_En_23_Chapter_Equv.gif)

by Definition 21.6. Since X f preserves ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq84.gif) the vector field [X, X f ] again lies in ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq85.gif) and, thus,

![
$$\\displaystyle{\\nabla _{X}\(Q_{\\mathrm{pre}}\(f\)s\) = Q_{\\mathrm{pre}}\(f\)\\nabla _{X}s + i\\hslash \\nabla _{\[X,X_{f}\]}s = 0,}$$
](A272900_1_En_23_Chapter_Equw.gif)

for every polarized section s, showing that Q pre(f)s is again polarized.

The converse of Theorem 23.24 is false in general. After all, as we will see in the following subsections, for a given polarization, there may not be any nonzero globally defined polarized sections, in which case, any function is quantizable. On the other hand, it can be shown that if Q pre(f) preserves the space of locally defined polarized sections, then the Hamiltonian flow generated by f must preserve ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq86.gif) This result follows by the same reasoning as in the proof of Theorem 23.24, once we know that there are sufficiently many locally defined polarized sections. We will establish such an existence result for purely real and purely complex polarizations in the following subsections; for the general case, see the discussion following Definition 9.1.1 in [45].

A special case of Theorem 23.24 is provided by "polarized functions," that is, functions f for which X(f) = 0 for all vector fields X lying in ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq87.gif) For such an f, the action of Q pre(f) on the quantum space is simply multiplication by f, as we anticipated in the introductory discussion in Sect. 23.4.

Proposition 23.25

If f is a smooth, complex-valued function on N and the derivatives of f in the ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq88.gif) directions are zero, then Q pre (f) preserves the space P-polarized sections, and the restriction of Q pre (f) to this space is simply multiplication by f.

We have already seen special cases of this result in the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq89.gif) case; see the discussion following Proposition 22.11.

Proof.

If the derivatives of f in the direction of ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq90.gif) are zero, then for ![
$$X \\in \\bar{P},$$
](A272900_1_En_23_Chapter_IEq91.gif) we have

![
$$\\displaystyle{0 = X\(f\) = df\(X\) =\\omega \(X_{f},X\),}$$
](A272900_1_En_23_Chapter_Equx.gif)

meaning that X f is in the ω-orthogonal complement of ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq92.gif) But since ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq93.gif) is Lagrangian, this complement is just ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq94.gif). Thus, X f belongs to ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq95.gif) and, in particular, X f preserves ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq96.gif) so that f is quantizable, by Theorem 23.24. Furthermore, ![
$$\\nabla _{X_{f}}s = 0$$
](A272900_1_En_23_Chapter_IEq97.gif) for any P-polarized section s, leaving only the fs term in the formula for Q pre(f)s.

### 23.5.2 The Real Case

In the ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq98.gif) case, we have already computed the space of polarized sections for the vertical polarization in Proposition 22.8. As we observed there, there are no nonzero polarized sections that are square integrable over ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_23_Chapter_IEq99.gif) The same difficulty is easily seen to arise for the vertical polarization on any cotangent bundle N = T ∗ M. In Sect. 23.6, we will introduce half-forms to deal with this failure of square integrability.

We now examine properties of general real polarizations. We will see that polarized sections always exist locally, but not always globally.

Proposition 23.26

If P is a purely real polarization on N, then for any z 0 ∈ N, there exist a neighborhood U of z 0 and a P-polarized section s of L defined over U such that s(z 0)≠0.

Proof.

According to the local form of the Frobenius theorem, we can find a neighborhood U of z 0 and a diffeomorphism Φ of U with a neighborhood V of the origin in ![
$${\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n}$$
](A272900_1_En_23_Chapter_IEq100.gif) such that under Φ, the polarization P looks like the vertical polarization. That is to say, for each z ∈ U, the image of P z under Φ ∗ (z) is just the span of the vectors ![
$$\\partial /\\partial y_{1},\\ldots,\\partial /\\partial y_{n},$$
](A272900_1_En_23_Chapter_IEq101.gif) where the y's are the coordinates on the second copy of ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_23_Chapter_IEq102.gif) By shrinking U if necessary, we can assume that L can be trivialized over U and that the open set V is the product of a ball B 1 centered at the origin in the first copy of ![
$${\\mathbb{R}}^{n}$$
](A272900_1_En_23_Chapter_IEq103.gif) with a ball B 2 centered at the origin in the second copy of ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_23_Chapter_IEq104.gif)

Let θ be the connection 1-form for an isometric trivialization of L over U and let ![
$$\\tilde{\\theta}= {\({\\Phi}^{-1}\)}^{{\\ast}}\(\\theta\).$$
](A272900_1_En_23_Chapter_IEq105.gif) Since the subspaces P z are Lagrangian, the restriction of ![
$$\\tilde{\\theta}$$
](A272900_1_En_23_Chapter_IEq106.gif) to the each set of the form ![
$$\\{\\mathbf{x}\\} \\times B_{2}$$
](A272900_1_En_23_Chapter_IEq107.gif) is closed. Since B 2 is simply connected, there exists, for each x ∈ B 1, a function f x on B 2 such that the restriction of ![
$$\\tilde{\\theta}$$
](A272900_1_En_23_Chapter_IEq108.gif) to ![
$$\\{\\mathbf{x}\\} \\times B_{2}$$
](A272900_1_En_23_Chapter_IEq109.gif) equals df x . If we assume that f x (0) = 0, then f x (y) will be smooth as a function of (x, y), since it is obtained simply by integrating ![
$$\\tilde{\\theta}$$
](A272900_1_En_23_Chapter_IEq110.gif) from 0 to y in the vertical directions.

Now, let ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq530.gif) be any smooth function on B 1 with ![
$$\\phi\(0\) \\neq 0$$
](A272900_1_En_23_Chapter_IEq546.gif) and define a function ![
$$\\psi$$
](A272900_1_En_23_Chapter_IEq527.gif) on B 1 ×B 2 by

![
$$\\displaystyle{\\psi \(\\mathbf{x},\\mathbf{y}\) =\\phi \(\\mathbf{x}\){e}^{if_{\\mathbf{x}}\(\\mathbf{y}\)/\\hslash}.}$$
](A272900_1_En_23_Chapter_Equy.gif)

For any "vertical" vector field X (i.e., one where X is a linear combination of ![
$$\\partial /\\partial y_{1},\\ldots,\\partial /\\partial y_{n}$$
](A272900_1_En_23_Chapter_IEq111.gif) with smooth coefficients), we compute that

![
$$\\displaystyle{X\\psi = \\frac{i} {\\hslash}\(Xf_{\\mathbf{x}}\)\\psi = \\frac{i} {\\hslash}df_{\\mathbf{x}}\(X\)\\psi = \\frac{i} {\\hslash}\\tilde{\\theta}\(X\)\\psi.}$$
](A272900_1_En_23_Chapter_Equz.gif)

Thus,

![
$$\\displaystyle{\\left\(X - \\frac{i} {\\hslash}\\tilde{\\theta}\(X\)\\right\)\\psi = 0,}$$
](A272900_1_En_23_Chapter_Equaa.gif)

from which it follows that the function ![
$$\\hat{\\psi}:=\\psi \\circ \\Phi $$
](A272900_1_En_23_Chapter_IEq112.gif) represents a polarized section on U in the given local trivialization of L.

The existence of nonzero global polarized sections for a purely real polarization P is a more delicate question. If the leaves of P are not embedded, there is little chance of finding global polarized sections. Even if the leaves are embedded, there are obstructions. Since the tangent spaces to the leaves of P are Lagrangian subspaces, the restriction of L to R has zero curvature. There may, nevertheless, be loops in R for which the holonomy (Definition 23.8) is nontrivial. After all, if a loop γ in R is not the boundary of a surface S in R, then we cannot apply (23.6) to conclude that the holonomy of γ is trivial. The collection of holonomies for a leaf R of P can be understood as a homomorphism of π 1(R) into S 1. If there is any loop in R with nontrivial holonomy, any polarized section of L must vanish on R.

Definition 23.27

A submanifold R of N is said to be Lagrangian if dim R = n and T z R is a Lagrangian subspace of T z N for each z ∈ R. A Lagrangian submanifold R of N is said to be Bohr–Sommerfeld (with respect to L) if the holonomy in L of every loop in R is trivial.

We may summarize the preceding discussion as follows.

Conclusion 23.28

For a purely real polarization P with embedded leaves, a polarized section vanishes on every leaf of P that is not Bohr–Sommerfeld.

Our next example suggests that when the leaves are compact, the Bohr–Sommerfeld leaves typically form a discrete set within the set of all leaves.

Example 23.29

Let ![
$$N = {S}^{1} \\times \\mathbb{R},$$
](A272900_1_En_23_Chapter_IEq113.gif) equipped with the symplectic form ![
$$\\omega = dx\\wedge d\\phi$$
](A272900_1_En_23_Chapter_IEq504.gif), where x is the linear coordinate on ![
$$\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq114.gif) and ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq506.gif) is the angular coordinate on S 1. Let L be the trivial line bundle on N, with sections that are identified with smooth functions. Let ![
$$\\theta = x \\ d\\phi$$
](A272900_1_En_23_Chapter_IEq507.gif) and define a connection ∇ on L by ![
$$\\nabla _{X} = X - \(i/\\hslash\)\\theta \(X\),$$
](A272900_1_En_23_Chapter_IEq115.gif) and let P be the purely real polarization of N for which the leaves are the sets of the form S 1 × {x}, for ![
$$x \\in \\mathbb{R}.$$
](A272900_1_En_23_Chapter_IEq116.gif) Then a leaf S 1 × {x} is Bohr–Sommerfeld if and only if ![
$$x/\\hslash $$
](A272900_1_En_23_Chapter_IEq117.gif) is an integer.

In particular, there are no nonzero, smooth polarized sections of L.

Proof.

If we define a section locally on a given leaf S 1 × {x} as

![
$$\\displaystyle{s\(\\phi\) = c{e}^{ix\\phi /\\hslash}}$$
](A272900_1_En_23_Chapter_Equab.gif)

for some nonzero constant c, then it is easily verified that ![
$$\\nabla _{\\partial /\\partial \\phi}s = 0.$$
](A272900_1_En_23_Chapter_IEq118.gif) After one trip around the circle, the value of this section will be the starting value times ![
$${e}^{2\\pi ix/\\hslash}.$$
](A272900_1_En_23_Chapter_IEq119.gif) Thus, the holonomy around S 1 ×{x} is trivial if and only if ![
$$x/\\hslash $$
](A272900_1_En_23_Chapter_IEq120.gif) is an integer. A polarized section, then, would have to vanish on all the leaves where ![
$$x/\\hslash $$
](A272900_1_En_23_Chapter_IEq121.gif) is not an integer. Since such leaves form a dense subset of N, any smooth polarized section must be identically zero.

Even in cases, such as Example 23.29, where there are no smooth polarized sections, one may still consider "distributional" polarized sections that are supported on the Bohr–Sommerfeld leaves, as on pp. 251–252 of [45].

### 23.5.3 The Complex Case

In Proposition 22.8, we computed the space of polarized sections for a certain positive, translation-invariant polarization on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_23_Chapter_IEq122.gif) namely the one for which P z is spanned by the vectors ∂ ∕ ∂ z j in (22.​9). The situation here is better than that for the vertical polarization, in that there are nonzero polarized sections that are square integrable over ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_23_Chapter_IEq123.gif) Recall, however, that if we take our polarization to be spanned by the vectors ![
$$\\partial /\\partial \\bar{z}_{j},$$
](A272900_1_En_23_Chapter_IEq124.gif) then see ([22.​13)], then there are no nonzero square-integrable polarized sections. This example indicates the importance of the positivity condition in Definition 23.19.

For our next example, we consider the example of the unit disk D, equipped with the unique (up to a constant) symplectic form that is invariant under the group of fractional linear transformations that map D onto D. In this case, the quantum Hilbert space can be identified with a weighted Bergman space, that is, an L 2 space of holomorphic functions on D with respect to a measure of the form ![
$${\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{\\nu}dx\\ dy.$$
](A272900_1_En_23_Chapter_IEq125.gif)

Example 23.30

Let N be the unit disk ![
$$D \\subset {\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq126.gif) equipped with the following symplectic form:

![
$$\\displaystyle{\\omega = 4{\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{-2}\\ dx \\wedge dy = {\(1 - {r}^{2}\)}^{-2}r\\ dr \\wedge d\\phi,}$$
](A272900_1_En_23_Chapter_Equac.gif)

where ![
$$\(r, \\phi\)$$
](A272900_1_En_23_Chapter_IEq508.gif) are the usual polar coordinates. Let L be the trivial line bundle over D with connection ![
$$\\nabla _{X} = X - \(i/\\hslash\)\\theta,$$
](A272900_1_En_23_Chapter_IEq127.gif) where θ is the symplectic potential for ω given by

![
$$\\displaystyle{\\theta = 2 \\frac{{r}^{2}} {1 - {r}^{2}}\\ d\\phi.}$$
](A272900_1_En_23_Chapter_Equad.gif)

Define a complex polarization on D by letting ![
$$P_{z} =\\mathrm{Span}\(\\partial /\\partial z\),$$
](A272900_1_En_23_Chapter_IEq128.gif) where ![
$$z = x - iy.$$
](A272900_1_En_23_Chapter_IEq129.gif) In that case, holomorphic sections s have the form

![
$$\\displaystyle{s\(z\) = F\(z\){\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{1/\\hslash},}$$
](A272900_1_En_23_Chapter_Equae.gif)

where F is holomorphic. The norm of such a section is computed as

![
$$\\displaystyle{{\\left\\Vert s\\right\\Vert}^{2} = 4\\int _{D}{\\left\\vert F\(z\)\\right\\vert}^{2}{\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{2/\\hslash -2}\\ dx\\ dy.}$$
](A272900_1_En_23_Chapter_Equaf.gif)

As in the case of the plane, the seemingly unnatural definition ![
$$z = x - iy$$
](A272900_1_En_23_Chapter_IEq130.gif) is necessary to obtain a Kähler polarization. If we used ![
$$z = x + iy$$
](A272900_1_En_23_Chapter_IEq131.gif) instead, the holomorphic sections would have the form ![
$$F\(z\){\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{-1/\\hslash},$$
](A272900_1_En_23_Chapter_IEq132.gif) in which case there would be no nonzero, square-integrable holomorphic sections.

Proof.

See Exercise 8.

We now consider general purely complex polarizations. Recall that, by Proposition 23.18 and the Newlander–Nirenberg theorem, N has a unique complex structure for which P z is the (1, 0)-subspace of ![
$$T_{z}^{\\mathbb{C}}N,$$
](A272900_1_En_23_Chapter_IEq133.gif) for all z ∈ N. As in the purely real case, there always exist local polarized sections.

Theorem 23.31

Suppose P is a purely complex polarization on N. Then for each z 0 ∈ N, there exists a P-polarized section s of L, defined in a neighborhood of z 0 , such that s(z 0)≠0.

We defer the proof of Theorem 23.31 until the end of this subsection.

Suppose s is as in the theorem and s ′ is any other locally defined P-polarized section. Then s ′ = fs for some unique complex-valued function f, and by the product rule for covariant derivatives, X(f) = 0 for all ![
$$X \\in \\bar{P}_{z}.$$
](A272900_1_En_23_Chapter_IEq134.gif) This means that f is holomorphic with respect to the complex structure on N for which P is the (1, 0)-tangent space. Thus, we have a preferred family of local trivializations of L (the ones given by nonvanishing local polarized sections) such that the "ratio" of any two such trivializations is a holomorphic function. This means that we have given L the structure of a "holomorphic line bundle" over the complex manifold N in such a way that the holomorphic sections of L are precisely the polarized sections with respect to P.

Arguing as in the proof of Proposition 14.15, it is not hard to show that for a purely complex polarization, the space of square-integrable polarized sections of L forms a closed subspace of the prequantum Hilbert space. For any z ∈ N, if we choose a linear identification of the fiber of L over z with ![
$$\\mathbb{C},$$
](A272900_1_En_23_Chapter_IEq135.gif) then the map s ↦ s(z) is a linear functional on the quantum Hilbert space. It is not hard to show, as in the proof of Proposition 14.15, that this linear functional is continuous, and can therefore be represented as an inner product with a unique element of the quantum Hilbert space.

Definition 23.32

Let P be a purely complex polarization on N. For each z ∈ N, choose a linear identification of the fiber of L over z with ![
$$\\mathbb{C}.$$
](A272900_1_En_23_Chapter_IEq136.gif) Then the coherent state χ z is the unique element of the quantum Hilbert space with respect to P such that

![
$$\\displaystyle{s\(z\) = \\left\\langle \\chi _{z},s\\right\\rangle}$$
](A272900_1_En_23_Chapter_Equag.gif)

for all s.

Suppose ![
$$N = {\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq137.gif) with a polarization given by ![
$$P_{z} =\\mathrm{Span}\(\\partial /\\partial z\),$$
](A272900_1_En_23_Chapter_IEq138.gif) where ![
$$z = x - i\\alpha p.$$
](A272900_1_En_23_Chapter_IEq139.gif) If we use the symplectic potential ![
$$\\theta = \(p\\ dx - x\\ dp\)/2,$$
](A272900_1_En_23_Chapter_IEq140.gif) then, as in the proof of Proposition 22.14, the quantum Hilbert space is naturally identifiable with the Segal–Bargmann space. In this case, the coherent states can be read off from Proposition 14.17.

It could happen that χ z = 0 for some z ∈ N, or even for all z ∈ N, depending on the choice of P. Even if χ z is nonzero, χ z is only well defined up to multiplication by a constant, because we must choose an identification of L − 1({z}) with ![
$$\\mathbb{C}.$$
](A272900_1_En_23_Chapter_IEq141.gif) But if χ z ≠0, the one-dimensional subspace spanned by χ z is independent of this choice. That is to say, whenever χ z ≠0, the span of χ z is a well-defined element of the projective space ![
$$\\mathcal{P}\(\\mathbf{H}\),$$
](A272900_1_En_23_Chapter_IEq142.gif) where H is the quantum Hilbert space.

Recall, meanwhile, that if (L, ∇) is a Hermitian line bundle with connection having curvature ![
$$\\omega /\\hslash,$$
](A272900_1_En_23_Chapter_IEq143.gif) then for any positive integer n, there is a natural Hermitian connection on L ⊗ k having curvature ![
$$k\\omega /\\hslash.$$
](A272900_1_En_23_Chapter_IEq144.gif) This means that if L is a prequantum line bundle with one value ![
$$\\hslash _{0}$$
](A272900_1_En_23_Chapter_IEq145.gif) of Planck's constant, then L ⊗ k is a prequantum line bundle with Planck's constant equal to ![
$$\\hslash _{0}/k.$$
](A272900_1_En_23_Chapter_IEq146.gif) The following result shows that in the case of compact symplectic manifolds with Kähler polarizations, things behave nicely when k tends to infinity.

Theorem 23.33

Assume N is compact and let P be a Kähler polarization on N. For each positive integer k, let H k denote the space of polarized sections of L ⊗k . Then for all k, H k is finite dimensional. Furthermore, for all sufficiently large k, we have the following results. First, the coherent state χ z ∈ H k is nonzero for each z ∈ N. Second, the map

![
$$\\displaystyle{z\\mapsto \\mathrm{Span}\(\\chi _{z}\)}$$
](A272900_1_En_23_Chapter_Equah.gif)

is an antiholomorphic embedding of N into ![
$$\\mathcal{P}\(\\mathbf{H}_{k}\).$$
](A272900_1_En_23_Chapter_IEq147.gif)

The finite dimensionality of H k is a standard result in the theory of compact, complex manifolds. The embedding of N into ![
$$\\mathcal{P}\(\\mathbf{H}_{k}\)$$
](A272900_1_En_23_Chapter_IEq148.gif) is the Kodaira embedding theorem, which we will not prove here. The Kodaira embedding theorem implies, in particular, that there exist nonzero, globally defined polarized sections of L ⊗ k , at least for large k. Since the value of Planck's constant for L ⊗ k is ![
$$\\hslash _{0}/k,$$
](A272900_1_En_23_Chapter_IEq149.gif) Planck's constant tends to zero as k tends to infinity. Thus, the study of holomorphic sections of L ⊗ k for large k can be understood as being part of semiclassical analysis.

We now turn to the proof of Theorem 23.31, in which we will make use of basic properties of complex-valued differential forms on complex manifolds. ("Complex-valued" means that we allow the value of a k-form on a collection of k tangent vectors to be a complex number.) In a holomorphic local coordinate system z 1,..., z n , each form can be written as a wedge product of the dz j 's and ![
$$d\\bar{z}_{j}$$
](A272900_1_En_23_Chapter_IEq150.gif)'s. A form is called a (p, q)-form if it is a linear combination of wedge products of p factors involving the dz j 's and q factors involving the ![
$$d\\bar{z}_{j}$$
](A272900_1_En_23_Chapter_IEq151.gif)'s. Each form can be decomposed uniquely as a linear combination of (p, q)-forms for various values of p and q, and this decomposition does not depend on the choice of holomorphic coordinate system. If α is a (p, q)-form, then d α will be a linear combination of a (p \+ 1, q)-form and a (p, q \+ 1)-form. We define operators ∂ and ![
$$\\bar{\\partial}$$
](A272900_1_En_23_Chapter_IEq152.gif) in such a way that ∂ maps (p, q)-forms to (p \+ 1, q)-forms, ![
$$\\bar{\\partial}$$
](A272900_1_En_23_Chapter_IEq153.gif) maps (p, q)-forms to (p, q \+ 1) forms, and ![
$$d = \\partial +\\bar{\\partial}.$$
](A272900_1_En_23_Chapter_IEq154.gif) In particular,

![
$$\\displaystyle\\begin{array}{rcl} & & \\partial \(f\\ dz_{j_{1}} \\wedge \\cdots \\wedge dz_{j_{p}} \\wedge d\\bar{z}_{k_{1}} \\wedge \\cdots \\wedge dz_{k_{q}}\) {}\\\\ & & =\\sum _{l} \\frac{\\partial f} {\\partial z_{l}}dz_{l} \\wedge dz_{j_{1}} \\wedge \\cdots \\wedge dz_{j_{p}} \\wedge d\\bar{z}_{k_{1}} \\wedge \\cdots \\wedge dz_{k_{q}} {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ16.gif)

and similarly for ![
$$\\bar{\\partial}$$
](A272900_1_En_23_Chapter_IEq155.gif) with ![
$$\(\\partial f/\\partial z_{l}\)\\ dz_{l}$$
](A272900_1_En_23_Chapter_IEq156.gif) replaced by ![
$$\(\\partial f/\\partial \\bar{z}_{l}\)\\ d\\bar{z}_{l}.$$
](A272900_1_En_23_Chapter_IEq157.gif)

The maps ∂ and ![
$$\\bar{\\partial}$$
](A272900_1_En_23_Chapter_IEq158.gif) satisfy the identities:

![
$$\\displaystyle\\begin{array}{rcl} \\partial \\partial & =& \\bar{\\partial}\\bar{\\partial} = 0 {}\\\\ \\partial \\bar{\\partial}& =& -\\bar{\\partial}\\partial. {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ17.gif)

The Dolbeault lemma states that if a (p, q)-form α satisfies ∂ α = 0, then α can be expressed locally as ∂ β for some (p − 1, q)-form, and if ![
$$\\bar{\\partial}\\alpha = 0$$
](A272900_1_En_23_Chapter_IEq159.gif), then α can be expressed locally as ![
$$\\bar{\\partial}\\beta$$
](A272900_1_En_23_Chapter_IEq160.gif) for some (p, q − 1)-form. A (p, 0)-form α is said to be holomorphic if it can be expressed in holomorphic coordinates as a sum of terms of the form

![
$$\\displaystyle{f\(z\)\\ dz_{j_{1}} \\wedge \\cdots \\wedge dz_{j_{p}},}$$
](A272900_1_En_23_Chapter_Equai.gif)

where the coefficient functions f is holomorphic. A (p, 0)-form α is holomorphic if and only if ![
$$\\bar{\\partial}\\alpha = 0.$$
](A272900_1_En_23_Chapter_IEq161.gif) If a holomorphic (p, 0)-form α satisfies d α = 0 (or, equivalently, ∂ α = 0), then α can be written locally as α = d β, for some holomorphic (p − 1, 0)-form.

Let P be a purely complex polarization on N and let J be the almost-complex structure for which P z is the (1, 0)-tangent space at z. Since (Proposition 23.18), ω is J-invariant, it follows (Exercise 6) that ω is a (1, 1)-form.

Lemma 23.34

Let N be a complex manifold with almost-complex structure J and let ω be a closed, J-invariant, real-valued (1,1)-form on N. Then for every point z 0 ∈ N, there exists a smooth, real-valued function κ defined in a neighborhood of z 0 such that ![
$$i\\partial \\bar{\\partial}\\kappa =\\omega.$$
](A272900_1_En_23_Chapter_IEq162.gif)

In the case that N is Kähler [i.e., the case where ω(X, JX) ≥ 0], a function κ as in the lemma is called a (local) Kähler potential for N.

Proof.

By assumption, ![
$$d\\omega = \(\\partial +\\bar{\\partial}\)\\omega = 0,$$
](A272900_1_En_23_Chapter_IEq163.gif) from which it follows that ![
$$\\partial \\omega =\\bar{\\partial}\\omega = 0,$$
](A272900_1_En_23_Chapter_IEq164.gif) because ∂ω is a (2, 1)-form and ![
$$\\bar{\\partial}\\omega$$
](A272900_1_En_23_Chapter_IEq165.gif) is a (1, 2) form. Thus, by the Dolbeault lemma, there exists a (1, 0)-form α, defined in a neighborhood of z 0, such that ![
$$\\bar{\\partial}\\alpha =\\omega.$$
](A272900_1_En_23_Chapter_IEq166.gif) Then ∂ α is a (2, 0)-form that satisfies

![
$$\\displaystyle{\\bar{\\partial}\\partial \\alpha = -\\partial \\bar{\\partial}\\alpha = -\\partial \\omega = 0.}$$
](A272900_1_En_23_Chapter_Equaj.gif)

This shows that ∂ α is actually a holomorphic (2, 0)-form.

Since also ∂ ∂ α = 0, we see that ∂ α is closed, which means that there exists a holomorphic 1-form η, defined in a possibly smaller neighborhood of z 0, such that ![
$$d\\eta = \\partial \\eta = \\partial \\alpha$$
](A272900_1_En_23_Chapter_IEq167.gif). Thus, ![
$$\\partial \(\\alpha -\\eta\) = 0,$$
](A272900_1_En_23_Chapter_IEq168.gif) and so by the Dolbeault lemma, there exists a function g, defined in a neighborhood of z 0, such that ![
$$\\partial g =\\alpha -\\eta$$
](A272900_1_En_23_Chapter_IEq169.gif). Thus, ![
$$\\alpha =\\eta +\\partial g$$
](A272900_1_En_23_Chapter_IEq170.gif) and so

![
$$\\displaystyle{\\omega =\\bar{\\partial}\\alpha =\\bar{\\partial}\\partial g = -\\partial \\bar{\\partial}g}$$
](A272900_1_En_23_Chapter_Equak.gif)

since ![
$$\\bar{\\partial}\\eta = 0.$$
](A272900_1_En_23_Chapter_IEq171.gif) The function κ : = ig then satisfies ![
$$i\\partial \\bar{\\partial}\\kappa =\\omega.$$
](A272900_1_En_23_Chapter_IEq172.gif)

Now, a calculation in coordinates (Exercise 7) shows that the map ![
$$\\kappa \\mapsto i\\partial \\bar{\\partial}f$$
](A272900_1_En_23_Chapter_IEq173.gif) is real, that is, it maps real-valued functions to real-valued 2-forms. Since ω is real, the operator ![
$$i\\partial \\bar{\\partial}$$
](A272900_1_En_23_Chapter_IEq174.gif) must map the imaginary part of κ to zero. Thus, ![
$$i\\partial \\bar{\\partial}\\kappa$$
](A272900_1_En_23_Chapter_IEq175.gif) is unchanged if κ is replaced by its real part.

Proof of Theorem 23.31.

Let κ be as in Lemma 23.34 and let θ be the real-valued 1-form given by

![
$$\\displaystyle{\\theta =\\mathrm{Im}\(\\partial \\kappa\) = \\frac{1} {2i}\\left\(\\partial \\kappa -\\bar{\\partial}\\kappa \\right\).}$$
](A272900_1_En_23_Chapter_Equ18.gif)

(23.13)

Then because ![
$${\\partial}^{2} =\\bar{{\\partial}}^{2} = 0,$$
](A272900_1_En_23_Chapter_IEq176.gif) we have

![
$$\\displaystyle{d\\theta = \(\\partial +\\bar{\\partial}\)\\theta = \\frac{1} {2i}\(\\bar{\\partial}\\partial \\kappa - \\partial \\bar{\\partial}\\kappa\) =\\omega.}$$
](A272900_1_En_23_Chapter_Equal.gif)

That is to say, θ is a symplectic potential for ω. Thus, by Proposition 23.6, we can find a local isometric trivialization s 0 of L for which the connection 1-form is ![
$$\\theta /\\hslash.$$
](A272900_1_En_23_Chapter_IEq177.gif)

For any vector X, we have

![
$$\\displaystyle{\\nabla _{X}\\left\({e}^{-\\kappa /\(2\\hslash\)}s_{0}\\right\) = \\left\(- \\frac{1} {2\\hslash}X\(\\kappa\) - \\frac{i} {\\hslash}\\theta \(X\)\\right\){e}^{-\\kappa /\\hslash}s_{0},}$$
](A272900_1_En_23_Chapter_Equ19.gif)

(23.14)

where ![
$$X\(\\kappa\) = d\\kappa \(X\) = \\partial \\kappa \(X\) +\\bar{\\partial}\\kappa \(X\).$$
](A272900_1_En_23_Chapter_IEq178.gif) Now, if X is of type (0, 1), then ∂ κ(X) = 0, in which case, if we use (23.13), we find that the two terms on the right-hand side of (23.14) cancel. Thus, ![
$${e}^{-\\kappa /\(2\\hslash\)}s_{0}$$
](A272900_1_En_23_Chapter_IEq179.gif) is the desired local polarized section.

## 23.6 Quantization with Half-Forms: The Real Case

In this section, we introduce a concept known as half-forms, which are designed to work around the problem that, in the case of real polarizations, there often do not exist any nonzero square-integrable polarized sections.

A polarized section s for a real polarization P tends to have infinite norm, because we may get infinity from integrating ![
$$\\vert {s\\vert}^{2}$$
](A272900_1_En_23_Chapter_IEq180.gif) along the leaves of the polarization. To illustrate how half-forms work around this problem, consider the case of the vertical polarization on ![
$${\\mathbb{R}}^{2}\\mathop{\\cong}{T}^{{\\ast}}\\mathbb{R}.$$
](A272900_1_En_23_Chapter_IEq181.gif) Elements of the half-form Hilbert space will be representable in the form ![
$$s \\otimes \\sqrt{dx},$$
](A272900_1_En_23_Chapter_IEq182.gif) where s is a polarized section of L and where ![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq183.gif) will be interpreted as a "section of the square root of the canonical bundle." To compute the norm of such an object, we first square it at each point to obtain the quantity ![
$$\\vert {s\\vert}^{2}\\ dx.$$
](A272900_1_En_23_Chapter_IEq184.gif) Since s is polarized, | s | 2 is a function of x only, independent of p. Thus, | s | 2 dx may be thought of as a 1-form on ![
$$\\mathbb{R},$$
](A272900_1_En_23_Chapter_IEq185.gif) rather than on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq186.gif), which we may then integrate to obtain

![
$$\\displaystyle{{\\left\\Vert s\\right\\Vert}^{2} :=\\int _{\\mathbb{R}}{\\left\\vert s\\right\\vert}^{2}\(x\)\\ dx.}$$
](A272900_1_En_23_Chapter_Equam.gif)

This procedure has two advantages over the one we used in Sect.​ 22.​4, where we simply integrated | s | 2 itself over ![
$$\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq187.gif). First, a version of this procedure works for real polarizations on general symplectic manifolds. Second, the half-form approach will allow quantized observables to be self-adjoint, which was not the case in Sect.​ 22.​5 when we simply restricted prequantized observables to the polarized subspace. (See the discussion following Proposition 22.12.)

Throughout this section, we assume that N is a quantizable symplectic manifold, that L is a fixed prequantum line bundle over N, and that P is a fixed purely real polarization on N.

### 23.6.1 The Space of Leaves

Recall that a leaf of P is a maximal connected, integral submanifold of P. We may then form the leaf space Ξ (the set of all leaves of P) and a quotient map q : N → Ξ sending each point z ∈ N to the unique leaf containing z. We may topologize Ξ by defining a set U in Ξ to be open if q − 1(U) is open in N.

In order to be able to carry out the program of geometric quantization with respect to P, we must assume that Ξ can be given the structure of a smooth, n-dimensional manifold in such a way that q : N → Ξ is smooth and such that the kernel of q ∗, z is equal to ![
$$P_{z}^{\\mathbb{R}},$$
](A272900_1_En_23_Chapter_IEq188.gif) the intersection of P z with the real tangent space of P z . We abbreviate this assumption on Ξ by saying that Ξ is a smooth manifold. In the case N = T ∗ M with the vertical polarization (Example 23.17), the leaf space Ξ is a smooth manifold diffeomorphic to M.

It should be emphasized that even if Ξ is a smooth manifold, there is no canonical "volume measure" on Ξ. Thus, our half-form Hilbert space will be defined in such a way that the pointwise "square" of an element will be an n-form, rather than a function, on the leaf space, which can then be integrated over the n-manifold Ξ.

### 23.6.2 The Canonical Bundle

We now introduce the canonical bundle of a purely real polarization P, with sections that are a special sort of n-form on N, along with a notion of polarized section of the canonical bundle. If the leaf space Ξ is a smooth manifold, the space of polarized sections of the canonical bundle can be identified with the space of all n-forms on the n-manifold Ξ.

Definition 23.35

The canonical bundle ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq189.gif) of P is the real line bundle with sections that are n-forms α having the property that

![
$$\\displaystyle{X\\lrcorner \\alpha = 0}$$
](A272900_1_En_23_Chapter_Equ20.gif)

(23.15)

for every vector field X lying in P. A section α of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq190.gif) is polarized if

![
$$\\displaystyle{X\\lrcorner \(d\\alpha\) = 0}$$
](A272900_1_En_23_Chapter_Equ21.gif)

(23.16)

for every vector field X lying in P.

If an n-form α satisfies (23.15), then α(X 1,..., X n ) = 0 if any of the X j 's belongs to P. Thus, the value of α at any point z can be viewed as an n-linear, alternating functional on the quotient vector space ![
$$T_{z}N/P_{z}^{\\mathbb{R}},$$
](A272900_1_En_23_Chapter_IEq191.gif) where ![
$$P_{z}^{\\mathbb{R}}$$
](A272900_1_En_23_Chapter_IEq192.gif) is the intersection of P z with the real tangent space. Since this quotient space is n-dimensional, we see that at each point, the space of possible values for α is one dimensional.

Meanwhile, if α satisfies (23.16), then at each point, d α is an (n \+ 1)-linear, alternating functional on ![
$$T_{z}N/P_{z}^{\\mathbb{R}},$$
](A272900_1_En_23_Chapter_IEq193.gif) which must be zero. Thus, for sections of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq194.gif) (23.16) is equivalent to the condition

![
$$\\displaystyle{d\\alpha = 0.}$$
](A272900_1_En_23_Chapter_Equ22.gif)

(23.17)

We can also introduce the complexified canonical bundle ![
$$\\mathcal{K}_{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq195.gif) the sections of which are complex-valued n-forms satisfying (23.15). We define a section of ![
$$\\mathcal{K}_{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq196.gif) to be polarized if it satisfies (23.16).

Example 23.36

Let ![
$$N = {T}^{{\\ast}}{\\mathbb{R}}^{n}{\\mathop{\\cong}\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq197.gif) and let P be the vertical polarization on N. Then an n-form α on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq198.gif) is a section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq199.gif) if and only if α is of the form

![
$$\\displaystyle{\\alpha = f\(\\mathbf{x},\\mathbf{p}\)\\ dx_{1} \\wedge \\cdots \\wedge dx_{n},}$$
](A272900_1_En_23_Chapter_Equ23.gif)

(23.18)

and α is a polarized section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq200.gif) if and only if α is of the form

![
$$\\displaystyle{\\alpha = g\(\\mathbf{x}\)\\ dx_{1} \\wedge \\cdots \\wedge dx_{n},}$$
](A272900_1_En_23_Chapter_Equ24.gif)

(23.19)

for smooth functions f on ![
$${\\mathbb{R}}^{2n}$$
](A272900_1_En_23_Chapter_IEq201.gif) and g on ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_23_Chapter_IEq202.gif)

Proof.

If α contained any term involving dp j , the contraction of α with ∂ ∕ ∂ p j would not be zero, leaving (23.18) as the only possible form for a section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq203.gif) Assuming α is of the form (23.18), if f is not independent of p, then d α will contain a nonzero term of the form ![
$$dp_{j} \\wedge dx_{1} \\wedge \\cdots \\wedge dx_{n},$$
](A272900_1_En_23_Chapter_IEq204.gif) leaving (23.19) as the only possible form for a polarized section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq205.gif)

In Example 23.36, the polarized sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq206.gif) are effectively just n-forms on the configuration space ![
$${\\mathbb{R}}^{n}.$$
](A272900_1_En_23_Chapter_IEq207.gif) This conclusion is a special case of the following result.

Proposition 23.37

If the leaf space Ξ of P is a smooth manifold and α is a polarized section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq208.gif) then there exists a unique n-form ![
$$\\tilde{\\alpha}$$
](A272900_1_En_23_Chapter_IEq209.gif) on Ξ such that

![
$$\\displaystyle{\\alpha = {q}^{{\\ast}}\(\\tilde{\\alpha}\),}$$
](A272900_1_En_23_Chapter_Equan.gif)

where q : N → Ξ is the quotient map. Conversely, if β is any n-form on Ξ, then α := q ∗ (β) is a polarized section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq210.gif)

Proof.

Suppose, first, that α = q ∗(β), for an n-form β on Ξ. Then X ⌟ α = 0 whenever X lies in P, since P is the kernel of q ∗. Furthermore, ![
$$d\\alpha = {q}^{{\\ast}}\(d\\beta\) = 0,$$
](A272900_1_En_23_Chapter_IEq211.gif) since β is an n-form on an n-manifold, showing that α is a polarized section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq212.gif)

In the other direction, we have already noted in the proof of Proposition 23.26 that N can be identified locally with a neighborhood U ×V of the origin ![
$${\\mathbb{R}}^{n} \\times {\\mathbb{R}}^{n}$$
](A272900_1_En_23_Chapter_IEq213.gif) in such a way that leaves of P correspond to the sets of the form ![
$$\\{\\mathbf{x}\\} \\times V.$$
](A272900_1_En_23_Chapter_IEq214.gif) We can use q to identify U ≅U ×{0} with an open set ![
$$\\tilde{U}$$
](A272900_1_En_23_Chapter_IEq215.gif) in Ξ. Thus, P looks locally just like the vertical polarization on ![
$${\\mathbb{R}}^{2n},$$
](A272900_1_En_23_Chapter_IEq216.gif) and so, by Example 23.36, any polarized section α of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq217.gif) will be of the form (23.19). Thus, α determines an n-form ![
$$\\hat{\\alpha}$$
](A272900_1_En_23_Chapter_IEq218.gif) on U and α is the pullback of ![
$$\\hat{\\alpha}$$
](A272900_1_En_23_Chapter_IEq219.gif) by the projection map of U ×V onto U. It follows that α is locally the pullback by q of an n-form ![
$$\\tilde{\\alpha}$$
](A272900_1_En_23_Chapter_IEq220.gif) on ![
$$\\tilde{U}.$$
](A272900_1_En_23_Chapter_IEq221.gif) We leave it to the reader to check that overlapping neighborhoods in N give the same form ![
$$\\tilde{\\alpha}$$
](A272900_1_En_23_Chapter_IEq222.gif) on Ξ and that the desired result holds globally.

Recall from Theorem 23.24 that Q pre(f) preserves the space of polarized sections with respect to P, provided that the flow of X f preserves ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq223.gif) (which equals P, in this case). We now establish that for any such f, the Lie derivative ![
$$\\mathcal{L}_{X_{f}}$$
](A272900_1_En_23_Chapter_IEq224.gif) preserves the space of polarized sections of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq225.gif) This result will eventually allow us to define a quantum operator Q(f) on the half-form Hilbert space associated to P.

Proposition 23.38

Suppose X is a vector field on N that preserves P, in the sense of Definition 23.22, and suppose α is a smooth section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq226.gif) Then the Lie derivative ![
$$\\mathcal{L}_{X}\\alpha$$
](A272900_1_En_23_Chapter_IEq227.gif) is another section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq228.gif) and if α is polarized, ![
$$\\mathcal{L}_{X}\\alpha$$
](A272900_1_En_23_Chapter_IEq229.gif) is also polarized.

Proof.

Suppose X 1,..., X n are smooth vector fields, with X 1 lying in ![
$$\\bar{P} = P.$$
](A272900_1_En_23_Chapter_IEq230.gif) Then, by a standard formula for the Lie derivative,

![
$$\\displaystyle\\begin{array}{rcl} & & \(\\mathcal{L}_{X}\\alpha\)\(X_{1},\\ldots,X_{n}\) \\\\ & & = X\(\\alpha \(X_{1},\\ldots,X_{n}\)\) -\\alpha \(\[X,X_{1}\],X_{2},\\ldots,X_{n}\) \\\\ & & -\\sum _{j=2}^{n}\\alpha \(X_{1},\\ldots,X_{j-1},\[X,X_{j}\],X_{j+1},\\ldots,X_{n}\).{}\\end{array}$$
](A272900_1_En_23_Chapter_Equ25.gif)

(23.20)

Now, because α is a section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq231.gif) the first and third terms on the right-hand side of (23.20) vanish. Because X preserves P, [X, X 1] will again lie in P, and so the second term vanishes as well. Thus, ![
$$X_{1}\\lrcorner \(\\mathcal{L}_{X}\\alpha\) = 0,$$
](A272900_1_En_23_Chapter_IEq232.gif) which means that ![
$$\\mathcal{L}_{X}\\alpha$$
](A272900_1_En_23_Chapter_IEq233.gif) is again a section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq234.gif)

Since ![
$$\\mathcal{L}_{X}\\alpha = X\\lrcorner d\\alpha + d\(X\\lrcorner \\alpha\),$$
](A272900_1_En_23_Chapter_IEq235.gif) if α satisfies (23.17), we have

![
$$\\displaystyle{d\(\\mathcal{L}_{X}\\alpha\) = {d}^{2}\(X\\lrcorner \\alpha\) = 0,}$$
](A272900_1_En_23_Chapter_Equao.gif)

showing that α is again polarized.

Proposition 23.39

Suppose the leaf space Ξ of P is a smooth manifold and that a vector field X on N preserves P. Then there exists a unique vector field Y on Ξ such that

![
$$\\displaystyle{q_{{\\ast},z}\(X\) = Y}$$
](A272900_1_En_23_Chapter_Equ26.gif)

(23.21)

for all z ∈ N. Furthermore, if α = q ∗ (β) is a polarized section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq236.gif) as in Proposition 23.37, then

![
$$\\displaystyle{\\mathcal{L}_{X}\({q}^{{\\ast}}\(\\beta\)\) = {q}^{{\\ast}}\(\\mathcal{L}_{Y}\(\\beta\)\).}$$
](A272900_1_En_23_Chapter_Equ27.gif)

(23.22)

That is to say, under the identification in Proposition 23.37 of polarized sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq237.gif) with n-forms on Ξ, the operator ![
$$\\mathcal{L}_{X}$$
](A272900_1_En_23_Chapter_IEq238.gif) corresponds to the Lie derivative on Ξ in the direction of Y.

Proof.

By Definition 23.22, [X, Z] lies in P whenever the vector field Z lies in P. Thus, if a function ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq513.gif) is constant along P (i.e., annihilated by every vector field Z lying in P), the same will be true of ![
$$X\\ \\phi$$
](A272900_1_En_23_Chapter_IEq545.gif). Thus, if ![
$$X\\ \\phi$$
](A272900_1_En_23_Chapter_IEq531.gif) is of the form ![
$${\\phi} $$
](A272900_1_En_23_Chapter_IEq631.gif) = ![
$$ {\\psi} $$
](A272900_1_En_23_Chapter_IEq600.gif) ∘ q for some function ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq514.gif) on Ξ, then X ![
$$ {\\phi} $$
](A272900_1_En_23_Chapter_IEq539.gif) is of the form ![
$$\\hat{\\psi}\\circ q$$
](A272900_1_En_23_Chapter_IEq239.gif) for some other function ![
$$\\hat{\\psi}$$
](A272900_1_En_23_Chapter_IEq240.gif) on Ξ. The map ![
$$\\psi \\mapsto \\hat{\\psi}$$
](A272900_1_En_23_Chapter_IEq241.gif) is easily seen to be a vector field, that is, a derivation of C ∞ (Ξ). We conclude, then, that there is a unique vector field Y on Ξ such that

![
$$\\displaystyle{X\(\\psi \\circ q\) = \(Y \\psi\) \\circ q}$$
](A272900_1_En_23_Chapter_Equ28.gif)

(23.23)

for every smooth function ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq515.gif) on Ξ. It then follows from the definition of the differential that (23.21) holds for all z ∈ N. From (23.21), it follows easily that for any n-form β on Ξ, we have

![
$$\\displaystyle{X\\lrcorner \({q}^{{\\ast}}\(\\beta\)\) = {q}^{{\\ast}}\(Y \\lrcorner \\beta\).}$$
](A272900_1_En_23_Chapter_Equ29.gif)

(23.24)

Since β, being a top-degree form, is closed, q ∗(β) is also closed. Thus, one of the terms in the formula (21.​7) for the Lie derivative of β and q ∗(β) is zero. Applying d to both sides of (23.24) then gives (23.22).

Given a vector field Y and a nowhere-vanishing n-form β on Ξ, let div β Y be the unique function on Ξ such that

![
$$\\displaystyle{\\mathcal{L}_{Y}\(\\beta\) = \(\\mathrm{div}_{\\beta}Y\)\\beta.}$$
](A272900_1_En_23_Chapter_Equap.gif)

Then by (23.22), we have

![
$$\\displaystyle{\\mathcal{L}_{X}\({q}^{{\\ast}}\(\\beta\)\) = \(\(\\mathrm{div}_{\\beta}Y\) \\circ q\){q}^{{\\ast}}\(\\beta\).}$$
](A272900_1_En_23_Chapter_Equ30.gif)

(23.25)

The expression (23.25) will be helpful in analyzing the quantization of observables in Sect. 23.6.5.

### 23.6.3 Square Roots of the Canonical Bundle

We now assume that the leaf space Ξ of P is an orientable manifold, and we choose on particular orientation of Ξ.

Definition 23.40

Choose a nowhere-vanishing, oriented n -form β on Ξ, so that α : = q ∗(β) is (Proposition 23.37) a nowhere-vanishing section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq242.gif) A section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq243.gif) is non-negative if it is, at each point, a non-negative multiple of α. This notion does not depend on the choice of oriented n -form β.

Since Ξ is orientable, the canonical bundle ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq244.gif) is trivializable, since the section α in Definition 23.40 is a globally trivializing section. Thus, we can find a square root of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq245.gif) that is, a line bundle δ P such that δ P ⊗ δ P is isomorphic to ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq246.gif) (We may, for example, take δ P to be the trivial bundle.) When we speak of a square root of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq247.gif) we will mean, more precisely, a bundle δ P together with a particular isomorphism of δ P ⊗ δ P with ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq248.gif). Thus, if s 1 and s 2 are sections of δ P , we think of s 1 ⊗ s 2 as being a section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq249.gif) We assume, further, that the isomorphism of δ P ⊗ δ P with ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq250.gif) is chosen so that for any section s of δ P , the section s ⊗ s of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq251.gif) is non-negative. (If the initial isomorphism of δ P ⊗ δ P with ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq252.gif) does not have this property, compose it with − I in the fibers of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq253.gif))

We may consider the complexification of δ P , that is, the line bundle ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq254.gif) whose fiber at each point is the complexification of the fiber of δ P . There is then a notion of complex conjugation for sections of ![
$$\\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq255.gif) which fixes the fiber of δ P inside the fiber of ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq256.gif) at each point. If s 1 and s 2 are sections of ![
$$\\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq257.gif) we think of s 1 ⊗ s 2 as a section of the complexified canonical bundle ![
$$\\mathcal{K}_{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq258.gif).

If α is a section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq259.gif) and X is a vector field lying in P, let us define an n-form ∇ X α by

![
$$\\displaystyle{\\nabla _{X}\\alpha = X\\lrcorner \(d\\alpha\).}$$
](A272900_1_En_23_Chapter_Equ31.gif)

(23.26)

Since α is a section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq260.gif) we have ![
$$X\\lrcorner \\alpha \\ = 0$$
](A272900_1_En_23_Chapter_IEq512.gif), which means that ∇ X α actually coincides with ![
$$\\mathcal{L}_{X}\\alpha,$$
](A272900_1_En_23_Chapter_IEq261.gif) by (21.​7). Since it lies in P, the vector field X preserves P, and thus ![
$$\\nabla _{X}\\alpha = \\mathcal{L}_{X}\\alpha$$
](A272900_1_En_23_Chapter_IEq262.gif) is again a section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq263.gif) by Proposition 23.38. The operator ∇ in (23.26) has all the properties of a connection on ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq264.gif) except that it is only defined in the directions of P. [Note that ![
$$\\mathcal{L}_{X}$$
](A272900_1_En_23_Chapter_IEq265.gif) does not, in general, satisfy the condition ![
$$\\mathcal{L}_{fX} = f\\mathcal{L}_{X},$$
](A272900_1_En_23_Chapter_IEq266.gif) as required by Definition 23.2. Since, however, ![
$$\\mathcal{L}_{X}\\alpha$$
](A272900_1_En_23_Chapter_IEq267.gif) can also be computed as in (23.26), for any section α of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq268.gif) the map ∇ does satisfy ∇ fX = f ∇ X . ]

We call ∇ the natural partial connection on ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq269.gif) According to Definition 23.35, a section α of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq270.gif) is polarized if and only if ∇ X α = 0 for each vector field X lying in P. We now show that both the partial connection and the Lie derivative "descend" to sections of δ P in a natural way. This result will, in particular, allow us to define a notion of polarized sections of δ P .

Proposition 23.41

Let δ P be a fixed square root of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq271.gif) For any vector field X lying in P, there is a unique linear operator ∇X mapping sections of δ P to sections of δ P , such that

![
$$\\displaystyle\\begin{array}{rcl} \\nabla _{X}\(fs_{1}\)& =& X\(f\)s_{1} + f\\nabla _{X}s_{1}{}\\end{array}$$
](A272900_1_En_23_Chapter_Equ32.gif)

(23.27)

![
$$\\displaystyle\\begin{array}{rcl} \\nabla _{X}\(s_{1} \\otimes s_{2}\)& =& \(\\nabla _{X}s_{1}\) \\otimes s_{2} + s_{1} \\otimes \(\\nabla _{X}s_{2}\){}\\end{array}$$
](A272900_1_En_23_Chapter_Equ33.gif)

(23.28)

for all smooth functions f and all sections s 1 and s 2 of δ P . On the left-hand side of (23.28),∇ X is the partial connection on ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq272.gif) given by (23.26).

If X is a vector field on N that preserves P, then there is a unique linear operator ![
$$\\mathcal{L}_{X},$$
](A272900_1_En_23_Chapter_IEq273.gif) mapping sections of δ P to sections of δ P such that

![
$$\\displaystyle\\begin{array}{rcl} \\mathcal{L}_{X}\(fs_{1}\)& =& X\(f\)s_{1} + f\\mathcal{L}_{X}s_{1} {}\\\\ \\mathcal{L}_{X}\(s_{1} \\otimes s_{2}\)& =& \(\\mathcal{L}_{X}s_{1}\) \\otimes s_{2} + s_{1} \\otimes \(\\mathcal{L}_{X}s_{2}\) {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ34.gif)

for all smooth functions f and all sections s 1 and s 2 of δ P.

Both of these constructions extend naturally from sections of δ P to sections of ![
$$\\delta _{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq274.gif)

We may then say that a section s of ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq275.gif) is polarized if ∇ X s = 0 for every smooth vector field X lying in P.

Proof.

If V is a one-dimensional vector space, then the map ⊗ : V ×V → V ⊗ V is commutative: u ⊗ v = v ⊗ u for all u, v ∈ V. Furthermore, if u 0 is a nonzero element of V, then the map u↦u ⊗ u 0 is an invertible linear map of V to V ⊗ V. Suppose s 0 is a local nonvanishing section of δ P . Applying (23.28) with ![
$$s_{1} = s_{2} = s_{0},$$
](A272900_1_En_23_Chapter_IEq276.gif) we want

![
$$\\displaystyle{2\(\\nabla _{X}s_{0}\) \\otimes s_{0} = \\nabla _{X}\(s_{0} \\otimes s_{0}\).}$$
](A272900_1_En_23_Chapter_Equ35.gif)

(23.29)

Since the operation of tensoring with s 0 is invertible, there is a unique section " ∇ X s 0" of δ P for which (23.29) holds.

Locally, any section s of δ P can be written as s = gs 0 for a unique function g. We then define ∇ X s by

![
$$\\displaystyle{\\nabla _{X}s = X\(g\)s_{0} + g\\nabla _{X}s_{0},}$$
](A272900_1_En_23_Chapter_Equ36.gif)

(23.30)

in which case, (23.27) is easily seen to hold. If ![
$$s_{1} = g_{1}s_{0}$$
](A272900_1_En_23_Chapter_IEq277.gif) and ![
$$s_{2} = g_{2}s_{0},$$
](A272900_1_En_23_Chapter_IEq278.gif) then using (23.29) and the symmetry of the tensor product, it is easy to verify that (23.28) holds, with both sides of the equation equal to

![
$$\\displaystyle{X\(g_{1}g_{2}\)\\nabla _{X}\(s_{0} \\otimes s_{0}\).}$$
](A272900_1_En_23_Chapter_Equaq.gif)

Uniqueness of ∇ X holds because both (23.29) and (23.30) are required by the definition of ∇ X . The action of ∇ X extends to sections of ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq279.gif), by writing such sections as complex-valued functions times s 0. The analysis of the Lie derivative is similar and is omitted.

### 23.6.4 The Half-Form Hilbert Space

We continue to assume that the leaf space Ξ of P is an orientable manifold, and that we have chosen an orientation on Ξ. We assume that we have chosen a square root δ P of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq280.gif) as in Sect. 23.6.3. If L is a prequantum line bundle over N, we now form the tensor product bundle ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq281.gif) Given two sections s 1 and s 2 of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq282.gif) we decompose them locally as ![
$$s_{j} =\\mu _{j} \\otimes \\nu _{j},$$
](A272900_1_En_23_Chapter_IEq283.gif) where μ j is a section of L and ν j is a section of ![
$$\\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq284.gif) and where, say, the μ j 's are taken to be nonvanishing. Then we can combine these sections to form the quantity

![
$$\\displaystyle{\(s_{1},s_{2}\) := \(\\mu _{1},\\mu _{2}\)\\overline{\\nu _{1}} \\otimes \\nu _{2},}$$
](A272900_1_En_23_Chapter_Equ37.gif)

(23.31)

where (μ 1, μ 2) is the pointwise inner product given by the Hermitian structure on L. Since (μ 1, μ 2) is a scalar-valued function and ![
$$\\overline{\\nu _{1}} \\otimes \\nu _{2}$$
](A272900_1_En_23_Chapter_IEq285.gif) is a section of ![
$$\\mathcal{K}_{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq286.gif), the quantity (s 1, s 2) is a section of ![
$$\\mathcal{K}_{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq287.gif) Any other decomposition of s j as the tensor product of a nonvanishing section of a L and a section of δ P is of the form (f μ j ) ⊗ (ν j ∕ f) for some nonvanishing function f, and the value of (s 1, s 2) is the same as for the original decomposition. Since it is independent of the choice of local decomposition, (s 1, s 2) is actually defined globally.

Given the connection on L and the partial connection (23.41) on ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq288.gif), we can form a partial connection on ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq289.gif) with the following property. For any vector field X lying in P, and any section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq290.gif) if we decompose s locally as s = μ ⊗ ν, where μ is a nonvanishing section of L and ν is a section of δ P , then

![
$$\\displaystyle{\\nabla _{X}\(s\) = \(\\nabla _{X}\\mu\) \\otimes \\nu +\\mu \\otimes \(\\nabla _{X}\\nu\).}$$
](A272900_1_En_23_Chapter_Equ38.gif)

(23.32)

The reader may verify that if μ ⊗ ν is replaced by (f μ) ⊗ (ν ∕ f) for some nonvanishing function f, the value of ∇ X (s) is unchanged. Thus, as with the quantity (s 1, s 2) in (23.31), ∇ X (s) is defined globally. We then define a section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq291.gif) to be polarized if ∇ X s = 0 for each vector field X lying in P. If s 1 and s 2 are polarized sections of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq292.gif) then the section (s 1, s 2) in (23.31) is easily seen to be a polarized section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq293.gif)

As in the case without half-forms there is an obstruction to the existence of globally defined polarized sections of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq294.gif) We say that a leaf R is Bohr–Sommerfeld (in the half-form sense, with respect to a particular choice of δ P ) if there exists a nonzero section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq295.gif) defined over R such that ∇ X s = 0 for each tangent vector to R. As in the case without half-forms, if the leaves are topologically nontrivial, the Bohr–Sommerfeld leaves will in general be a discrete set in the space of all leaves.

The Bohr–Sommerfeld leaves in the half-form sense need not be the same as the Bohr–Sommerfeld leaves in the sense of Definition 23.27. In the setting of Example 23.29, for instance, the canonical bundle ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq296.gif) is trivial, but the square-root bundle δ P may be chosen to be nontrivial, by putting in a twist by 180 degrees over each copy of S 1. (That is to say, we think of S 1 as the interval [0, 2π] with the ends identified, and we attach a copy of ![
$$\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq297.gif) to each point. But when identifying the fiber at 2π with the fiber at 0, we use the negative of the identity map.) As Exercise 9 shows, in this example, the Bohr–Sommerfeld leaves are the sets of the form ![
$$\\{x\\} \\times {S}^{1},$$
](A272900_1_En_23_Chapter_IEq298.gif) where ![
$$x/\\hslash = n + 1/2$$
](A272900_1_En_23_Chapter_IEq299.gif) for some integer n.

Definition 23.42

For any purely real polarization P and any square root δ P of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq300.gif) the half-form space is the space of smooth, polarized sections of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq301.gif) For a polarized section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq302.gif) define the norm of s by

![
$$\\displaystyle{{\\left\\Vert s\\right\\Vert}^{2} =\\int _{\\Xi}\\widetilde{\(s,s\)},}$$
](A272900_1_En_23_Chapter_Equ39.gif)

(23.33)

where (s, s) is as in (23.31) and where ![
$$\\widetilde{\(s,s\)}$$
](A272900_1_En_23_Chapter_IEq303.gif) is the n-form on Ξ given by Proposition 23.37. If s 1 and s 2 are elements of the half-form space with ![
$$\\left\\Vert s_{1}\\right\\Vert < \\infty $$
](A272900_1_En_23_Chapter_IEq304.gif) and ![
$$\\left\\Vert s_{2}\\right\\Vert < \\infty,$$
](A272900_1_En_23_Chapter_IEq305.gif) define the inner product of s 1 and s 2 by

![
$$\\displaystyle{\\left\\langle s_{1},s_{2}\\right\\rangle =\\int _{\\Xi}\\widetilde{\(s_{1},s_{2}\)}.}$$
](A272900_1_En_23_Chapter_Equar.gif)

The half-form Hilbert space is the completion with respect to the norm (23.33) of the space of polarized sections s for which ∥ s ∥ 2 < ∞.

The integral of n-forms on Ξ is taken with respect to the chosen orientation on Ξ. We can always decompose s locally as s = μ ⊗ ν with ν being a section of δ P (as opposed to ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq306.gif)) and μ being a section of L. Then

![
$$\\displaystyle{\(s,s\) = \(\\mu,\\mu\)\\nu \\otimes \\nu,}$$
](A272900_1_En_23_Chapter_Equas.gif)

from which we see that (s, s) is a non-negative section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq307.gif) (Definition 23.40). (Recall that we have chosen the identification of δ P ⊗ δ P with ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq308.gif) in a particular way, so that ν ⊗ ν is always the pullback by q of an oriented form on Ξ.) Thus, the integral on the right-hand side of (23.33) is non-negative, but possibly infinite.

Example 23.43

Let ![
$$N = {T}^{{\\ast}}\\mathbb{R}\\mathop{\\cong}{\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq309.gif) and let L be the trivial bundle on N, with connection ![
$$\\nabla _{X} = X - \(i/\\hslash\)\\theta \(X\),$$
](A272900_1_En_23_Chapter_IEq310.gif) where θ = p dx. Let P be the vertical polarization on N and orient ![
$$\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq311.gif) so that oriented 1-forms are positive multiples of dx. Let δ P to be the trivial bundle and with a trivializing section"![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq312.gif)" of δ P such that ![
$$\\sqrt{dx} \\otimes \\sqrt{dx} = dx.$$
](A272900_1_En_23_Chapter_IEq313.gif) Then every polarized section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq314.gif) has the form

![
$$\\displaystyle{s =\\psi \(x\) \\otimes \\sqrt{dx}}$$
](A272900_1_En_23_Chapter_Equ40.gif)

(23.34)

for some function ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq516.gif) on ![
$$\\mathbb{R}.$$
](A272900_1_En_23_Chapter_IEq315.gif) The norm of such a section is computed as

![
$$\\displaystyle{{\\left\\Vert s\\right\\Vert}^{2} =\\int _{\\mathbb{R}}{\\left\\vert \\psi \(x\)\\right\\vert}^{2}\\ dx.}$$
](A272900_1_En_23_Chapter_Equat.gif)

Proof.

The sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq316.gif) are 1-forms that are zero on ∂ ∕ ∂ p, that is, 1-forms of the form α = f(x, p) dx. Such a 1-form satisfies d α = 0 if and only if f is independent of p. Thus, dx is a globally defined polarized section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq317.gif) If we choose δ P to be trivial and let ![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq318.gif) be such that ![
$$\\sqrt{dx} \\otimes \\sqrt{dx} = dx,$$
](A272900_1_En_23_Chapter_IEq319.gif) then ![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq320.gif) will be a polarized section of δ P . Every section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq321.gif) can be written uniquely as ![
$$s =\\psi \(x,p\) \\otimes \\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq322.gif) for some function ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq517.gif). Since ![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq323.gif) is polarized and ![
$$\\theta \(\\partial /\\partial p\) = 0,$$
](A272900_1_En_23_Chapter_IEq324.gif) we see that s is polarized if and only if ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq518.gif) is independent of p. For a section of the form (23.34), we have ![
$$\(s,s\) =\\vert \\psi {\(x\)\\vert}^{2}\\ dx,$$
](A272900_1_En_23_Chapter_IEq325.gif) in which case, ![
$$\\widetilde{\(s,s\)}$$
](A272900_1_En_23_Chapter_IEq326.gif) is given by the same formula as (s, s), but now interpreted as a 1-form on ![
$$\\Xi \\mathop{\\cong}\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq327.gif) rather than ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_23_Chapter_IEq328.gif)

### 23.6.5 Quantization of Observables

Suppose f is a function on N for which X f preserves P in the sense of Definition 23.22. We will now associate with f a self-adjoint (or, at least, symmetric) operator Q(f) on the half-form Hilbert space of P. Operators of this sort will satisfy exactly the desired commutation relations.

Definition 23.44

For any function f on N for which X f preserves P, let Q(f) be the operator on the half-form space of P given by

![
$$\\displaystyle{Q\(f\)s = \(Q_{\\mathrm{pre}}\(f\)\\mu\) \\otimes \\nu +i\\hslash \\ \\mu \\otimes \\mathcal{L}_{X_{f}}\\nu,}$$
](A272900_1_En_23_Chapter_Equau.gif)

where s is decomposed locally as s = μ ⊗ ν, with μ being a section of L and ν a section of ![
$$\\delta _{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq329.gif)

The operator Q(f) is well defined (i.e., independent of the choice of local trivialization) as may easily be verified. This independence holds, however, only because the coefficient ![
$$i\\hslash $$
](A272900_1_En_23_Chapter_IEq330.gif) of ![
$$\\nabla _{X_{f}}$$
](A272900_1_En_23_Chapter_IEq331.gif) in the first term exactly matches the coefficient ![
$$i\\hslash $$
](A272900_1_En_23_Chapter_IEq332.gif) of ![
$$\\mathcal{L}_{X_{f}}$$
](A272900_1_En_23_Chapter_IEq333.gif) in the second term.

Before describing the general properties of the operators Q(f), we consider a simple example that illustrates the essential role of the Lie derivative term in Definition 23.44.

Example 23.45

Let the notation be as in Example23.43, and let ![
$$f : {\\mathbb{R}}^{2} \\rightarrow \\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq334.gif) be of the form

![
$$\\displaystyle{f\(x,p\) = a\(x\) + b\(x\)p,}$$
](A272900_1_En_23_Chapter_Equav.gif)

for some smooth functions a and b on ![
$$\\mathbb{R}.$$
](A272900_1_En_23_Chapter_IEq335.gif) Then X f preserves P and

![
$$\\displaystyle{Q\(f\)\(\\psi \(x\) \\otimes \\sqrt{dx}\) =\\tilde{\\psi} \(x\) \\otimes \\sqrt{dx},}$$
](A272900_1_En_23_Chapter_Equaw.gif)

where

![
$$\\displaystyle{\\tilde{\\psi}\(x\) = -i\\hslash \\left\(b{\(x\)\\psi}^{{\\prime}}\(x\) + \\frac{1} {2}{b}^{{\\prime}}\(x\)\\psi \(x\)\\right\) + a\(x\)\\psi \(x\).}$$
](A272900_1_En_23_Chapter_Equax.gif)

In particular, if f(x, p) = x, then ![
$$\\tilde{\\psi}\(x\) = x\\psi \(x\)$$
](A272900_1_En_23_Chapter_IEq336.gif) and if f(x, p) = p, then ![
$$\\tilde{\\psi}\(x\) = -i\\hslash \\ \\partial \\psi /\\partial x.$$
](A272900_1_En_23_Chapter_IEq337.gif) More generally, if a and b are polynomials, then the action of Q(f) on ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq519.gif) coincides with the Weyl quantization of f (Exercise 8 in Chap.​ 13).

The term involving b ′ (x) comes from the presence of half-forms and is absent in the formula (22.​15) for Q pre(f). The b ′ term, with the exact coefficient of 1 ∕ 2, is necessary for Q(f) to be self-adjoint (or, at least, symmetric); see Exercise 10. Example 23.45 is actually quite representative of the general case. [Compare (23.38) in the proof of Theorem 23.47 and Example 23.48.]

Proof.

We have computed Q pre(f) in (22.​15) in the proof of Proposition 22.12. We compute that X f is equal to ![
$$-b\(x\)\\ \\partial /\\partial x$$
](A272900_1_En_23_Chapter_IEq338.gif) plus a term involving ∂ ∕ ∂ p. Since the 1-form dx is closed, we obtain, by (21.​7),

![
$$\\displaystyle{\\mathcal{L}_{X_{f}}\(dx\) = d\(X_{f}\\lrcorner dx\) = -db\(x\) = -{b}^{{\\prime}}\(x\)\\ dx.}$$
](A272900_1_En_23_Chapter_Equay.gif)

Using Proposition 23.41, we then obtain

![
$$\\displaystyle{\\mathcal{L}_{X_{f}}\\left\(\\sqrt{dx}\\right\) \\otimes \\sqrt{dx} = -\\frac{1} {2}{b}^{{\\prime}}\(x\)\\ dx = -\\frac{1} {2}{b}^{{\\prime}}\(x\)\\sqrt{dx} \\otimes \\sqrt{dx},}$$
](A272900_1_En_23_Chapter_Equ41.gif)

(23.35)

which gives

![
$$\\displaystyle{\\mathcal{L}_{X_{f}}\\left\(\\sqrt{dx}\\right\) = -\\frac{1} {2}{b}^{{\\prime}}\(x\)\\sqrt{dx}.}$$
](A272900_1_En_23_Chapter_Equaz.gif)

Adding the ![
$$\\mathcal{L}_{X_{f}}$$
](A272900_1_En_23_Chapter_IEq339.gif) term to the previously computed expression for Q pre(f) gives the desired result.

Returning now to the setting of general real polarizations, we establish two key results for the quantized observables Q(f), that they satisfy the desired commutation relations and that they are self-adjoint (or, at least, symmetric) whenever f is real valued. It can also be shown that when f is a polarized function (i.e., constant along each leaf of P), then Q(f) acts on the quantum Hilbert space simply as multiplication by f. See Exercise 11.

Theorem 23.46

Suppose f and g are functions on N for which X f and X g preserve P. Then the operators Q(f) and Q(g) satisfy

![
$$\\displaystyle{\\frac{1} {i\\hslash}\\left\[Q\(f\),Q\(g\)\\right\] = Q\(\\{f,g\\}\)}$$
](A272900_1_En_23_Chapter_Equba.gif)

on the space of smooth, polarized sections of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}.$$
](A272900_1_En_23_Chapter_IEq340.gif)

Proof.

Since Q(h) is a local operator for any function h, it suffices to prove the result locally. Let us choose, then, a local nonvanishing section ν 0 of ![
$$\\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq341.gif), so that, locally, each section s of ![
$$L \\otimes \\delta _{P}^{\\mathbb{C}}$$
](A272900_1_En_23_Chapter_IEq342.gif) can be decomposed uniquely as s = μ ⊗ ν 0. For any vector field preserving P, we let γ(X) be the function such that

![
$$\\displaystyle{\\mathcal{L}_{X}\(\\nu _{0}\) =\\gamma \(X\)\\nu _{0}.}$$
](A272900_1_En_23_Chapter_Equbb.gif)

We then have ![
$$Q\(f\)\(\\mu \\otimes \\nu _{0}\) =\\tilde{\\mu} \\otimes \\nu _{0},$$
](A272900_1_En_23_Chapter_IEq343.gif) where

![
$$\\displaystyle{\\tilde{\\mu}= \[Q_{\\mathrm{pre}}\(f\) + i\\hslash \\gamma \(X_{f}\)\]\\mu.}$$
](A272900_1_En_23_Chapter_Equbc.gif)

We now compute that

![
$$\\displaystyle\\begin{array}{rcl} & & \[Q_{\\mathrm{pre}}\(f\) + i\\hslash \\gamma \(X_{f}\),Q_{\\mathrm{pre}}\(g\) + i\\hslash \\gamma \(X_{g}\)\] {}\\\\ & & = \[Q_{\\mathrm{pre}}\(f\),Q_{\\mathrm{pre}}\(g\)\] + i\\hslash \[Q_{\\mathrm{pre}}\(f\),\\gamma \(X_{g}\)\] + i\\hslash \[\\gamma \(X_{g}\),Q_{\\mathrm{pre}}\(f\)\] {}\\\\ & & = i\\hslash Q_{\\mathrm{pre}}\(\\{f,g\\}\) + {\(i\\hslash\)}^{2}\\left\(X_{f}\(\\gamma \(X_{g}\)\) - X_{g}\(\\gamma \(X_{f}\)\)\\right\). {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ42.gif)

The desired result will follow if we can verify that

![
$$\\displaystyle{X_{f}\(\\gamma \(X_{g}\)\) - X_{g}\(\\gamma \(X_{f}\)\) =\\gamma \(X_{\\{f,g\\}}\).}$$
](A272900_1_En_23_Chapter_Equ43.gif)

(23.36)

To verify (23.36), we use a standard identity for the Lie derivative on forms: ![
$$\\mathcal{L}_{\[X,Y \]} = \[\\mathcal{L}_{X},\\mathcal{L}_{Y}\].$$
](A272900_1_En_23_Chapter_IEq344.gif) Using Proposition 23.41, we can easily show that this identity holds also on sections of ![
$$\\delta _{P}^{\\mathbb{C}},$$
](A272900_1_En_23_Chapter_IEq345.gif) for vector fields that preserve P. It is then a simple calculation (Exercise 12) to verify (23.36).

Theorem 23.47

If f ∈ C ∞ (N) is real valued and X f preserves P, then the operator Q(f) is symmetric on the space of smooth sections s in the half-form space for which ![
$$\\widetilde{\(s,s\)}$$
](A272900_1_En_23_Chapter_IEq346.gif) has compact support on Ξ.

Proof.

Suppose α = q ∗(β) is polarized section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq347.gif) so that there is, at least locally, a corresponding polarized section ![
$$\\sqrt{{q}^{{\\ast}}\(\\beta\)}$$
](A272900_1_En_23_Chapter_IEq348.gif) of δ P . If X f preserves P, then by Proposition 23.39, there is a unique vector field Y f on Ξ such that ![
$$q_{{\\ast},z}\(X_{f}\) = Y _{f}$$
](A272900_1_En_23_Chapter_IEq349.gif) for all z ∈ N. Using (23.25) and Proposition 23.41, we get

![
$$\\displaystyle{\\mathcal{L}_{X_{f}}\\left\(\\sqrt{{q}^{{\\ast}} \(\\beta\)}\\right\) = \\frac{1} {2}\(\(\\mathrm{div}_{\\beta}Y _{f}\) \\circ q\)\\sqrt{{q}^{{\\ast}} \(\\beta\)}.}$$
](A272900_1_En_23_Chapter_Equbd.gif)

Meanwhile, it is not hard to show (Exercise 13) that it is possible to choose a local symplectic potential θ that is zero in the directions of P. Thus, we can trivialize L locally in such a way that sections that are covariantly constant along P are simply functions that are constant along P in the ordinary sense. Thus, elements s of the half-form space have, locally, the form

![
$$\\displaystyle{s = \(\\psi \\circ q\) \\otimes \\sqrt{{q}^{{\\ast}} \(\\beta\)}}$$
](A272900_1_En_23_Chapter_Equ44.gif)

(23.37)

for some function ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq520.gif) and n-form β on Ξ. Thus, if X f preserves P, and a section s is decomposed locally as in (23.37), we have

![
$$\\displaystyle{Q\(f\)\(s\) = \(\\tilde{\\psi}\\circ q\) \\otimes \\sqrt{{q}^{{\\ast}} \(\\beta\)},}$$
](A272900_1_En_23_Chapter_Eqube.gif)

where

![
$$\\displaystyle{\\tilde{\\psi}= i\\hslash \\left\(Y _{f}\\psi + \\frac{1} {2}\(\\mathrm{div}_{\\beta}Y _{f}\)\\psi \\right\) + \(-\\theta \(X_{f}\) - f\)\\psi.}$$
](A272900_1_En_23_Chapter_Equ45.gif)

(23.38)

It can be verified (Exercise 14) that the function ![
$$-\\theta \(X_{f}\) - f$$
](A272900_1_En_23_Chapter_IEq350.gif) is constant along P and thus may be thought of as a function on Ξ.

By multiplying elements of the half-form space by functions of the form χ ∘ q, with χ having compact support in Ξ, we can "localize" the calculations on Ξ. Suppose s 1 and s 2 are two elements of the half-form space decomposed as in (23.37) near a point z ∈ N, with the same β and two different functions ![
$$ {\\psi} $$
](A272900_1_En_23_Chapter_IEq601.gif) 1 and ![
$$ {\\psi} $$
](A272900_1_En_23_Chapter_IEq603.gif) 2 on Ξ. Then ![
$$\\widetilde{\(s_{1},s_{2}\)}$$
](A272900_1_En_23_Chapter_IEq351.gif) has the form ![
$$\\overline{\\psi _{1}}\\psi _{2}\\beta$$
](A272900_1_En_23_Chapter_IEq352.gif) in a neighborhood U of q(z). By localization, we may assume that ![
$$\\widetilde{\(s_{1},s_{2}\)}$$
](A272900_1_En_23_Chapter_IEq353.gif) has compact support in U, and we then have

![
$$\\displaystyle{\\left\\langle s_{1},Q\(f\)s_{2}\\right\\rangle = -i\\hslash \\int _{\\Xi}\\overline{\\psi _{1}}\\tilde{\\psi}_{2}\\ \\beta,}$$
](A272900_1_En_23_Chapter_Equbf.gif)

where ![
$$\\tilde{\\psi}_{2}$$
](A272900_1_En_23_Chapter_IEq354.gif) is as in (23.38). "Integration by parts" (Exercise 15) with respect to β then shows that this quantity coincides with ![
$$\\left\\langle Q\(f\)s_{1},s_{2}\\right\\rangle.$$
](A272900_1_En_23_Chapter_IEq355.gif)

Example 23.48 (Cotangent Bundles)

Let N = T ∗ M for an oriented manifold M, let θ be the canonical 1-form on N, and let L be the trivial line bundle on N, with connection ![
$$\\nabla _{X} = X - \(i/\\hslash\)\\theta \(X\).$$
](A272900_1_En_23_Chapter_IEq356.gif) Let P be the vertical polarization on N, so that ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq357.gif) is trivial, and let δ P be chosen to be trivial. Let β be an arbitrary nowhere-vanishing, oriented n-form on M, so that α : = π ∗(β) is a nowhere-vanishing section of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq358.gif) and choose a trivializing section ![
$$\\sqrt{\\alpha}$$
](A272900_1_En_23_Chapter_IEq359.gif) of δ P with ![
$$\\sqrt{\\alpha}\\otimes \\sqrt{\\alpha} =\\alpha.$$
](A272900_1_En_23_Chapter_IEq360.gif) In that case, elements s of the half-form Hilbert space have the form ![
$$s = \(\\psi \\circ \\pi\) \\otimes \\sqrt{\\alpha},$$
](A272900_1_En_23_Chapter_IEq361.gif) where ![
$$\\phi$$
](A272900_1_En_23_Chapter_IEq521.gif) is a function on M, and

![
$$\\displaystyle{{\\left\\Vert s\\right\\Vert}^{2} =\\int _{M}{\\left\\vert \\psi \\right\\vert}^{2}\\beta.}$$
](A272900_1_En_23_Chapter_Equbg.gif)

The half-form Hilbert space may, thus, be identified with L 2(M, β).

Suppose now that f is a function on T ∗ M of the form ![
$$f = f_{1} + f_{2},$$
](A272900_1_En_23_Chapter_IEq362.gif) where f 1 is constant on each fiber of T ∗ M and f 2 is linear on each fiber. Then f 2 may be thought of as a section of T ∗ ∗ M ≅TM, that is, as a vector field Y f on M. In that case, X f preserves P and Q(f) acts on elements of the half-forms space as

![
$$\\displaystyle{Q\(f\)\\left\(\(\\psi \\circ \\pi\) \\otimes \\sqrt{\\alpha}\\right\) = \(\\tilde{\\psi}\\circ \\pi\) \\otimes \\sqrt{\\alpha},}$$
](A272900_1_En_23_Chapter_Equbh.gif)

where

![
$$\\displaystyle{\\tilde{\\psi}= i\\hslash \\left\(Y _{f}\\psi + \\frac{1} {2}\(\\mathrm{div}_{\\beta}Y _{f}\)\\psi \\right\) + f_{1}\\psi.}$$
](A272900_1_En_23_Chapter_Equbi.gif)

Here div β Y f is the unique function such that ![
$$\\mathcal{L}_{Y _{f}}\\beta = \(\\mathrm{div}_{\\beta}Y _{f}\)\\beta.$$
](A272900_1_En_23_Chapter_IEq363.gif)

A simple calculation in coordinates shows that the vector field Y f in the example satisfies X f (![
$$ {\\psi} $$
](A272900_1_En_23_Chapter_IEq604.gif) ∘ π) = (Y f ![
$$ {\\psi} $$
](A272900_1_En_23_Chapter_IEq605.gif)) ∘ π, so that our notation is consistent with that in Proposition 23.39 [see (23.23)].

Proof.

The calculation is precisely the same as in the proof of Theorem 23.47, except that the decomposition in (23.37) is now global. The claimed form of Q(f) is nothing but the expression (23.38), where the reader may easily compute, using local coordinates, that ![
$$-\\theta \(X_{f}\) - f = f_{1}.$$
](A272900_1_En_23_Chapter_IEq364.gif)

It is an unfortunate feature of geometric quantization that in the case of the vertical polarization on cotangent bundles, it only permits us to quantize functions that are at most linear in the momentum variables. In a typical physical system having T ∗ M as its phase space, there will be a "kinetic energy" term in the classical Hamiltonian that is quadratic in p. To quantize such a system, one has to find a way to quantize the kinetic energy term, "by hook or by crook."

One approach to this problem is to allow the exponentiated quantized Hamiltonian to change the polarization, and then to use pairing maps (Sect. 23.8) to "project" back to the Hilbert space for the original polarization. As explained in Sect. 9.​7 of [45], this approach succeeds in the case that the kinetic energy term is g(p, p) ∕ (2m), where g is the Riemannian structure on T ∗ M induced by a Riemannian structure on TM. The quantized kinetic energy operator turns out to be given by the map

![
$$\\displaystyle{\\psi \\mapsto - \\frac{{\\hslash}^{2}} {2m}\\left\(\(\\Delta \\psi\)\(x\) -\\frac{1} {6}R\(x\)\\psi \(x\)\\right\),}$$
](A272900_1_En_23_Chapter_Equ46.gif)

(23.39)

where Δ is the Laplacian for M (taken to be a negative operator) and where R(x) is the scalar curvature of the Riemannian structure on TM. The calculation in [45] glosses over one technical issue, which is that the time-evolved polarizations may not be everywhere transverse to the original polarization. Nevertheless, the calculation provides a reasonable geometric motivation for the formula (23.39).

It should be emphasized that, because of the projections involved in the computation of the quantized kinetic energy operator, it does not satisfy the desired commutation relations with the quantizations of functions whose flow preserves the vertical polarization. Nevertheless, this approach to quantizing the kinetic energy may simply be the best one can do.

## 23.7 Quantization with Half-Forms: The Complex Case

In the case of a purely complex polarization, half-forms are not "necessary," in that we typically have a nonzero Hilbert space even without them. Nevertheless, their inclusion gives advantages. In the first place, using half-forms makes the complex case more parallel to the real case. In the second place, complex quantization with half-forms simply gives better results than without half-forms. In the case of the harmonic oscillator, for example, the inclusion of half-forms allows (Example 23.53) geometric quantization to reproduce precisely the spectrum ![
$$\(n + 1/2\)\\hslash \\omega,$$
](A272900_1_En_23_Chapter_IEq365.gif) n = 0, 1, 2,..., that we found in the traditional treatment. This result should be compared to Proposition 22.14 without half-forms, where the spectrum is found to be ![
$$n\\hslash \\omega.$$
](A272900_1_En_23_Chapter_IEq366.gif)

Throughout this section, we assume that (N, ω) is a 2n-dimensional quantizable symplectic manifold, that (L, ∇) is prequantum line bundle over N, and that P is a Kähler polarization on N (Definition 23.19). Since the definitions in the complex case are very similar to those in the real case (with a few important differences), we will run through them quickly. Since ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq367.gif) is no longer equal to P, we need to replace P by ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq368.gif) in may of the formulas from Sect. 23.6.

The canonical bundle ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq369.gif) of P is the complex line bundle for which the sections are n-forms α satisfying

![
$$\\displaystyle{X\\lrcorner \\alpha}$$
](A272900_1_En_23_Chapter_Equbj.gif)

for each vector field X lying in ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq370.gif) Sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq371.gif) are precisely the (n, 0)-forms on N. A section of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq372.gif) is said to be polarized if

![
$$\\displaystyle{X\\lrcorner \(d\\alpha\) = 0}$$
](A272900_1_En_23_Chapter_Equ47.gif)

(23.40)

for every vector field lying in ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq373.gif) or, equivalently, if d α = 0. Polarized sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq374.gif) are precisely the holomorphic (n, 0)-forms on N. By a square root of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq375.gif) we will mean a complex line bundle δ P over N such that δ P ⊗ δ P is isomorphic with ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq376.gif) together with a particular isomorphism of δ P ⊗ δ P with ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq377.gif) Thus, if s 1 and s 2 are sections of δ P , we think of s 1 ⊗ s 2 as being a section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq378.gif) We assume that such a square root exists and we fix for the remainder of this section one particular square root δ P .

If X is a vector field that preserves ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq379.gif) in the sense of Definition 23.22, then ![
$$\\mathcal{L}_{X}$$
](A272900_1_En_23_Chapter_IEq380.gif) preserves the space of sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq381.gif) and also the space of polarized sections of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq382.gif) The condition (23.40) defining polarized sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq383.gif) can be understood as the vanishing of a partial connection ∇⋅, defined for vector fields lying in ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq384.gif) and given by

![
$$ \\Delta_{X}\\alpha=X\\lrcorner{\(d\\alpha\)}$$
](A272900_1_En_23_Chapter_Equ10001.gif)

. Both the partial connection (for vector fields lying in ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq385.gif)) and the Lie derivative (for vector fields preserving ![
$$\\bar{P}$$
](A272900_1_En_23_Chapter_IEq386.gif)) descend from ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq387.gif) to δ P , as in Proposition 23.41 in the real case. The connection on L and the partial connection on δ P combine to give a partial connection on L ⊗ δ P . A section s of L ⊗ δ P is said to be polarized if ∇ X s = 0 for all vector fields X lying in ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq388.gif)

Notation 23.49

If β is any 2n-form on N, let the expression

![
$$\\displaystyle{\\frac{\\beta} {\\lambda}}$$
](A272900_1_En_23_Chapter_Equbk.gif)

denote the unique function on N such that ![
$$\\beta = \(\\beta /\\lambda\)\\lambda,$$
](A272900_1_En_23_Chapter_IEq389.gif) where λ is the Liouville form in Definition 21.16.

Unlike the canonical bundle in the real case, the canonical bundle in the purely complex case carries a natural Hermitian structure.

Proposition 23.50

If α is an (n,0)-form on N, then at each point the 2n-form

![
$$\\displaystyle{{\(-1\)}^{n\(n-1\)/2}{\(-i\)}^{n}\\ \\bar{\\alpha}\\wedge \\alpha}$$
](A272900_1_En_23_Chapter_Equbl.gif)

is a non-negative multiple of the Liouville form λ. There is then a unique Hermitian structure on δ P with the property that for each section s of δ P we have

![
$$\\displaystyle{{\\left\\vert s\\right\\vert}^{2} ={\\left\(\\frac{{\(-1\)}^{n\(n-1\)/2}{\(-i\)}^{n}} {{2}^{n}} \\frac{\\overline{\(s \\otimes s\)} \\wedge \(s \\otimes s\)} {\\lambda} \\right\)}^{1/2}.}$$
](A272900_1_En_23_Chapter_Equ48.gif)

(23.41)

The factor of 2 n in the denominator in (23.41) is inserted for convenience, to make certain formulas come out more nicely.

Proof.

See Exercise 17.

Since, by assumption, there is Hermitian structure on L, the above Hermitian structure on δ P gives rise in a natural way to a Hermitian structure on L ⊗ δ P .

Definition 23.51

The half-form Hilbert space for a Kähler polarization P on N is the space of square-integrable polarized sections of L ⊗ δ P .

In the ![
$${\\mathbb{C}}^{n}$$
](A272900_1_En_23_Chapter_IEq390.gif) case, using the canonical 1-form as our symplectic potential, elements of the half-form Hilbert space take the form

![
$$\\displaystyle{{e}^{-{\\left\\vert \\mathrm{Im}\\mathbf{z}\\right\\vert}^{2}/\(2\\alpha \\hslash\)}F\(\\mathbf{z}\) \\otimes \\sqrt{dz_{1} \\wedge \\cdots \\wedge dz_{n}}.}$$
](A272900_1_En_23_Chapter_Equbm.gif)

In this special case, the norm of the half-form factor ![
$$\\sqrt{dz_{1} \\wedge \\cdots \\wedge dz_{n}}$$
](A272900_1_En_23_Chapter_IEq391.gif) is constant and the half-form Hilbert space is still identifiable with the space in Conclusion 22.10. In the case of the unit disk, on the other hand, the presence of half-forms alters the inner product; see Exercise 16.

We now define quantized observables on the half-form Hilbert space, using the same formula as in the real case.

Definition 23.52

If f is a function on N for which X f preserves ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq392.gif) let Q(f) be the operator on the half-form Hilbert space of P given by

![
$$\\displaystyle{Q\(f\)s = \(Q_{\\mathrm{pre}}\(f\)\\mu\) \\otimes \\nu -i\\hslash \\ \\mu \\otimes \\mathcal{L}_{X_{f}}\\nu,}$$
](A272900_1_En_23_Chapter_Equbn.gif)

where s is decomposed locally as s = μ ⊗ ν, with μ being a section of L and ν a section of δ P .

These operators satisfy ![
$$\\left\[Q\(f\),Q\(g\)\\right\]/\(i\\hslash\) = Q\(\\{f,g\\}\)$$
](A272900_1_En_23_Chapter_IEq393.gif) on the space of smooth polarized sections of L ⊗ δ P , with the proof of this result being identical to the proof of Theorem 23.46 in the real case. If f is real-valued and X f preserves ![
$$\\bar{P},$$
](A272900_1_En_23_Chapter_IEq394.gif) then Q(f) will be at least symmetric, assuming we can find a dense subspace of the half-form Hilbert space consisting of "nice" functions. (Finding dense subspaces is more difficult in the holomorphic case than in the real case.) A proof of this claim is sketched in Exercise 18.

Example 23.53

Consider ![
$${\\mathbb{R}}^{2}\\mathop{\\cong}{T}^{{\\ast}}\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq395.gif) with the Kähler polarization P given by the global complex coordinate ![
$$z = \(x - ip/\(m\\omega\)\),$$
](A272900_1_En_23_Chapter_IEq396.gif) for some positive number ω. Take δ P to be trivial with trivializing section ![
$$\\sqrt{dz}.$$
](A272900_1_En_23_Chapter_IEq397.gif) Consider also the harmonic oscillator Hamiltonian ![
$$H := \({p}^{2} + {\(m\\omega x\)}^{2}\)/\(2m\).$$
](A272900_1_En_23_Chapter_IEq398.gif) Then X H preserves the P and the operator Q(H) on the half-form Hilbert space has spectrum consisting of numbers of the form ![
$$\(n + 1/2\)\\hslash \\omega,$$
](A272900_1_En_23_Chapter_IEq399.gif) where n = 0, 1, 2,....

In this example, ω is the frequency of the oscillator and not the canonical 2-form.

Proof.

The calculation is the same as in the proof of Proposition 22.14, except for the addition of the Lie derivative term. A simple calculation shows that ![
$$\\mathcal{L}_{X_{H}}\(dz\) = i\\omega \\ dz,$$
](A272900_1_En_23_Chapter_IEq400.gif) from which it follows that ![
$$\\mathcal{L}_{X_{H}}\\sqrt{dz} = \(i\\omega /2\)\\sqrt{dz}.$$
](A272900_1_En_23_Chapter_IEq401.gif) It is then easy to see that the set of elements of the form ![
$${e}^{-m\\omega {\\left\\vert \\mathrm{Im}z\\right\\vert}^{2}/\(2\\hslash\)}{z}^{n} \\otimes \\sqrt{dz}$$
](A272900_1_En_23_Chapter_IEq402.gif) form an orthonormal basis of eigenvectors for Q(H), with eigenvalues ![
$$\(n + 1/2\)\\hslash \\omega.$$
](A272900_1_En_23_Chapter_IEq403.gif)

## 23.8 Pairing Maps

Pairing maps are designed to allow us to compare the results of quantizing with respect to two different polarizations. We consider mainly the case of two "transverse" real polarizations; the case of two complex polarizations or one real and one complex polarization can be treated with minor modifications.

Suppose that P and P ′ are two purely real polarizations and that the associated leaf spaces Ξ1 and Ξ2 are oriented manifolds. Suppose also that P and P ′ are transverse at each point z ∈ N, meaning that ![
$$P_{z} \\cap P_{z}^{{\\prime}} =\\{0\\}.$$
](A272900_1_En_23_Chapter_IEq404.gif) If α and β are polarized sections of ![
$$\\mathcal{K}_{P}$$
](A272900_1_En_23_Chapter_IEq405.gif) and ![
$$\\mathcal{K}_{{P}^{{\\prime}}},$$
](A272900_1_En_23_Chapter_IEq406.gif) respectively, the transversality assumption is easily shown to imply that α ∧ β is a nowhere-vanishing 2n-form on N. Thus, for any point z ∈ N, we can define a bilinear "pairing" from ![
$$\\delta _{P,z} \\times \\delta _{{P}^{{\\prime}},z} \\rightarrow \\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq407.gif) by

![
$$\\displaystyle{\(\\nu _{1},\\nu _{2}\) ={\\left\(\\frac{\(\\nu _{1} \\otimes \\nu _{1}\) \\wedge \(\\nu _{2} \\otimes \\nu _{2}\)} {\\lambda} \\right\)}^{1/2}.}$$
](A272900_1_En_23_Chapter_Equ49.gif)

(23.42)

(Recall Notation 23.49.) We can extend this pairing to a pairing ![
$$\\delta _{P,z}^{\\mathbb{C}} \\times \\delta _{{P}^{{\\prime}},z}^{\\mathbb{C}} \\rightarrow \\mathbb{C}$$
](A272900_1_En_23_Chapter_IEq408.gif) that is conjugate linear in the first factor and linear in the second factor. Finally, we extend to a pairing of ![
$$\(L_{z} \\otimes \\delta _{P,z}^{\\mathbb{C}}\) \\times \(L_{z} \\otimes \\delta _{{P}^{{\\prime}},z}^{\\mathbb{C}}\) \\rightarrow \\mathbb{C}$$
](A272900_1_En_23_Chapter_IEq409.gif) by setting ![
$$\(\\mu _{1} \\otimes \\nu _{1},\\mu _{2} \\otimes \\nu _{2}\)$$
](A272900_1_En_23_Chapter_IEq410.gif) equal to ![
$$\(\\mu _{1},\\mu _{2}\)\(\\nu _{1},\\nu _{2}\),$$
](A272900_1_En_23_Chapter_IEq411.gif) where (μ 1, μ 2) is computed with respect to the Hermitian structure on L.

Let H 1 and H 2 denote the half-form Hilbert spaces for P and P ′ , respectively. Given s 1 ∈ H 1 and s 2 ∈ H 2, we define the pairing of s 1 and s 2 by

![
$$\\displaystyle{\\left\\langle s_{1},s_{2}\\right\\rangle _{P,{P}^{{\\prime}}} := c\\int _{N}\(s_{1},s_{2}\)\\ \\lambda,}$$
](A272900_1_En_23_Chapter_Equbo.gif)

provided that the integral is absolutely convergent. Here (s 1, s 2) is the pointwise pairing of s 1 and s 2 defined in the previous paragraph and c is a certain "universal" constant, depending only on ![
$$\\hslash $$
](A272900_1_En_23_Chapter_IEq412.gif) and the dimension of n, that can be chosen to make certain examples work out nicely. We now look for a pairing map ![
$$\\Lambda _{P,{P}^{{\\prime}}} : \\mathbf{H}_{1} \\rightarrow \\mathbf{H}_{2}$$
](A272900_1_En_23_Chapter_IEq413.gif) with the property that

![
$$\\displaystyle{\\left\\langle s_{1},s_{2}\\right\\rangle _{P,{P}^{{\\prime}}} = \\left\\langle \\Lambda _{P,{P}^{{\\prime}}}s_{1},s_{2}\\right\\rangle _{\\mathbf{H}_{2}}.}$$
](A272900_1_En_23_Chapter_Equ50.gif)

(23.43)

If the pairing is bounded (i.e., it satisfies ![
$$\\vert \\,\\left\\langle s_{1},s_{2}\\right\\rangle _{P,{P}^{{\\prime}}}\\vert \\ \\,\\leq C\\left\\Vert s_{1}\\right\\Vert \\left\\Vert s_{2}\\right\\Vert$$
](A272900_1_En_23_Chapter_IEq414.gif) for some constant C), there is a unique bounded operator ![
$$\\Lambda _{P,{P}^{{\\prime}}}$$
](A272900_1_En_23_Chapter_IEq415.gif) satisfying (23.43). Even if the pairing is unbounded, we may be able to define ![
$$\\Lambda _{P,{P}^{{\\prime}}}$$
](A272900_1_En_23_Chapter_IEq416.gif) as an unbounded operator.

If we were optimistic, we might hope that the pairing map for any two transverse polarizations would be unitary, or at least a constant multiple of a unitary map. If this were the case, it would suggest that quantization is independent of the choice of polarization, in the sense that there would be a natural unitary map between the Hilbert spaces for two different polarizations. As it turns out, however, the typical pairing map is not a constant multiple of a unitary map. Nevertheless, there are certain special cases where the pairing map is unitary (up to a constant), including the case of translation-invariant polarizations on ![
$${\\mathbb{R}}^{2n}.$$
](A272900_1_En_23_Chapter_IEq417.gif) See also [20] for an example of a pairing map between a real and a complex polarization that is a constant multiple of a unitary map.

We compute just one very special case of the pairing map between two real polarizations.

Example 23.54

Consider ![
$$N = {\\mathbb{R}}^{2}\\mathop{\\cong}{T}^{{\\ast}}\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq418.gif) and take L to be trivial with connection 1-form θ = p dx. Let P be the vertical polarization, spanned at each point by ∂ ∕ ∂ p, and let P ′ be the horizontal polarization, spanned at each point by ∂ ∕ ∂ x. Then elements s 1 of the half-form space for P have the form

![
$$\\displaystyle{s_{1}\(x,p\) =\\phi \(x\) \\otimes \\sqrt{dx}}$$
](A272900_1_En_23_Chapter_Equ51.gif)

(23.44)

and elements s 2 of the half-form space for P ′ have the form

![
$$\\displaystyle{s_{2}\(x,p\) =\\psi \(p\){e}^{ixp/\\hslash} \\otimes \\sqrt{dp},}$$
](A272900_1_En_23_Chapter_Equ52.gif)

(23.45)

where ![
$${\\phi} $$
](A272900_1_En_23_Chapter_IEq632.gif) and ![
$$\\psi$$
](A272900_1_En_23_Chapter_IEq522.gif) are functions on ![
$$\\mathbb{R}.$$
](A272900_1_En_23_Chapter_IEq419.gif) If c = 1, the pairing is computed as

![
$$\\displaystyle{\\left\\langle s_{1},s_{2}\\right\\rangle _{P,{P}^{{\\prime}}} = -\\int _{{\\mathbb{R}}^{2}}\\overline{\\phi \(x\)}\\psi \(p\){e}^{ixp/\\hslash}\\ dx\\ dp.}$$
](A272900_1_En_23_Chapter_Equ53.gif)

(23.46)

If s 1 has the form (23.44), then ![
$$\\Lambda _{P,{P}^{{\\prime}}}\(s_{1}\)$$
](A272900_1_En_23_Chapter_IEq420.gif) has the form (23.45), where

![
$$\\displaystyle{\\psi \(p\) = -\\int _{\\mathbb{R}}\\phi \(x\){e}^{-ixp/\\hslash}\\ dx.}$$
](A272900_1_En_23_Chapter_Equbp.gif)

Thus, ![
$$\\Lambda _{P,{P}^{{\\prime}}}$$
](A272900_1_En_23_Chapter_IEq421.gif) is a scaled version of the Fourier transform and is, in particular, a constant multiple of a unitary map.

The pairing should be defined initially on some dense subspace of the Hilbert spaces, such as the subspaces where ![
$${\\phi} $$
](A272900_1_En_23_Chapter_IEq633.gif) and ![
$$\\psi$$
](A272900_1_En_23_Chapter_IEq523.gif) are Schwartz functions. The pairing map can also be defined initially on the Schwartz space, recognized as being unitary (up to a constant), and then extended by continuity to all of H 1. Once the pairing map is extended to H 1, the pairing itself can be defined for all s 1 ∈ H 1 and s 2 ∈ H 2 by taking (23.43) as the definition of ![
$$\\left\\langle s_{1},s_{2}\\right\\rangle _{P,{P}^{{\\prime}}}.$$
](A272900_1_En_23_Chapter_IEq422.gif) Even though it is possible, as just described, to extend the pairing to all of H 1 ×H 2, the integral in (23.46) is not always absolutely convergent.

Proof.

The forms (23.44) and (23.45) are obtained by a simple modification of the argument in the proof of Proposition 22.8. We can compute that the pointwise pairing of ![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq423.gif) and ![
$$\\sqrt{dp}$$
](A272900_1_En_23_Chapter_IEq424.gif) is − 1, which gives the indicated form of the pairing in (23.46). The pairing may be rewritten as

![
$$\\displaystyle{\\int _{\\mathbb{R}}\\overline{\\int _{\\mathbb{R}}\\phi \(x\){e}^{-ixp/\\hslash}\\ dx}\\ \\psi \(p\)\\ dp,}$$
](A272900_1_En_23_Chapter_Equbq.gif)

which gives the indicated form of the pairing map.

## 23.9 Exercises

1.

Let L be a line bundle with connection ∇ over N. Let s be a section of L and let X 1 and X 2 be two vector fields on N such that X 1(z) = X 2(z) for some fixed point z ∈ N. Show that

![
$$\\displaystyle{\\nabla _{X_{1}}\(s\)\(z\) = \\nabla _{X_{2}}\(s\)\(z\).}$$
](A272900_1_En_23_Chapter_Equbr.gif)

Hint: Use the assumption that ∇ fX = f ∇ X .

2.

Let L be a Hermitian line bundle with Hermitian connection ∇ and let s 0 be a locally defined section of L such that ![
$$\(s_{0},s_{0}\) \\equiv 1.$$
](A272900_1_En_23_Chapter_IEq425.gif) Given a vector field X, let θ(X) be the unique function such that

![
$$\\displaystyle{\\nabla _{X}s_{0} = -i\\theta \(X\)s_{0}.}$$
](A272900_1_En_23_Chapter_Equbs.gif)

Show that θ(X) is real valued.

Hint: Use the Hermitian property of the connection.

3.

Consider the definition of the curvature 2-form ω(X, Y) in Definition 23.4.

(a)

Show that the expression for ω is C ∞ -linear in each of the variables X, Y, and s. That is to say, show that for all smooth functions f, we have ω(fX, Y)s = f ω(X, Y)s, and similarly for the variables Y and s.

(b)

Show that the value of ω(X, Y)s at a point z depends only on the values of X, Y, and s at the point z.

(c)

Show that the value of ω(X, Y) at a point z does not depend on the value of s at z, provided that s(z)≠0.

4.

Consider the symplectic form ω = dp ∧ dx on ![
$${\\mathbb{R}}^{2}.$$
](A272900_1_En_23_Chapter_IEq426.gif) Define a purely complex polarization on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq427.gif) by taking P z to be the span of the vector ∂ ∕ ∂ z in (22.​9), for some fixed α > 0. Show that P is a Kähler polarization.

5.

Let P be the polarization on ![
$${\\mathbb{R}}^{2}$$
](A272900_1_En_23_Chapter_IEq428.gif) in Exercise 4. Show that the function κ(x, p) : = α p 2 is a Kähler potential for P.

6.

Suppose that ω is a J-invariant 2-form on a complex manifold N. Show that ω is a (1, 1)-form. (Recall the definitions preceding Lemma 23.34.)

Hint: Write ![
$$\\omega {=\\omega}^{1} {+\\omega}^{2},$$
](A272900_1_En_23_Chapter_IEq429.gif) where ω 1 is a (1, 1)-form and ω 2 is a sum of a (2, 0)-form and a (0, 2)-form. Show that

![
$${\\displaystyle{\\omega}^{2}\(JX,JY\) = {-\\omega}^{2}\(X,Y\)}$$
](A272900_1_En_23_Chapter_Equbt.gif)

for all tangent vectors X and Y.

7.

Suppose that κ is a smooth, real-valued function on a complex manifold N. Show that the 2-form ![
$$i\\partial \\bar{\\partial}\\kappa$$
](A272900_1_En_23_Chapter_IEq430.gif) is a real-valued 2-form.

8.

In Example 23.30, verify that θ is a symplectic potential for ω, and compute ![
$$\\theta \(\\partial /\\partial \\bar{z}\),$$
](A272900_1_En_23_Chapter_IEq431.gif) where, with ![
$$z = x - iy,$$
](A272900_1_En_23_Chapter_IEq432.gif) we have ![
$$\\partial /\\partial \\bar{z} = \(\\partial /\\partial x - i\\partial /\\partial y\)/2.$$
](A272900_1_En_23_Chapter_IEq433.gif) Then verify that ![
$$s_{0}\(z\) := {\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{1/\\hslash}$$
](A272900_1_En_23_Chapter_IEq434.gif) satisfies ![
$$\\nabla _{\\partial /\\partial \\bar{z}}s_{0} = 0$$
](A272900_1_En_23_Chapter_IEq435.gif) and thus constitutes a global trivializing holomorphic section.

9.

Consider the situation in Example 23.29. Show that the canonical bundle for P is trivial, with trivializing section dx. Let δ P be the (nontrivial) bundle described in the paragraph preceding Definition 23.42. Since the tensor product of any real line bundle with itself is trivial, δ P ⊗ δ P is isomorphic to ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq436.gif) Let ![
$$\\sqrt{dx}$$
](A272900_1_En_23_Chapter_IEq437.gif) denote a discontinuous section defined over the set 0 < ![
$${\\phi} $$
](A272900_1_En_23_Chapter_IEq6341.gif) < 2π such that ![
$$\\sqrt{dx} \\otimes \\sqrt{dx} = dx.$$
](A272900_1_En_23_Chapter_IEq438.gif) Show that ∇ X (dx) = 0 and ![
$$\\nabla _{X}\\sqrt{dx} = 0$$
](A272900_1_En_23_Chapter_IEq439.gif) for every vector field lying in P. Now show that the Bohr–Sommerfeld leaves (in the half-form sense, for this choice of δ P ) are the sets of the form ![
$$\\{x\\} \\times {S}^{1},$$
](A272900_1_En_23_Chapter_IEq440.gif) where ![
$$x/\\hslash = n + 1/2$$
](A272900_1_En_23_Chapter_IEq441.gif) for some integer n.

10.

Let b be a smooth, real-valued function on ![
$$\\mathbb{R}$$
](A272900_1_En_23_Chapter_IEq442.gif) and let c be a real constant. Show that an operator of the form

![
$$\\displaystyle{\\psi \\mapsto - i\\hslash \\left\(b{\(x\)\\psi}^{{\\prime}}\(x\) + c{b}^{{\\prime}}\(x\)\\psi \(x\)\\right\)}$$
](A272900_1_En_23_Chapter_Equbu.gif)

is symmetric on ![
$$C_{c}^{\\infty}\(\\mathbb{R}\) \\subset {L}^{2}\(\\mathbb{R}\)$$
](A272900_1_En_23_Chapter_IEq443.gif) if and only if ![
$$c = 1/2.$$
](A272900_1_En_23_Chapter_IEq444.gif)

11.

Let P be a real polarization and let f be a smooth polarized function on N, that is, one for which derivatives in the direction of P are zero. Show that Q(f) acts on the half-form Hilbert space simply as multiplication by f. (Compare Proposition 23.25 in the case without half-forms.)

Hint: Show that ![
$$\\mathcal{L}_{X_{f}}\\alpha = 0$$
](A272900_1_En_23_Chapter_IEq445.gif) whenever α is a polarized section of ![
$$\\mathcal{K}_{P}.$$
](A272900_1_En_23_Chapter_IEq446.gif)

12.

Using the identities ![
$$\\mathcal{L}_{\[X,Y \]} = \[\\mathcal{L}_{X},\\mathcal{L}_{Y}\]$$
](A272900_1_En_23_Chapter_IEq447.gif) and ![
$$X_{\\{f,g\\}} = \[X_{f},X_{g}\],$$
](A272900_1_En_23_Chapter_IEq448.gif) verify the identity (23.36).

13.

Prove that if P is a real polarization on N, it is possible to choose a symplectic potential θ locally in such a way that θ is zero on P.

Hint: Use functions f x as in the proof of Proposition 23.26.

14.

Suppose that P is a purely real polarization on N and θ is a local symplectic potential that vanishes on P. Suppose also that f is a real-valued function for which X f preserves P. Show that the function ![
$$\\,-\\theta \(X_{f}\) - f$$
](A272900_1_En_23_Chapter_IEq449.gif) is constant along the leaves of P.

Hint: If X is a vector field lying in P, use (21.​6) to show that X(θ(X f )) = dθ(X, X f ).

15.

Suppose that β is a nowhere vanishing n-form on an oriented manifold Ξ, that X is a real vector field on Ξ, and that ![
$${\\phi} $$
](A272900_1_En_23_Chapter_IEq635.gif) and ![
$$\\psi$$
](A272900_1_En_23_Chapter_IEq524.gif) are smooth, compactly supported functions on Ξ. Verify the following formula for "integration by parts":

![
$$\\displaystyle{\\int _{\\Xi}\(X\\phi\)\\psi \\ \\beta = -\\int _{\\Xi}\\phi \(X\\psi\)\\ \\beta -\\int _{\\Xi}\\phi \\psi \(\\mathrm{div}_{\\beta}X\)\\ \\beta,}$$
](A272900_1_En_23_Chapter_Equbv.gif)

where div β X is the function such that ![
$$\\mathcal{L}_{X}\\beta = \(\\mathrm{div}_{\\beta}X\)\\beta.$$
](A272900_1_En_23_Chapter_IEq450.gif)

Hint: If Φ  t is the flow generated by X, then for all sufficiently small t, Φ  t (x) is defined for all x in the support of ![
$$ {\\phi}{\\psi} $$
](A272900_1_En_23_Chapter_IEq639.gif) and the integral of ![
$$ \(\\Phi_t\)^*\({\\phi}{\\psi}\\beta\) $$
](A272900_1_En_23_Chapter_IEq589.gif)(over Ξ is independent of t.

16.

Let the notation be as in Exercise 8. Then the canonical bundle for P is trivial, with trivializing section dz. Take δ P to be trivial, with trivializing section ![
$$\\sqrt{dz}.$$
](A272900_1_En_23_Chapter_IEq451.gif) Show that every polarized section s of L ⊗ δ P is of the form

![
$$\\displaystyle{s = F\(z\)s_{0}\(z\) \\otimes \\sqrt{dz},}$$
](A272900_1_En_23_Chapter_Equbw.gif)

where F is holomorphic. Show that the norm of such a section is, up to a constant, the L 2 norm of F with respect to a measure of the form ![
$${\(1 -{\\left\\vert z\\right\\vert}^{2}\)}^{\\nu},$$
](A272900_1_En_23_Chapter_IEq452.gif) but that the value of ν is not the same as when half-forms are not included.

17.

Let P be a Kähler polarization on N, let z 1,..., z n be holomorphic local coordinates on N, and let A be the matrix given by

![
$$\\displaystyle{A_{jk} =\\omega \\, \\left\(\\frac{\\partial} {\\partial \\bar{z}_{j}}, \\frac{\\partial} {\\partial z_{k}}\\right\).}$$
](A272900_1_En_23_Chapter_Equbx.gif)

(a)

Show that the matrix iA is positive definite.

(b)

Show that ![
$$\\omega = A_{jk}\\ d\\bar{z}_{j} \\wedge dz_{k}.$$
](A272900_1_En_23_Chapter_IEq453.gif)

(c)

Show that the quantity ω ⊗ n ∕ n! may be computed as

![
$$\\displaystyle{\\det \(iA\){\(-1\)}^{n\(n-1\)/2}{\(-i\)}^{n}d\\bar{z}_{1} \\wedge \\cdots \\wedge d\\bar{z}_{n} \\wedge dz_{1} \\wedge \\cdots \\wedge dz_{n}.}$$
](A272900_1_En_23_Chapter_Equby.gif)

(d)

Verify Proposition 23.50.

18.

Let P be a Kähler polarization on N, let δ P be a fixed square root of ![
$$\\mathcal{K}_{P},$$
](A272900_1_En_23_Chapter_IEq454.gif) and let f be a smooth, real-valued function such that X f preserves ![
$$\\bar{P}.$$
](A272900_1_En_23_Chapter_IEq455.gif) Throughout this problem, if s 1 and s 2 are local sections of a line bundle, with s 2 nonvanishing, s 1 ∕ s 2 will denote the unique function such that ![
$$s_{1} = \(s_{1}/s_{2}\)s_{2}.$$
](A272900_1_En_23_Chapter_IEq456.gif)

(a)

Show that for any continuous compactly supported function ![
$$\\psi$$
](A272900_1_En_23_Chapter_IEq525.gif) on N, we have

![
$$\\displaystyle{\\int _{N}X_{f}\(\\psi\)\\ \\lambda = 0.}$$
](A272900_1_En_23_Chapter_Equbz.gif)

Hint: Use Liouville's theorem.

Note: The same result holds if ![
$$\\psi$$
](A272900_1_En_23_Chapter_IEq526.gif) is not compactly supported but is "sufficiently nice."

(b)

If ν is a local nonvanishing section of δ P , show that

![
$$\\displaystyle{\\frac{\\mathcal{L}_{X_{f}}\\nu} {\\nu} = \\frac{1} {2} \\frac{\\mathcal{L}_{X_{f}}\(\\nu \\otimes \\nu\)} {\\nu \\otimes \\nu}.}$$
](A272900_1_En_23_Chapter_Equca.gif)

(c)

If α is any 2n-form on N, show that

![
$$\\displaystyle{\\frac{\\mathcal{L}_{X_{f}}\\alpha} {\\lambda} = X_{f}\\,\\left\(\\frac{\\alpha} {\\lambda}\\right\).}$$
](A272900_1_En_23_Chapter_Equcb.gif)

(d)

Suppose s 1 and s 2 are polarized sections of L ⊗ δ P , decomposed locally as ![
$$s_{j} =\\mu _{j} \\otimes \\nu _{j},$$
](A272900_1_En_23_Chapter_IEq457.gif) j = 1, 2. Show that

![
$$\\displaystyle\\begin{array}{rcl} iX_{f}\(s_{1},s_{2}\)& =& \(i\(\\nabla _{X_{f}}\\mu _{1}\) \\otimes \\nu _{1},s_{2}\) + \(i\\mu _{1} \\otimes \(\\mathcal{L}_{X_{f}}\\nu _{1}\) \\otimes s_{2}\) {}\\\\ & & +\(s_{1},i\(\\nabla _{X_{f}}\\mu _{2}\) \\otimes \\nu _{2}\) + \(s_{1},i\\mu _{2} \\otimes \(\\mathcal{L}_{X_{f}}\\nu _{2}\)\), {}\\\\ \\end{array}$$
](A272900_1_En_23_Chapter_Equ54.gif)

where (⋅, ⋅) is computed with respect to the Hermitian structure on L ⊗ δ P described in Sect. 23.7.

Hint: Use the identity ![
$$\\mathcal{L}_{X_{f}}\(\\alpha \\wedge \\beta\) = \(\\mathcal{L}_{X_{f}}\\alpha\) \\wedge \\beta +\\alpha \\wedge \(\\mathcal{L}_{X_{f}}\\beta\).$$
](A272900_1_En_23_Chapter_IEq458.gif)

(e)

Suppose s 1 and s 2 are polarized sections of L ⊗ δ P belonging to the domain of Q(f) and such that (s 1, s 2) is "sufficiently nice." Show that

![
$$\\displaystyle{\\left\\langle s_{1},Q\(f\)s_{2}\\right\\rangle = \\left\\langle Q\(f\)s_{1},s_{2}\\right\\rangle.}$$
](A272900_1_En_23_Chapter_Equcc.gif)

References

[4].

R.J. Blattner, Quantization and representation theory. In Harmonic Analysis on Homogeneous Spaces (Proceedings of Symposia in Pure Mathematics, vol. XXVI, Williams College, Williamstown, MA, 1972). (American Mathematical Society, Providence, RI, 1973), pp. 147–165

[20].

B.C. Hall, Geometric quantization and the generalized Segal–Bargmann transform for Lie groups of compact type. Comm. Math. Phys. 226, 233–268 (2002)CrossRefMATHMathSciNet

[29].

J. Lee, Introduction to Smooth Manifolds, 2nd edn. (Springer, London, 2006)

[45].

N. Woodhouse, Geometric Quantization, 2nd edn. (Oxford University Press, Oxford, 1992)MATH
Brian C. HallGraduate Texts in MathematicsQuantum Theory for Mathematicians201310.1007/978-1-4614-7116-5© Springer Science+Business Media New York 2013

## Appendix A Review of Basic Material

### A.1 Tensor Products of Vector Spaces

Given two vector spaces V 1 and V 2 over   the tensor product is a new vector space V 1 ⊗ V 2 , together with a bilinear "product" map   If V 1 and V 2 are finite dimensional with bases   and   then V 1 ⊗ V 2 is finite dimensional with   forming a basis for V 1 ⊗ V 2 . In the finite dimensional case, we could simply define the tensor product by this basis property, but then we would have to worry about whether the construction is basis independent. Instead, we define V 1 ⊗ V 2 by a "universal property."

Definition A.1.

Suppose V 1 and V 2 are vector spaces over a field   Then a tensor product of V 1 and V 2 is a vector space W over   together with a bilinear map T : V 1 × V 2 → W having the following "universal property": If U is any vector space over   and Φ : V 1 × V 2 → U is a bilinear map, then there exists a unique linear map   such that the following diagram commutes:

Proposition A.2.

For any two vector spaces V 1 and V 2 , a tensor product of V 1 and V 2 exists and is unique up to "canonical isomorphism." That is, for two tensor products ( W 1 , T 1 ) and ( W 2 , T 2 ), there is a unique invertible linear map Ψ : W 1 → W 2 such that T 2 = Ψ ∘ T 1 .

In light of the uniqueness result, we may speak of "the" tensor product of V 1 and V 2 . We choose any one tensor product and we denote it by V 1 ⊗ V 2 . We also denote the linear map   as ( u , v ) ↦ u ⊗ v . In this notation, the universal property reads as follows: Given any bilinear map Φ of V 1 × V 2 into a vector space U , there exists a unique linear map   such that

Proposition A.3.

If V 1 and V 2 are finite-dimensional vector spaces with bases   and   then V 1 ⊗ V 2 is finite dimensional and the set of elements of the form u j ⊗ v k ,   forms a basis for V 1 ⊗ V 2 . In particular ,

It should be emphasized that, in general, not every element of V 1 ⊗ V 2 is of the form u ⊗ v with u ∈ V 1 and v ∈ V 2 . All we can say is that each element of V 1 ⊗ V 2 can be decomposed as a linear combination of elements of the form u ⊗ v . This decomposition, furthermore, is far from canonical; even in the finite-dimensional case, it depends on a choice of bases for V 1 and V 2 . Nevertheless, the universal property of the tensor product tells us that we can define linear maps from V 1 ⊗ V 2 to any vector space U , simply by defining them on elements of the form u ⊗ v . Provided that Φ( u , v ) is bilinear in u and v , the universal property tells us that there is a unique linear map   on V 1 ⊗ V 2 such that on element of the form u ⊗ v ,   is equal to Φ( u , v ). A representative application of the universal property is in the following result.

Proposition A.4.

If A ∈ End (V 1 ) and B ∈ End (V 2 ), there exists a unique linear map   such that

For   and   we have

To construct A ⊗ B , we apply the universal property with U = V 1 ⊗ V 2 and Φ( u , v ) = ( Au ) ⊗ ( Bv ). Since A and B are linear and ⊗ is bilinear, Φ is bilinear. The linear map   is then the map that we denote A ⊗ B .

The tensor product, as we have defined it in this section, applies to all vector spaces, whether finite dimensional or infinite dimensional. The construction, however, is purely algebraic; if there is a topology on V 1 and V 2 , the tensor product takes no account of that topology. In the Hilbert space setting, then, we will have to refine the notion of the tensor product so that the tensor product of two Hilbert spaces will again be a Hilbert space. See Sect. A.4.5 .

### A.2 Measure Theory

It is assumed that the reader is familiar with the basic notions of measure theory, including the concepts of σ -algebras, measures, measurable functions, and the Lebesgue integral. A triple ( X , Ω, μ ), consisting of a set X , a σ -algebra Ω of subsets of X , and a (non-negative) measure μ on Ω is called a measure space . A measurable function   is said to be integrable if   . The σ -algebra generated by any collection of subsets of a set X is the smallest σ -algebra of subsets of X containing that collection.

We assume those parts of measure theory that are entirely standard: the monotone convergence and dominated convergence theorems, L p spaces, and Fubini's theorem. We briefly review a few other topics that might not be as familiar.

A measure μ on a measurable space ( X , μ) is said to be σ- finite if X can be written as a countable union of measurable sets of finite measure.

Definition A.5.

Suppose μ and ν are two σ-finite measures on a measure space ( X , Ω). Then we say that μ is absolutely continuous with respect to ν if for all E ∈ Ω, if ν( E ) = 0 then μ ( E ) = 0. We say that μ and ν are equivalent if each measure is absolutely continuous with respect to the other.

Theorem A.6 (Radon–Nikodym).

Suppose μ and ν are two σ-finite measures on a measure space ( X , Ω) and that μ is absolutely continuous with respect to ν. Then there exists a non-negative, measurable function ρ on X such that

for all E ∈ Ω. The function ρ is called the density of μ with respect to ν.

Definition A.7.

A collection   of subsets of a set X is called a monotone class if   is closed under countable increasing unions and countable decreasing intersections.

A countable increasing union means the union of a sequence E j of sets where E j is contained in E j \+ 1  for each j , with a similar definition for countable decreasing intersections.

Theorem A.8 (Monotone Class Lemma).

Suppose   is a monotone class of subsets of a set X and suppose   contains an algebra   of subsets of X. Then   contains the σ-algebra generated by

Corollary A.9.

Suppose μ and ν are two finite measures on a measure space ( X , Ω). Suppose μ and ν agree on an algebra   Then μ and ν agree on the σ-algebra generated by

Note that in general, the collection of sets on which two measures agree is not a σ -algebra, nor even an algebra.

Theorem A.10.

Suppose μ is a measure on the Borel σ-algebra in a locally compact, separable metric space X. Suppose also that μ ( K ) < ∞ for each compact subset K of X. Then the space of continuous functions of compact support on X is dense in L p ( X, μ ), for all p with 1 ≤ p < ∞.

A word of clarification is in order here. If ψ is a continuous function on X with compact support, then   is finite, since ψ is bounded and μ is finite on compact sets. Thus, we can define a map from C c ( X ) into L p ( X , μ ) by mapping a continuous function ψ of compact support to the equivalence class [ ψ ]. The theorem is asserting, more precisely, that the image of C c ( X ) under this map is dense in L p ( X , μ ). It should be noted, however, that the map ψ ↦ [ ψ ] need not be injective. After all, if there is a nonempty open set U inside X with μ ( U ) = 0, then for any ψ with support contained in U , the equivalence class [ ψ ] will be the zero element of L p ( X , μ ). Nevertheless, we will allow ourselves a small abuse of terminology and say that C c ( X ) is dense in L p ( X , μ ).

### A.3 Elementary Functional Analysis

In this section, we briefly review some of the results from elementary functional analysis that we make use of the text. Most of these results can be found in the book of Rudin [ 32 ].

#### A.3.1 The Stone–Weierstrass Theorem

The Weierstrass theorem states that every continuous, real-valued function on an interval can be uniformly approximated by polynomials. A substantial generalization of this was obtained by Stone. If X is a compact metric space, let   and   denote the space of continuous real- and complex-valued continuous functions, respectively. A subset   of   is called an algebra if it is closed under pointwise addition, pointwise multiplication, and multiplication by elements of   , where   or   . An algebra   is said to separate points if for any two distinct points x and y in X , there exists   such that f ( x ) ≠ f ( y ). We use on   the supremum norm , given by

and   is complete with respect to the associated distance function, d ( f , g ) = || f − g || sup .

Theorem A.11 (Stone–Weierstrass, Real Version).

Let X be a compact metric space and let   be an algebra in   If   contains the constant functions and separates points, then   is dense in   with respect to the supremum norm.

Theorem A.12 (Stone–Weierstrass, Complex Version).

Let X be a compact metric space and let   be an algebra in   If   contains the constant functions, separates points, and is closed under complex conjugation, then   is dense in   with respect to the supremum norm.

A consequence of the complex version of the Stone–Weierstrass theorem is the following: If K is a compact subset of   then every continuous, complex-valued function on K can be uniformly approximated by polynomials in z and

#### A.3.2 The Fourier Transform

We now describe the Fourier transform on   in various forms.

Definition A.13.

For any   define the Fourier transform of ψ to be the function   on   given by

Proposition A.14.

For any   the Fourier transform   of ψ has the following properties: (1)   (2)   is continuous, and (3)   tends to zero as | k | tends to ∞.

The bound on   is obvious and the continuity of   follows from dominated convergence. To show that   tends to zero at infinity, we first establish this on a dense subspace of   (e.g., the Schwartz space; see below) and then take uniform limits.

Definition A.15.

The Schwartz space   is the space of all C ∞ functions ψ on   such that

for all n-tuples of non-negative integers j and k . Here if j = (j 1 ,..., j n ) then   and

An element of the Schwartz space is called a Schwartz function .

Proposition A.16.

If ψ belongs to   then   also belongs to

The proof of this result hinges on the behavior of the Fourier transform under differentiation and under multiplication by x , results which are of interest in their on right.

Proposition A.17.

If ψ is a Schwartz function, the following properties hold

1.

We have

(A.1)

2.

The function   is differentiable at every point and the Fourier transform of the function x j ψ(x) is given by

(A.2)

The first point is proved by integration by parts and the second by differentiation under the integral in the definition of

Theorem A.18 (Fourier Inversion and Plancherel Formula, I).

The Fourier transform on   has the following properties.

1.

The Fourier transform maps the Schwartz space onto the Schwartz space.

2.

For all   the function ψ can be recovered from its Fourier transform by the Fourier inversion formula :

3.

For all   we have the Plancherel theorem :

Since the Schwartz space is dense in L 2 (ℝ  n ), the BLT theorem and Theorem A.18 imply that the Fourier transform extends uniquely to an isometric map of   onto L 2 (ℝ  n ).

Theorem A.19 (Fourier Inversion and Plancherel Theorem, II).

The Fourier transform extends to an isometric map   of   onto   This map may be computed as

(A.3)

where the limit is in the norm topology of   The inverse map   may be computed as

If ψ belongs to   then by dominated convergence, the limit in coincides with the L 1 Fourier transform in Definition A.13.

Definition A.20.

For two measurable functions ϕ and ψ, define the convolution ϕ ∗ ψ of ϕ and ψ by the formula

provided that the integral is absolutely convergent for all x .

Proposition A.21.

Suppose that ϕ and ψ belong to   Then ϕ ∗ ψ is defined and belongs to   and we have

This result is proved by plugging ϕ ∗ ψ into the definition of the Fourier transform, writing e − i k ⋅ x as   , and using Fubini's theorem.

We will have occasion to use the following Gaussian integral.

Proposition A.22.

For all a > 0 and   we have

Taking b = ik in the last part of the proposition gives us the Fourier transform of the Gaussian function   Taking b = 0 allows us to determine the proper normalization of the Gaussian probability density.

#### A.3.3 Distributions

In this section we give a brief account of the theory of distributions—what physicists call "generalized functions"—including the notion of "derivative in the distribution sense."

The idea is that we study functions by studying their integral against some class of very nice "test functions." Consider, for example, a locally integrable function f and consider integrals of the form

(A.4)

where χ belongs to   the space of smooth, compactly supported functions. We might think, for example, that χ is positive, has integral equal to 1, and is supported near some point   In that case, the integral ( A.4 ) is an approximation to the value of f at a , what physicists describe as a "smeared out" version of f ( a ).

Proposition A.23.

Suppose f 1 and f 2 are locally integrable functions on   If

for all   then   for almost every x .

The idea now is that we allow objects that do not have values at points, but for which something like ( A.4 ) makes sense. Mathematically, we think of ( A.4 ) as a linear functional on

Definition A.24.

A sequence   is said to converge to   if (1) there exists a single compact set K containing the support of all the χ n 's, (2) χ m converges uniformly to χ, and (3) each derivative of χ m converges uniformly to the corresponding derivative of χ.

Definition A.25.

A distribution on   is a linear map   having the following continuity property: If χ m converges to χ in the sense of Definition A.24, T(χ m ) converges to T(χ).

The continuity condition on T should be regarded as a technicality, in that any functional that is well defined and linear on all of   and is obtained in a reasonably constructive fashion will satisfy this property.

Example A.26.

The Dirac δ -"function" is the distribution δ defined by

Definition A.27.

If T is a distribution and f is a locally integrable function, the expression "T is equal to f" or "T is given by f" means that

for all

Definition A.28.

If T is a distribution, define the distribution ∂T∕∂x j by the formula

It is easy to verify that if T has the continuity property in Definition A.25, then so does ∂T ∕ ∂x j . Furthermore, if T is given by a continuously differentiable function, then the derivative of T is in the distribution sense coincides with the derivative of T in the classical sense, as can easily be shown using integration by parts. If T is a distribution, we may define ΔT by repeated applications of Definition A.28, with the result that

Proposition A.29.

If ϕ and ψ are L 2 functions, the equation ∂ψ∕∂x j = ϕ holds in the distribution sense if and only if

for all   Similarly, the equation Δ ψ = ϕ holds in the distribution sense if and only if

for all

Proposition A.30.

If T is a distribution on   and dT∕dx is the zero distribution, then T is a constant, meaning that there is some constant c such that

(A.5)

Suppose, in particular, that if T is given by a locally integrable function f , and the derivative of T is zero. Then Proposition A.30 tells us that for some constant c , we have   for all   Then Proposition A.23 tells us that f ( x ) = c almost everywhere. This means that if the derivative of f is zero, even in the weak (or distributional) sense, then f must be constant.

#### A.3.4 Banach Spaces

In this section, we define Banach spaces and describe some of their elementary properties.

Definition A.31.

A norm on a vector space V over   (   or   ) is a map from V into   , denoted ψ ↦ ∥ψ∥, with the following properties.

1.

For all ψ ∈ V, ∥ψ∥ ≥ 0, with equality if and only if ψ = 0.

2.

For all ψ ∈ V and   we have

3.

For all ϕ, ψ ∈ V, we have

If ||⋅|| is a norm on V , then we can define a distance function d on V by setting d ( ϕ , ψ ) = ∥ ψ − ϕ ∥.

Definition A.32.

A normed vector space is said to be a Banach space if it is complete with respect to the associated distance function. A Banach space is said to be separable if contains a countable dense subset.

One important class of examples of Banach spaces are the L p spaces.

Definition A.33.

An infinite series ,   with values in normed space V, is said to converge if there exists some L ∈ V such that

where

Proposition A.34.

If V is a Banach space, then absolute convergence implies convergence in V. That is, if

then   converges in V.

Definition A.35.

If V 1 and V 2 are normed spaces, a linear map T : V 1 → V 2 is bounded if

(A.6)

If T is bounded, then the supremum in ( A.6 ) is called the operator norm of T, denoted T.

Theorem A.36 (Bounded Linear Transformation Theorem).

Let V 1 be a normed space and V 2 a Banach space. Suppose W is a dense subspace of V 1 and T : W → V 2 is a bounded linear map. Then there exists a unique bounded linear map   such that   Furthermore, the norm of   equals the norm of T.

Definition A.37.

If V is a normed space over   (   or   ), then a bounded linear functional on V is a bounded linear map of V into   where on   we use the norm given by the absolute value. The collection of all bounded linear functionals, with the norm given by ( A.6 ), is called the dual space to V, denoted V ∗ .

Theorem A.38.

If V is a normed vector space, then the following results hold.

1.

The dual space V ∗ is a Banach space.

2.

For all ψ ∈ V, there exists a nonzero ξ ∈ V ∗ such that

In particular, if ξ(ψ) = 0 for all ξ ∈ V ∗ , then ψ = 0.

Theorem A.39 (Closed Graph Theorem).

Suppose that V 1 is a Banach space and V 2 a normed vector space. For any linear map T : V 1 → V 2 , let Graph(T) denote the set of pairs (ψ,Tψ) in V 1 × V 2 such that ψ ∈ V 1 . If the graph of T is a closed subset of V 1 × V 2 , then T is bounded.

Here is a simple example of how the closed graph theorem can be applied. Suppose V 1 and V 2 are Banach spaces and T : V 1 → V 2 is a linear map that is one-to-one, onto, and bounded. Then the inverse map   is automatically bounded. To verify this, we first check that if T is bounded, then the graph of T is closed (easy). Then we observe that the graph of T − 1 is also closed, since it is obtained from the graph of T by the map ( ϕ , ψ ) ↦ ( ψ , ϕ ). Thus, the theorem tells us that T − 1 is bounded.

Theorem A.40 (Principle of Uniform Boundedness).

Suppose   is any family of bounded linear maps from a Banach space V 1 to a normed space V 2 . Suppose that for each ψ ∈ V 1 , there is a constant C ψ such that   for all α. Then there exists a constant C such that ∥ T α ∥ ≤ C for all α.

That is, in contrapositive form, if the family   is unbounded,   must be unbounded on ψ for some ψ ∈ V 1 .

Corollary A.41.

Suppose V is a Banach space and E is a nonempty subset of V. Suppose that for all ξ ∈ V ∗ there exists a constant C ξ such that ξ(ψ) ≤ C ξ for all ψ ∈ E. Then E is a bounded set.

The corollary is obtained by identifying each ψ ∈ V with the linear map   given by evaluation on ψ ; that is, e ψ ( ξ ) = ξ ( ψ ). Note that by Point 2 of Theorem A.38, the norm of e ψ as an element of V ∗ ∗ is equal to the norm of ψ as an element of V .

### A.4 Hilbert Spaces and Operators on Them

#### A.4.1 Inner Product Spaces and Hilbert Spaces

We now introduce a generalization to arbitrary vector spaces over   or   of the usual inner product (or dot product) on

Definition A.42.

An inner product on a vector space over   (   or   ) is a map   with the following properties.

1.

For all ϕ, ψ ∈ V, we have

2.

For all   is real and non-negative, and   only if ϕ = 0.

3.

For all ϕ, ψ ∈ V and   we have   and ϕ, cψ = cϕ, ψ.

4.

For all ϕ, ψ, χ ∈ V, we have ϕ + ψ, χ = ϕ, χ + ψ, χ and

Note that we are following the physics convention of taking the complex conjugate in Point 3 of the definition on the first factor in the inner product.

Proposition A.43.

If V is an inner product space, then for all ϕ, ψ ∈ V, we have the Cauchy–Schwarz inequality :

Furthermore, if   is defined by

(A.7)

then ∥⋅∥ is a norm on V.

Definition A.44.

A Hilbert space is a vector space H over   or   equipped with an inner product 〈⋅, ⋅〉, such that H is complete in the norm given by ( A.7 ).

That is to say, a Hilbert space is a Banach space in which the norm comes from an inner product. In Appendix A.4 only, we allow H to denote an arbitrary Hilbert space over   or   (In the main body of the text, H denotes a separable complex Hilbert space.)

Definition A.45.

Suppose H j is a sequence of separable Hilbert spaces. Then the Hilbert space direct sum , denoted

is the space of sequences   such that ψ n ∈ H n and such that

(A.8)

The finite direct sum of the H j 's is the set of   such that ψ j = 0 for all but finitely many values of j.

We define an inner product on the direct sum by setting

(A.9)

for all ϕ , ψ ∈ H . This inner product is well defined and H is complete with respect to this inner product, and hence a Hilbert space.

One important example of a Hilbert space is L 2 ( X , μ ), where ( X , μ ) is a measure space.

Definition A.46.

If (X, μ) is a measure space, define an inner product on L 2 (X, μ) by the formula

(A.10)

A standard result in measure theory states that the integral on the right-hand side of ( A.10 ) is absolutely convergent for all ϕ and ψ in L 2 ( X , μ ). It is then easy to verify that 〈⋅, ⋅〉is indeed an inner product on L 2 ( X , μ ). Another standard result states that L 2 ( X , μ ) is complete with respect to the norm associated with the inner product in ( A.10 ); thus, L 2 ( X , μ ) is a Hilbert space.

#### A.4.2 Orthogonality

One reason that Hilbert spaces are nicer to work with than general Banach spaces is that we have the concept of orthogonality.

Definition A.47.

Two elements ϕ and ψ of an inner product space are orthogonal if 〈ϕ, ψ〉 = 0.

Definition A.48.

If V is any subspace of H , define a subspace V ⊥ of H by

Then V ⊥ is called the orthogonal space of V.

Proposition A.49.

1.

If V is a closed subspace of H , every ψ ∈ H can be decomposed uniquely as   with ψ 1 ∈ V and

2.

If V is any subspace of H , then   where   is the closure of V. In particular, if V is closed, then

If V is closed, we call V ⊥ the orthogonal complement of V .

Definition A.50.

A set   of elements of H , where j ranges over an arbitrary index set, is said to be orthonormal if

An orthonormal set   is an orthonormal basis for H if the space of finite linear combinations of the e j 's is dense in H .

If H = L 2 ([ − L , L ]), for some positive number L , then the functions,

(A.11)

form an orthonormal basis for H .

Proposition A.51.

Suppose   is an orthonormal basis for H . Then every ψ can be expressed uniquely as a convergent sum

(A.12)

where the coefficients are given by a j = e j , ψ. If ψ is as in ( A.12 ), then

Finally, if a j is any sequence such that   there exists a unique ψ ∈ H such that 〈 e j , ψ 〉 = a j for all j.

In the case that the orthonormal basis is the one in ( A.11 ), the resulting series ( A.12 ) is called the Fourier series of ψ .

#### A.4.3 The Riesz Theorem and Adjoints

We let   denote the space of bounded linear maps of H to H . It is not hard to show that   forms a Banach space under the operator norm.

Theorem A.52 (Riesz Theorem).

If   is a bounded linear functional, then there exists a unique χ ∈ H such that

for all ψ ∈ H . Furthermore, the operator norm of ξ as a linear functional is equal to the norm of χ as an element of H .

We now turn to the concept of the adjoint of a bounded operator, along with the related concept of quadratic forms on H .

Proposition A.53.

For any   there exists a unique linear operator A ∗ : H → H , called the adjoint of A, such that

for all ϕ, ψ ∈ H . For all   and   we have

The operator A ∗ is bounded and

Since A is a bounded operator, the map ψ ↦ ϕ , A ψ is a bounded linear functional for each fixed ϕ ∈ H . The Riesz theorem then tells us that there is a unique χ ∈ H such that 〈 ϕ , A ψ 〉 = 〈 χ , ψ 〉. The operator A ∗ is defined by setting A ∗ ϕ = χ . It is not hard to check that this definition makes A ∗ into a bounded linear operator.

Definition A.54.

An operator   is said to be self-adjoint if A ∗ = A and skew-self-adjoint if A ∗ = −A.

Definition A.55.

An operator U on H is unitary if U is surjective and preserves inner products, that is , 〈 Uϕ, Uψ 〉 = 〈 ϕ, ψ 〉 for all ϕ, ψ ∈ H .

If U is unitary, then U preserves norms (   for all ψ ∈ H ); therefore, U is bounded with U = 1. By the polarization identity (Proposition A.59), if U preserves norms, then it also preserves inner products.

Proposition A.56.

A bounded operator U is unitary if and only if   that is, if and only if

Proposition A.57.

For any closed subspace V ⊂ H , there is a unique bounded operator P such that P = I on V and P = 0 on the orthogonal complement V ⊥ . This operator is called the orthogonal projection onto V and it satisfies P 2 = P and P ∗ = P.

Conversely, if P is any bounded operator on H satisfying P 2 = P and P ∗ = P, then P is the orthogonal projection onto a closed subspace V, where V = range (P).

#### A.4.4 Quadratic Forms

In this section, we develop the theory of quadratic forms on Hilbert spaces. Since this is customarily done only for the inner product itself, we include the proofs of the results.

Definition A.58.

A sesquilinear form on H is a map   that is conjugate linear in the first factor and linear in the second factor. A sesquilinear form is bounded if there exists a constant C such that

for all ϕ, ψ ∈ H .

Proposition A.59.

If L is a sesquilinear form on H , L can be recovered from its values on the diagonal (i.e., the value of L(ψ, ψ) for various ψ's) as follows:

(A.13)

This formula is known as the polarization identity .

Note that we do not assume any relationship between L ( ϕ , ψ ) and L ( ψ , ϕ ).

Proof.

Direct calculation.

Definition A.60.

A quadratic form on a Hilbert space H is a map   with the following properties: (1) Q(λψ) = λ 2 Q(ψ) for all ψ ∈ H and   and (2) the map   defined by

is a sesquilinear form. A quadratic form Q is bounded if there exists a constant C such that

for all ϕ ∈ H . The smallest such constant C is the norm of Q.

Proposition A.61.

If Q is a quadratic form on H and L is the associated sesquilinear form, we have the following results.

1.

For all ψ ∈ H , we have Q(ψ) = L(ψ, ψ).

2.

If Q is a bounded, then L is bounded.

3.

If Q(ψ) belongs to   for all ψ ∈ H , then L is conjugate symmetric, that is ,

for all ϕ, ψ ∈ H .

Proof.

Proof. Point 1 of the proposition is verified by taking ϕ = ψ in the expression for L ( ϕ , ψ ) and then using the relation   For Point 2, suppose   for all ψ ∈ H . If   then ϕ \+ ψ and ϕ \+ i ψ have norm at most 2, and so

Now, for any ϕ and ψ in H , we can find unit vectors   and   such that   and   Then since L is assumed to be sesquilinear, we have

showing that L is bounded.

For Point 3, assume that Q ( ψ ) is real for all ψ ∈ H and define a map   by

Then M is real-bilinear (because it is the real part of L ) and symmetric (because of the expression for M in terms of Q ). Furthermore, M ( i ϕ , i ψ ) = M ( ϕ , ψ ). These properties of M show that M ( ϕ , i ψ ) = − M ( ψ , i ϕ ), and so

which is what we wanted to prove.

Example A.62.

If A is a bounded operator on H , one can construct a bounded quadratic form Q A on H by setting

The associated sesquilinear form L A is then given by

Proposition A.63.

If Q is a bounded quadratic form on H , there is a unique   such that Q(ψ) = 〈ψ,Aψ〉 for all ψ ∈ H . If Q(ψ) belongs to   for all ψ ∈ H , then the operator A is self-adjoint.

Proof.

Since Q is bounded, L is also bounded, meaning that there exists a constant C such that   for all   Thus, for any ϕ ∈ H , the linear functional ψ ↦ L ( ϕ , ψ ) is bounded, with norm at most C ϕ . By the Riesz theorem, then, there exists a unique χ ∈ H , with   such that   We now define a map   by defining   Direct calculation shows that B is linear, and the inequality   shows that B is bounded. Setting A = B ∗ establishes the existence of the desired operator. Uniqueness of A follows from the observation that if 〈 ϕ , A ψ 〉 = 0 for all ϕ , ψ ∈ H , then A is the zero operator.

If Q ( ψ ) is real for all ψ ∈ H , then by Point 3 of Proposition A.61, L is conjugate symmetric. Thus,

for all ϕ , ψ ∈ H , showing that A is self-adjoint.

#### A.4.5 Tensor Products of Hilbert Spaces

Recall from Appendix A.1 the concept of the tensor product of two vector spaces.

Proposition A.64.

Suppose V 1 and V 2 are inner product spaces, with inner products 〈⋅, ⋅〉 1 and 〈⋅, ⋅〉 2 . Then there exists a unique inner product 〈⋅, ⋅〉 on V 1 ⊗ V 2 such that

for all   and

If H 1 and H 2 are Hilbert spaces, then we can equip the tensor product H 1 ⊗ H 2 with the inner product in Proposition A.64. If H 1 and H 2 are both infinite dimensional, however, H 1 ⊗ H 2 will not be complete with respect to this inner product. Nevertheless, we can complete H 1 ⊗ H 2 with respect to this inner product, thus obtaining a new Hilbert space.

Definition A.65.

If H 1 and H 2 are Hilbert spaces, then the Hilbert tensor product of H 1 and H 2 , denoted   is the Hilbert space obtained by completing H 1 ⊗ H 2 with respect to the inner product in Proposition A.64.

Proposition A.66.

If H 1 and H 2 are Hilbert spaces with orthonormal bases   and   respectively, then   is an orthonormal basis for the Hilbert space

Proposition A.67.

If A is a bounded operator on H 1 and B is a bounded operator on H 2 , then there exists a unique bounded operator on   denoted A ⊗ B, such that

for all ϕ ∈ H 1 and ψ ∈ H 2 .

To see that   is bounded, first write A ⊗ B as ( A ⊗ I )( I ⊗ B ). Then, given any orthonormal basis   for H 2 , we can decompose   as the Hilbert space direct sum of subspaces of the form H 1 ⊗ f j . The operator A ⊗ I acts on this decomposition as a block-diagonal operator with A in each diagonal block. From this, it is easy to verify that A ⊗ I = A . A similar argument shows that   , and so

Meanwhile, by taking a sequence of unit vector ϕ n ∈ H 1 and ψ n ∈ H 2 with   and   we see that the reverse inequality holds, and thus that

References

[1]

V. Bargmann, On unitary ray representations of continuous groups. Ann. Math. 59 (2), 1–46 (1954)

[2]

V. Bargmann, On a Hilbert space of analytic functions and an associated integral transform Part I. Comm. Pure Appl. Math. 14 , 187–214 (1961)

[3]

S.J. Bernau, The spectral theorem for unbounded normal operators. Pacific J. Math. 19 , 391–406 (1966)

[4]

R.J. Blattner, Quantization and representation theory. In Harmonic Analysis on Homogeneous Spaces (Proceedings of Symposia in Pure Mathematics, vol. XXVI, Williams College, Williamstown, MA, 1972). (American Mathematical Society, Providence, RI, 1973), pp. 147–165

[5]

P.A.M. Dirac, A new notation for quantum mechanics. Math. Proc. Cambridge Philosoph. Soc. 35 , 416–418 (1939)

[6]

P.A.M. Dirac, The Principles of Quantum Mechanics , 4th edn. (Oxford University Press, Oxford, 1982)

[7]

S. De Bièvre, J.-C. Houard, M. Irac-Astaud, Wave packets localized on closed classical trajectories. In Differential Equations with Applications to Mathematical Physics . Mathematics in Science and Engineering, vol. 192 (Academic, Boston, 1993), pp. 25–32

[8]

S. Dong, Wave Equations in Higher Dimensions (Springer, New York, 2011)

[9]

V. Fock, Verallgemeinerung und Lösung der Diracschen statistischen Gleichung. Zeit. Phys. 49 , 339–350 (1928)

[10]

G.B. Folland, A Course in Abstract Harmonic Analysis (CRC Press, Boca Raton, FL, 1995)

[11]

G.B. Folland, Harmonic Analysis in Phase Space . Annals of Mathematics Studies, vol. 122 (Princeton University Press, Princeton, 1989)

[12]

G.B. Folland, Real Analysis: Modern Techniques and Their Applications , 2nd edn. (Wiley, New York, 1999)

[13]

G.B. Folland, Quantum Field Theory: A Tourist Guide for Mathematicians . Mathematical Surveys and Monographs, vol. 149 (American Mathematical Society, Providence, RI, 2008)

[14]

J. Glimm, A. Jaffe, Quantum Physics: A Functional Integral Point of View , 2nd edn. (Springer, New York, 1987)

[15]

M.J. Gotay, On the Groenewold-Van Hove problem for   . J. Math. Phys. 40 , 2107–2116 (1999)

[16]

L. Gross, Abstract Wiener Spaces. In Proceedings of Fifth Berkeley Symposium on Mathematical Statistics and Probability (Berkeley, CA, 1965/1966), vol. II: Contributions to Probability Theory, Part 1 (University of California Press, Berkeley, CA, 1967), pp. 31–42

[17]

V. Guillemin, S. Sternberg, Variations on a Theme by Kepler . Colloquium Publications, vol. 42 (American Mathematical Society, Providence, RI, 1990)

[18]

A. Gut, Probability: A Graduate Course (Springer, New York, 2005)

[19]

M. Gutzwiller, Chaos in Classical and Quantum Mechanics (Springer, Berlin, 1990)

[20]

B.C. Hall, Geometric quantization and the generalized Segal–Bargmann transform for Lie groups of compact type. Comm. Math. Phys. 226 , 233–268 (2002)

[21]

B.C. Hall, Lie Groups, Lie Algebras, and Representations: An Elementary Introduction . Graduate Texts in Mathematics, vol. 222 (Springer, New York, 2003)

[22]

K. Hannabuss, An Introduction to Quantum Theory . Oxford Graduate Texts in Mathematics (Oxford University Press, Oxford, 1997)

[23]

G. Hagedorn, S. Robinson, Bohr–Sommerfeld quantization rules in the semiclassical limit. J. Phys. A 31 , 10113–10130 (1998)

[24]

K. Hoffman, R. Kunze, Linear Algebra , 2nd edn. (Prentice-Hall, Englewood Cliffs, NJ, 1971)

[25]

N. Jacobson, Lie Algebras (Dover Publications, New York, 1979)

[26]

M.V. Karasëv, Connections on Lagrangian submanifolds and some problems in quasiclassical approximation. I. (Russian); translation in J. Soviet Math. 59 , 1053–1062 (1992)

[27]

T. Kato, Perturbation Theory for Linear Operators (Reprint of the 1980 edition). (Springer, Berlin, 1995)

[28]

W.G. Kelley, A.C. Petersen, The Theory of Differential Equations: Classical and Qualitative (Universitext) , 2nd edn. (Springer, New York, 2010)

[29]

J. Lee, Introduction to Smooth Manifolds , 2nd edn. (Springer, London, 2006)

[30]

P. Miller, Applied Asymptotic Analysis (American Mathematical Society, Providence, RI, 2006)

[31]

T. Paul, A. Uribe, A construction of quasi-modes using coherent states. Ann. Inst. H. Poincaré Phys. Théor 59 , 357–381 (1993)

[32]

W. Rudin, Real and Complex Analysis , 3rd edn. (McGraw-Hill, New York, 1987)

[33]

W. Rudin, Functional Analysis , 2nd edn. International Series in Pure and Applied Mathematics (McGraw-Hill, New York, 1991)

[34]

M. Reed, B. Simon, Methods of Modern Mathematical Physics . Volume I: Functional Analysis, 2nd edn. (Academic, San Diego, 1980). Volume II: Fourier Analysis, Self-Adjointness (Academic, New York, 1975). Volume III: Scattering Theory (Academic, New York, 1979). Volume IV: Analysis of Operators (Academic, New York, 1978)

[35]

K. Schmüdgen, Unbounded Self-Adjoint Operators on Hilbert Space . Graduate Texts in Mathematics, vol. 265 (Springer, Dordrecht, 2012)

[36]

I.E. Segal, Mathematical problems of relativistic physics. In Proceedings of the Summer Seminar, Boulder, Colorado, 1960 , ed. by M. Kac (American Mathematical Society, Providence, RI, 1963)

[37]

B. Simon, Functional Integration and Quantum Physics , 2nd edn. (American Mathematical Society, Providence, RI, 2005)

[38]

R.F. Streater, A.S. Wightman, PCT, Spin and Statistics, and All That (Corrected third printing of the 1978 edition). Princeton Landmarks in Physics (Princeton University Press, Princeton, NJ, 2000)

[39]

L.A. Takhtajan, Quantum Mechanics for Mathematicians . Graduate Studies in Mathematics, vol. 95 (American Mathematical Society, Providence, RI, 2008)

[40]

W. Thirring, A Course in Mathematical Physics I: Classical Dynamical Systems (Translated by Evans M. Harrell). (Springer, New York, 1978)

[41]

J. von Neumann, Die Eindeutigkeit der Schrödingerschen operatoren. Math. Ann. 105 , 570–578 (1931)

[42]

A. Voros, Wentzel–Kramers–Brillouin method in the Bargmann representation. Phys. Rev. A 40 (3), 6814–6825 (1989)

[43]

N.R. Wallach, Real Reductive Groups I (Academic, San Diego, 1988)

[44]

R.E. Williamson, R.H. Crowell, H.F. Trotter, Calculus of Vector Functions , 3rd edn. (Prentice-Hall, Englewood Cliffs, NJ, 1968)

[45]

N. Woodhouse, Geometric Quantization , 2nd edn. (Oxford University Press, Oxford, 1992)

[46]

K. Yosida, Functional Analysis , 4th edn. (Springer, New York, 1980)

Index

Action functional

Adjoint

of a bounded operator

of an unbounded operator

Airy function

Almost complex structure

Angular momentum

addition of

function

operator

vector

Axioms of quantum mechanics

Baker–Campbell–Hausdorff

formula

Banach space

Bargmann space, see

Segal–Bargmann space

Bergman space

Blackbody radiation

BLT theorem

Bohr, Niels

Bohr–de Broglie model of hydrogen

Bohr–Sommerfeld condition

Born, Max

Bose–Einstein

condensate

statistics

Boson

Bounded operator

Bounded-below operator

Bra-ket notation

Brownian motion

Canonical

1-form

2-form

bundle

commutation relations

Canonical transformation, see Symplectomorphism

Casimir operator

Cauchy–Schwarz inequality

Cayley transform

Center of mass

Classically forbidden region

Closed graph theorem

Closed operator

Closure of an operator

Coherent

state

superposition

Collapse of the wave function

Commutator

Compact operator

Complex structure

Connection 1-form

Connection formula

Conservation

of angular momentum

of energy

of momentum

of the Runge–Lenz vector

Conserved quantity

Constant of motion, see

Conserved quantity

Continuous spectrum, see

Spectrum, continuous

Convolution

Copenhagen interpretation

Cotangent bundle

Covariant derivative

Creation and annihilation

operators, see Raising

operator, lowering

operator

Cross product

Curvature

Cyclic vector

de Broglie hypothesis

de Broglie, Louis

Density matrix

Dirac notation

Direct integral

Discrete spectrum, see Spectrum, discrete

Dispersion relation

Distribution

Domain of an operator

Double-slit experiment

Eigenvector

Einstein's summation

convention, see

Summation convention

Einstein, Albert

Electron diffraction

Elliptical trajectory

Energy conservation, see

Conservation of energy

Entropy, see von Neumann

entropy

εjkl , see Totally antisymmetric

symbol

Equipartition theorem

Essential spectrum

Essentially self-adjoint operator

Excited state

Expectation value

Exponential

of a matrix

of an operator

Exponentiated commutation

relations

Extension of an operator

Fermi–Dirac statistics

Fermion

Feynman path integral formula

Feynman–Kac formula

Flow

Fourier transform

Functional calculus

for a bounded operator

for a normal operator

for an unbounded operator

Fundamental solution

Gauge transformation

Gaussian measure

Generalized eigenvector

Generalized function, see

Distribution

Geometric quantization

GL( n ;ℂ)

Groenewold's theorem

Ground state

Group velocity

Half-forms

Hamilton's equations

Hamiltonian

flow

operator

system

vector field

Harmonic oscillator

Heisenberg picture

Heisenberg uncertainty principle

See see Uncertainty

principle

Heisenberg, Werner

Hermite polynomials

Hermitian

conjugate

line bundle

operator

Hilbert space

direct sum

Hilbert–Schmidt operator

Holonomy

Homomorphism

of Lie algebras

of matrix Lie groups

Hydrogen atom

Identical particles

Imaginary time

Incoherent superposition

Infinitesimal generator

Inner product

Integral operator

Interference

Interpretation of quantum

mechanics

Intertwining map

Invariant subspace

Inverse square law

Irreducible representation

Jacobi identity

Kähler

polarization

potential

Kato–Rellich theorem

Kepler problem

Kepler's laws

first

second

third

Ket

Kinetic energy operator

Kodaira embedding theorem

Lagrangian

submanifold

subspace

Laplacian

Lie

algebra

derivative

group

product formula

Line bundle

Liouville form

Liouville's theorem

Lowering operator

Maslov correction

Matrix Lie group

Measurement

Metaplectic correction, see

Half-forms

Minimum uncertainty state

Mixed state

Moments

Momentum

operator

wave function

Monotone class lemma

Morphism, see Intertwining map

Moyal product

Multiplication operator

Multiplicity function

Newton's laws

second

third

Newton, Isaac

"No go" theorem

Nobel Prize

Non-negative operator

Norm

Hilbert–Schmidt

operator

Normal operator

Observable

Old quantum theory

O( n )

One-parameter

subgroup

unitary group

Operator norm, see Norm

operator

Orthogonal

complement

projection

Orthonormal basis

continuous

Pairing map

Partial connection

Particle in a box

Particle in a square well

Partition function

Path integral

Pauli exclusion princple

Phase velocity

Photoelectric effect

Photon

Plancherel theorem

Planck's constant

Planck, Max

Poisson bracket

Polarization

Polarization identity

Polarized section

Position operator

Potential energy

function

operator

Prequantization

Prequantized operator

Prequantum Hilbert space

Principle of uniform

boundedness

Product of unbounded

operators

Projection-valued measure

Pseudodifferential operator

quantization

Pure state

Quadratic form

Quantizable

function

manifold

Quantization

of observables

Quantum field theory

Radon–Nikodym theorem

Raising operator

Reduced mass

Relatively bounded operator

Relatively compact

perturbation

Representation

finite dimensional

infinite dimensional

projective unitary

unitary

Reproducing kernel

Resolvent

operator

set

Riesz representation theorem

Riesz theorem

Rodrigues formula

Runge–Lenz vector

Rydberg constant

Rydberg, Johannes

Schrödinger equation

free

time dependent

time independent

Schrödinger operator

Schrödinger, Erwin

Schur's lemma

Schwartz space

Section

of a direct integral

of a line bundle

Segal–Bargmann

space

transform

Self-adjoint operator

bounded

unbounded

Sesquilinear form

SO( n )

SO(3)

so(3)

so(4)

so( n )

Spectral mapping theorem

Spectral radius

Spectral subspace

Spectral theorem

for a bounded operator

for a normal operator

for an unbounded operator

Spectrum

continuous

discrete

of a bounded operator

of a self-adjoint operator

of an unbounded operator

Spherical harmonics

Spin

Spin–statistics theorem

Spread of wave packet, see wave

packet, spread of

Star product

State of a system

Stationary state

Statistical mechanics

Statistics

Stoke's theorem

Stone's theorem

Stone–von Neumann theorem

Stone–Weierstrass theorem

Strong continuity

Subsystem

Sum of self-adjoint operators

Summation convention

SU( n )

su(2)

su( n )

Symmetric operator

Symplectic

manifold

potential

Symplectomorphism

Tensor product

of Hilbert spaces

of line bundles

of operators

of representations

of vector spaces

Totally antisymmetric symbol

Trace of an operator

Trace-class operator

Trajectory

Trotter product formula

Tunneling

Turning point

Two-slit experiment, see

Double-slit experiment

U( n )

Unbounded operator

Uncertainty

of an operator

principle

Unitary equivalence

Unitary operator

Universal covering group

van Hove's theorem

Vector

operator

Vector field

Vector product, see Cross

product

Vertical polarization

von Neumann entropy

Wave packet

spread of

Wave–particle duality

Weyl quantization

Wick-ordered quantization

Wiener measure

Wigner–Eckart theorem

WKB approximation

# Source Metadata

- Domain: mathematics
- Context ID: b855a979d7ae35ca6e93b1c43a01e5de
- Document ID: 245caccda9f80c01977ce16cbf134df7
- Approx. Length: 617463 characters